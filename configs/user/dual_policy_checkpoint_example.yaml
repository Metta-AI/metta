# Dual-Policy Training Configuration
# This config enables training where some agents use the training policy and others use an NPC policy

# Inherit from a base user config
defaults:
  - user: bullm  # or another base user config
  - _self_

# Dual-policy configuration
trainer:
  dual_policy:
    enabled: true
    training_agents_pct: 0.5  # 50% of agents use training policy, 50% use NPC
    checkpoint_npc:
      uri: "wandb://metta-research/dual_policy_training/model/bullm_dual_policy_against_roomba_v9:v2"
      type: "specific"  # Use specific version
      range: 1
      metric: "epoch"

# Training parameters
trainer:
  total_timesteps: 10000000000  # 10B timesteps
  num_workers: 4
  batch_size: 524288
  minibatch_size: 16384

  # Environment configuration
  curriculum: "/env/mettagrid/curriculum/arena/learning_progress"

  # Checkpoint configuration
  checkpoint:
    checkpoint_interval: 60
    wandb_checkpoint_interval: 300

  # Simulation/evaluation configuration
  simulation:
    evaluate_interval: 300  # Evaluate every 5 minutes
    replay_dir: "replays"

  # PPO parameters
  ppo:
    clip_coef: 0.1
    ent_coef: 0.0021
    gae_lambda: 0.916
    gamma: 0.977
    max_grad_norm: 0.5
    vf_clip_coef: 0.1
    vf_coef: 0.44
    norm_adv: true
    clip_vloss: true

  # Optimizer parameters
  optimizer:
    type: "adam"
    learning_rate: 0.0004573146765703167
    beta1: 0.9
    beta2: 0.999
    eps: 1e-12
    weight_decay: 0

# WandB configuration
wandb:
  enabled: true
  project: "dual_policy_training"
  entity: "metta-research"
  tags: ["dual_policy", "checkpoint_npc"]
