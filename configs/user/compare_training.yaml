defaults:
  - /agent/fast
  - /trainer/trainer
  - /wandb/comparision_trainer
  - _self_

seed: 1

# Essential keys from common config (self-contained to avoid include issues)
device: cuda
vectorization: multiprocessing
data_dir: ${oc.env:DATA_DIR,./train_dir}
run_dir: ${data_dir}/${run}
policy_uri: file://${run_dir}/checkpoints
torch_deterministic: true
dist_cfg_path: null
stats_server_uri: https://api.observatory.softmax-research.net

train_job:
  map_preview_uri: s3://softmax-public/training_runs/${run}/map_preview.json.z
  evals:
    name: arena_evaluation
    simulations:
      arena/basic:
        env: /env/mettagrid/arena/basic
        num_episodes: 10
        max_time_s: 30
        env_overrides:
          _pre_built_env_config:
            sampling: 0
            num_agents: 4
            width: 32
            height: 32
      arena/combat:
        env: /env/mettagrid/arena/combat
        num_episodes: 10
        max_time_s: 30
        env_overrides:
          _pre_built_env_config:
            sampling: 0
            num_agents: 4
            width: 32
            height: 32
      arena/advanced:
        env: /env/mettagrid/arena/advanced
        num_episodes: 10
        max_time_s: 30
        env_overrides:
          _pre_built_env_config:
            sampling: 0
            num_agents: 4
            width: 32
            height: 32
      arena/tag:
        env: /env/mettagrid/arena/tag
        num_episodes: 10
        max_time_s: 30
        env_overrides:
          _pre_built_env_config:
            sampling: 0
            num_agents: 4
            width: 32
            height: 32

trainer:
  # Core training parameters matching bullm_run.py
  curriculum: /env/mettagrid/curriculum/arena/learning_progress
  total_timesteps: 200_000_000  # Increased to 200M timesteps for longer comparison
  
  # Optimizer matching bullm_run.py
  optimizer:
    type: muon
    learning_rate: 0.002  # Reduced learning rate for stability (2.0e-3)
  
  # PPO parameters matching bullm_run.py
  ppo:
    clip_coef: 0.1
    ent_coef: 0.01
    gamma: 0.99
    gae_lambda: 0.95
    max_grad_norm: 0.5  # Add gradient clipping for stability
  
  # Checkpoint and evaluation intervals matching bullm_run.py
  checkpoint:
    checkpoint_interval: 50
    wandb_checkpoint_interval: 0
  
  simulation:
    evaluate_interval: 50  # Arena-specific evaluation interval
  
  # Other parameters matching bullm_run.py
  batch_size: 524288
  minibatch_size: 16384
  bptt_horizon: 64
  update_epochs: 1
  forward_pass_minibatch_target_size: 4096
  async_factor: 2
  grad_mean_variance_interval: 150
  scale_batches_by_world_size: false
  cpu_offload: false
  zero_copy: true

cmd: train 