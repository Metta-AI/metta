# @package __global__

defaults:
  - /sim/navigation@sim_job.simulation_suite
  - _self_

# Basic config variables
run_id: 21
run: ${oc.env:USER}.local.${run_id}
data_dir: ./train_dir
run_dir: ${data_dir}/${run}
policy_uri: wandb://run/navigation_poisson_sparser.r.2
trained_policy_uri: ${run_dir}/checkpoints
eval_db_uri: wandb://artifacts/navigation_db

trainer:
  env: /env/mettagrid/reward_dr
  env_overrides:
    sampling: 0.7
    game:
      num_agents: 36
      max_steps: 1000
  evaluate_interval: 50
  checkpoint_interval: 50

env:
  semi_compact_obs: true
  game:
    max_steps: 2000

analyzer:
  policy_uri: ${..policy_uri}
  view_type: latest
  analysis:
    metrics:
      - metric: episode_reward
  output_path: s3://softmax-public/policydash/dashboard.html
#  output_path: s3://softmax-public/users/jack/policydash/dashboard.html

sim_job:
  simulation_suite:
    num_episodes: 2
    num_envs: 2
s
  num_episodes: 1
  num_envs: 1
  policy_uri: ${..policy_uri}
  selector_type: latest
  eval_db_uri: wandb://artifacts/navigation_db
  max_time_s: 3
  policy_uris:
    - "wandb://run/b.daphne.navigation_varied_obstacle_shapes_pretrained.r.1"
    - "wandb://run/b.daphne.navigation_varied_obstacle_shapes.r.0"
    - "wandb://run/navigation_poisson_sparser.r.2"
    - "wandb://run/navigation_infinite_cooldown_sparser_pretrained.r.0"
    - "wandb://run/navigation_infinite_cooldown_sparser.r.0"
    - "wandb://run/navigation_poisson_sparser_pretrained.r.6"
    - "wandb://run/b.daveey.t.64.dr90.1"

train_job:
  evals:
    num_episodes: 2
    num_envs: 2

wandb:
  checkpoint_interval: 1

sweep_name: jack.test.sweep.devbox2
# sweep_name: ${oc.env:USER}.local.sweep.${run_id}