# @package __global__

#POLICIES TO EVALUATE

#b.daphne.navigation_varied_obstacle_shapes_pretrained.r.1
#b.daphne.navigation_varied_obstacle_shapes.r.0
#navigation_poisson_sparser.r.2
#navigation_infinite_cooldown_sparser_pretrained.r.0
#navigation_infinite_cooldown_sparser.r.0
#navigation_poisson_sparser_pretrained.r.6

defaults:
  - _self_

trainer:
<<<<<<< HEAD
  env: /env/mettagrid/navigation_sequence/training/multienv_seq
  evaluate_interval: 10
=======
  env: /env/mettagrid/walkaround
  evaluate_interval: 2

eval_db_uri: wandb://artifacts/memory_db

# policy: wandb://run/b.daveey.train.maze.sm.dr.warm.0
# baselines: wandb://run/b.daveey.train.maze.sm.11x11.0

# policy_uri: wandb://run/b.daveey.sm.train.er.new.0
# policy_uri: wandb://run/daveey.ar.cards.1
# policy_uri: wandb://run/b.daveey.t.32.instant
#policy_uri: ${trained_policy_uri}
policy_uri: wandb://run/b.georgedeane.terrain_extra_hard
# b.daphne.terrain_varied_cyl_lab_pretrained:v0
# policy_uri: wandb://run/terrain_training_multienv_april18
# policy_uri: wandb://run/b.daphne.terrain_multienv_april18
>>>>>>> 72b692c733a3311d1ae364d7d303c715c1b42ef9

# Infinite_cooldown models:
# navigation_infinite_cooldown_sweep_2g_.r.0 - ok
# navigation_infinite_cooldown_sweep_2g.r.1 - 9 reward after 400 timesteps
# navigation_infinite_cooldown_high_ent_no_initial_heart - ~9, current best
# navigation_poisson_train_sampling5 breaks in infinite_cooldown, works great in poisson with short distance
# navigation_poisson_train_sampling5
# npc_policy_uri: ${trained_policy_uri}

sim:
  num_episodes: 2
  max_time_s: 600

  # policy_uri: ${..policy_uri}
  # npc_policy_uri: ${..npc_policy_uri}
  env: /env/mettagrid/navigation/training/empty_world

run_id: 103
run: ${oc.env:USER}.local.${run_id}
trained_policy_uri: ${run_dir}/checkpoints
