# @package __global__

defaults:
  - override /agent: simple
  - override /eval: navigation
  - override /analyzer: eval_analyzer

trainer:
  env: /env/mettagrid/reward_dr
  evaluate_interval: 200
  env_overrides:
    sampling: 0.7
    game:
      num_agents: 36
      max_steps: 1000
  evaluate_interval: 10


policy_uri: wandb://run/b.daveey.t.64.dr90.1

analyzer:
  policy_uri: ${..policy_uri}
  analysis:
    metrics:
      - metric: episode_reward
    output_path: s3://softmax-public/policydash/dashboard.html
eval:
  policy_uri: ${..policy_uri}
  selector_type: all
  eval_db_uri: wandb://artifacts/navigation_db
  policy_uris:
    - "wandb://run/b.daphne.navigation_varied_obstacle_shapes_pretrained.r.1"
    - "wandb://run/b.daphne.navigation_varied_obstacle_shapes.r.0"
    - "wandb://run/navigation_poisson_sparser.r.2"
    - "wandb://run/navigation_infinite_cooldown_sparser_pretrained.r.0"
    - "wandb://run/navigation_infinite_cooldown_sparser.r.0"
    - "wandb://run/navigation_poisson_sparser_pretrained.r.6"
    - "wandb://run/b.daveey.t.64.dr90.1"


wandb:
  checkpoint_interval: 1

run_id: 17  
run: ${oc.env:USER}.local.${run_id}
trained_policy_uri: ${run_dir}/checkpoints

sweep_params: "sweep/fast"
sweep_name: "${oc.env:USER}.local.sweep.${run_id}"
seed: null
