============================= test session starts ==============================
platform darwin -- Python 3.11.7, pytest-8.3.3, pluggy-1.6.0
benchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /Users/axel/Documents/Softmax/metta
configfile: pyproject.toml
plugins: hydra-core-1.4.0.dev1, anyio-4.9.0, benchmark-5.1.0, cov-6.1.1
collected 29 items

tests/agent/lib/test_lstm.py FFFF........                                [ 41%]
tests/agent/lib/test_metta_module.py ......                              [ 62%]
tests/agent/lib/test_metta_modules.py ....                               [ 75%]
tests/agent/lib/test_modular_network.py .......                          [100%]

=================================== FAILURES ===================================
______________ TestLSTMComparison.test_identical_outputs_no_state ______________

self = <tests.agent.lib.test_lstm.TestLSTMComparison object at 0x1158ea910>
lstm_pair = {'lstm': LSTM(
  (_net): LSTM(10, 20, num_layers=2)
), 'metta_lstm': MettaEncodedLSTM(
  (_net): LSTM(10, 20, num_layers=2)
), 'params': {'batch_size': 4, 'hidden_size': 20, 'input_size': 10, 'num_layers': 2, ...}}

    def test_identical_outputs_no_state(self, lstm_pair):
        """Test that both LSTMs produce identical outputs with no initial state."""
        lstm = lstm_pair["lstm"]
        metta_lstm = lstm_pair["metta_lstm"]
        params = lstm_pair["params"]
        output_key = "_lstm_test_"
    
        # Create identical input tensors
        x = torch.randn(params["batch_size"] * params["seq_length"], params["input_size"])
        hidden = torch.randn(params["batch_size"] * params["seq_length"], params["input_size"])
        state = None
    
        td_orig = TensorDict(
            {
                "x": x,
                "encoded_features": x,
                "hidden": hidden,
                "_B_": torch.tensor(params["batch_size"]),
                "_TT_": torch.tensor(params["seq_length"]),
            },
            batch_size=[],
        )
        td_orig["state"] = state
        result_orig = lstm._forward(td_orig)
    
        td_metta = TensorDict({"encoded_features": x}, batch_size=[])
        md = MettaDict(td_metta, {"global": {"batch_size": params["batch_size"], "tt": params["seq_length"]}})
        md.td[output_key] = {"state": state}
        result_metta = metta_lstm(md)
    
        # Compare outputs
>       torch.testing.assert_close(
            result_orig[output_key], result_metta.td[output_key], msg="Output tensors should be identical"
        )
E       AssertionError: Output tensors should be identical

tests/agent/lib/test_lstm.py:123: AssertionError
---------------------------- Captured stdout setup -----------------------------

Original LSTM parameters:
weight_ih_l0: mean=0.006781, std=0.111667, min=-0.308878, max=0.368985
weight_hh_l0: mean=-0.000478, std=0.111837, min=-0.332292, max=0.310430
bias_ih_l0: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
bias_hh_l0: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
weight_ih_l1: mean=-0.000966, std=0.111834, min=-0.351437, max=0.381767
weight_hh_l1: mean=0.002455, std=0.111811, min=-0.392487, max=0.312265
bias_ih_l1: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
bias_hh_l1: mean=1.000000, std=0.000000, min=1.000000, max=1.000000

MettaEncodedLSTM parameters:
weight_ih_l0: mean=0.006781, std=0.111667, min=-0.308878, max=0.368985
weight_hh_l0: mean=-0.000478, std=0.111837, min=-0.332292, max=0.310430
bias_ih_l0: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
bias_hh_l0: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
weight_ih_l1: mean=-0.000966, std=0.111834, min=-0.351437, max=0.381767
weight_hh_l1: mean=0.002455, std=0.111811, min=-0.392487, max=0.312265
bias_ih_l1: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
bias_hh_l1: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
_____________ TestLSTMComparison.test_identical_outputs_with_state _____________

self = <tests.agent.lib.test_lstm.TestLSTMComparison object at 0x1158eafd0>
lstm_pair = {'lstm': LSTM(
  (_net): LSTM(10, 20, num_layers=2)
), 'metta_lstm': MettaEncodedLSTM(
  (_net): LSTM(10, 20, num_layers=2)
), 'params': {'batch_size': 4, 'hidden_size': 20, 'input_size': 10, 'num_layers': 2, ...}}

    def test_identical_outputs_with_state(self, lstm_pair):
        """Test that both LSTMs produce identical outputs with initial state."""
        lstm = lstm_pair["lstm"]
        metta_lstm = lstm_pair["metta_lstm"]
        params = lstm_pair["params"]
        output_key = "_lstm_test_"
    
        x = torch.randn(params["batch_size"] * params["seq_length"], params["input_size"])
        hidden = torch.randn(params["batch_size"] * params["seq_length"], params["input_size"])
        h_0 = torch.randn(params["num_layers"], params["batch_size"] * params["seq_length"], params["hidden_size"])
        c_0 = torch.randn(params["num_layers"], params["batch_size"] * params["seq_length"], params["hidden_size"])
        state = torch.cat([h_0, c_0], dim=0)
    
        td_orig = TensorDict(
            {
                "x": x,
                "encoded_features": x,
                "hidden": hidden,
                "state": state,
                "_B_": torch.tensor(params["batch_size"]),
                "_TT_": torch.tensor(params["seq_length"]),
            },
            batch_size=[],
        )
>       result_orig = lstm._forward(td_orig)

tests/agent/lib/test_lstm.py:154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
metta/agent/lib/lstm.py:85: in _forward
    hidden, state = self._net(hidden, state)
.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:1120: in forward
    self.check_forward_args(input, hx, batch_sizes)
.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:1003: in check_forward_args
    self.check_hidden_size(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LSTM(10, 20, num_layers=2)
hx = tensor([[[-5.4364e-02,  3.3866e-01, -9.2881e-01, -5.1019e-01,  2.5040e-01,
           8.2842e-01, -1.0950e+00,  8.0615...0, -1.0954e+00,  6.8370e-01, -1.9545e+00,
          -1.1568e+00,  1.5826e+00, -1.0880e+00, -7.4008e-01, -9.2591e-01]]])
expected_hidden_size = (2, 4, 20), msg = 'Expected hidden[0] size {}, got {}'

    def check_hidden_size(
        self,
        hx: Tensor,
        expected_hidden_size: tuple[int, int, int],
        msg: str = "Expected hidden size {}, got {}",
    ) -> None:
        if hx.size() != expected_hidden_size:
>           raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))
E           RuntimeError: Expected hidden[0] size (2, 4, 20), got [2, 12, 20]

.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:347: RuntimeError
---------------------------- Captured stdout setup -----------------------------

Original LSTM parameters:
weight_ih_l0: mean=0.006781, std=0.111667, min=-0.308878, max=0.368985
weight_hh_l0: mean=-0.000478, std=0.111837, min=-0.332292, max=0.310430
bias_ih_l0: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
bias_hh_l0: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
weight_ih_l1: mean=-0.000966, std=0.111834, min=-0.351437, max=0.381767
weight_hh_l1: mean=0.002455, std=0.111811, min=-0.392487, max=0.312265
bias_ih_l1: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
bias_hh_l1: mean=1.000000, std=0.000000, min=1.000000, max=1.000000

MettaEncodedLSTM parameters:
weight_ih_l0: mean=0.006781, std=0.111667, min=-0.308878, max=0.368985
weight_hh_l0: mean=-0.000478, std=0.111837, min=-0.332292, max=0.310430
bias_ih_l0: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
bias_hh_l0: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
weight_ih_l1: mean=-0.000966, std=0.111834, min=-0.351437, max=0.381767
weight_hh_l1: mean=0.002455, std=0.111811, min=-0.392487, max=0.312265
bias_ih_l1: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
bias_hh_l1: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
______________ TestLSTMComparison.test_identical_outputs_sequence ______________

self = <tests.agent.lib.test_lstm.TestLSTMComparison object at 0x1158eb610>
lstm_pair = {'lstm': LSTM(
  (_net): LSTM(10, 20, num_layers=2)
), 'metta_lstm': MettaEncodedLSTM(
  (_net): LSTM(10, 20, num_layers=2)
), 'params': {'batch_size': 4, 'hidden_size': 20, 'input_size': 10, 'num_layers': 2, ...}}

    def test_identical_outputs_sequence(self, lstm_pair):
        """Test that both LSTMs produce identical outputs over a sequence of steps."""
        lstm = lstm_pair["lstm"]
        metta_lstm = lstm_pair["metta_lstm"]
        params = lstm_pair["params"]
        output_key = "_lstm_test_"
    
        state_orig = None
        state_metta = None
    
        for _ in range(3):
            x = torch.randn(params["batch_size"] * params["seq_length"], params["input_size"])
            hidden = torch.randn(params["batch_size"] * params["seq_length"], params["input_size"])
    
            td_orig = TensorDict(
                {
                    "x": x,
                    "encoded_features": x,
                    "hidden": hidden,
                    "_B_": torch.tensor(params["batch_size"]),
                    "_TT_": torch.tensor(params["seq_length"]),
                },
                batch_size=[],
            )
            td_orig["state"] = state_orig
            result_orig = lstm._forward(td_orig)
            state_orig = result_orig["state"]
    
            td_metta = TensorDict({"encoded_features": x}, batch_size=[])
            md = MettaDict(td_metta, {"global": {"batch_size": params["batch_size"], "tt": params["seq_length"]}})
            if state_metta is not None:
                md.td[output_key] = {"state": state_metta}
            result_metta = metta_lstm(md)
            state_metta = result_metta.data[output_key]["state"]
    
>           torch.testing.assert_close(
                result_orig[output_key], result_metta.td[output_key], msg="Output tensors should be identical"
            )
E           AssertionError: Output tensors should be identical

tests/agent/lib/test_lstm.py:203: AssertionError
---------------------------- Captured stdout setup -----------------------------

Original LSTM parameters:
weight_ih_l0: mean=0.006781, std=0.111667, min=-0.308878, max=0.368985
weight_hh_l0: mean=-0.000478, std=0.111837, min=-0.332292, max=0.310430
bias_ih_l0: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
bias_hh_l0: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
weight_ih_l1: mean=-0.000966, std=0.111834, min=-0.351437, max=0.381767
weight_hh_l1: mean=0.002455, std=0.111811, min=-0.392487, max=0.312265
bias_ih_l1: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
bias_hh_l1: mean=1.000000, std=0.000000, min=1.000000, max=1.000000

MettaEncodedLSTM parameters:
weight_ih_l0: mean=0.006781, std=0.111667, min=-0.308878, max=0.368985
weight_hh_l0: mean=-0.000478, std=0.111837, min=-0.332292, max=0.310430
bias_ih_l0: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
bias_hh_l0: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
weight_ih_l1: mean=-0.000966, std=0.111834, min=-0.351437, max=0.381767
weight_hh_l1: mean=0.002455, std=0.111811, min=-0.392487, max=0.312265
bias_ih_l1: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
bias_hh_l1: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
__________ TestLSTMComparison.test_identical_outputs_batch_variations __________

self = <tests.agent.lib.test_lstm.TestLSTMComparison object at 0x1158ebcd0>
lstm_pair = {'lstm': LSTM(
  (_net): LSTM(10, 20, num_layers=2)
), 'metta_lstm': MettaEncodedLSTM(
  (_net): LSTM(10, 20, num_layers=2)
), 'params': {'batch_size': 4, 'hidden_size': 20, 'input_size': 10, 'num_layers': 2, ...}}

    def test_identical_outputs_batch_variations(self, lstm_pair):
        """Test that both LSTMs handle different batch sizes identically."""
        lstm = lstm_pair["lstm"]
        metta_lstm = lstm_pair["metta_lstm"]
        params = lstm_pair["params"]
        output_key = "_lstm_test_"
    
        batch_sizes = [1, 2, 4, 8]
        for batch_size in batch_sizes:
            x = torch.randn(batch_size * params["seq_length"], params["input_size"])
            hidden = torch.randn(batch_size * params["seq_length"], params["input_size"])
            state = None
    
            td_orig = TensorDict(
                {
                    "x": x,
                    "encoded_features": x,
                    "hidden": hidden,
                    "_B_": torch.tensor(batch_size),
                    "_TT_": torch.tensor(params["seq_length"]),
                },
                batch_size=[],
            )
            td_orig["state"] = state
            result_orig = lstm._forward(td_orig)
    
            td_metta = TensorDict({"encoded_features": x}, batch_size=[])
            md = MettaDict(td_metta, {"global": {"batch_size": batch_size, "tt": params["seq_length"]}})
            result_metta = metta_lstm(md)
    
>           torch.testing.assert_close(
                result_orig[output_key],
                result_metta.td[output_key],
                msg=f"Output tensors should be identical for batch size {batch_size}",
            )
E           AssertionError: Output tensors should be identical for batch size 1

tests/agent/lib/test_lstm.py:240: AssertionError
---------------------------- Captured stdout setup -----------------------------

Original LSTM parameters:
weight_ih_l0: mean=0.006781, std=0.111667, min=-0.308878, max=0.368985
weight_hh_l0: mean=-0.000478, std=0.111837, min=-0.332292, max=0.310430
bias_ih_l0: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
bias_hh_l0: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
weight_ih_l1: mean=-0.000966, std=0.111834, min=-0.351437, max=0.381767
weight_hh_l1: mean=0.002455, std=0.111811, min=-0.392487, max=0.312265
bias_ih_l1: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
bias_hh_l1: mean=1.000000, std=0.000000, min=1.000000, max=1.000000

MettaEncodedLSTM parameters:
weight_ih_l0: mean=0.006781, std=0.111667, min=-0.308878, max=0.368985
weight_hh_l0: mean=-0.000478, std=0.111837, min=-0.332292, max=0.310430
bias_ih_l0: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
bias_hh_l0: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
weight_ih_l1: mean=-0.000966, std=0.111834, min=-0.351437, max=0.381767
weight_hh_l1: mean=0.002455, std=0.111811, min=-0.392487, max=0.312265
bias_ih_l1: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
bias_hh_l1: mean=1.000000, std=0.000000, min=1.000000, max=1.000000
=========================== short test summary info ============================
FAILED tests/agent/lib/test_lstm.py::TestLSTMComparison::test_identical_outputs_no_state
FAILED tests/agent/lib/test_lstm.py::TestLSTMComparison::test_identical_outputs_with_state
FAILED tests/agent/lib/test_lstm.py::TestLSTMComparison::test_identical_outputs_sequence
FAILED tests/agent/lib/test_lstm.py::TestLSTMComparison::test_identical_outputs_batch_variations
========================= 4 failed, 25 passed in 1.33s =========================
