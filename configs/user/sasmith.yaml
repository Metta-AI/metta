# @package __global__

defaults:
  - override /agent: simple
  - override /eval: simple
  - override /analyzer: eval_analyzer

trainer:
  env: /env/mettagrid/bases
  evaluate_interval: 200
  env_overrides:
    # sampling: 0.7
    game:
      num_agents: 36
      max_steps: 1000
  evaluate: false

policy_uri: wandb://run/sasmith.converter.queues.5
# npc_policy_uri: ${trained_policy_uri}
eval_db_uri: wandb://artifacts/testing

analyzer:
  eval_stats_uri: ${run_dir}/eval_stats
  policy_uri: ${..policy_uri}
  analysis:
    metrics:
      - metric: episode_reward

eval:
  num_envs: 10
  num_episodes: 16
  max_time_s: 600
  env: /env/mettagrid/cognitive_evals/navigating_obstacles

  policy_uri: ${..policy_uri}
  # npc_policy_uri: ${..npc_policy_uri}
  eval_db_uri: ${..eval_db_uri}


wandb:
  enabled: false
  track: false
  checkpoint_interval: 1

env:
  # clean this up
  semi_compact_obs: true
  game:
    max_steps: 2000

sweep_params: "sweep/fast"
sweep_name: "${oc.env:USER}.local.sweep.${run_id}"
sweep:
  metric: action.use

seed: null
run_id: 20250408.2
run: ${oc.env:USER}.local.${run_id}
trained_policy_uri: ./train_dir/${oc.env:USER}.local.train.${run_id}/checkpoints