_target_: agent.metta_agent.MettaAgent

policy_selector:
  uri: null
  type: top
  range: 0
  metric: final.score
  generation: null

observations:
  obs_key: grid_obs
  track_last_action: false

clip_range: 3.0 # clip weights greater or less than this value * largest weight in layer * clip_scale
effective_rank_interval: 10 # compute effective rank every N epochs and log to wandb
l2_init_weight_update_interval: 0 # update the copy of initial weights every N epochs, scaled by to alpha

# List each component of your agent below. Component code can be found in
# agent/lib, or you can write your own and reference it under _target_.
#
# Components must have their name as their top-level attribute. The input_source
# is also necessary but can be set to null. The output_size is necessary unless
# it is defined by the size of the input source. Do not enter an input_size
# as it's defined by the input_source's output_size.
# Necessary sources: _obs_, _core_
# These interact with the trainer in a special way and use custom classes.

# Necessary outputs: _action_type_ and _value_ (and _action_param_ if MultiDiscrete)
# You must have layers with these names, and their output sizes must correspond
# to your action and value space. They can otherwise be any class that works
# with MettaAgent.

# Components are nn.Modules. Linear and Conv modules get extra weight helper
# functions found in the ParamLayer class.
# ***Note that these layers are also
# appended with a nonlinear layer unless you specify nonlinearity: null.
# Nonlinear layers should be specified as nn.<nonlinearity>, such as nn.Tanh.

# There are also merge layers that allow you to merge multiple outputs into a
# single output to feed into a layer. You can merge in various ways, such as
# concatenating (DenseNet), summing (ResNet), taking the mean, etc. You can
# also take slices of a single output to feed into a layer.

# Go through the components below to find additional examples.

components:

  _obs_:
    _target_: agent.lib.obs_shaper.ObsShaper
    input_source: null

  obs_normalizer:
    _target_: agent.lib.observation_normalizer.ObservationNormalizer
    input_source: _obs_

  channel_selector_0-11: # a merge layer that takes a slice of the input
    _target_: agent.lib.merge_layer.ConcatMergeLayer
    sources:
      - source_name: obs_normalizer
        slice: [0, 12]    # Use channels 0 to 11
        dim: 1            # Channel dimension
    output_size: 12

  channel_selector_12-22:
    _target_: agent.lib.merge_layer.ConcatMergeLayer
    sources:
      - source_name: obs_normalizer
        slice: [12, 22]   # Use channels 12 to 23
        dim: 1
    output_size: 12

  cnn1_channels_0-11:
    _target_: agent.lib.nn_layer_library.Conv2d
    input_source: channel_selector_0-11
    output_size: 64
    clip_scale: 0
    nn_params:
      kernel_size: 5
      stride: 3
    # when defining nn.Modules, put your keyword argements under nn_params.
    #Do not specify input_size or output_size.

  cnn1_channels_12-22:
    _target_: agent.lib.nn_layer_library.Conv2d
    input_source: channel_selector_12-22
    output_size: 64
    nn_params:
      kernel_size: 5
      stride: 3

  cnn2_channels_0-11:
    _target_: agent.lib.nn_layer_library.Conv2d
    input_source: cnn1_channels_0-11
    output_size: 64
    nn_params:
      kernel_size: 3
      stride: 1

  cnn2_channels_12-22:
    _target_: agent.lib.nn_layer_library.Conv2d
    input_source: cnn1_channels_12-22
    output_size: 64
    nn_params:
      kernel_size: 3
      stride: 1

  cnn_merger: # a merge layer that takes two slices of the input and concatenates them
    _target_: agent.lib.merge_layer.ConcatMergeLayer
    sources:
      - source_name: cnn2_channels_0-11
        slice: [0, 64]
        dim: 1
      - source_name: cnn2_channels_12-22
        slice: [0, 64]
        dim: 1

  obs_flattener:
    _target_: agent.lib.nn_layer_library.Flatten
    input_source: cnn_merger

  obs_dropout:
    _target_: agent.lib.nn_layer_library.Dropout
    input_source: obs_flattener
    nn_params:
      p: 0.5

  # using our first Linear layer as an example of the minimum required parameters
  encoded_obs:
    _target_: agent.lib.nn_layer_library.Linear
    input_source: obs_dropout
    output_size: 128

  _core_:
    _target_: agent.lib.lstm.LSTM
    input_source: encoded_obs
    output_size: 128
    nn_params:
      num_layers: 2

  # using our second Linear layer as an example of all available parameters
  critic_1:
    _target_: agent.lib.nn_layer_library.Linear
    input_source: _core_
    output_size: 512
    nonlinearity: nn.Tanh
    effective_rank: true
    l2_norm_scale: 1.0
    l2_init_scale: 1.0
    clip_scale: 1.0
    initialization: xavier
    nn_params:
      bias: false

  critic_2:
    _target_: agent.lib.nn_layer_library.Linear
    input_source: critic_1
    output_size: 128

  critic_3:
    _target_: agent.lib.nn_layer_library.Linear
    input_source: critic_2
    output_size: 128
    effective_rank: true # need to turn effective rank on if you want it

  _value_:
    _target_: agent.lib.nn_layer_library.Linear
    input_source: critic_3
    output_size: 1
    nonlinearity: null # we don't want a nonlinearity here

  actor_1:
    _target_: agent.lib.nn_layer_library.Linear
    input_source: _core_
    output_size: 512

  actor_2:
    _target_: agent.lib.nn_layer_library.Linear
    input_source: actor_1
    output_size: 512

  _action_type_:
    _target_: agent.lib.action.ActionType
    input_source: actor_1
    nonlinearity: null # we don't want a nonlinearity here because we'll use a softmax on the action space

  _action_param_:
    _target_: agent.lib.action.ActionParam
    input_source: actor_1
    nonlinearity: null
