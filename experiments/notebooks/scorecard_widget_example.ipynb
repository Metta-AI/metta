{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Interactive Scorecard Widget Example\n",
    "\n",
    "This notebook demonstrates how to use the `ScorecardWidget` - an anywidget-based implementation of the observatory scorecard component for Jupyter notebooks.\n",
    "\n",
    "The widget provides interactive policy evaluation scorecards with:\n",
    "- Have control over the number of policies displayed\n",
    "- Decide and select metrics to render\n",
    "- Choose which runs to get policies from\n",
    "- Dynamically get data from the Observatory API to render\n",
    "- Display scorecards for custom metrics if you like\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Import and Basic Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext anywidget\n",
    "\n",
    "print(\"Setup complete! Auto-reload enabled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Real Data from Metta Database\n",
    "\n",
    "Now let's write code that fetches real evaluation data from metta's databases:\n",
    "\n",
    "First we'll need some API variables.\n",
    "\n",
    "Then we'll make an API client for the metta API.\n",
    "\n",
    "Then we'll use the client to retrieve policy data.\n",
    "\n",
    "Then we'll render it with the ScorecardWidget.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metta.app_backend.clients.scorecard_client import ScorecardClient\n",
    "from experiments.notebooks.utils.scorecard_widget.scorecard_widget.ScorecardWidget import ScorecardWidget\n",
    "client = ScorecardClient()\n",
    "\n",
    "scorecard_widget = ScorecardWidget(client=client)\n",
    "scorecard_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Example: Finding policies with search text\n",
    "\n",
    "Now let's explore what's available in the database and create a scorecard with real data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, let's try with some common metrics and see what we find:\n",
    "\n",
    "# You can search for policies with a list of search texts\n",
    "restrict_to_policy_names = [\"zfogg.1753775626\", \"daveey.arena.rnd.\"]\n",
    "\n",
    "# You can get training run policies by exact training run names\n",
    "# restrict_to_policy_names = [\n",
    "#     \"daveey.arena.rnd.16x4.2\",\n",
    "#     \"relh.skypilot.fff.j20.666\",\n",
    "#     \"bullm.navigation.low_reward.baseline\",\n",
    "#     \"bullm.navigation.low_reward.baseline.07-17\", \n",
    "#     \"bullm.navigation.low_reward.baseline.07-23\",\n",
    "#     \"relh.multigpu.fff.1\",\n",
    "#     \"relh.skypilot.fff.j21.2\",\n",
    "# ]\n",
    "\n",
    "scorecard2 = ScorecardWidget(client=client)\n",
    "await scorecard2.fetch_real_scorecard_data(\n",
    "    restrict_to_policy_names=restrict_to_policy_names,\n",
    "    restrict_to_metrics=[\"reward\", \"heart.get\", \"action.move.success\"],\n",
    "    policy_selector=\"latest\", # \"best\" or \"latest\"\n",
    "    max_policies=50  # Limit display to keep it manageable\n",
    ")\n",
    "    \n",
    "scorecard2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Example: Finding policies using training run names\n",
    "\n",
    "Here's how to create a scorecard with your own training runs and metrics:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create a custom scorecard with specific training runs and metrics\n",
    "\n",
    "# Use training run names (recommended - uses smart selection)\n",
    "my_training_runs = [\n",
    "    # Add your training run names here, for example:\n",
    "    \"gregorypylypovych.navigation.ffa_NAV_DEFAULT_vtm_4rooms_of_4_seed0.07-27\",\n",
    "    \"gregorypylypovych.navigation.ffa_DEFAULT_vtm_4rooms_of_4_seed0.07-27\",\n",
    "    \"gregorypylypovych.navigation.ffa_DEFAULT_tfn_4rooms_of_4_seed0.07-27\",\n",
    "    \"gregorypylypovych.navigation.ffa_DEFAULT_vtb_4rooms_of_4_seed0.07-27\",\n",
    "]\n",
    "\n",
    "# Step 2: Define metrics you want to compare\n",
    "my_metrics = [\n",
    "    \"reward\",\n",
    "    \"heart.get\",           # Example game-specific metric\n",
    "    \"action.move.success\", # Example action success rate\n",
    "    # Add more metrics as needed\n",
    "]\n",
    "\n",
    "print(\"ðŸŽ¯ Creating custom scorecard with best policies from training runs...\")\n",
    "# Select best policies from training runs\n",
    "custom_scorecard = ScorecardWidget(client=client)\n",
    "await custom_scorecard.fetch_real_scorecard_data(\n",
    "    restrict_to_policy_names=my_training_runs,\n",
    "    restrict_to_metrics=my_metrics,\n",
    "    policy_selector=\"best\",\n",
    "    max_policies=20\n",
    ")\n",
    "\n",
    "print(\"ðŸ“Š Custom scorecard created! Try:\")\n",
    "print(\"   - Hovering over cells to see detailed values\")\n",
    "print(\"   - Changing metrics with: custom_scorecard.update_metric('heart.get')\")\n",
    "print(\"   - Adjusting policies shown: custom_scorecard.set_num_policies(15)\")\n",
    "\n",
    "custom_scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Example: Setting the metric\n",
    "\n",
    "Now let's see the `update_metric` functionality working properly! This example shows a scorecard where changing the metric actually changes the displayed values:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last one. Scroll up again to see the change.\n",
    "print(\"\\nðŸ”„ Changing metric to 'success_rate'...\")\n",
    "custom_scorecard.update_metric('action.move.success')\n",
    "\n",
    "print(\"Now the scorecard in the cell that ran before this one should have changed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now let's change it to reward.\n",
    "custom_scorecard.update_metric('reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Custom metrics\n",
    "\n",
    "We can really define our cells to have any metric data we want. This is useful because we plan to have all sorts of metrics. Let's look at an example of using any old metric we decide.\n",
    "\n",
    "First, you need to know the data format:\n",
    "\n",
    "### Info: Data Cell Format Reference\n",
    "\n",
    "The scorecard widget expects data in a specific format that matches the\n",
    "observatory dashboard:\n",
    "\n",
    "```python\n",
    "cells = {\n",
    "    'policy_name': {\n",
    "        'eval_name': {\n",
    "            'metrics': {\n",
    "                'reward': 50,\n",
    "                'heart.get': 98,\n",
    "                'action.move.success': 5,\n",
    "                'ore_red.get': 24.2,\n",
    "                # ... more metrics\n",
    "            },\n",
    "            'replayUrl': str,         # URL to replay file\n",
    "            'evalName': str,          # Should match the key\n",
    "        },\n",
    "        # ... more evaluations\n",
    "    },\n",
    "    # ... more policies\n",
    "}\n",
    "```\n",
    "\n",
    "**Important notes:**\n",
    "- Evaluation names with \"/\" will be grouped by category (the part before \"/\")\n",
    "- The scorecard shows policies sorted by average score (worst to best, bottom to top)\n",
    "- Policy names that contain \":v\" will have WandB URLs generated automatically\n",
    "- Replay URLs should be accessible URLs or file paths\n",
    "\n",
    "This widget provides the same interactive functionality as the observatory dashboard but in a python environment, making it perfect for exploratory analysis and sharing results via Jupyter notebooks!\n",
    "\n",
    "\n",
    "### Here's how to create a scorecard with your own data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new scorecard widget\n",
    "from experiments.notebooks.utils.scorecard_widget.scorecard_widget.ScorecardWidget import create_scorecard_widget\n",
    "\n",
    "custom_widget = create_scorecard_widget()\n",
    "\n",
    "# Define your data structure\n",
    "# This should match the format expected by the observatory dashboard\n",
    "cells_data = {\n",
    "    'my_policy_v1': {\n",
    "        'task_a/level1': {\n",
    "            'metrics': {\n",
    "                'custom_score': 85.2,\n",
    "            },\n",
    "            'replayUrl': 'https://example.com/replay1.json', \n",
    "            'evalName': 'task_a/level1'\n",
    "        },\n",
    "        'task_a/level2': {\n",
    "            'metrics': {\n",
    "                'custom_score': 87.5,\n",
    "            },\n",
    "            'replayUrl': 'https://example.com/replay2.json', \n",
    "            'evalName': 'task_a/level2'\n",
    "        },\n",
    "        'task_b/challenge1': {\n",
    "            'metrics': {\n",
    "                'custom_score': 92.5,\n",
    "            },\n",
    "            'replayUrl': 'https://example.com/replay3.json', \n",
    "            'evalName': 'task_b/challenge1'\n",
    "        },\n",
    "    },\n",
    "    'my_policy_v2': {\n",
    "        'task_a/level1': {\n",
    "            'metrics': {\n",
    "                'custom_score': 22.5,\n",
    "            },\n",
    "            'replayUrl': 'https://example.com/replay4.json', \n",
    "            'evalName': 'task_a/level1'\n",
    "        },\n",
    "        'task_a/level2': {\n",
    "            'metrics': {\n",
    "                'custom_score': 42.5,\n",
    "            },\n",
    "            'replayUrl': 'https://example.com/replay5.json', \n",
    "            'evalName': 'task_a/level2'\n",
    "        },\n",
    "        'task_b/challenge1': {\n",
    "            'metrics': {\n",
    "                'custom_score': 62.5,\n",
    "            },\n",
    "            'replayUrl': 'https://example.com/replay6.json', \n",
    "            'evalName': 'task_b/challenge1'\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "eval_names = ['task_a/level1', 'task_a/level2', 'task_b/challenge1']\n",
    "policy_names = ['my_policy_v1', 'my_policy_v2']\n",
    "policy_averages = {\n",
    "    'my_policy_v1': 91.6,\n",
    "    'my_policy_v2': 89.6,\n",
    "}\n",
    "\n",
    "# Set the data\n",
    "custom_widget.set_data(\n",
    "    cells=cells_data,\n",
    "    eval_names=eval_names,\n",
    "    policy_names=policy_names,\n",
    "    policy_average_scores=policy_averages,\n",
    "    selected_metric=\"custom_score\"\n",
    ")\n",
    "\n",
    "# Display the widget\n",
    "custom_widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
