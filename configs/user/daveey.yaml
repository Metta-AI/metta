# @package __global__

seed: null


defaults:
  - /sweep: fast
  - override /eval: eval
  - override /agent: simple
  # - override /env/mettagrid@env: bases

# policy: wandb://run/b.daveey.train.maze.sm.dr.warm.0
# baselines: wandb://run/b.daveey.train.maze.sm.11x11.0

# policy_uri: wandb://run/b.daveey.sm.train.er.new.0
# policy_uri: wandb://run/daveey.ar.cards.1
policy_uri: wandb://run/b.daveey.4.sweep.10.r.47
# policy_uri: ${trained_policy_uri}
# npc_policy_uri: ${trained_policy_uri}
# eval_db_uri: wandb://artifacts/daveey_eval_testing

env:
  # sampling: 0.7
  game:
  #   num_agents: 36

  #   agent:
  #     rewards:
  #       ore_max: 100

    # group_reward_pct: 0.9
    max_steps: 1000

    # map_builder:
    #   border_width: 1
    #   room:
    #     border_width: 0

trainer:
  evaluate_interval: 200

analyzer:
  eval_stats_uri: ${run_dir}/eval_stats
  analysis:
    metrics:
      - metric: episode_reward
      - metric: "*.get"

eval:
  num_envs: 2
  num_episodes: 2
  max_time_s: 600

  policy_uri: ${..policy_uri}
  # npc_policy_uri: ${..npc_policy_uri}
  # eval_db_uri: ${..eval_db_uri} #file://daphne/sweep_stats
  env: /env/mettagrid/simple
  env_overrides:
    game:
      max_steps: 1000

wandb:
  checkpoint_interval: 1

run_id: 9
run: ${oc.env:USER}.local.${run_id}
trained_policy_uri: ${run_dir}/checkpoints

sweep_name: "${oc.env:USER}.local.sweep.0"
