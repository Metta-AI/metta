# @package _global_

sweep:
  trainer:
    optimizer:
      learning_rate:
        distribution: log_normal
        min: 1e-5
        max: 1e-2
        mean: 1e-3
        scale: 1.0

    gamma:
      distribution: uniform
      min: 0.9
      max: 0.999
      mean: 0.95
      scale: 1.0

    batch_size:
      distribution: int_uniform
      min: 32
      max: 128
      mean: 64
      scale: 1.0

    clip_coef:
      distribution: uniform
      min: 0.1
      max: 0.3
      mean: 0.2
      scale: 1.0
