[
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "Generator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Final",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TYPE_CHECKING",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "DefaultDict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Generator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "LiteralString",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "ContextManager",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Final",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "ClassVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Annotated",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Generator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Generic",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "get_args",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "get_origin",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeAlias",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "ClassVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TYPE_CHECKING",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Generator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TYPE_CHECKING",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "get_args",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "get_args",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "get_args",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Protocol",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "fnmatch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "fnmatch",
        "description": "fnmatch",
        "detail": "fnmatch",
        "documentation": {}
    },
    {
        "label": "Github",
        "importPath": "github",
        "description": "github",
        "isExtraImport": true,
        "detail": "github",
        "documentation": {}
    },
    {
        "label": "Github",
        "importPath": "github",
        "description": "github",
        "isExtraImport": true,
        "detail": "github",
        "documentation": {}
    },
    {
        "label": "Github",
        "importPath": "github",
        "description": "github",
        "isExtraImport": true,
        "detail": "github",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "asdict",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "asdict",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "asdict",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timezone",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timezone",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timezone",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timezone",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "platform",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "platform",
        "description": "platform",
        "detail": "platform",
        "documentation": {}
    },
    {
        "label": "socket",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "socket",
        "description": "socket",
        "detail": "socket",
        "documentation": {}
    },
    {
        "label": "ast",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ast",
        "description": "ast",
        "detail": "ast",
        "documentation": {}
    },
    {
        "label": "threading",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "threading",
        "description": "threading",
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "RLock",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Lock",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "psutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "psutil",
        "description": "psutil",
        "detail": "psutil",
        "documentation": {}
    },
    {
        "label": "abc",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "abc",
        "description": "abc",
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "zipfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "zipfile",
        "description": "zipfile",
        "detail": "zipfile",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "StringIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "Logger",
        "importPath": "logging",
        "description": "logging",
        "isExtraImport": true,
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "Logger",
        "importPath": "logging",
        "description": "logging",
        "isExtraImport": true,
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "Logger",
        "importPath": "logging",
        "description": "logging",
        "isExtraImport": true,
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "ZoneInfo",
        "importPath": "zoneinfo",
        "description": "zoneinfo",
        "isExtraImport": true,
        "detail": "zoneinfo",
        "documentation": {}
    },
    {
        "label": "run_with_benchmark",
        "importPath": "utils.benchmark",
        "description": "utils.benchmark",
        "isExtraImport": true,
        "detail": "utils.benchmark",
        "documentation": {}
    },
    {
        "label": "SmokeTest",
        "importPath": "utils.smoke_test",
        "description": "utils.smoke_test",
        "isExtraImport": true,
        "detail": "utils.smoke_test",
        "documentation": {}
    },
    {
        "label": "SmokeTest",
        "importPath": "utils.smoke_test",
        "description": "utils.smoke_test",
        "isExtraImport": true,
        "detail": "utils.smoke_test",
        "documentation": {}
    },
    {
        "label": "SmokeTest",
        "importPath": "utils.smoke_test",
        "description": "utils.smoke_test",
        "isExtraImport": true,
        "detail": "utils.smoke_test",
        "documentation": {}
    },
    {
        "label": "GeminiAIClient",
        "importPath": "gemini_client",
        "description": "gemini_client",
        "isExtraImport": true,
        "detail": "gemini_client",
        "documentation": {}
    },
    {
        "label": "MODEL_CONFIG",
        "importPath": "gemini_client",
        "description": "gemini_client",
        "isExtraImport": true,
        "detail": "gemini_client",
        "documentation": {}
    },
    {
        "label": "GeminiAIClient",
        "importPath": "gemini_client",
        "description": "gemini_client",
        "isExtraImport": true,
        "detail": "gemini_client",
        "documentation": {}
    },
    {
        "label": "concurrent.futures",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "as_completed",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "PRAnalyzer",
        "importPath": "gemini_analyze_pr",
        "description": "gemini_analyze_pr",
        "isExtraImport": true,
        "detail": "gemini_analyze_pr",
        "documentation": {}
    },
    {
        "label": "PRSummary",
        "importPath": "gemini_analyze_pr",
        "description": "gemini_analyze_pr",
        "isExtraImport": true,
        "detail": "gemini_analyze_pr",
        "documentation": {}
    },
    {
        "label": "google.generativeai",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "HarmBlockThreshold",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "HarmCategory",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "wandb",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "wandb",
        "description": "wandb",
        "detail": "wandb",
        "documentation": {}
    },
    {
        "label": "runpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "runpy",
        "description": "runpy",
        "detail": "runpy",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "site",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "site",
        "description": "site",
        "detail": "site",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "pformat",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "pformat",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "pformat",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "jmespath",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "jmespath",
        "description": "jmespath",
        "detail": "jmespath",
        "documentation": {}
    },
    {
        "label": "exceptions",
        "importPath": "jmespath",
        "description": "jmespath",
        "isExtraImport": true,
        "detail": "jmespath",
        "documentation": {}
    },
    {
        "label": "exceptions",
        "importPath": "jmespath",
        "description": "jmespath",
        "isExtraImport": true,
        "detail": "jmespath",
        "documentation": {}
    },
    {
        "label": "exceptions",
        "importPath": "jmespath",
        "description": "jmespath",
        "isExtraImport": true,
        "detail": "jmespath",
        "documentation": {}
    },
    {
        "label": "pufferlib.models",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pufferlib.models",
        "description": "pufferlib.models",
        "detail": "pufferlib.models",
        "documentation": {}
    },
    {
        "label": "pufferlib.pytorch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pufferlib.pytorch",
        "description": "pufferlib.pytorch",
        "detail": "pufferlib.pytorch",
        "documentation": {}
    },
    {
        "label": "sample_logits",
        "importPath": "pufferlib.pytorch",
        "description": "pufferlib.pytorch",
        "isExtraImport": true,
        "detail": "pufferlib.pytorch",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "einops",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "einops",
        "description": "einops",
        "detail": "einops",
        "documentation": {}
    },
    {
        "label": "rearrange",
        "importPath": "einops",
        "description": "einops",
        "isExtraImport": true,
        "detail": "einops",
        "documentation": {}
    },
    {
        "label": "rearrange",
        "importPath": "einops",
        "description": "einops",
        "isExtraImport": true,
        "detail": "einops",
        "documentation": {}
    },
    {
        "label": "repeat",
        "importPath": "einops",
        "description": "einops",
        "isExtraImport": true,
        "detail": "einops",
        "documentation": {}
    },
    {
        "label": "rearrange",
        "importPath": "einops",
        "description": "einops",
        "isExtraImport": true,
        "detail": "einops",
        "documentation": {}
    },
    {
        "label": "repeat",
        "importPath": "einops",
        "description": "einops",
        "isExtraImport": true,
        "detail": "einops",
        "documentation": {}
    },
    {
        "label": "rearrange",
        "importPath": "einops",
        "description": "einops",
        "isExtraImport": true,
        "detail": "einops",
        "documentation": {}
    },
    {
        "label": "rearrange",
        "importPath": "einops",
        "description": "einops",
        "isExtraImport": true,
        "detail": "einops",
        "documentation": {}
    },
    {
        "label": "TensorDict",
        "importPath": "tensordict",
        "description": "tensordict",
        "isExtraImport": true,
        "detail": "tensordict",
        "documentation": {}
    },
    {
        "label": "TensorDict",
        "importPath": "tensordict",
        "description": "tensordict",
        "isExtraImport": true,
        "detail": "tensordict",
        "documentation": {}
    },
    {
        "label": "TensorDict",
        "importPath": "tensordict",
        "description": "tensordict",
        "isExtraImport": true,
        "detail": "tensordict",
        "documentation": {}
    },
    {
        "label": "TensorDict",
        "importPath": "tensordict",
        "description": "tensordict",
        "isExtraImport": true,
        "detail": "tensordict",
        "documentation": {}
    },
    {
        "label": "TensorDict",
        "importPath": "tensordict",
        "description": "tensordict",
        "isExtraImport": true,
        "detail": "tensordict",
        "documentation": {}
    },
    {
        "label": "TensorDict",
        "importPath": "tensordict",
        "description": "tensordict",
        "isExtraImport": true,
        "detail": "tensordict",
        "documentation": {}
    },
    {
        "label": "TensorDict",
        "importPath": "tensordict",
        "description": "tensordict",
        "isExtraImport": true,
        "detail": "tensordict",
        "documentation": {}
    },
    {
        "label": "TensorDict",
        "importPath": "tensordict",
        "description": "tensordict",
        "isExtraImport": true,
        "detail": "tensordict",
        "documentation": {}
    },
    {
        "label": "TensorDict",
        "importPath": "tensordict",
        "description": "tensordict",
        "isExtraImport": true,
        "detail": "tensordict",
        "documentation": {}
    },
    {
        "label": "TensorDict",
        "importPath": "tensordict",
        "description": "tensordict",
        "isExtraImport": true,
        "detail": "tensordict",
        "documentation": {}
    },
    {
        "label": "TensorDict",
        "importPath": "tensordict",
        "description": "tensordict",
        "isExtraImport": true,
        "detail": "tensordict",
        "documentation": {}
    },
    {
        "label": "TensorDict",
        "importPath": "tensordict",
        "description": "tensordict",
        "isExtraImport": true,
        "detail": "tensordict",
        "documentation": {}
    },
    {
        "label": "TensorClass",
        "importPath": "tensordict",
        "description": "tensordict",
        "isExtraImport": true,
        "detail": "tensordict",
        "documentation": {}
    },
    {
        "label": "TensorDict",
        "importPath": "tensordict",
        "description": "tensordict",
        "isExtraImport": true,
        "detail": "tensordict",
        "documentation": {}
    },
    {
        "label": "TensorDict",
        "importPath": "tensordict",
        "description": "tensordict",
        "isExtraImport": true,
        "detail": "tensordict",
        "documentation": {}
    },
    {
        "label": "TensorDict",
        "importPath": "tensordict",
        "description": "tensordict",
        "isExtraImport": true,
        "detail": "tensordict",
        "documentation": {}
    },
    {
        "label": "TensorDict",
        "importPath": "tensordict",
        "description": "tensordict",
        "isExtraImport": true,
        "detail": "tensordict",
        "documentation": {}
    },
    {
        "label": "TensorDict",
        "importPath": "tensordict",
        "description": "tensordict",
        "isExtraImport": true,
        "detail": "tensordict",
        "documentation": {}
    },
    {
        "label": "metta.agent.lib.nn_layer_library",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "metta.agent.lib.nn_layer_library",
        "description": "metta.agent.lib.nn_layer_library",
        "detail": "metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "LayerBase",
        "importPath": "metta.agent.lib.nn_layer_library",
        "description": "metta.agent.lib.nn_layer_library",
        "isExtraImport": true,
        "detail": "metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "LayerBase",
        "importPath": "metta.agent.lib.nn_layer_library",
        "description": "metta.agent.lib.nn_layer_library",
        "isExtraImport": true,
        "detail": "metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "prod",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "LayerBase",
        "importPath": "metta.agent.lib.metta_layer",
        "description": "metta.agent.lib.metta_layer",
        "isExtraImport": true,
        "detail": "metta.agent.lib.metta_layer",
        "documentation": {}
    },
    {
        "label": "LayerBase",
        "importPath": "metta.agent.lib.metta_layer",
        "description": "metta.agent.lib.metta_layer",
        "isExtraImport": true,
        "detail": "metta.agent.lib.metta_layer",
        "documentation": {}
    },
    {
        "label": "LayerBase",
        "importPath": "metta.agent.lib.metta_layer",
        "description": "metta.agent.lib.metta_layer",
        "isExtraImport": true,
        "detail": "metta.agent.lib.metta_layer",
        "documentation": {}
    },
    {
        "label": "LayerBase",
        "importPath": "metta.agent.lib.metta_layer",
        "description": "metta.agent.lib.metta_layer",
        "isExtraImport": true,
        "detail": "metta.agent.lib.metta_layer",
        "documentation": {}
    },
    {
        "label": "ParamLayer",
        "importPath": "metta.agent.lib.metta_layer",
        "description": "metta.agent.lib.metta_layer",
        "isExtraImport": true,
        "detail": "metta.agent.lib.metta_layer",
        "documentation": {}
    },
    {
        "label": "LayerBase",
        "importPath": "metta.agent.lib.metta_layer",
        "description": "metta.agent.lib.metta_layer",
        "isExtraImport": true,
        "detail": "metta.agent.lib.metta_layer",
        "documentation": {}
    },
    {
        "label": "LayerBase",
        "importPath": "metta.agent.lib.metta_layer",
        "description": "metta.agent.lib.metta_layer",
        "isExtraImport": true,
        "detail": "metta.agent.lib.metta_layer",
        "documentation": {}
    },
    {
        "label": "omegaconf",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "omegaconf",
        "description": "omegaconf",
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "ListConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "ListConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "ListConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "SCMode",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "ListConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "ListConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "ListConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "ListConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "ListConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "ListConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "ListConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "ListConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "ListConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "ListConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "ListConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "random",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "analyze_weights",
        "importPath": "metta.agent.util.weights_analysis",
        "description": "metta.agent.util.weights_analysis",
        "isExtraImport": true,
        "detail": "metta.agent.util.weights_analysis",
        "documentation": {}
    },
    {
        "label": "MettaModule",
        "importPath": "metta.agent.lib.metta_module",
        "description": "metta.agent.lib.metta_module",
        "isExtraImport": true,
        "detail": "metta.agent.lib.metta_module",
        "documentation": {}
    },
    {
        "label": "MettaModule",
        "importPath": "metta.agent.lib.metta_module",
        "description": "metta.agent.lib.metta_module",
        "isExtraImport": true,
        "detail": "metta.agent.lib.metta_module",
        "documentation": {}
    },
    {
        "label": "MettaLinear",
        "importPath": "metta.agent.lib.metta_module",
        "description": "metta.agent.lib.metta_module",
        "isExtraImport": true,
        "detail": "metta.agent.lib.metta_module",
        "documentation": {}
    },
    {
        "label": "MettaReLU",
        "importPath": "metta.agent.lib.metta_module",
        "description": "metta.agent.lib.metta_module",
        "isExtraImport": true,
        "detail": "metta.agent.lib.metta_module",
        "documentation": {}
    },
    {
        "label": "MettaLinear",
        "importPath": "metta.agent.lib.metta_module",
        "description": "metta.agent.lib.metta_module",
        "isExtraImport": true,
        "detail": "metta.agent.lib.metta_module",
        "documentation": {}
    },
    {
        "label": "MettaReLU",
        "importPath": "metta.agent.lib.metta_module",
        "description": "metta.agent.lib.metta_module",
        "isExtraImport": true,
        "detail": "metta.agent.lib.metta_module",
        "documentation": {}
    },
    {
        "label": "MettaAgent",
        "importPath": "metta.agent.metta_agent",
        "description": "metta.agent.metta_agent",
        "isExtraImport": true,
        "detail": "metta.agent.metta_agent",
        "documentation": {}
    },
    {
        "label": "make_policy",
        "importPath": "metta.agent.metta_agent",
        "description": "metta.agent.metta_agent",
        "isExtraImport": true,
        "detail": "metta.agent.metta_agent",
        "documentation": {}
    },
    {
        "label": "MettaAgent",
        "importPath": "metta.agent.metta_agent",
        "description": "metta.agent.metta_agent",
        "isExtraImport": true,
        "detail": "metta.agent.metta_agent",
        "documentation": {}
    },
    {
        "label": "MettaAgent",
        "importPath": "metta.agent.metta_agent",
        "description": "metta.agent.metta_agent",
        "isExtraImport": true,
        "detail": "metta.agent.metta_agent",
        "documentation": {}
    },
    {
        "label": "DistributedMettaAgent",
        "importPath": "metta.agent.metta_agent",
        "description": "metta.agent.metta_agent",
        "isExtraImport": true,
        "detail": "metta.agent.metta_agent",
        "documentation": {}
    },
    {
        "label": "make_policy",
        "importPath": "metta.agent.metta_agent",
        "description": "metta.agent.metta_agent",
        "isExtraImport": true,
        "detail": "metta.agent.metta_agent",
        "documentation": {}
    },
    {
        "label": "PolicyMetadata",
        "importPath": "metta.agent.policy_metadata",
        "description": "metta.agent.policy_metadata",
        "isExtraImport": true,
        "detail": "metta.agent.policy_metadata",
        "documentation": {}
    },
    {
        "label": "PolicyMetadata",
        "importPath": "metta.agent.policy_metadata",
        "description": "metta.agent.policy_metadata",
        "isExtraImport": true,
        "detail": "metta.agent.policy_metadata",
        "documentation": {}
    },
    {
        "label": "PolicyMetadata",
        "importPath": "metta.agent.policy_metadata",
        "description": "metta.agent.policy_metadata",
        "isExtraImport": true,
        "detail": "metta.agent.policy_metadata",
        "documentation": {}
    },
    {
        "label": "PolicyMetadata",
        "importPath": "metta.agent.policy_metadata",
        "description": "metta.agent.policy_metadata",
        "isExtraImport": true,
        "detail": "metta.agent.policy_metadata",
        "documentation": {}
    },
    {
        "label": "PolicyMetadata",
        "importPath": "metta.agent.policy_metadata",
        "description": "metta.agent.policy_metadata",
        "isExtraImport": true,
        "detail": "metta.agent.policy_metadata",
        "documentation": {}
    },
    {
        "label": "PolicyRecord",
        "importPath": "metta.agent.policy_record",
        "description": "metta.agent.policy_record",
        "isExtraImport": true,
        "detail": "metta.agent.policy_record",
        "documentation": {}
    },
    {
        "label": "PolicyRecord",
        "importPath": "metta.agent.policy_record",
        "description": "metta.agent.policy_record",
        "isExtraImport": true,
        "detail": "metta.agent.policy_record",
        "documentation": {}
    },
    {
        "label": "PolicyRecord",
        "importPath": "metta.agent.policy_record",
        "description": "metta.agent.policy_record",
        "isExtraImport": true,
        "detail": "metta.agent.policy_record",
        "documentation": {}
    },
    {
        "label": "PolicyRecord",
        "importPath": "metta.agent.policy_record",
        "description": "metta.agent.policy_record",
        "isExtraImport": true,
        "detail": "metta.agent.policy_record",
        "documentation": {}
    },
    {
        "label": "PolicyRecord",
        "importPath": "metta.agent.policy_record",
        "description": "metta.agent.policy_record",
        "isExtraImport": true,
        "detail": "metta.agent.policy_record",
        "documentation": {}
    },
    {
        "label": "PolicyRecord",
        "importPath": "metta.agent.policy_record",
        "description": "metta.agent.policy_record",
        "isExtraImport": true,
        "detail": "metta.agent.policy_record",
        "documentation": {}
    },
    {
        "label": "PolicyRecord",
        "importPath": "metta.agent.policy_record",
        "description": "metta.agent.policy_record",
        "isExtraImport": true,
        "detail": "metta.agent.policy_record",
        "documentation": {}
    },
    {
        "label": "PolicyRecord",
        "importPath": "metta.agent.policy_record",
        "description": "metta.agent.policy_record",
        "isExtraImport": true,
        "detail": "metta.agent.policy_record",
        "documentation": {}
    },
    {
        "label": "PolicyRecord",
        "importPath": "metta.agent.policy_record",
        "description": "metta.agent.policy_record",
        "isExtraImport": true,
        "detail": "metta.agent.policy_record",
        "documentation": {}
    },
    {
        "label": "PolicyRecord",
        "importPath": "metta.agent.policy_record",
        "description": "metta.agent.policy_record",
        "isExtraImport": true,
        "detail": "metta.agent.policy_record",
        "documentation": {}
    },
    {
        "label": "PolicyRecord",
        "importPath": "metta.agent.policy_record",
        "description": "metta.agent.policy_record",
        "isExtraImport": true,
        "detail": "metta.agent.policy_record",
        "documentation": {}
    },
    {
        "label": "PolicyRecord",
        "importPath": "metta.agent.policy_record",
        "description": "metta.agent.policy_record",
        "isExtraImport": true,
        "detail": "metta.agent.policy_record",
        "documentation": {}
    },
    {
        "label": "torch.jit",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.jit",
        "description": "torch.jit",
        "detail": "torch.jit",
        "documentation": {}
    },
    {
        "label": "RecursiveScriptModule",
        "importPath": "torch.jit",
        "description": "torch.jit",
        "isExtraImport": true,
        "detail": "torch.jit",
        "documentation": {}
    },
    {
        "label": "ScriptModule",
        "importPath": "torch.jit",
        "description": "torch.jit",
        "isExtraImport": true,
        "detail": "torch.jit",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "seaborn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "seaborn",
        "description": "seaborn",
        "detail": "seaborn",
        "documentation": {}
    },
    {
        "label": "cosine_similarity",
        "importPath": "sklearn.metrics.pairwise",
        "description": "sklearn.metrics.pairwise",
        "isExtraImport": true,
        "detail": "sklearn.metrics.pairwise",
        "documentation": {}
    },
    {
        "label": "euclidean_distances",
        "importPath": "sklearn.metrics.pairwise",
        "description": "sklearn.metrics.pairwise",
        "isExtraImport": true,
        "detail": "sklearn.metrics.pairwise",
        "documentation": {}
    },
    {
        "label": "gymnasium",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gymnasium",
        "description": "gymnasium",
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "Env",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "stats",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "stats",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "hydra",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hydra",
        "description": "hydra",
        "detail": "hydra",
        "documentation": {}
    },
    {
        "label": "compose",
        "importPath": "hydra",
        "description": "hydra",
        "isExtraImport": true,
        "detail": "hydra",
        "documentation": {}
    },
    {
        "label": "initialize",
        "importPath": "hydra",
        "description": "hydra",
        "isExtraImport": true,
        "detail": "hydra",
        "documentation": {}
    },
    {
        "label": "compose",
        "importPath": "hydra",
        "description": "hydra",
        "isExtraImport": true,
        "detail": "hydra",
        "documentation": {}
    },
    {
        "label": "initialize_config_dir",
        "importPath": "hydra",
        "description": "hydra",
        "isExtraImport": true,
        "detail": "hydra",
        "documentation": {}
    },
    {
        "label": "DistributedDataParallel",
        "importPath": "torch.nn.parallel",
        "description": "torch.nn.parallel",
        "isExtraImport": true,
        "detail": "torch.nn.parallel",
        "documentation": {}
    },
    {
        "label": "PolicyState",
        "importPath": "metta.agent.policy_state",
        "description": "metta.agent.policy_state",
        "isExtraImport": true,
        "detail": "metta.agent.policy_state",
        "documentation": {}
    },
    {
        "label": "PolicyState",
        "importPath": "metta.agent.policy_state",
        "description": "metta.agent.policy_state",
        "isExtraImport": true,
        "detail": "metta.agent.policy_state",
        "documentation": {}
    },
    {
        "label": "PolicyState",
        "importPath": "metta.agent.policy_state",
        "description": "metta.agent.policy_state",
        "isExtraImport": true,
        "detail": "metta.agent.policy_state",
        "documentation": {}
    },
    {
        "label": "PolicyState",
        "importPath": "metta.agent.policy_state",
        "description": "metta.agent.policy_state",
        "isExtraImport": true,
        "detail": "metta.agent.policy_state",
        "documentation": {}
    },
    {
        "label": "PolicyState",
        "importPath": "metta.agent.policy_state",
        "description": "metta.agent.policy_state",
        "isExtraImport": true,
        "detail": "metta.agent.policy_state",
        "documentation": {}
    },
    {
        "label": "PolicyState",
        "importPath": "metta.agent.policy_state",
        "description": "metta.agent.policy_state",
        "isExtraImport": true,
        "detail": "metta.agent.policy_state",
        "documentation": {}
    },
    {
        "label": "PolicyState",
        "importPath": "metta.agent.policy_state",
        "description": "metta.agent.policy_state",
        "isExtraImport": true,
        "detail": "metta.agent.policy_state",
        "documentation": {}
    },
    {
        "label": "assert_shape",
        "importPath": "metta.agent.util.debug",
        "description": "metta.agent.util.debug",
        "isExtraImport": true,
        "detail": "metta.agent.util.debug",
        "documentation": {}
    },
    {
        "label": "assert_shape",
        "importPath": "metta.agent.util.debug",
        "description": "metta.agent.util.debug",
        "isExtraImport": true,
        "detail": "metta.agent.util.debug",
        "documentation": {}
    },
    {
        "label": "evaluate_actions",
        "importPath": "metta.agent.util.distribution_utils",
        "description": "metta.agent.util.distribution_utils",
        "isExtraImport": true,
        "detail": "metta.agent.util.distribution_utils",
        "documentation": {}
    },
    {
        "label": "sample_actions",
        "importPath": "metta.agent.util.distribution_utils",
        "description": "metta.agent.util.distribution_utils",
        "isExtraImport": true,
        "detail": "metta.agent.util.distribution_utils",
        "documentation": {}
    },
    {
        "label": "evaluate_actions",
        "importPath": "metta.agent.util.distribution_utils",
        "description": "metta.agent.util.distribution_utils",
        "isExtraImport": true,
        "detail": "metta.agent.util.distribution_utils",
        "documentation": {}
    },
    {
        "label": "sample_actions",
        "importPath": "metta.agent.util.distribution_utils",
        "description": "metta.agent.util.distribution_utils",
        "isExtraImport": true,
        "detail": "metta.agent.util.distribution_utils",
        "documentation": {}
    },
    {
        "label": "evaluate_actions",
        "importPath": "metta.agent.util.distribution_utils",
        "description": "metta.agent.util.distribution_utils",
        "isExtraImport": true,
        "detail": "metta.agent.util.distribution_utils",
        "documentation": {}
    },
    {
        "label": "sample_actions",
        "importPath": "metta.agent.util.distribution_utils",
        "description": "metta.agent.util.distribution_utils",
        "isExtraImport": true,
        "detail": "metta.agent.util.distribution_utils",
        "documentation": {}
    },
    {
        "label": "safe_get_from_obs_space",
        "importPath": "metta.agent.util.safe_get",
        "description": "metta.agent.util.safe_get",
        "isExtraImport": true,
        "detail": "metta.agent.util.safe_get",
        "documentation": {}
    },
    {
        "label": "convert_to_dict",
        "importPath": "metta.common.util.omegaconf",
        "description": "metta.common.util.omegaconf",
        "isExtraImport": true,
        "detail": "metta.common.util.omegaconf",
        "documentation": {}
    },
    {
        "label": "collections",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "collections",
        "description": "collections",
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "SimpleNamespace",
        "importPath": "types",
        "description": "types",
        "isExtraImport": true,
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "SimpleNamespace",
        "importPath": "types",
        "description": "types",
        "isExtraImport": true,
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "PolicyCache",
        "importPath": "metta.agent.policy_cache",
        "description": "metta.agent.policy_cache",
        "isExtraImport": true,
        "detail": "metta.agent.policy_cache",
        "documentation": {}
    },
    {
        "label": "PolicyCache",
        "importPath": "metta.agent.policy_cache",
        "description": "metta.agent.policy_cache",
        "isExtraImport": true,
        "detail": "metta.agent.policy_cache",
        "documentation": {}
    },
    {
        "label": "load_pytorch_policy",
        "importPath": "metta.rl.policy",
        "description": "metta.rl.policy",
        "isExtraImport": true,
        "detail": "metta.rl.policy",
        "documentation": {}
    },
    {
        "label": "TrainerConfig",
        "importPath": "metta.rl.trainer_config",
        "description": "metta.rl.trainer_config",
        "isExtraImport": true,
        "detail": "metta.rl.trainer_config",
        "documentation": {}
    },
    {
        "label": "parse_trainer_config",
        "importPath": "metta.rl.trainer_config",
        "description": "metta.rl.trainer_config",
        "isExtraImport": true,
        "detail": "metta.rl.trainer_config",
        "documentation": {}
    },
    {
        "label": "parse_trainer_config",
        "importPath": "metta.rl.trainer_config",
        "description": "metta.rl.trainer_config",
        "isExtraImport": true,
        "detail": "metta.rl.trainer_config",
        "documentation": {}
    },
    {
        "label": "OptimizerConfig",
        "importPath": "metta.rl.trainer_config",
        "description": "metta.rl.trainer_config",
        "isExtraImport": true,
        "detail": "metta.rl.trainer_config",
        "documentation": {}
    },
    {
        "label": "parse_trainer_config",
        "importPath": "metta.rl.trainer_config",
        "description": "metta.rl.trainer_config",
        "isExtraImport": true,
        "detail": "metta.rl.trainer_config",
        "documentation": {}
    },
    {
        "label": "parse_trainer_config",
        "importPath": "metta.rl.trainer_config",
        "description": "metta.rl.trainer_config",
        "isExtraImport": true,
        "detail": "metta.rl.trainer_config",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "LSTM",
        "importPath": "metta.agent.lib.lstm",
        "description": "metta.agent.lib.lstm",
        "isExtraImport": true,
        "detail": "metta.agent.lib.lstm",
        "documentation": {}
    },
    {
        "label": "ModularNetwork",
        "importPath": "metta.agent.lib.modular_network",
        "description": "metta.agent.lib.modular_network",
        "isExtraImport": true,
        "detail": "metta.agent.lib.modular_network",
        "documentation": {}
    },
    {
        "label": "ObsTokenToBoxShaper",
        "importPath": "metta.agent.lib.obs_token_to_box_shaper",
        "description": "metta.agent.lib.obs_token_to_box_shaper",
        "isExtraImport": true,
        "detail": "metta.agent.lib.obs_token_to_box_shaper",
        "documentation": {}
    },
    {
        "label": "ObsTokenPadStrip",
        "importPath": "metta.agent.lib.obs_tokenizers",
        "description": "metta.agent.lib.obs_tokenizers",
        "isExtraImport": true,
        "detail": "metta.agent.lib.obs_tokenizers",
        "documentation": {}
    },
    {
        "label": "MockPolicy",
        "importPath": "metta.agent.mocks",
        "description": "metta.agent.mocks",
        "isExtraImport": true,
        "detail": "metta.agent.mocks",
        "documentation": {}
    },
    {
        "label": "MockPolicy",
        "importPath": "metta.agent.mocks",
        "description": "metta.agent.mocks",
        "isExtraImport": true,
        "detail": "metta.agent.mocks",
        "documentation": {}
    },
    {
        "label": "MockPolicyRecord",
        "importPath": "metta.agent.mocks",
        "description": "metta.agent.mocks",
        "isExtraImport": true,
        "detail": "metta.agent.mocks",
        "documentation": {}
    },
    {
        "label": "MockPolicyRecord",
        "importPath": "metta.agent.mocks",
        "description": "metta.agent.mocks",
        "isExtraImport": true,
        "detail": "metta.agent.mocks",
        "documentation": {}
    },
    {
        "label": "MockPolicyRecord",
        "importPath": "metta.agent.mocks",
        "description": "metta.agent.mocks",
        "isExtraImport": true,
        "detail": "metta.agent.mocks",
        "documentation": {}
    },
    {
        "label": "tempfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tempfile",
        "description": "tempfile",
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "mkstemp",
        "importPath": "tempfile",
        "description": "tempfile",
        "isExtraImport": true,
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "fastapi",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "fastapi",
        "description": "fastapi",
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "APIRouter",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Depends",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "APIRouter",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Depends",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "APIRouter",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Depends",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Query",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "APIRouter",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Query",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Depends",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Request",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "status",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Request",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Response",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Request",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "WebSocket",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Connection",
        "importPath": "psycopg",
        "description": "psycopg",
        "isExtraImport": true,
        "detail": "psycopg",
        "documentation": {}
    },
    {
        "label": "errors",
        "importPath": "psycopg",
        "description": "psycopg",
        "isExtraImport": true,
        "detail": "psycopg",
        "documentation": {}
    },
    {
        "label": "Connection",
        "importPath": "psycopg",
        "description": "psycopg",
        "isExtraImport": true,
        "detail": "psycopg",
        "documentation": {}
    },
    {
        "label": "Connection",
        "importPath": "psycopg",
        "description": "psycopg",
        "isExtraImport": true,
        "detail": "psycopg",
        "documentation": {}
    },
    {
        "label": "Cursor",
        "importPath": "psycopg",
        "description": "psycopg",
        "isExtraImport": true,
        "detail": "psycopg",
        "documentation": {}
    },
    {
        "label": "Connection",
        "importPath": "psycopg",
        "description": "psycopg",
        "isExtraImport": true,
        "detail": "psycopg",
        "documentation": {}
    },
    {
        "label": "sql",
        "importPath": "psycopg",
        "description": "psycopg",
        "isExtraImport": true,
        "detail": "psycopg",
        "documentation": {}
    },
    {
        "label": "class_row",
        "importPath": "psycopg.rows",
        "description": "psycopg.rows",
        "isExtraImport": true,
        "detail": "psycopg.rows",
        "documentation": {}
    },
    {
        "label": "TupleRow",
        "importPath": "psycopg.rows",
        "description": "psycopg.rows",
        "isExtraImport": true,
        "detail": "psycopg.rows",
        "documentation": {}
    },
    {
        "label": "SQL",
        "importPath": "psycopg.sql",
        "description": "psycopg.sql",
        "isExtraImport": true,
        "detail": "psycopg.sql",
        "documentation": {}
    },
    {
        "label": "Composable",
        "importPath": "psycopg.sql",
        "description": "psycopg.sql",
        "isExtraImport": true,
        "detail": "psycopg.sql",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "Field",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "ConfigDict",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "Field",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "TypeAdapter",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "ValidationError",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "validate_call",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "ConfigDict",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "Field",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "Field",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "ConfigDict",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "Field",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "model_validator",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "validate_call",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "model_validator",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "Field",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "RootModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "conint",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "Field",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "RootModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "validate_call",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "ValidationError",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "ValidationError",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "ValidationError",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "ValidationError",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "query_logger",
        "importPath": "metta.app_backend",
        "description": "metta.app_backend",
        "isExtraImport": true,
        "detail": "metta.app_backend",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "metta.app_backend",
        "description": "metta.app_backend",
        "isExtraImport": true,
        "detail": "metta.app_backend",
        "documentation": {}
    },
    {
        "label": "create_user_or_token_dependency",
        "importPath": "metta.app_backend.auth",
        "description": "metta.app_backend.auth",
        "isExtraImport": true,
        "detail": "metta.app_backend.auth",
        "documentation": {}
    },
    {
        "label": "create_user_or_token_dependency",
        "importPath": "metta.app_backend.auth",
        "description": "metta.app_backend.auth",
        "isExtraImport": true,
        "detail": "metta.app_backend.auth",
        "documentation": {}
    },
    {
        "label": "create_user_or_token_dependency",
        "importPath": "metta.app_backend.auth",
        "description": "metta.app_backend.auth",
        "isExtraImport": true,
        "detail": "metta.app_backend.auth",
        "documentation": {}
    },
    {
        "label": "UserEmail",
        "importPath": "metta.app_backend.auth",
        "description": "metta.app_backend.auth",
        "isExtraImport": true,
        "detail": "metta.app_backend.auth",
        "documentation": {}
    },
    {
        "label": "user_from_header_or_token",
        "importPath": "metta.app_backend.auth",
        "description": "metta.app_backend.auth",
        "isExtraImport": true,
        "detail": "metta.app_backend.auth",
        "documentation": {}
    },
    {
        "label": "MettaRepo",
        "importPath": "metta.app_backend.metta_repo",
        "description": "metta.app_backend.metta_repo",
        "isExtraImport": true,
        "detail": "metta.app_backend.metta_repo",
        "documentation": {}
    },
    {
        "label": "MettaRepo",
        "importPath": "metta.app_backend.metta_repo",
        "description": "metta.app_backend.metta_repo",
        "isExtraImport": true,
        "detail": "metta.app_backend.metta_repo",
        "documentation": {}
    },
    {
        "label": "MettaRepo",
        "importPath": "metta.app_backend.metta_repo",
        "description": "metta.app_backend.metta_repo",
        "isExtraImport": true,
        "detail": "metta.app_backend.metta_repo",
        "documentation": {}
    },
    {
        "label": "MettaRepo",
        "importPath": "metta.app_backend.metta_repo",
        "description": "metta.app_backend.metta_repo",
        "isExtraImport": true,
        "detail": "metta.app_backend.metta_repo",
        "documentation": {}
    },
    {
        "label": "MettaRepo",
        "importPath": "metta.app_backend.metta_repo",
        "description": "metta.app_backend.metta_repo",
        "isExtraImport": true,
        "detail": "metta.app_backend.metta_repo",
        "documentation": {}
    },
    {
        "label": "MettaRepo",
        "importPath": "metta.app_backend.metta_repo",
        "description": "metta.app_backend.metta_repo",
        "isExtraImport": true,
        "detail": "metta.app_backend.metta_repo",
        "documentation": {}
    },
    {
        "label": "MettaRepo",
        "importPath": "metta.app_backend.metta_repo",
        "description": "metta.app_backend.metta_repo",
        "isExtraImport": true,
        "detail": "metta.app_backend.metta_repo",
        "documentation": {}
    },
    {
        "label": "MettaRepo",
        "importPath": "metta.app_backend.metta_repo",
        "description": "metta.app_backend.metta_repo",
        "isExtraImport": true,
        "detail": "metta.app_backend.metta_repo",
        "documentation": {}
    },
    {
        "label": "MettaRepo",
        "importPath": "metta.app_backend.metta_repo",
        "description": "metta.app_backend.metta_repo",
        "isExtraImport": true,
        "detail": "metta.app_backend.metta_repo",
        "documentation": {}
    },
    {
        "label": "MettaRepo",
        "importPath": "metta.app_backend.metta_repo",
        "description": "metta.app_backend.metta_repo",
        "isExtraImport": true,
        "detail": "metta.app_backend.metta_repo",
        "documentation": {}
    },
    {
        "label": "MettaRepo",
        "importPath": "metta.app_backend.metta_repo",
        "description": "metta.app_backend.metta_repo",
        "isExtraImport": true,
        "detail": "metta.app_backend.metta_repo",
        "documentation": {}
    },
    {
        "label": "execute_query_and_log",
        "importPath": "metta.app_backend.query_logger",
        "description": "metta.app_backend.query_logger",
        "isExtraImport": true,
        "detail": "metta.app_backend.query_logger",
        "documentation": {}
    },
    {
        "label": "execute_query_and_log",
        "importPath": "metta.app_backend.query_logger",
        "description": "metta.app_backend.query_logger",
        "isExtraImport": true,
        "detail": "metta.app_backend.query_logger",
        "documentation": {}
    },
    {
        "label": "timed_route",
        "importPath": "metta.app_backend.route_logger",
        "description": "metta.app_backend.route_logger",
        "isExtraImport": true,
        "detail": "metta.app_backend.route_logger",
        "documentation": {}
    },
    {
        "label": "timed_route",
        "importPath": "metta.app_backend.route_logger",
        "description": "metta.app_backend.route_logger",
        "isExtraImport": true,
        "detail": "metta.app_backend.route_logger",
        "documentation": {}
    },
    {
        "label": "timed_route",
        "importPath": "metta.app_backend.route_logger",
        "description": "metta.app_backend.route_logger",
        "isExtraImport": true,
        "detail": "metta.app_backend.route_logger",
        "documentation": {}
    },
    {
        "label": "timed_route",
        "importPath": "metta.app_backend.route_logger",
        "description": "metta.app_backend.route_logger",
        "isExtraImport": true,
        "detail": "metta.app_backend.route_logger",
        "documentation": {}
    },
    {
        "label": "asyncio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "asyncio",
        "description": "asyncio",
        "detail": "asyncio",
        "documentation": {}
    },
    {
        "label": "uuid",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "uuid",
        "description": "uuid",
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "UUID",
        "importPath": "uuid",
        "description": "uuid",
        "isExtraImport": true,
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "RedirectResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "HTMLResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "FileResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "HTMLResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "hashlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib",
        "description": "hashlib",
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "secrets",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "secrets",
        "description": "secrets",
        "detail": "secrets",
        "documentation": {}
    },
    {
        "label": "Jsonb",
        "importPath": "psycopg.types.json",
        "description": "psycopg.types.json",
        "isExtraImport": true,
        "detail": "psycopg.types.json",
        "documentation": {}
    },
    {
        "label": "SqlMigration",
        "importPath": "metta.app_backend.schema_manager",
        "description": "metta.app_backend.schema_manager",
        "isExtraImport": true,
        "detail": "metta.app_backend.schema_manager",
        "documentation": {}
    },
    {
        "label": "run_migrations",
        "importPath": "metta.app_backend.schema_manager",
        "description": "metta.app_backend.schema_manager",
        "isExtraImport": true,
        "detail": "metta.app_backend.schema_manager",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "redirect_stdout",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "Query",
        "importPath": "psycopg.abc",
        "description": "psycopg.abc",
        "isExtraImport": true,
        "detail": "psycopg.abc",
        "documentation": {}
    },
    {
        "label": "functools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "functools",
        "description": "functools",
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "uvicorn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "uvicorn",
        "description": "uvicorn",
        "detail": "uvicorn",
        "documentation": {}
    },
    {
        "label": "CORSMiddleware",
        "importPath": "fastapi.middleware.cors",
        "description": "fastapi.middleware.cors",
        "isExtraImport": true,
        "detail": "fastapi.middleware.cors",
        "documentation": {}
    },
    {
        "label": "CORSMiddleware",
        "importPath": "fastapi.middleware.cors",
        "description": "fastapi.middleware.cors",
        "isExtraImport": true,
        "detail": "fastapi.middleware.cors",
        "documentation": {}
    },
    {
        "label": "dashboard_routes",
        "importPath": "metta.app_backend.routes",
        "description": "metta.app_backend.routes",
        "isExtraImport": true,
        "detail": "metta.app_backend.routes",
        "documentation": {}
    },
    {
        "label": "sql_routes",
        "importPath": "metta.app_backend.routes",
        "description": "metta.app_backend.routes",
        "isExtraImport": true,
        "detail": "metta.app_backend.routes",
        "documentation": {}
    },
    {
        "label": "stats_routes",
        "importPath": "metta.app_backend.routes",
        "description": "metta.app_backend.routes",
        "isExtraImport": true,
        "detail": "metta.app_backend.routes",
        "documentation": {}
    },
    {
        "label": "token_routes",
        "importPath": "metta.app_backend.routes",
        "description": "metta.app_backend.routes",
        "isExtraImport": true,
        "detail": "metta.app_backend.routes",
        "documentation": {}
    },
    {
        "label": "httpx",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "httpx",
        "description": "httpx",
        "detail": "httpx",
        "documentation": {}
    },
    {
        "label": "Client",
        "importPath": "httpx",
        "description": "httpx",
        "isExtraImport": true,
        "detail": "httpx",
        "documentation": {}
    },
    {
        "label": "EpisodeCreate",
        "importPath": "metta.app_backend.routes.stats_routes",
        "description": "metta.app_backend.routes.stats_routes",
        "isExtraImport": true,
        "detail": "metta.app_backend.routes.stats_routes",
        "documentation": {}
    },
    {
        "label": "EpochCreate",
        "importPath": "metta.app_backend.routes.stats_routes",
        "description": "metta.app_backend.routes.stats_routes",
        "isExtraImport": true,
        "detail": "metta.app_backend.routes.stats_routes",
        "documentation": {}
    },
    {
        "label": "PolicyCreate",
        "importPath": "metta.app_backend.routes.stats_routes",
        "description": "metta.app_backend.routes.stats_routes",
        "isExtraImport": true,
        "detail": "metta.app_backend.routes.stats_routes",
        "documentation": {}
    },
    {
        "label": "PolicyIdResponse",
        "importPath": "metta.app_backend.routes.stats_routes",
        "description": "metta.app_backend.routes.stats_routes",
        "isExtraImport": true,
        "detail": "metta.app_backend.routes.stats_routes",
        "documentation": {}
    },
    {
        "label": "TrainingRunCreate",
        "importPath": "metta.app_backend.routes.stats_routes",
        "description": "metta.app_backend.routes.stats_routes",
        "isExtraImport": true,
        "detail": "metta.app_backend.routes.stats_routes",
        "documentation": {}
    },
    {
        "label": "unittest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "unittest",
        "description": "unittest",
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "mock",
        "importPath": "unittest",
        "description": "unittest",
        "isExtraImport": true,
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "ClientEpochResponse",
        "importPath": "metta.app_backend.stats_client",
        "description": "metta.app_backend.stats_client",
        "isExtraImport": true,
        "detail": "metta.app_backend.stats_client",
        "documentation": {}
    },
    {
        "label": "ClientPolicyResponse",
        "importPath": "metta.app_backend.stats_client",
        "description": "metta.app_backend.stats_client",
        "isExtraImport": true,
        "detail": "metta.app_backend.stats_client",
        "documentation": {}
    },
    {
        "label": "ClientTrainingRunResponse",
        "importPath": "metta.app_backend.stats_client",
        "description": "metta.app_backend.stats_client",
        "isExtraImport": true,
        "detail": "metta.app_backend.stats_client",
        "documentation": {}
    },
    {
        "label": "StatsClient",
        "importPath": "metta.app_backend.stats_client",
        "description": "metta.app_backend.stats_client",
        "isExtraImport": true,
        "detail": "metta.app_backend.stats_client",
        "documentation": {}
    },
    {
        "label": "StatsClient",
        "importPath": "metta.app_backend.stats_client",
        "description": "metta.app_backend.stats_client",
        "isExtraImport": true,
        "detail": "metta.app_backend.stats_client",
        "documentation": {}
    },
    {
        "label": "StatsClient",
        "importPath": "metta.app_backend.stats_client",
        "description": "metta.app_backend.stats_client",
        "isExtraImport": true,
        "detail": "metta.app_backend.stats_client",
        "documentation": {}
    },
    {
        "label": "StatsClient",
        "importPath": "metta.app_backend.stats_client",
        "description": "metta.app_backend.stats_client",
        "isExtraImport": true,
        "detail": "metta.app_backend.stats_client",
        "documentation": {}
    },
    {
        "label": "StatsClient",
        "importPath": "metta.app_backend.stats_client",
        "description": "metta.app_backend.stats_client",
        "isExtraImport": true,
        "detail": "metta.app_backend.stats_client",
        "documentation": {}
    },
    {
        "label": "StatsClient",
        "importPath": "metta.app_backend.stats_client",
        "description": "metta.app_backend.stats_client",
        "isExtraImport": true,
        "detail": "metta.app_backend.stats_client",
        "documentation": {}
    },
    {
        "label": "StatsClient",
        "importPath": "metta.app_backend.stats_client",
        "description": "metta.app_backend.stats_client",
        "isExtraImport": true,
        "detail": "metta.app_backend.stats_client",
        "documentation": {}
    },
    {
        "label": "StatsClient",
        "importPath": "metta.app_backend.stats_client",
        "description": "metta.app_backend.stats_client",
        "isExtraImport": true,
        "detail": "metta.app_backend.stats_client",
        "documentation": {}
    },
    {
        "label": "StatsClient",
        "importPath": "metta.app_backend.stats_client",
        "description": "metta.app_backend.stats_client",
        "isExtraImport": true,
        "detail": "metta.app_backend.stats_client",
        "documentation": {}
    },
    {
        "label": "StatsClient",
        "importPath": "metta.app_backend.stats_client",
        "description": "metta.app_backend.stats_client",
        "isExtraImport": true,
        "detail": "metta.app_backend.stats_client",
        "documentation": {}
    },
    {
        "label": "DockerContainer",
        "importPath": "testcontainers.core.container",
        "description": "testcontainers.core.container",
        "isExtraImport": true,
        "detail": "testcontainers.core.container",
        "documentation": {}
    },
    {
        "label": "PostgresContainer",
        "importPath": "testcontainers.postgres",
        "description": "testcontainers.postgres",
        "isExtraImport": true,
        "detail": "testcontainers.postgres",
        "documentation": {}
    },
    {
        "label": "PostgresContainer",
        "importPath": "testcontainers.postgres",
        "description": "testcontainers.postgres",
        "isExtraImport": true,
        "detail": "testcontainers.postgres",
        "documentation": {}
    },
    {
        "label": "PostgresContainer",
        "importPath": "testcontainers.postgres",
        "description": "testcontainers.postgres",
        "isExtraImport": true,
        "detail": "testcontainers.postgres",
        "documentation": {}
    },
    {
        "label": "PostgresContainer",
        "importPath": "testcontainers.postgres",
        "description": "testcontainers.postgres",
        "isExtraImport": true,
        "detail": "testcontainers.postgres",
        "documentation": {}
    },
    {
        "label": "PostgresContainer",
        "importPath": "testcontainers.postgres",
        "description": "testcontainers.postgres",
        "isExtraImport": true,
        "detail": "testcontainers.postgres",
        "documentation": {}
    },
    {
        "label": "PostgresContainer",
        "importPath": "testcontainers.postgres",
        "description": "testcontainers.postgres",
        "isExtraImport": true,
        "detail": "testcontainers.postgres",
        "documentation": {}
    },
    {
        "label": "TestClient",
        "importPath": "fastapi.testclient",
        "description": "fastapi.testclient",
        "isExtraImport": true,
        "detail": "fastapi.testclient",
        "documentation": {}
    },
    {
        "label": "TestClient",
        "importPath": "fastapi.testclient",
        "description": "fastapi.testclient",
        "isExtraImport": true,
        "detail": "fastapi.testclient",
        "documentation": {}
    },
    {
        "label": "TestClient",
        "importPath": "fastapi.testclient",
        "description": "fastapi.testclient",
        "isExtraImport": true,
        "detail": "fastapi.testclient",
        "documentation": {}
    },
    {
        "label": "TestClient",
        "importPath": "fastapi.testclient",
        "description": "fastapi.testclient",
        "isExtraImport": true,
        "detail": "fastapi.testclient",
        "documentation": {}
    },
    {
        "label": "TestClient",
        "importPath": "fastapi.testclient",
        "description": "fastapi.testclient",
        "isExtraImport": true,
        "detail": "fastapi.testclient",
        "documentation": {}
    },
    {
        "label": "create_app",
        "importPath": "metta.app_backend.server",
        "description": "metta.app_backend.server",
        "isExtraImport": true,
        "detail": "metta.app_backend.server",
        "documentation": {}
    },
    {
        "label": "create_app",
        "importPath": "metta.app_backend.server",
        "description": "metta.app_backend.server",
        "isExtraImport": true,
        "detail": "metta.app_backend.server",
        "documentation": {}
    },
    {
        "label": "create_app",
        "importPath": "metta.app_backend.server",
        "description": "metta.app_backend.server",
        "isExtraImport": true,
        "detail": "metta.app_backend.server",
        "documentation": {}
    },
    {
        "label": "create_app",
        "importPath": "metta.app_backend.server",
        "description": "metta.app_backend.server",
        "isExtraImport": true,
        "detail": "metta.app_backend.server",
        "documentation": {}
    },
    {
        "label": "create_app",
        "importPath": "metta.app_backend.server",
        "description": "metta.app_backend.server",
        "isExtraImport": true,
        "detail": "metta.app_backend.server",
        "documentation": {}
    },
    {
        "label": "inspect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "inspect",
        "description": "inspect",
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "weakref",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "weakref",
        "description": "weakref",
        "detail": "weakref",
        "documentation": {}
    },
    {
        "label": "yellow",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "blue",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "bold",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "colorize",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "cyan",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "green",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "magenta",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "red",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "use_colors",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "yellow",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "bold",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "bold",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "green",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "yellow",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "bold",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "red",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "blue",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "green",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "yellow",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "blue",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "bold",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "cyan",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "green",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "magenta",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "red",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "yellow",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "bold",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "cyan",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "green",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "magenta",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "red",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "yellow",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "Fore",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "blue",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "bold",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "colorize",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "cyan",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "green",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "red",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "yellow",
        "importPath": "metta.common.util.colorama",
        "description": "metta.common.util.colorama",
        "isExtraImport": true,
        "detail": "metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "Fore",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "Style",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "init",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "Fore",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "Style",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "signal",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "signal",
        "description": "signal",
        "detail": "signal",
        "documentation": {}
    },
    {
        "label": "torch.distributed",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.distributed",
        "description": "torch.distributed",
        "detail": "torch.distributed",
        "documentation": {}
    },
    {
        "label": "RichHandler",
        "importPath": "rich.logging",
        "description": "rich.logging",
        "isExtraImport": true,
        "detail": "rich.logging",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "override",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "NotRequired",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "override",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "config_from_path",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "copy_omegaconf_config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "config_from_path",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "copy_omegaconf_config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "config_from_path",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "config_from_path",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "metta.common.util.config",
        "description": "metta.common.util.config",
        "isExtraImport": true,
        "detail": "metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "Callback",
        "importPath": "hydra.experimental.callback",
        "description": "hydra.experimental.callback",
        "isExtraImport": true,
        "detail": "hydra.experimental.callback",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_logger",
        "importPath": "metta.common.util.logging",
        "description": "metta.common.util.logging",
        "isExtraImport": true,
        "detail": "metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_logger",
        "importPath": "metta.common.util.logging",
        "description": "metta.common.util.logging",
        "isExtraImport": true,
        "detail": "metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_logger",
        "importPath": "metta.common.util.logging",
        "description": "metta.common.util.logging",
        "isExtraImport": true,
        "detail": "metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_logger",
        "importPath": "metta.common.util.logging",
        "description": "metta.common.util.logging",
        "isExtraImport": true,
        "detail": "metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_logger",
        "importPath": "metta.common.util.logging",
        "description": "metta.common.util.logging",
        "isExtraImport": true,
        "detail": "metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_logger",
        "importPath": "metta.common.util.logging",
        "description": "metta.common.util.logging",
        "isExtraImport": true,
        "detail": "metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_logger",
        "importPath": "metta.common.util.logging",
        "description": "metta.common.util.logging",
        "isExtraImport": true,
        "detail": "metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_logger",
        "importPath": "metta.common.util.logging",
        "description": "metta.common.util.logging",
        "isExtraImport": true,
        "detail": "metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_logger",
        "importPath": "metta.common.util.logging",
        "description": "metta.common.util.logging",
        "isExtraImport": true,
        "detail": "metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_logger",
        "importPath": "metta.common.util.logging",
        "description": "metta.common.util.logging",
        "isExtraImport": true,
        "detail": "metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_logger",
        "importPath": "metta.common.util.logging",
        "description": "metta.common.util.logging",
        "isExtraImport": true,
        "detail": "metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_logger",
        "importPath": "metta.common.util.logging",
        "description": "metta.common.util.logging",
        "isExtraImport": true,
        "detail": "metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_logger",
        "importPath": "metta.common.util.logging",
        "description": "metta.common.util.logging",
        "isExtraImport": true,
        "detail": "metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_logger",
        "importPath": "metta.common.util.logging",
        "description": "metta.common.util.logging",
        "isExtraImport": true,
        "detail": "metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_logger",
        "importPath": "metta.common.util.logging",
        "description": "metta.common.util.logging",
        "isExtraImport": true,
        "detail": "metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_logger",
        "importPath": "metta.common.util.logging",
        "description": "metta.common.util.logging",
        "isExtraImport": true,
        "detail": "metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_logger",
        "importPath": "metta.common.util.logging",
        "description": "metta.common.util.logging",
        "isExtraImport": true,
        "detail": "metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_logger",
        "importPath": "metta.common.util.logging",
        "description": "metta.common.util.logging",
        "isExtraImport": true,
        "detail": "metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf.omegaconf",
        "description": "omegaconf.omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf.omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf.omegaconf",
        "description": "omegaconf.omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf.omegaconf",
        "documentation": {}
    },
    {
        "label": "traceback",
        "importPath": "rich",
        "description": "rich",
        "isExtraImport": true,
        "detail": "rich",
        "documentation": {}
    },
    {
        "label": "traceback",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "traceback",
        "description": "traceback",
        "detail": "traceback",
        "documentation": {}
    },
    {
        "label": "yaml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yaml",
        "description": "yaml",
        "detail": "yaml",
        "documentation": {}
    },
    {
        "label": "get_repo_root",
        "importPath": "metta.common.util.fs",
        "description": "metta.common.util.fs",
        "isExtraImport": true,
        "detail": "metta.common.util.fs",
        "documentation": {}
    },
    {
        "label": "cd_repo_root",
        "importPath": "metta.common.util.fs",
        "description": "metta.common.util.fs",
        "isExtraImport": true,
        "detail": "metta.common.util.fs",
        "documentation": {}
    },
    {
        "label": "cd_repo_root",
        "importPath": "metta.common.util.fs",
        "description": "metta.common.util.fs",
        "isExtraImport": true,
        "detail": "metta.common.util.fs",
        "documentation": {}
    },
    {
        "label": "cd_repo_root",
        "importPath": "metta.common.util.fs",
        "description": "metta.common.util.fs",
        "isExtraImport": true,
        "detail": "metta.common.util.fs",
        "documentation": {}
    },
    {
        "label": "wait_for_file",
        "importPath": "metta.common.util.fs",
        "description": "metta.common.util.fs",
        "isExtraImport": true,
        "detail": "metta.common.util.fs",
        "documentation": {}
    },
    {
        "label": "atomic_write",
        "importPath": "metta.common.util.fs",
        "description": "metta.common.util.fs",
        "isExtraImport": true,
        "detail": "metta.common.util.fs",
        "documentation": {}
    },
    {
        "label": "cd_repo_root",
        "importPath": "metta.common.util.fs",
        "description": "metta.common.util.fs",
        "isExtraImport": true,
        "detail": "metta.common.util.fs",
        "documentation": {}
    },
    {
        "label": "cd_repo_root",
        "importPath": "metta.common.util.fs",
        "description": "metta.common.util.fs",
        "isExtraImport": true,
        "detail": "metta.common.util.fs",
        "documentation": {}
    },
    {
        "label": "copy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "copy",
        "description": "copy",
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "wandb.errors",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "wandb.errors",
        "description": "wandb.errors",
        "detail": "wandb.errors",
        "documentation": {}
    },
    {
        "label": "CommError",
        "importPath": "wandb.errors",
        "description": "wandb.errors",
        "isExtraImport": true,
        "detail": "wandb.errors",
        "documentation": {}
    },
    {
        "label": "CommError",
        "importPath": "wandb.errors",
        "description": "wandb.errors",
        "isExtraImport": true,
        "detail": "wandb.errors",
        "documentation": {}
    },
    {
        "label": "wandb.sdk.wandb_run",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "wandb.sdk.wandb_run",
        "description": "wandb.sdk.wandb_run",
        "detail": "wandb.sdk.wandb_run",
        "documentation": {}
    },
    {
        "label": "get_object_size",
        "importPath": "metta.common.profiling.memory_monitor",
        "description": "metta.common.profiling.memory_monitor",
        "isExtraImport": true,
        "detail": "metta.common.profiling.memory_monitor",
        "documentation": {}
    },
    {
        "label": "MemoryMonitor",
        "importPath": "metta.common.profiling.memory_monitor",
        "description": "metta.common.profiling.memory_monitor",
        "isExtraImport": true,
        "detail": "metta.common.profiling.memory_monitor",
        "documentation": {}
    },
    {
        "label": "Checkpoint",
        "importPath": "metta.common.profiling.stopwatch",
        "description": "metta.common.profiling.stopwatch",
        "isExtraImport": true,
        "detail": "metta.common.profiling.stopwatch",
        "documentation": {}
    },
    {
        "label": "Stopwatch",
        "importPath": "metta.common.profiling.stopwatch",
        "description": "metta.common.profiling.stopwatch",
        "isExtraImport": true,
        "detail": "metta.common.profiling.stopwatch",
        "documentation": {}
    },
    {
        "label": "with_instance_timer",
        "importPath": "metta.common.profiling.stopwatch",
        "description": "metta.common.profiling.stopwatch",
        "isExtraImport": true,
        "detail": "metta.common.profiling.stopwatch",
        "documentation": {}
    },
    {
        "label": "with_timer",
        "importPath": "metta.common.profiling.stopwatch",
        "description": "metta.common.profiling.stopwatch",
        "isExtraImport": true,
        "detail": "metta.common.profiling.stopwatch",
        "documentation": {}
    },
    {
        "label": "Stopwatch",
        "importPath": "metta.common.profiling.stopwatch",
        "description": "metta.common.profiling.stopwatch",
        "isExtraImport": true,
        "detail": "metta.common.profiling.stopwatch",
        "documentation": {}
    },
    {
        "label": "with_instance_timer",
        "importPath": "metta.common.profiling.stopwatch",
        "description": "metta.common.profiling.stopwatch",
        "isExtraImport": true,
        "detail": "metta.common.profiling.stopwatch",
        "documentation": {}
    },
    {
        "label": "Stopwatch",
        "importPath": "metta.common.profiling.stopwatch",
        "description": "metta.common.profiling.stopwatch",
        "isExtraImport": true,
        "detail": "metta.common.profiling.stopwatch",
        "documentation": {}
    },
    {
        "label": "with_instance_timer",
        "importPath": "metta.common.profiling.stopwatch",
        "description": "metta.common.profiling.stopwatch",
        "isExtraImport": true,
        "detail": "metta.common.profiling.stopwatch",
        "documentation": {}
    },
    {
        "label": "patch",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "Mock",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "patch",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "MagicMock",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "patch",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "Mock",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "patch",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "Mock",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "die",
        "importPath": "metta.common.util.cli",
        "description": "metta.common.util.cli",
        "isExtraImport": true,
        "detail": "metta.common.util.cli",
        "documentation": {}
    },
    {
        "label": "get_user_confirmation",
        "importPath": "metta.common.util.cli",
        "description": "metta.common.util.cli",
        "isExtraImport": true,
        "detail": "metta.common.util.cli",
        "documentation": {}
    },
    {
        "label": "sh",
        "importPath": "metta.common.util.cli",
        "description": "metta.common.util.cli",
        "isExtraImport": true,
        "detail": "metta.common.util.cli",
        "documentation": {}
    },
    {
        "label": "get_user_confirmation",
        "importPath": "metta.common.util.cli",
        "description": "metta.common.util.cli",
        "isExtraImport": true,
        "detail": "metta.common.util.cli",
        "documentation": {}
    },
    {
        "label": "get_user_confirmation",
        "importPath": "metta.common.util.cli",
        "description": "metta.common.util.cli",
        "isExtraImport": true,
        "detail": "metta.common.util.cli",
        "documentation": {}
    },
    {
        "label": "sh",
        "importPath": "metta.common.util.cli",
        "description": "metta.common.util.cli",
        "isExtraImport": true,
        "detail": "metta.common.util.cli",
        "documentation": {}
    },
    {
        "label": "get_user_confirmation",
        "importPath": "metta.common.util.cli",
        "description": "metta.common.util.cli",
        "isExtraImport": true,
        "detail": "metta.common.util.cli",
        "documentation": {}
    },
    {
        "label": "flatten_config",
        "importPath": "metta.common.util.datastruct",
        "description": "metta.common.util.datastruct",
        "isExtraImport": true,
        "detail": "metta.common.util.datastruct",
        "documentation": {}
    },
    {
        "label": "GitError",
        "importPath": "metta.common.util.git",
        "description": "metta.common.util.git",
        "isExtraImport": true,
        "detail": "metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "get_branch_commit",
        "importPath": "metta.common.util.git",
        "description": "metta.common.util.git",
        "isExtraImport": true,
        "detail": "metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "get_commit_message",
        "importPath": "metta.common.util.git",
        "description": "metta.common.util.git",
        "isExtraImport": true,
        "detail": "metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "get_current_branch",
        "importPath": "metta.common.util.git",
        "description": "metta.common.util.git",
        "isExtraImport": true,
        "detail": "metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "get_current_commit",
        "importPath": "metta.common.util.git",
        "description": "metta.common.util.git",
        "isExtraImport": true,
        "detail": "metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "has_unstaged_changes",
        "importPath": "metta.common.util.git",
        "description": "metta.common.util.git",
        "isExtraImport": true,
        "detail": "metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "is_commit_pushed",
        "importPath": "metta.common.util.git",
        "description": "metta.common.util.git",
        "isExtraImport": true,
        "detail": "metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "run_git",
        "importPath": "metta.common.util.git",
        "description": "metta.common.util.git",
        "isExtraImport": true,
        "detail": "metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "validate_git_ref",
        "importPath": "metta.common.util.git",
        "description": "metta.common.util.git",
        "isExtraImport": true,
        "detail": "metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "get_current_commit",
        "importPath": "metta.common.util.git",
        "description": "metta.common.util.git",
        "isExtraImport": true,
        "detail": "metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "validate_git_ref",
        "importPath": "metta.common.util.git",
        "description": "metta.common.util.git",
        "isExtraImport": true,
        "detail": "metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "get_commit_message",
        "importPath": "metta.common.util.git",
        "description": "metta.common.util.git",
        "isExtraImport": true,
        "detail": "metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "get_matched_pr",
        "importPath": "metta.common.util.git",
        "description": "metta.common.util.git",
        "isExtraImport": true,
        "detail": "metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "has_unstaged_changes",
        "importPath": "metta.common.util.git",
        "description": "metta.common.util.git",
        "isExtraImport": true,
        "detail": "metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "is_commit_pushed",
        "importPath": "metta.common.util.git",
        "description": "metta.common.util.git",
        "isExtraImport": true,
        "detail": "metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "clean_numpy_types",
        "importPath": "metta.common.util.numpy_helpers",
        "description": "metta.common.util.numpy_helpers",
        "isExtraImport": true,
        "detail": "metta.common.util.numpy_helpers",
        "documentation": {}
    },
    {
        "label": "clean_numpy_types",
        "importPath": "metta.common.util.numpy_helpers",
        "description": "metta.common.util.numpy_helpers",
        "isExtraImport": true,
        "detail": "metta.common.util.numpy_helpers",
        "documentation": {}
    },
    {
        "label": "oc_add",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_choose",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_clamp",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_date_format",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_divide",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_equals",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_greater_than",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_greater_than_or_equal",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_if",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_iir",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_less_than",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_less_than_or_equal",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_make_integer",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_multiply",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_scale",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_scaled_range",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_subtract",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_to_odd_min3",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_uniform",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "register_resolvers",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "register_resolvers",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "register_resolvers",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "register_resolvers",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "register_resolvers",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "register_resolvers",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "register_resolvers",
        "importPath": "metta.common.util.resolvers",
        "description": "metta.common.util.resolvers",
        "isExtraImport": true,
        "detail": "metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "SystemMonitor",
        "importPath": "metta.common.util.system_monitor",
        "description": "metta.common.util.system_monitor",
        "isExtraImport": true,
        "detail": "metta.common.util.system_monitor",
        "documentation": {}
    },
    {
        "label": "SystemMonitor",
        "importPath": "metta.common.util.system_monitor",
        "description": "metta.common.util.system_monitor",
        "isExtraImport": true,
        "detail": "metta.common.util.system_monitor",
        "documentation": {}
    },
    {
        "label": "WandbConfigOff",
        "importPath": "metta.common.wandb.wandb_context",
        "description": "metta.common.wandb.wandb_context",
        "isExtraImport": true,
        "detail": "metta.common.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "WandbConfigOn",
        "importPath": "metta.common.wandb.wandb_context",
        "description": "metta.common.wandb.wandb_context",
        "isExtraImport": true,
        "detail": "metta.common.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "WandbContext",
        "importPath": "metta.common.wandb.wandb_context",
        "description": "metta.common.wandb.wandb_context",
        "isExtraImport": true,
        "detail": "metta.common.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "WandbRun",
        "importPath": "metta.common.wandb.wandb_context",
        "description": "metta.common.wandb.wandb_context",
        "isExtraImport": true,
        "detail": "metta.common.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "WandbRun",
        "importPath": "metta.common.wandb.wandb_context",
        "description": "metta.common.wandb.wandb_context",
        "isExtraImport": true,
        "detail": "metta.common.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "WandbContext",
        "importPath": "metta.common.wandb.wandb_context",
        "description": "metta.common.wandb.wandb_context",
        "isExtraImport": true,
        "detail": "metta.common.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "WandbContext",
        "importPath": "metta.common.wandb.wandb_context",
        "description": "metta.common.wandb.wandb_context",
        "isExtraImport": true,
        "detail": "metta.common.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "WandbContext",
        "importPath": "metta.common.wandb.wandb_context",
        "description": "metta.common.wandb.wandb_context",
        "isExtraImport": true,
        "detail": "metta.common.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "WandbContext",
        "importPath": "metta.common.wandb.wandb_context",
        "description": "metta.common.wandb.wandb_context",
        "isExtraImport": true,
        "detail": "metta.common.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "WandbContext",
        "importPath": "metta.common.wandb.wandb_context",
        "description": "metta.common.wandb.wandb_context",
        "isExtraImport": true,
        "detail": "metta.common.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "WandbRun",
        "importPath": "metta.common.wandb.wandb_context",
        "description": "metta.common.wandb.wandb_context",
        "isExtraImport": true,
        "detail": "metta.common.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "publish_cmdline",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "default_description",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "publish_cmdline",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "default_description",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "publish_cmdline",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "default_description",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "publish_cmdline",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "publish_cmdline",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "default_description",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "publish_cmdline_to_binary",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "default_description",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "publish_cmdline",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "default_description",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "publish_cmdline",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "default_description",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "publish_cmdline",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "publish_cmdline",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "default_description",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "publish_cmdline",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "default_description",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "locale",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "locale",
        "description": "locale",
        "detail": "locale",
        "documentation": {}
    },
    {
        "label": "manpage",
        "importPath": "docutils.writers",
        "description": "docutils.writers",
        "isExtraImport": true,
        "detail": "docutils.writers",
        "documentation": {}
    },
    {
        "label": "Writer",
        "importPath": "docutils.writers.odf_odt",
        "description": "docutils.writers.odf_odt",
        "isExtraImport": true,
        "detail": "docutils.writers.odf_odt",
        "documentation": {}
    },
    {
        "label": "Reader",
        "importPath": "docutils.writers.odf_odt",
        "description": "docutils.writers.odf_odt",
        "isExtraImport": true,
        "detail": "docutils.writers.odf_odt",
        "documentation": {}
    },
    {
        "label": "etree",
        "importPath": "lxml",
        "description": "lxml",
        "isExtraImport": true,
        "detail": "lxml",
        "documentation": {}
    },
    {
        "label": "shlex",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shlex",
        "description": "shlex",
        "detail": "shlex",
        "documentation": {}
    },
    {
        "label": "get_jobs_controller_name",
        "importPath": "devops.skypilot.utils",
        "description": "devops.skypilot.utils",
        "isExtraImport": true,
        "detail": "devops.skypilot.utils",
        "documentation": {}
    },
    {
        "label": "get_jobs_controller_name",
        "importPath": "devops.skypilot.utils",
        "description": "devops.skypilot.utils",
        "isExtraImport": true,
        "detail": "devops.skypilot.utils",
        "documentation": {}
    },
    {
        "label": "check_config_files",
        "importPath": "devops.skypilot.utils",
        "description": "devops.skypilot.utils",
        "isExtraImport": true,
        "detail": "devops.skypilot.utils",
        "documentation": {}
    },
    {
        "label": "check_git_state",
        "importPath": "devops.skypilot.utils",
        "description": "devops.skypilot.utils",
        "isExtraImport": true,
        "detail": "devops.skypilot.utils",
        "documentation": {}
    },
    {
        "label": "display_job_summary",
        "importPath": "devops.skypilot.utils",
        "description": "devops.skypilot.utils",
        "isExtraImport": true,
        "detail": "devops.skypilot.utils",
        "documentation": {}
    },
    {
        "label": "launch_task",
        "importPath": "devops.skypilot.utils",
        "description": "devops.skypilot.utils",
        "isExtraImport": true,
        "detail": "devops.skypilot.utils",
        "documentation": {}
    },
    {
        "label": "sky.jobs",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sky.jobs",
        "description": "sky.jobs",
        "detail": "sky.jobs",
        "documentation": {}
    },
    {
        "label": "sky",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sky",
        "description": "sky",
        "detail": "sky",
        "documentation": {}
    },
    {
        "label": "sky.cli",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sky.cli",
        "description": "sky.cli",
        "detail": "sky.cli",
        "documentation": {}
    },
    {
        "label": "sky.server.common",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sky.server.common",
        "description": "sky.server.common",
        "detail": "sky.server.common",
        "documentation": {}
    },
    {
        "label": "anthropic",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "anthropic",
        "description": "anthropic",
        "detail": "anthropic",
        "documentation": {}
    },
    {
        "label": "webbrowser",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "webbrowser",
        "description": "webbrowser",
        "detail": "webbrowser",
        "documentation": {}
    },
    {
        "label": "urlencode",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "unquote",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "quote",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "quote",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "quote",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "quote",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "quote",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "quote",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "quote",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "tabulate",
        "importPath": "tabulate",
        "description": "tabulate",
        "isExtraImport": true,
        "detail": "tabulate",
        "documentation": {}
    },
    {
        "label": "AnalysisConfig",
        "importPath": "metta.eval.analysis_config",
        "description": "metta.eval.analysis_config",
        "isExtraImport": true,
        "detail": "metta.eval.analysis_config",
        "documentation": {}
    },
    {
        "label": "AnalysisConfig",
        "importPath": "metta.eval.analysis_config",
        "description": "metta.eval.analysis_config",
        "isExtraImport": true,
        "detail": "metta.eval.analysis_config",
        "documentation": {}
    },
    {
        "label": "EvalStatsDB",
        "importPath": "metta.eval.eval_stats_db",
        "description": "metta.eval.eval_stats_db",
        "isExtraImport": true,
        "detail": "metta.eval.eval_stats_db",
        "documentation": {}
    },
    {
        "label": "EvalStatsDB",
        "importPath": "metta.eval.eval_stats_db",
        "description": "metta.eval.eval_stats_db",
        "isExtraImport": true,
        "detail": "metta.eval.eval_stats_db",
        "documentation": {}
    },
    {
        "label": "EvalStatsDB",
        "importPath": "metta.eval.eval_stats_db",
        "description": "metta.eval.eval_stats_db",
        "isExtraImport": true,
        "detail": "metta.eval.eval_stats_db",
        "documentation": {}
    },
    {
        "label": "EvalStatsDB",
        "importPath": "metta.eval.eval_stats_db",
        "description": "metta.eval.eval_stats_db",
        "isExtraImport": true,
        "detail": "metta.eval.eval_stats_db",
        "documentation": {}
    },
    {
        "label": "EvalStatsDB",
        "importPath": "metta.eval.eval_stats_db",
        "description": "metta.eval.eval_stats_db",
        "isExtraImport": true,
        "detail": "metta.eval.eval_stats_db",
        "documentation": {}
    },
    {
        "label": "local_copy",
        "importPath": "metta.mettagrid.util.file",
        "description": "metta.mettagrid.util.file",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.file",
        "documentation": {}
    },
    {
        "label": "write_data",
        "importPath": "metta.mettagrid.util.file",
        "description": "metta.mettagrid.util.file",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.file",
        "documentation": {}
    },
    {
        "label": "local_copy",
        "importPath": "metta.mettagrid.util.file",
        "description": "metta.mettagrid.util.file",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.file",
        "documentation": {}
    },
    {
        "label": "write_file",
        "importPath": "metta.mettagrid.util.file",
        "description": "metta.mettagrid.util.file",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.file",
        "documentation": {}
    },
    {
        "label": "exists",
        "importPath": "metta.mettagrid.util.file",
        "description": "metta.mettagrid.util.file",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.file",
        "documentation": {}
    },
    {
        "label": "local_copy",
        "importPath": "metta.mettagrid.util.file",
        "description": "metta.mettagrid.util.file",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.file",
        "documentation": {}
    },
    {
        "label": "write_file",
        "importPath": "metta.mettagrid.util.file",
        "description": "metta.mettagrid.util.file",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.file",
        "documentation": {}
    },
    {
        "label": "read",
        "importPath": "metta.mettagrid.util.file",
        "description": "metta.mettagrid.util.file",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.file",
        "documentation": {}
    },
    {
        "label": "http_url",
        "importPath": "metta.mettagrid.util.file",
        "description": "metta.mettagrid.util.file",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.file",
        "documentation": {}
    },
    {
        "label": "write_data",
        "importPath": "metta.mettagrid.util.file",
        "description": "metta.mettagrid.util.file",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.file",
        "documentation": {}
    },
    {
        "label": "http_url",
        "importPath": "metta.mettagrid.util.file",
        "description": "metta.mettagrid.util.file",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.file",
        "documentation": {}
    },
    {
        "label": "local_copy",
        "importPath": "metta.mettagrid.util.file",
        "description": "metta.mettagrid.util.file",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.file",
        "documentation": {}
    },
    {
        "label": "PolicySelectorConfig",
        "importPath": "metta.agent.policy_store",
        "description": "metta.agent.policy_store",
        "isExtraImport": true,
        "detail": "metta.agent.policy_store",
        "documentation": {}
    },
    {
        "label": "PolicyStore",
        "importPath": "metta.agent.policy_store",
        "description": "metta.agent.policy_store",
        "isExtraImport": true,
        "detail": "metta.agent.policy_store",
        "documentation": {}
    },
    {
        "label": "PolicyStore",
        "importPath": "metta.agent.policy_store",
        "description": "metta.agent.policy_store",
        "isExtraImport": true,
        "detail": "metta.agent.policy_store",
        "documentation": {}
    },
    {
        "label": "PolicyStore",
        "importPath": "metta.agent.policy_store",
        "description": "metta.agent.policy_store",
        "isExtraImport": true,
        "detail": "metta.agent.policy_store",
        "documentation": {}
    },
    {
        "label": "PolicyStore",
        "importPath": "metta.agent.policy_store",
        "description": "metta.agent.policy_store",
        "isExtraImport": true,
        "detail": "metta.agent.policy_store",
        "documentation": {}
    },
    {
        "label": "PolicyStore",
        "importPath": "metta.agent.policy_store",
        "description": "metta.agent.policy_store",
        "isExtraImport": true,
        "detail": "metta.agent.policy_store",
        "documentation": {}
    },
    {
        "label": "PolicyStore",
        "importPath": "metta.agent.policy_store",
        "description": "metta.agent.policy_store",
        "isExtraImport": true,
        "detail": "metta.agent.policy_store",
        "documentation": {}
    },
    {
        "label": "PolicyStore",
        "importPath": "metta.agent.policy_store",
        "description": "metta.agent.policy_store",
        "isExtraImport": true,
        "detail": "metta.agent.policy_store",
        "documentation": {}
    },
    {
        "label": "PolicyStore",
        "importPath": "metta.agent.policy_store",
        "description": "metta.agent.policy_store",
        "isExtraImport": true,
        "detail": "metta.agent.policy_store",
        "documentation": {}
    },
    {
        "label": "PolicyStore",
        "importPath": "metta.agent.policy_store",
        "description": "metta.agent.policy_store",
        "isExtraImport": true,
        "detail": "metta.agent.policy_store",
        "documentation": {}
    },
    {
        "label": "PolicyStore",
        "importPath": "metta.agent.policy_store",
        "description": "metta.agent.policy_store",
        "isExtraImport": true,
        "detail": "metta.agent.policy_store",
        "documentation": {}
    },
    {
        "label": "PolicyStore",
        "importPath": "metta.agent.policy_store",
        "description": "metta.agent.policy_store",
        "isExtraImport": true,
        "detail": "metta.agent.policy_store",
        "documentation": {}
    },
    {
        "label": "PolicyStore",
        "importPath": "metta.agent.policy_store",
        "description": "metta.agent.policy_store",
        "isExtraImport": true,
        "detail": "metta.agent.policy_store",
        "documentation": {}
    },
    {
        "label": "PolicyStore",
        "importPath": "metta.agent.policy_store",
        "description": "metta.agent.policy_store",
        "isExtraImport": true,
        "detail": "metta.agent.policy_store",
        "documentation": {}
    },
    {
        "label": "PolicyStore",
        "importPath": "metta.agent.policy_store",
        "description": "metta.agent.policy_store",
        "isExtraImport": true,
        "detail": "metta.agent.policy_store",
        "documentation": {}
    },
    {
        "label": "PolicyStore",
        "importPath": "metta.agent.policy_store",
        "description": "metta.agent.policy_store",
        "isExtraImport": true,
        "detail": "metta.agent.policy_store",
        "documentation": {}
    },
    {
        "label": "PolicyStore",
        "importPath": "metta.agent.policy_store",
        "description": "metta.agent.policy_store",
        "isExtraImport": true,
        "detail": "metta.agent.policy_store",
        "documentation": {}
    },
    {
        "label": "SimulationStatsDB",
        "importPath": "metta.sim.simulation_stats_db",
        "description": "metta.sim.simulation_stats_db",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_stats_db",
        "documentation": {}
    },
    {
        "label": "SimulationStatsDB",
        "importPath": "metta.sim.simulation_stats_db",
        "description": "metta.sim.simulation_stats_db",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_stats_db",
        "documentation": {}
    },
    {
        "label": "SimulationStatsDB",
        "importPath": "metta.sim.simulation_stats_db",
        "description": "metta.sim.simulation_stats_db",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_stats_db",
        "documentation": {}
    },
    {
        "label": "SimulationStatsDB",
        "importPath": "metta.sim.simulation_stats_db",
        "description": "metta.sim.simulation_stats_db",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_stats_db",
        "documentation": {}
    },
    {
        "label": "SimulationStatsDB",
        "importPath": "metta.sim.simulation_stats_db",
        "description": "metta.sim.simulation_stats_db",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_stats_db",
        "documentation": {}
    },
    {
        "label": "SimulationStatsDB",
        "importPath": "metta.sim.simulation_stats_db",
        "description": "metta.sim.simulation_stats_db",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_stats_db",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "Scene",
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "isExtraImport": true,
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "Scene",
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "isExtraImport": true,
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "Scene",
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "isExtraImport": true,
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "Scene",
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "isExtraImport": true,
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "Scene",
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "isExtraImport": true,
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "Scene",
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "isExtraImport": true,
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "Scene",
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "isExtraImport": true,
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "Scene",
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "isExtraImport": true,
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "make_scene",
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "isExtraImport": true,
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "Scene",
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "isExtraImport": true,
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "Scene",
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "isExtraImport": true,
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "Scene",
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "isExtraImport": true,
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "Scene",
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "isExtraImport": true,
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "Scene",
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "isExtraImport": true,
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "Scene",
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "isExtraImport": true,
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "Scene",
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "isExtraImport": true,
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "Scene",
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "isExtraImport": true,
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "Scene",
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "isExtraImport": true,
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "make_scene",
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "isExtraImport": true,
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "make_scene",
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "isExtraImport": true,
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "Scene",
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "isExtraImport": true,
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "Scene",
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "isExtraImport": true,
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "InlineAscii",
        "importPath": "metta.map.scenes.inline_ascii",
        "description": "metta.map.scenes.inline_ascii",
        "isExtraImport": true,
        "detail": "metta.map.scenes.inline_ascii",
        "documentation": {}
    },
    {
        "label": "InlineAscii",
        "importPath": "metta.map.scenes.inline_ascii",
        "description": "metta.map.scenes.inline_ascii",
        "isExtraImport": true,
        "detail": "metta.map.scenes.inline_ascii",
        "documentation": {}
    },
    {
        "label": "InlineAscii",
        "importPath": "metta.map.scenes.inline_ascii",
        "description": "metta.map.scenes.inline_ascii",
        "isExtraImport": true,
        "detail": "metta.map.scenes.inline_ascii",
        "documentation": {}
    },
    {
        "label": "InlineAscii",
        "importPath": "metta.map.scenes.inline_ascii",
        "description": "metta.map.scenes.inline_ascii",
        "isExtraImport": true,
        "detail": "metta.map.scenes.inline_ascii",
        "documentation": {}
    },
    {
        "label": "ChildrenAction",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "AreaWhere",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "ChildrenAction",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "MapGrid",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "MapGrid",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "SceneCfg",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "AreaWhere",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "ChildrenAction",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "ChildrenAction",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "ChildrenAction",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "SceneCfg",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "ChildrenAction",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "MapGrid",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "MapGrid",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "MapGrid",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "AreaQuery",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "ChildrenAction",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "MapGrid",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "SceneCfg",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "ChildrenAction",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "ChildrenAction",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "AreaQuery",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "ChildrenAction",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "MapGrid",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "AreaQuery",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "AreaWhere",
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "isExtraImport": true,
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "BSPLayout",
        "importPath": "metta.map.scenes.bsp",
        "description": "metta.map.scenes.bsp",
        "isExtraImport": true,
        "detail": "metta.map.scenes.bsp",
        "documentation": {}
    },
    {
        "label": "BSP",
        "importPath": "metta.map.scenes.bsp",
        "description": "metta.map.scenes.bsp",
        "isExtraImport": true,
        "detail": "metta.map.scenes.bsp",
        "documentation": {}
    },
    {
        "label": "MakeConnected",
        "importPath": "metta.map.scenes.make_connected",
        "description": "metta.map.scenes.make_connected",
        "isExtraImport": true,
        "detail": "metta.map.scenes.make_connected",
        "documentation": {}
    },
    {
        "label": "MakeConnected",
        "importPath": "metta.map.scenes.make_connected",
        "description": "metta.map.scenes.make_connected",
        "isExtraImport": true,
        "detail": "metta.map.scenes.make_connected",
        "documentation": {}
    },
    {
        "label": "Mirror",
        "importPath": "metta.map.scenes.mirror",
        "description": "metta.map.scenes.mirror",
        "isExtraImport": true,
        "detail": "metta.map.scenes.mirror",
        "documentation": {}
    },
    {
        "label": "Mirror",
        "importPath": "metta.map.scenes.mirror",
        "description": "metta.map.scenes.mirror",
        "isExtraImport": true,
        "detail": "metta.map.scenes.mirror",
        "documentation": {}
    },
    {
        "label": "Random",
        "importPath": "metta.map.scenes.random",
        "description": "metta.map.scenes.random",
        "isExtraImport": true,
        "detail": "metta.map.scenes.random",
        "documentation": {}
    },
    {
        "label": "Random",
        "importPath": "metta.map.scenes.random",
        "description": "metta.map.scenes.random",
        "isExtraImport": true,
        "detail": "metta.map.scenes.random",
        "documentation": {}
    },
    {
        "label": "Random",
        "importPath": "metta.map.scenes.random",
        "description": "metta.map.scenes.random",
        "isExtraImport": true,
        "detail": "metta.map.scenes.random",
        "documentation": {}
    },
    {
        "label": "Random",
        "importPath": "metta.map.scenes.random",
        "description": "metta.map.scenes.random",
        "isExtraImport": true,
        "detail": "metta.map.scenes.random",
        "documentation": {}
    },
    {
        "label": "RandomObjects",
        "importPath": "metta.map.scenes.random_objects",
        "description": "metta.map.scenes.random_objects",
        "isExtraImport": true,
        "detail": "metta.map.scenes.random_objects",
        "documentation": {}
    },
    {
        "label": "RandomObjects",
        "importPath": "metta.map.scenes.random_objects",
        "description": "metta.map.scenes.random_objects",
        "isExtraImport": true,
        "detail": "metta.map.scenes.random_objects",
        "documentation": {}
    },
    {
        "label": "RandomScene",
        "importPath": "metta.map.scenes.random_scene",
        "description": "metta.map.scenes.random_scene",
        "isExtraImport": true,
        "detail": "metta.map.scenes.random_scene",
        "documentation": {}
    },
    {
        "label": "RandomSceneCandidate",
        "importPath": "metta.map.scenes.random_scene",
        "description": "metta.map.scenes.random_scene",
        "isExtraImport": true,
        "detail": "metta.map.scenes.random_scene",
        "documentation": {}
    },
    {
        "label": "RandomScene",
        "importPath": "metta.map.scenes.random_scene",
        "description": "metta.map.scenes.random_scene",
        "isExtraImport": true,
        "detail": "metta.map.scenes.random_scene",
        "documentation": {}
    },
    {
        "label": "RandomSceneCandidate",
        "importPath": "metta.map.scenes.random_scene",
        "description": "metta.map.scenes.random_scene",
        "isExtraImport": true,
        "detail": "metta.map.scenes.random_scene",
        "documentation": {}
    },
    {
        "label": "RandomScene",
        "importPath": "metta.map.scenes.random_scene",
        "description": "metta.map.scenes.random_scene",
        "isExtraImport": true,
        "detail": "metta.map.scenes.random_scene",
        "documentation": {}
    },
    {
        "label": "RoomGrid",
        "importPath": "metta.map.scenes.room_grid",
        "description": "metta.map.scenes.room_grid",
        "isExtraImport": true,
        "detail": "metta.map.scenes.room_grid",
        "documentation": {}
    },
    {
        "label": "RoomGrid",
        "importPath": "metta.map.scenes.room_grid",
        "description": "metta.map.scenes.room_grid",
        "isExtraImport": true,
        "detail": "metta.map.scenes.room_grid",
        "documentation": {}
    },
    {
        "label": "RoomGrid",
        "importPath": "metta.map.scenes.room_grid",
        "description": "metta.map.scenes.room_grid",
        "isExtraImport": true,
        "detail": "metta.map.scenes.room_grid",
        "documentation": {}
    },
    {
        "label": "RoomGrid",
        "importPath": "metta.map.scenes.room_grid",
        "description": "metta.map.scenes.room_grid",
        "isExtraImport": true,
        "detail": "metta.map.scenes.room_grid",
        "documentation": {}
    },
    {
        "label": "FloatDistribution",
        "importPath": "metta.map.utils.random",
        "description": "metta.map.utils.random",
        "isExtraImport": true,
        "detail": "metta.map.utils.random",
        "documentation": {}
    },
    {
        "label": "IntDistribution",
        "importPath": "metta.map.utils.random",
        "description": "metta.map.utils.random",
        "isExtraImport": true,
        "detail": "metta.map.utils.random",
        "documentation": {}
    },
    {
        "label": "sample_int_distribution",
        "importPath": "metta.map.utils.random",
        "description": "metta.map.utils.random",
        "isExtraImport": true,
        "detail": "metta.map.utils.random",
        "documentation": {}
    },
    {
        "label": "IntDistribution",
        "importPath": "metta.map.utils.random",
        "description": "metta.map.utils.random",
        "isExtraImport": true,
        "detail": "metta.map.utils.random",
        "documentation": {}
    },
    {
        "label": "sample_int_distribution",
        "importPath": "metta.map.utils.random",
        "description": "metta.map.utils.random",
        "isExtraImport": true,
        "detail": "metta.map.utils.random",
        "documentation": {}
    },
    {
        "label": "FloatDistribution",
        "importPath": "metta.map.utils.random",
        "description": "metta.map.utils.random",
        "isExtraImport": true,
        "detail": "metta.map.utils.random",
        "documentation": {}
    },
    {
        "label": "sample_float_distribution",
        "importPath": "metta.map.utils.random",
        "description": "metta.map.utils.random",
        "isExtraImport": true,
        "detail": "metta.map.utils.random",
        "documentation": {}
    },
    {
        "label": "MaybeSeed",
        "importPath": "metta.map.utils.random",
        "description": "metta.map.utils.random",
        "isExtraImport": true,
        "detail": "metta.map.utils.random",
        "documentation": {}
    },
    {
        "label": "Pattern",
        "importPath": "metta.map.utils.pattern",
        "description": "metta.map.utils.pattern",
        "isExtraImport": true,
        "detail": "metta.map.utils.pattern",
        "documentation": {}
    },
    {
        "label": "Symmetry",
        "importPath": "metta.map.utils.pattern",
        "description": "metta.map.utils.pattern",
        "isExtraImport": true,
        "detail": "metta.map.utils.pattern",
        "documentation": {}
    },
    {
        "label": "ascii_to_weights_of_all_patterns",
        "importPath": "metta.map.utils.pattern",
        "description": "metta.map.utils.pattern",
        "isExtraImport": true,
        "detail": "metta.map.utils.pattern",
        "documentation": {}
    },
    {
        "label": "Symmetry",
        "importPath": "metta.map.utils.pattern",
        "description": "metta.map.utils.pattern",
        "isExtraImport": true,
        "detail": "metta.map.utils.pattern",
        "documentation": {}
    },
    {
        "label": "ascii_to_patterns_with_counts",
        "importPath": "metta.map.utils.pattern",
        "description": "metta.map.utils.pattern",
        "isExtraImport": true,
        "detail": "metta.map.utils.pattern",
        "documentation": {}
    },
    {
        "label": "Pattern",
        "importPath": "metta.map.utils.pattern",
        "description": "metta.map.utils.pattern",
        "isExtraImport": true,
        "detail": "metta.map.utils.pattern",
        "documentation": {}
    },
    {
        "label": "ascii_to_patterns_with_counts",
        "importPath": "metta.map.utils.pattern",
        "description": "metta.map.utils.pattern",
        "isExtraImport": true,
        "detail": "metta.map.utils.pattern",
        "documentation": {}
    },
    {
        "label": "ascii_to_weights_of_all_patterns",
        "importPath": "metta.map.utils.pattern",
        "description": "metta.map.utils.pattern",
        "isExtraImport": true,
        "detail": "metta.map.utils.pattern",
        "documentation": {}
    },
    {
        "label": "parse_ascii_into_grid",
        "importPath": "metta.map.utils.pattern",
        "description": "metta.map.utils.pattern",
        "isExtraImport": true,
        "detail": "metta.map.utils.pattern",
        "documentation": {}
    },
    {
        "label": "char_grid_to_lines",
        "importPath": "metta.map.utils.ascii_grid",
        "description": "metta.map.utils.ascii_grid",
        "isExtraImport": true,
        "detail": "metta.map.utils.ascii_grid",
        "documentation": {}
    },
    {
        "label": "char_grid_to_lines",
        "importPath": "metta.map.utils.ascii_grid",
        "description": "metta.map.utils.ascii_grid",
        "isExtraImport": true,
        "detail": "metta.map.utils.ascii_grid",
        "documentation": {}
    },
    {
        "label": "grid_to_lines",
        "importPath": "metta.map.utils.ascii_grid",
        "description": "metta.map.utils.ascii_grid",
        "isExtraImport": true,
        "detail": "metta.map.utils.ascii_grid",
        "documentation": {}
    },
    {
        "label": "lines_to_grid",
        "importPath": "metta.map.utils.ascii_grid",
        "description": "metta.map.utils.ascii_grid",
        "isExtraImport": true,
        "detail": "metta.map.utils.ascii_grid",
        "documentation": {}
    },
    {
        "label": "add_pretty_border",
        "importPath": "metta.map.utils.ascii_grid",
        "description": "metta.map.utils.ascii_grid",
        "isExtraImport": true,
        "detail": "metta.map.utils.ascii_grid",
        "documentation": {}
    },
    {
        "label": "char_grid_to_lines",
        "importPath": "metta.map.utils.ascii_grid",
        "description": "metta.map.utils.ascii_grid",
        "isExtraImport": true,
        "detail": "metta.map.utils.ascii_grid",
        "documentation": {}
    },
    {
        "label": "char_grid_to_lines",
        "importPath": "metta.map.utils.ascii_grid",
        "description": "metta.map.utils.ascii_grid",
        "isExtraImport": true,
        "detail": "metta.map.utils.ascii_grid",
        "documentation": {}
    },
    {
        "label": "char_to_grid_object",
        "importPath": "metta.mettagrid.char_encoder",
        "description": "metta.mettagrid.char_encoder",
        "isExtraImport": true,
        "detail": "metta.mettagrid.char_encoder",
        "documentation": {}
    },
    {
        "label": "char_to_grid_object",
        "importPath": "metta.mettagrid.char_encoder",
        "description": "metta.mettagrid.char_encoder",
        "isExtraImport": true,
        "detail": "metta.mettagrid.char_encoder",
        "documentation": {}
    },
    {
        "label": "grid_object_to_char",
        "importPath": "metta.mettagrid.char_encoder",
        "description": "metta.mettagrid.char_encoder",
        "isExtraImport": true,
        "detail": "metta.mettagrid.char_encoder",
        "documentation": {}
    },
    {
        "label": "grid_object_to_char",
        "importPath": "metta.mettagrid.char_encoder",
        "description": "metta.mettagrid.char_encoder",
        "isExtraImport": true,
        "detail": "metta.mettagrid.char_encoder",
        "documentation": {}
    },
    {
        "label": "char_to_grid_object",
        "importPath": "metta.mettagrid.char_encoder",
        "description": "metta.mettagrid.char_encoder",
        "isExtraImport": true,
        "detail": "metta.mettagrid.char_encoder",
        "documentation": {}
    },
    {
        "label": "CHAR_TO_NAME",
        "importPath": "metta.mettagrid.char_encoder",
        "description": "metta.mettagrid.char_encoder",
        "isExtraImport": true,
        "detail": "metta.mettagrid.char_encoder",
        "documentation": {}
    },
    {
        "label": "CHAR_TO_NAME",
        "importPath": "metta.mettagrid.char_encoder",
        "description": "metta.mettagrid.char_encoder",
        "isExtraImport": true,
        "detail": "metta.mettagrid.char_encoder",
        "documentation": {}
    },
    {
        "label": "normalize_grid_char",
        "importPath": "metta.mettagrid.char_encoder",
        "description": "metta.mettagrid.char_encoder",
        "isExtraImport": true,
        "detail": "metta.mettagrid.char_encoder",
        "documentation": {}
    },
    {
        "label": "normalize_grid_char",
        "importPath": "metta.mettagrid.char_encoder",
        "description": "metta.mettagrid.char_encoder",
        "isExtraImport": true,
        "detail": "metta.mettagrid.char_encoder",
        "documentation": {}
    },
    {
        "label": "scenes_root",
        "importPath": "metta.map.config",
        "description": "metta.map.config",
        "isExtraImport": true,
        "detail": "metta.map.config",
        "documentation": {}
    },
    {
        "label": "scenes_root",
        "importPath": "metta.map.config",
        "description": "metta.map.config",
        "isExtraImport": true,
        "detail": "metta.map.config",
        "documentation": {}
    },
    {
        "label": "scenes_root",
        "importPath": "metta.map.config",
        "description": "metta.map.config",
        "isExtraImport": true,
        "detail": "metta.map.config",
        "documentation": {}
    },
    {
        "label": "heapq",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "heapq",
        "description": "heapq",
        "detail": "heapq",
        "documentation": {}
    },
    {
        "label": "urllib.request",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "urllib.request",
        "description": "urllib.request",
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "Pool",
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "isExtraImport": true,
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "make_convchain_config_from_pattern",
        "importPath": "metta.map.utils.make_scene_config",
        "description": "metta.map.utils.make_scene_config",
        "isExtraImport": true,
        "detail": "metta.map.utils.make_scene_config",
        "documentation": {}
    },
    {
        "label": "make_wfc_config_from_pattern",
        "importPath": "metta.map.utils.make_scene_config",
        "description": "metta.map.utils.make_scene_config",
        "isExtraImport": true,
        "detail": "metta.map.utils.make_scene_config",
        "documentation": {}
    },
    {
        "label": "MapGen",
        "importPath": "metta.map.mapgen",
        "description": "metta.map.mapgen",
        "isExtraImport": true,
        "detail": "metta.map.mapgen",
        "documentation": {}
    },
    {
        "label": "numpy.typing",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy.typing",
        "description": "numpy.typing",
        "detail": "numpy.typing",
        "documentation": {}
    },
    {
        "label": "mettascope.server",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "mettascope.server",
        "description": "mettascope.server",
        "detail": "mettascope.server",
        "documentation": {}
    },
    {
        "label": "StorableMap",
        "importPath": "metta.map.utils.storable_map",
        "description": "metta.map.utils.storable_map",
        "isExtraImport": true,
        "detail": "metta.map.utils.storable_map",
        "documentation": {}
    },
    {
        "label": "grid_to_lines",
        "importPath": "metta.map.utils.storable_map",
        "description": "metta.map.utils.storable_map",
        "isExtraImport": true,
        "detail": "metta.map.utils.storable_map",
        "documentation": {}
    },
    {
        "label": "StorableMap",
        "importPath": "metta.map.utils.storable_map",
        "description": "metta.map.utils.storable_map",
        "isExtraImport": true,
        "detail": "metta.map.utils.storable_map",
        "documentation": {}
    },
    {
        "label": "StorableMap",
        "importPath": "metta.map.utils.storable_map",
        "description": "metta.map.utils.storable_map",
        "isExtraImport": true,
        "detail": "metta.map.utils.storable_map",
        "documentation": {}
    },
    {
        "label": "StorableMapDict",
        "importPath": "metta.map.utils.storable_map",
        "description": "metta.map.utils.storable_map",
        "isExtraImport": true,
        "detail": "metta.map.utils.storable_map",
        "documentation": {}
    },
    {
        "label": "StorableMapIndex",
        "importPath": "metta.map.utils.storable_map",
        "description": "metta.map.utils.storable_map",
        "isExtraImport": true,
        "detail": "metta.map.utils.storable_map",
        "documentation": {}
    },
    {
        "label": "map_builder_cfg_to_storable_map",
        "importPath": "metta.map.utils.storable_map",
        "description": "metta.map.utils.storable_map",
        "isExtraImport": true,
        "detail": "metta.map.utils.storable_map",
        "documentation": {}
    },
    {
        "label": "grid_to_lines",
        "importPath": "metta.map.utils.storable_map",
        "description": "metta.map.utils.storable_map",
        "isExtraImport": true,
        "detail": "metta.map.utils.storable_map",
        "documentation": {}
    },
    {
        "label": "StorableMap",
        "importPath": "metta.map.utils.storable_map",
        "description": "metta.map.utils.storable_map",
        "isExtraImport": true,
        "detail": "metta.map.utils.storable_map",
        "documentation": {}
    },
    {
        "label": "map_builder_cfg_to_storable_map",
        "importPath": "metta.map.utils.storable_map",
        "description": "metta.map.utils.storable_map",
        "isExtraImport": true,
        "detail": "metta.map.utils.storable_map",
        "documentation": {}
    },
    {
        "label": "map_builder_cfg_to_storable_map",
        "importPath": "metta.map.utils.storable_map",
        "description": "metta.map.utils.storable_map",
        "isExtraImport": true,
        "detail": "metta.map.utils.storable_map",
        "documentation": {}
    },
    {
        "label": "StorableMap",
        "importPath": "metta.map.utils.storable_map",
        "description": "metta.map.utils.storable_map",
        "isExtraImport": true,
        "detail": "metta.map.utils.storable_map",
        "documentation": {}
    },
    {
        "label": "SingleTaskCurriculum",
        "importPath": "metta.mettagrid.curriculum.core",
        "description": "metta.mettagrid.curriculum.core",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "Curriculum",
        "importPath": "metta.mettagrid.curriculum.core",
        "description": "metta.mettagrid.curriculum.core",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "Curriculum",
        "importPath": "metta.mettagrid.curriculum.core",
        "description": "metta.mettagrid.curriculum.core",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "SingleTaskCurriculum",
        "importPath": "metta.mettagrid.curriculum.core",
        "description": "metta.mettagrid.curriculum.core",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "Curriculum",
        "importPath": "metta.mettagrid.curriculum.core",
        "description": "metta.mettagrid.curriculum.core",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "Curriculum",
        "importPath": "metta.mettagrid.curriculum.core",
        "description": "metta.mettagrid.curriculum.core",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "Task",
        "importPath": "metta.mettagrid.curriculum.core",
        "description": "metta.mettagrid.curriculum.core",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "Curriculum",
        "importPath": "metta.mettagrid.curriculum.core",
        "description": "metta.mettagrid.curriculum.core",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "Task",
        "importPath": "metta.mettagrid.curriculum.core",
        "description": "metta.mettagrid.curriculum.core",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "Curriculum",
        "importPath": "metta.mettagrid.curriculum.core",
        "description": "metta.mettagrid.curriculum.core",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "Task",
        "importPath": "metta.mettagrid.curriculum.core",
        "description": "metta.mettagrid.curriculum.core",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "Curriculum",
        "importPath": "metta.mettagrid.curriculum.core",
        "description": "metta.mettagrid.curriculum.core",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "SingleTaskCurriculum",
        "importPath": "metta.mettagrid.curriculum.core",
        "description": "metta.mettagrid.curriculum.core",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "Curriculum",
        "importPath": "metta.mettagrid.curriculum.core",
        "description": "metta.mettagrid.curriculum.core",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "SingleTaskCurriculum",
        "importPath": "metta.mettagrid.curriculum.core",
        "description": "metta.mettagrid.curriculum.core",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "SingleTaskCurriculum",
        "importPath": "metta.mettagrid.curriculum.core",
        "description": "metta.mettagrid.curriculum.core",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "SingleTaskCurriculum",
        "importPath": "metta.mettagrid.curriculum.core",
        "description": "metta.mettagrid.curriculum.core",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "SingleTaskCurriculum",
        "importPath": "metta.mettagrid.curriculum.core",
        "description": "metta.mettagrid.curriculum.core",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "SingleTaskCurriculum",
        "importPath": "metta.mettagrid.curriculum.core",
        "description": "metta.mettagrid.curriculum.core",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "SingleTaskCurriculum",
        "importPath": "metta.mettagrid.curriculum.core",
        "description": "metta.mettagrid.curriculum.core",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "Level",
        "importPath": "metta.mettagrid.level_builder",
        "description": "metta.mettagrid.level_builder",
        "isExtraImport": true,
        "detail": "metta.mettagrid.level_builder",
        "documentation": {}
    },
    {
        "label": "Level",
        "importPath": "metta.mettagrid.level_builder",
        "description": "metta.mettagrid.level_builder",
        "isExtraImport": true,
        "detail": "metta.mettagrid.level_builder",
        "documentation": {}
    },
    {
        "label": "Level",
        "importPath": "metta.mettagrid.level_builder",
        "description": "metta.mettagrid.level_builder",
        "isExtraImport": true,
        "detail": "metta.mettagrid.level_builder",
        "documentation": {}
    },
    {
        "label": "LevelBuilder",
        "importPath": "metta.mettagrid.level_builder",
        "description": "metta.mettagrid.level_builder",
        "isExtraImport": true,
        "detail": "metta.mettagrid.level_builder",
        "documentation": {}
    },
    {
        "label": "Level",
        "importPath": "metta.mettagrid.level_builder",
        "description": "metta.mettagrid.level_builder",
        "isExtraImport": true,
        "detail": "metta.mettagrid.level_builder",
        "documentation": {}
    },
    {
        "label": "LevelBuilder",
        "importPath": "metta.mettagrid.level_builder",
        "description": "metta.mettagrid.level_builder",
        "isExtraImport": true,
        "detail": "metta.mettagrid.level_builder",
        "documentation": {}
    },
    {
        "label": "Level",
        "importPath": "metta.mettagrid.level_builder",
        "description": "metta.mettagrid.level_builder",
        "isExtraImport": true,
        "detail": "metta.mettagrid.level_builder",
        "documentation": {}
    },
    {
        "label": "MettaGridEnv",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_actions",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "MettaGridEnv",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "MettaGridEnv",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "MettaGridEnv",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "MettaGridEnv",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_actions",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "MettaGridEnv",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "MettaGridEnv",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_actions",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "MettaGridEnv",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_observations",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_rewards",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_terminals",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_truncations",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_actions",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_observations",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_rewards",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_terminals",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_truncations",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "MettaGridEnv",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "MettaGridEnv",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_actions",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "MettaGridEnv",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_actions",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_observations",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_rewards",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_terminals",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_truncations",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "MettaGridEnv",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_actions",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_observations",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_rewards",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_terminals",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_truncations",
        "importPath": "metta.mettagrid.mettagrid_env",
        "description": "metta.mettagrid.mettagrid_env",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "write_local_map_preview",
        "importPath": "metta.sim.map_preview",
        "description": "metta.sim.map_preview",
        "isExtraImport": true,
        "detail": "metta.sim.map_preview",
        "documentation": {}
    },
    {
        "label": "list_objects",
        "importPath": "metta.map.utils.s3utils",
        "description": "metta.map.utils.s3utils",
        "isExtraImport": true,
        "detail": "metta.map.utils.s3utils",
        "documentation": {}
    },
    {
        "label": "file",
        "importPath": "metta.mettagrid.util",
        "description": "metta.mettagrid.util",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util",
        "documentation": {}
    },
    {
        "label": "file",
        "importPath": "metta.mettagrid.util",
        "description": "metta.mettagrid.util",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util",
        "documentation": {}
    },
    {
        "label": "file",
        "importPath": "metta.mettagrid.util",
        "description": "metta.mettagrid.util",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Room",
        "importPath": "metta.mettagrid.room.room",
        "description": "metta.mettagrid.room.room",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "Load",
        "importPath": "metta.map.load",
        "description": "metta.map.load",
        "isExtraImport": true,
        "detail": "metta.map.load",
        "documentation": {}
    },
    {
        "label": "Load",
        "importPath": "metta.map.load",
        "description": "metta.map.load",
        "isExtraImport": true,
        "detail": "metta.map.load",
        "documentation": {}
    },
    {
        "label": "s3utils",
        "importPath": "metta.map.utils",
        "description": "metta.map.utils",
        "isExtraImport": true,
        "detail": "metta.map.utils",
        "documentation": {}
    },
    {
        "label": "importlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "importlib",
        "description": "importlib",
        "detail": "importlib",
        "documentation": {}
    },
    {
        "label": "pufferlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pufferlib",
        "description": "pufferlib",
        "detail": "pufferlib",
        "documentation": {}
    },
    {
        "label": "_C",
        "importPath": "pufferlib",
        "description": "pufferlib",
        "isExtraImport": true,
        "detail": "pufferlib",
        "documentation": {}
    },
    {
        "label": "PufferEnv",
        "importPath": "pufferlib",
        "description": "pufferlib",
        "isExtraImport": true,
        "detail": "pufferlib",
        "documentation": {}
    },
    {
        "label": "unroll_nested_dict",
        "importPath": "metta.mettagrid.util.dict_utils",
        "description": "metta.mettagrid.util.dict_utils",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.dict_utils",
        "documentation": {}
    },
    {
        "label": "unroll_nested_dict",
        "importPath": "metta.mettagrid.util.dict_utils",
        "description": "metta.mettagrid.util.dict_utils",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.dict_utils",
        "documentation": {}
    },
    {
        "label": "Experience",
        "importPath": "metta.rl.experience",
        "description": "metta.rl.experience",
        "isExtraImport": true,
        "detail": "metta.rl.experience",
        "documentation": {}
    },
    {
        "label": "Experience",
        "importPath": "metta.rl.experience",
        "description": "metta.rl.experience",
        "isExtraImport": true,
        "detail": "metta.rl.experience",
        "documentation": {}
    },
    {
        "label": "Losses",
        "importPath": "metta.rl.losses",
        "description": "metta.rl.losses",
        "isExtraImport": true,
        "detail": "metta.rl.losses",
        "documentation": {}
    },
    {
        "label": "Losses",
        "importPath": "metta.rl.losses",
        "description": "metta.rl.losses",
        "isExtraImport": true,
        "detail": "metta.rl.losses",
        "documentation": {}
    },
    {
        "label": "Losses",
        "importPath": "metta.rl.losses",
        "description": "metta.rl.losses",
        "isExtraImport": true,
        "detail": "metta.rl.losses",
        "documentation": {}
    },
    {
        "label": "KickstartConfig",
        "importPath": "metta.rl.kickstarter_config",
        "description": "metta.rl.kickstarter_config",
        "isExtraImport": true,
        "detail": "metta.rl.kickstarter_config",
        "documentation": {}
    },
    {
        "label": "KickstartTeacherConfig",
        "importPath": "metta.rl.kickstarter_config",
        "description": "metta.rl.kickstarter_config",
        "isExtraImport": true,
        "detail": "metta.rl.kickstarter_config",
        "documentation": {}
    },
    {
        "label": "KickstartConfig",
        "importPath": "metta.rl.kickstarter_config",
        "description": "metta.rl.kickstarter_config",
        "isExtraImport": true,
        "detail": "metta.rl.kickstarter_config",
        "documentation": {}
    },
    {
        "label": "BaseModelWithForbidExtra",
        "importPath": "metta.common.util.typed_config",
        "description": "metta.common.util.typed_config",
        "isExtraImport": true,
        "detail": "metta.common.util.typed_config",
        "documentation": {}
    },
    {
        "label": "BaseModelWithForbidExtra",
        "importPath": "metta.common.util.typed_config",
        "description": "metta.common.util.typed_config",
        "isExtraImport": true,
        "detail": "metta.common.util.typed_config",
        "documentation": {}
    },
    {
        "label": "BaseModelWithForbidExtra",
        "importPath": "metta.common.util.typed_config",
        "description": "metta.common.util.typed_config",
        "isExtraImport": true,
        "detail": "metta.common.util.typed_config",
        "documentation": {}
    },
    {
        "label": "BaseModelWithForbidExtra",
        "importPath": "metta.common.util.typed_config",
        "description": "metta.common.util.typed_config",
        "isExtraImport": true,
        "detail": "metta.common.util.typed_config",
        "documentation": {}
    },
    {
        "label": "instantiate",
        "importPath": "hydra.utils",
        "description": "hydra.utils",
        "isExtraImport": true,
        "detail": "hydra.utils",
        "documentation": {}
    },
    {
        "label": "instantiate",
        "importPath": "hydra.utils",
        "description": "hydra.utils",
        "isExtraImport": true,
        "detail": "hydra.utils",
        "documentation": {}
    },
    {
        "label": "gzip",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gzip",
        "description": "gzip",
        "detail": "gzip",
        "documentation": {}
    },
    {
        "label": "boto3",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "boto3",
        "description": "boto3",
        "detail": "boto3",
        "documentation": {}
    },
    {
        "label": "torch.profiler",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.profiler",
        "description": "torch.profiler",
        "detail": "torch.profiler",
        "documentation": {}
    },
    {
        "label": "ForeachMuon",
        "importPath": "heavyball",
        "description": "heavyball",
        "isExtraImport": true,
        "detail": "heavyball",
        "documentation": {}
    },
    {
        "label": "record_heartbeat",
        "importPath": "metta.common.util.heartbeat",
        "description": "metta.common.util.heartbeat",
        "isExtraImport": true,
        "detail": "metta.common.util.heartbeat",
        "documentation": {}
    },
    {
        "label": "record_heartbeat",
        "importPath": "metta.common.util.heartbeat",
        "description": "metta.common.util.heartbeat",
        "isExtraImport": true,
        "detail": "metta.common.util.heartbeat",
        "documentation": {}
    },
    {
        "label": "curriculum_from_config_path",
        "importPath": "metta.mettagrid.curriculum.util",
        "description": "metta.mettagrid.curriculum.util",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.util",
        "documentation": {}
    },
    {
        "label": "config_from_path",
        "importPath": "metta.mettagrid.curriculum.util",
        "description": "metta.mettagrid.curriculum.util",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.util",
        "documentation": {}
    },
    {
        "label": "curriculum_from_config_path",
        "importPath": "metta.mettagrid.curriculum.util",
        "description": "metta.mettagrid.curriculum.util",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.util",
        "documentation": {}
    },
    {
        "label": "accumulate_rollout_stats",
        "importPath": "metta.rl.functions",
        "description": "metta.rl.functions",
        "isExtraImport": true,
        "detail": "metta.rl.functions",
        "documentation": {}
    },
    {
        "label": "calculate_batch_sizes",
        "importPath": "metta.rl.functions",
        "description": "metta.rl.functions",
        "isExtraImport": true,
        "detail": "metta.rl.functions",
        "documentation": {}
    },
    {
        "label": "calculate_explained_variance",
        "importPath": "metta.rl.functions",
        "description": "metta.rl.functions",
        "isExtraImport": true,
        "detail": "metta.rl.functions",
        "documentation": {}
    },
    {
        "label": "calculate_prioritized_sampling_params",
        "importPath": "metta.rl.functions",
        "description": "metta.rl.functions",
        "isExtraImport": true,
        "detail": "metta.rl.functions",
        "documentation": {}
    },
    {
        "label": "compute_advantage",
        "importPath": "metta.rl.functions",
        "description": "metta.rl.functions",
        "isExtraImport": true,
        "detail": "metta.rl.functions",
        "documentation": {}
    },
    {
        "label": "get_lstm_config",
        "importPath": "metta.rl.functions",
        "description": "metta.rl.functions",
        "isExtraImport": true,
        "detail": "metta.rl.functions",
        "documentation": {}
    },
    {
        "label": "perform_rollout_step",
        "importPath": "metta.rl.functions",
        "description": "metta.rl.functions",
        "isExtraImport": true,
        "detail": "metta.rl.functions",
        "documentation": {}
    },
    {
        "label": "process_minibatch_update",
        "importPath": "metta.rl.functions",
        "description": "metta.rl.functions",
        "isExtraImport": true,
        "detail": "metta.rl.functions",
        "documentation": {}
    },
    {
        "label": "validate_policy_environment_match",
        "importPath": "metta.rl.functions",
        "description": "metta.rl.functions",
        "isExtraImport": true,
        "detail": "metta.rl.functions",
        "documentation": {}
    },
    {
        "label": "Kickstarter",
        "importPath": "metta.rl.kickstarter",
        "description": "metta.rl.kickstarter",
        "isExtraImport": true,
        "detail": "metta.rl.kickstarter",
        "documentation": {}
    },
    {
        "label": "Kickstarter",
        "importPath": "metta.rl.kickstarter",
        "description": "metta.rl.kickstarter",
        "isExtraImport": true,
        "detail": "metta.rl.kickstarter",
        "documentation": {}
    },
    {
        "label": "KickstartTeacherConfig",
        "importPath": "metta.rl.kickstarter",
        "description": "metta.rl.kickstarter",
        "isExtraImport": true,
        "detail": "metta.rl.kickstarter",
        "documentation": {}
    },
    {
        "label": "TorchProfiler",
        "importPath": "metta.rl.torch_profiler",
        "description": "metta.rl.torch_profiler",
        "isExtraImport": true,
        "detail": "metta.rl.torch_profiler",
        "documentation": {}
    },
    {
        "label": "TrainerCheckpoint",
        "importPath": "metta.rl.trainer_checkpoint",
        "description": "metta.rl.trainer_checkpoint",
        "isExtraImport": true,
        "detail": "metta.rl.trainer_checkpoint",
        "documentation": {}
    },
    {
        "label": "make_vecenv",
        "importPath": "metta.rl.vecenv",
        "description": "metta.rl.vecenv",
        "isExtraImport": true,
        "detail": "metta.rl.vecenv",
        "documentation": {}
    },
    {
        "label": "make_vecenv",
        "importPath": "metta.rl.vecenv",
        "description": "metta.rl.vecenv",
        "isExtraImport": true,
        "detail": "metta.rl.vecenv",
        "documentation": {}
    },
    {
        "label": "Simulation",
        "importPath": "metta.sim.simulation",
        "description": "metta.sim.simulation",
        "isExtraImport": true,
        "detail": "metta.sim.simulation",
        "documentation": {}
    },
    {
        "label": "Simulation",
        "importPath": "metta.sim.simulation",
        "description": "metta.sim.simulation",
        "isExtraImport": true,
        "detail": "metta.sim.simulation",
        "documentation": {}
    },
    {
        "label": "SimulationCompatibilityError",
        "importPath": "metta.sim.simulation",
        "description": "metta.sim.simulation",
        "isExtraImport": true,
        "detail": "metta.sim.simulation",
        "documentation": {}
    },
    {
        "label": "SimulationResults",
        "importPath": "metta.sim.simulation",
        "description": "metta.sim.simulation",
        "isExtraImport": true,
        "detail": "metta.sim.simulation",
        "documentation": {}
    },
    {
        "label": "Simulation",
        "importPath": "metta.sim.simulation",
        "description": "metta.sim.simulation",
        "isExtraImport": true,
        "detail": "metta.sim.simulation",
        "documentation": {}
    },
    {
        "label": "Simulation",
        "importPath": "metta.sim.simulation",
        "description": "metta.sim.simulation",
        "isExtraImport": true,
        "detail": "metta.sim.simulation",
        "documentation": {}
    },
    {
        "label": "Simulation",
        "importPath": "metta.sim.simulation",
        "description": "metta.sim.simulation",
        "isExtraImport": true,
        "detail": "metta.sim.simulation",
        "documentation": {}
    },
    {
        "label": "Simulation",
        "importPath": "metta.sim.simulation",
        "description": "metta.sim.simulation",
        "isExtraImport": true,
        "detail": "metta.sim.simulation",
        "documentation": {}
    },
    {
        "label": "Simulation",
        "importPath": "metta.sim.simulation",
        "description": "metta.sim.simulation",
        "isExtraImport": true,
        "detail": "metta.sim.simulation",
        "documentation": {}
    },
    {
        "label": "Simulation",
        "importPath": "metta.sim.simulation",
        "description": "metta.sim.simulation",
        "isExtraImport": true,
        "detail": "metta.sim.simulation",
        "documentation": {}
    },
    {
        "label": "Simulation",
        "importPath": "metta.sim.simulation",
        "description": "metta.sim.simulation",
        "isExtraImport": true,
        "detail": "metta.sim.simulation",
        "documentation": {}
    },
    {
        "label": "Simulation",
        "importPath": "metta.sim.simulation",
        "description": "metta.sim.simulation",
        "isExtraImport": true,
        "detail": "metta.sim.simulation",
        "documentation": {}
    },
    {
        "label": "SimulationSuiteConfig",
        "importPath": "metta.sim.simulation_config",
        "description": "metta.sim.simulation_config",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_config",
        "documentation": {}
    },
    {
        "label": "SingleEnvSimulationConfig",
        "importPath": "metta.sim.simulation_config",
        "description": "metta.sim.simulation_config",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_config",
        "documentation": {}
    },
    {
        "label": "SingleEnvSimulationConfig",
        "importPath": "metta.sim.simulation_config",
        "description": "metta.sim.simulation_config",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_config",
        "documentation": {}
    },
    {
        "label": "SimulationSuiteConfig",
        "importPath": "metta.sim.simulation_config",
        "description": "metta.sim.simulation_config",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_config",
        "documentation": {}
    },
    {
        "label": "SingleEnvSimulationConfig",
        "importPath": "metta.sim.simulation_config",
        "description": "metta.sim.simulation_config",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_config",
        "documentation": {}
    },
    {
        "label": "SimulationSuiteConfig",
        "importPath": "metta.sim.simulation_config",
        "description": "metta.sim.simulation_config",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_config",
        "documentation": {}
    },
    {
        "label": "SingleEnvSimulationConfig",
        "importPath": "metta.sim.simulation_config",
        "description": "metta.sim.simulation_config",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_config",
        "documentation": {}
    },
    {
        "label": "SimulationSuiteConfig",
        "importPath": "metta.sim.simulation_config",
        "description": "metta.sim.simulation_config",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_config",
        "documentation": {}
    },
    {
        "label": "SimulationSuiteConfig",
        "importPath": "metta.sim.simulation_config",
        "description": "metta.sim.simulation_config",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_config",
        "documentation": {}
    },
    {
        "label": "SimulationSuiteConfig",
        "importPath": "metta.sim.simulation_config",
        "description": "metta.sim.simulation_config",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_config",
        "documentation": {}
    },
    {
        "label": "SimulationSuiteConfig",
        "importPath": "metta.sim.simulation_config",
        "description": "metta.sim.simulation_config",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_config",
        "documentation": {}
    },
    {
        "label": "SingleEnvSimulationConfig",
        "importPath": "metta.sim.simulation_config",
        "description": "metta.sim.simulation_config",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_config",
        "documentation": {}
    },
    {
        "label": "SingleEnvSimulationConfig",
        "importPath": "metta.sim.simulation_config",
        "description": "metta.sim.simulation_config",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_config",
        "documentation": {}
    },
    {
        "label": "SingleEnvSimulationConfig",
        "importPath": "metta.sim.simulation_config",
        "description": "metta.sim.simulation_config",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_config",
        "documentation": {}
    },
    {
        "label": "SingleEnvSimulationConfig",
        "importPath": "metta.sim.simulation_config",
        "description": "metta.sim.simulation_config",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_config",
        "documentation": {}
    },
    {
        "label": "SingleEnvSimulationConfig",
        "importPath": "metta.sim.simulation_config",
        "description": "metta.sim.simulation_config",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_config",
        "documentation": {}
    },
    {
        "label": "SingleEnvSimulationConfig",
        "importPath": "metta.sim.simulation_config",
        "description": "metta.sim.simulation_config",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_config",
        "documentation": {}
    },
    {
        "label": "SimulationSuite",
        "importPath": "metta.sim.simulation_suite",
        "description": "metta.sim.simulation_suite",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_suite",
        "documentation": {}
    },
    {
        "label": "SimulationSuite",
        "importPath": "metta.sim.simulation_suite",
        "description": "metta.sim.simulation_suite",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_suite",
        "documentation": {}
    },
    {
        "label": "SimulationSuite",
        "importPath": "metta.sim.simulation_suite",
        "description": "metta.sim.simulation_suite",
        "isExtraImport": true,
        "detail": "metta.sim.simulation_suite",
        "documentation": {}
    },
    {
        "label": "pufferlib.vector",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pufferlib.vector",
        "description": "pufferlib.vector",
        "detail": "pufferlib.vector",
        "documentation": {}
    },
    {
        "label": "ReplayWriter",
        "importPath": "metta.mettagrid.replay_writer",
        "description": "metta.mettagrid.replay_writer",
        "isExtraImport": true,
        "detail": "metta.mettagrid.replay_writer",
        "documentation": {}
    },
    {
        "label": "ReplayWriter",
        "importPath": "metta.mettagrid.replay_writer",
        "description": "metta.mettagrid.replay_writer",
        "isExtraImport": true,
        "detail": "metta.mettagrid.replay_writer",
        "documentation": {}
    },
    {
        "label": "ReplayWriter",
        "importPath": "metta.mettagrid.replay_writer",
        "description": "metta.mettagrid.replay_writer",
        "isExtraImport": true,
        "detail": "metta.mettagrid.replay_writer",
        "documentation": {}
    },
    {
        "label": "StatsWriter",
        "importPath": "metta.mettagrid.stats_writer",
        "description": "metta.mettagrid.stats_writer",
        "isExtraImport": true,
        "detail": "metta.mettagrid.stats_writer",
        "documentation": {}
    },
    {
        "label": "StatsWriter",
        "importPath": "metta.mettagrid.stats_writer",
        "description": "metta.mettagrid.stats_writer",
        "isExtraImport": true,
        "detail": "metta.mettagrid.stats_writer",
        "documentation": {}
    },
    {
        "label": "StatsWriter",
        "importPath": "metta.mettagrid.stats_writer",
        "description": "metta.mettagrid.stats_writer",
        "isExtraImport": true,
        "detail": "metta.mettagrid.stats_writer",
        "documentation": {}
    },
    {
        "label": "StatsWriter",
        "importPath": "metta.mettagrid.stats_writer",
        "description": "metta.mettagrid.stats_writer",
        "isExtraImport": true,
        "detail": "metta.mettagrid.stats_writer",
        "documentation": {}
    },
    {
        "label": "SetupModule",
        "importPath": "metta.setup.components.base",
        "description": "metta.setup.components.base",
        "isExtraImport": true,
        "detail": "metta.setup.components.base",
        "documentation": {}
    },
    {
        "label": "SetupModule",
        "importPath": "metta.setup.components.base",
        "description": "metta.setup.components.base",
        "isExtraImport": true,
        "detail": "metta.setup.components.base",
        "documentation": {}
    },
    {
        "label": "SetupModule",
        "importPath": "metta.setup.components.base",
        "description": "metta.setup.components.base",
        "isExtraImport": true,
        "detail": "metta.setup.components.base",
        "documentation": {}
    },
    {
        "label": "SetupModule",
        "importPath": "metta.setup.components.base",
        "description": "metta.setup.components.base",
        "isExtraImport": true,
        "detail": "metta.setup.components.base",
        "documentation": {}
    },
    {
        "label": "SetupModule",
        "importPath": "metta.setup.components.base",
        "description": "metta.setup.components.base",
        "isExtraImport": true,
        "detail": "metta.setup.components.base",
        "documentation": {}
    },
    {
        "label": "SetupModule",
        "importPath": "metta.setup.components.base",
        "description": "metta.setup.components.base",
        "isExtraImport": true,
        "detail": "metta.setup.components.base",
        "documentation": {}
    },
    {
        "label": "SetupModule",
        "importPath": "metta.setup.components.base",
        "description": "metta.setup.components.base",
        "isExtraImport": true,
        "detail": "metta.setup.components.base",
        "documentation": {}
    },
    {
        "label": "SetupModule",
        "importPath": "metta.setup.components.base",
        "description": "metta.setup.components.base",
        "isExtraImport": true,
        "detail": "metta.setup.components.base",
        "documentation": {}
    },
    {
        "label": "SetupModule",
        "importPath": "metta.setup.components.base",
        "description": "metta.setup.components.base",
        "isExtraImport": true,
        "detail": "metta.setup.components.base",
        "documentation": {}
    },
    {
        "label": "SetupModule",
        "importPath": "metta.setup.components.base",
        "description": "metta.setup.components.base",
        "isExtraImport": true,
        "detail": "metta.setup.components.base",
        "documentation": {}
    },
    {
        "label": "SetupModule",
        "importPath": "metta.setup.components.base",
        "description": "metta.setup.components.base",
        "isExtraImport": true,
        "detail": "metta.setup.components.base",
        "documentation": {}
    },
    {
        "label": "register_module",
        "importPath": "metta.setup.registry",
        "description": "metta.setup.registry",
        "isExtraImport": true,
        "detail": "metta.setup.registry",
        "documentation": {}
    },
    {
        "label": "register_module",
        "importPath": "metta.setup.registry",
        "description": "metta.setup.registry",
        "isExtraImport": true,
        "detail": "metta.setup.registry",
        "documentation": {}
    },
    {
        "label": "register_module",
        "importPath": "metta.setup.registry",
        "description": "metta.setup.registry",
        "isExtraImport": true,
        "detail": "metta.setup.registry",
        "documentation": {}
    },
    {
        "label": "register_module",
        "importPath": "metta.setup.registry",
        "description": "metta.setup.registry",
        "isExtraImport": true,
        "detail": "metta.setup.registry",
        "documentation": {}
    },
    {
        "label": "register_module",
        "importPath": "metta.setup.registry",
        "description": "metta.setup.registry",
        "isExtraImport": true,
        "detail": "metta.setup.registry",
        "documentation": {}
    },
    {
        "label": "register_module",
        "importPath": "metta.setup.registry",
        "description": "metta.setup.registry",
        "isExtraImport": true,
        "detail": "metta.setup.registry",
        "documentation": {}
    },
    {
        "label": "register_module",
        "importPath": "metta.setup.registry",
        "description": "metta.setup.registry",
        "isExtraImport": true,
        "detail": "metta.setup.registry",
        "documentation": {}
    },
    {
        "label": "register_module",
        "importPath": "metta.setup.registry",
        "description": "metta.setup.registry",
        "isExtraImport": true,
        "detail": "metta.setup.registry",
        "documentation": {}
    },
    {
        "label": "register_module",
        "importPath": "metta.setup.registry",
        "description": "metta.setup.registry",
        "isExtraImport": true,
        "detail": "metta.setup.registry",
        "documentation": {}
    },
    {
        "label": "register_module",
        "importPath": "metta.setup.registry",
        "description": "metta.setup.registry",
        "isExtraImport": true,
        "detail": "metta.setup.registry",
        "documentation": {}
    },
    {
        "label": "register_module",
        "importPath": "metta.setup.registry",
        "description": "metta.setup.registry",
        "isExtraImport": true,
        "detail": "metta.setup.registry",
        "documentation": {}
    },
    {
        "label": "get_all_modules",
        "importPath": "metta.setup.registry",
        "description": "metta.setup.registry",
        "isExtraImport": true,
        "detail": "metta.setup.registry",
        "documentation": {}
    },
    {
        "label": "get_applicable_modules",
        "importPath": "metta.setup.registry",
        "description": "metta.setup.registry",
        "isExtraImport": true,
        "detail": "metta.setup.registry",
        "documentation": {}
    },
    {
        "label": "info",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "error",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "success",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "info",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "success",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "warning",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "info",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "success",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "warning",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "info",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "success",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "info",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "success",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "warning",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "error",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "info",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "success",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "warning",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "info",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "success",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "warning",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "info",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "success",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "warning",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "error",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "header",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "import_all_modules_from_subpackage",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "info",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "success",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "warning",
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "isExtraImport": true,
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "SetupConfig",
        "importPath": "metta.setup.config",
        "description": "metta.setup.config",
        "isExtraImport": true,
        "detail": "metta.setup.config",
        "documentation": {}
    },
    {
        "label": "UserType",
        "importPath": "metta.setup.config",
        "description": "metta.setup.config",
        "isExtraImport": true,
        "detail": "metta.setup.config",
        "documentation": {}
    },
    {
        "label": "CURRENT_CONFIG_VERSION",
        "importPath": "metta.setup.config",
        "description": "metta.setup.config",
        "isExtraImport": true,
        "detail": "metta.setup.config",
        "documentation": {}
    },
    {
        "label": "PROFILE_DEFINITIONS",
        "importPath": "metta.setup.config",
        "description": "metta.setup.config",
        "isExtraImport": true,
        "detail": "metta.setup.config",
        "documentation": {}
    },
    {
        "label": "SetupConfig",
        "importPath": "metta.setup.config",
        "description": "metta.setup.config",
        "isExtraImport": true,
        "detail": "metta.setup.config",
        "documentation": {}
    },
    {
        "label": "UserType",
        "importPath": "metta.setup.config",
        "description": "metta.setup.config",
        "isExtraImport": true,
        "detail": "metta.setup.config",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "textwrap",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "textwrap",
        "description": "textwrap",
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "zlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "zlib",
        "description": "zlib",
        "detail": "zlib",
        "documentation": {}
    },
    {
        "label": "wandb_run",
        "importPath": "wandb.sdk",
        "description": "wandb.sdk",
        "isExtraImport": true,
        "detail": "wandb.sdk",
        "documentation": {}
    },
    {
        "label": "SamplingCurriculum",
        "importPath": "metta.mettagrid.curriculum.sampling",
        "description": "metta.mettagrid.curriculum.sampling",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.sampling",
        "documentation": {}
    },
    {
        "label": "SampledTaskCurriculum",
        "importPath": "metta.mettagrid.curriculum.sampling",
        "description": "metta.mettagrid.curriculum.sampling",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.sampling",
        "documentation": {}
    },
    {
        "label": "SamplingCurriculum",
        "importPath": "metta.mettagrid.curriculum.sampling",
        "description": "metta.mettagrid.curriculum.sampling",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.sampling",
        "documentation": {}
    },
    {
        "label": "SamplingCurriculum",
        "importPath": "metta.mettagrid.curriculum.sampling",
        "description": "metta.mettagrid.curriculum.sampling",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.sampling",
        "documentation": {}
    },
    {
        "label": "SampledTaskCurriculum",
        "importPath": "metta.mettagrid.curriculum.sampling",
        "description": "metta.mettagrid.curriculum.sampling",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.sampling",
        "documentation": {}
    },
    {
        "label": "SamplingCurriculum",
        "importPath": "metta.mettagrid.curriculum.sampling",
        "description": "metta.mettagrid.curriculum.sampling",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.sampling",
        "documentation": {}
    },
    {
        "label": "duckdb",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "duckdb",
        "description": "duckdb",
        "detail": "duckdb",
        "documentation": {}
    },
    {
        "label": "DuckDBPyConnection",
        "importPath": "duckdb",
        "description": "duckdb",
        "isExtraImport": true,
        "detail": "duckdb",
        "documentation": {}
    },
    {
        "label": "EpisodeStatsDB",
        "importPath": "metta.mettagrid.episode_stats_db",
        "description": "metta.mettagrid.episode_stats_db",
        "isExtraImport": true,
        "detail": "metta.mettagrid.episode_stats_db",
        "documentation": {}
    },
    {
        "label": "EpisodeStatsDB",
        "importPath": "metta.mettagrid.episode_stats_db",
        "description": "metta.mettagrid.episode_stats_db",
        "isExtraImport": true,
        "detail": "metta.mettagrid.episode_stats_db",
        "documentation": {}
    },
    {
        "label": "EpisodeStatsDB",
        "importPath": "metta.mettagrid.episode_stats_db",
        "description": "metta.mettagrid.episode_stats_db",
        "isExtraImport": true,
        "detail": "metta.mettagrid.episode_stats_db",
        "documentation": {}
    },
    {
        "label": "CfgKind",
        "importPath": "metta.common.util.mettagrid_cfgs",
        "description": "metta.common.util.mettagrid_cfgs",
        "isExtraImport": true,
        "detail": "metta.common.util.mettagrid_cfgs",
        "documentation": {}
    },
    {
        "label": "MettagridCfgFile",
        "importPath": "metta.common.util.mettagrid_cfgs",
        "description": "metta.common.util.mettagrid_cfgs",
        "isExtraImport": true,
        "detail": "metta.common.util.mettagrid_cfgs",
        "documentation": {}
    },
    {
        "label": "MettagridCfgFileMetadata",
        "importPath": "metta.common.util.mettagrid_cfgs",
        "description": "metta.common.util.mettagrid_cfgs",
        "isExtraImport": true,
        "detail": "metta.common.util.mettagrid_cfgs",
        "documentation": {}
    },
    {
        "label": "MettagridCfgFileMetadata",
        "importPath": "metta.common.util.mettagrid_cfgs",
        "description": "metta.common.util.mettagrid_cfgs",
        "isExtraImport": true,
        "detail": "metta.common.util.mettagrid_cfgs",
        "documentation": {}
    },
    {
        "label": "pyro",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pyro",
        "description": "pyro",
        "detail": "pyro",
        "documentation": {}
    },
    {
        "label": "gp",
        "importPath": "pyro.contrib",
        "description": "pyro.contrib",
        "isExtraImport": true,
        "detail": "pyro.contrib",
        "documentation": {}
    },
    {
        "label": "generate_valid_random_actions",
        "importPath": "metta.mettagrid.util.actions",
        "description": "metta.mettagrid.util.actions",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.actions",
        "documentation": {}
    },
    {
        "label": "Orientation",
        "importPath": "metta.mettagrid.util.actions",
        "description": "metta.mettagrid.util.actions",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.actions",
        "documentation": {}
    },
    {
        "label": "get_agent_position",
        "importPath": "metta.mettagrid.util.actions",
        "description": "metta.mettagrid.util.actions",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.actions",
        "documentation": {}
    },
    {
        "label": "move",
        "importPath": "metta.mettagrid.util.actions",
        "description": "metta.mettagrid.util.actions",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.actions",
        "documentation": {}
    },
    {
        "label": "Orientation",
        "importPath": "metta.mettagrid.util.actions",
        "description": "metta.mettagrid.util.actions",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.actions",
        "documentation": {}
    },
    {
        "label": "get_agent_position",
        "importPath": "metta.mettagrid.util.actions",
        "description": "metta.mettagrid.util.actions",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.actions",
        "documentation": {}
    },
    {
        "label": "move",
        "importPath": "metta.mettagrid.util.actions",
        "description": "metta.mettagrid.util.actions",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.actions",
        "documentation": {}
    },
    {
        "label": "rotate",
        "importPath": "metta.mettagrid.util.actions",
        "description": "metta.mettagrid.util.actions",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.actions",
        "documentation": {}
    },
    {
        "label": "generate_valid_random_actions",
        "importPath": "metta.mettagrid.util.actions",
        "description": "metta.mettagrid.util.actions",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.actions",
        "documentation": {}
    },
    {
        "label": "get_cfg",
        "importPath": "metta.mettagrid.util.hydra",
        "description": "metta.mettagrid.util.hydra",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.hydra",
        "documentation": {}
    },
    {
        "label": "config_from_path",
        "importPath": "metta.mettagrid.util.hydra",
        "description": "metta.mettagrid.util.hydra",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.hydra",
        "documentation": {}
    },
    {
        "label": "config_from_path",
        "importPath": "metta.mettagrid.util.hydra",
        "description": "metta.mettagrid.util.hydra",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.hydra",
        "documentation": {}
    },
    {
        "label": "get_cfg",
        "importPath": "metta.mettagrid.util.hydra",
        "description": "metta.mettagrid.util.hydra",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.hydra",
        "documentation": {}
    },
    {
        "label": "get_cfg",
        "importPath": "metta.mettagrid.util.hydra",
        "description": "metta.mettagrid.util.hydra",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.hydra",
        "documentation": {}
    },
    {
        "label": "get_cfg",
        "importPath": "metta.mettagrid.util.hydra",
        "description": "metta.mettagrid.util.hydra",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.hydra",
        "documentation": {}
    },
    {
        "label": "product",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "Discrete",
        "importPath": "gymnasium.spaces",
        "description": "gymnasium.spaces",
        "isExtraImport": true,
        "detail": "gymnasium.spaces",
        "documentation": {}
    },
    {
        "label": "Discrete",
        "importPath": "gymnasium.spaces",
        "description": "gymnasium.spaces",
        "isExtraImport": true,
        "detail": "gymnasium.spaces",
        "documentation": {}
    },
    {
        "label": "RandomCurriculum",
        "importPath": "metta.mettagrid.curriculum.random",
        "description": "metta.mettagrid.curriculum.random",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.random",
        "documentation": {}
    },
    {
        "label": "RandomCurriculum",
        "importPath": "metta.mettagrid.curriculum.random",
        "description": "metta.mettagrid.curriculum.random",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.random",
        "documentation": {}
    },
    {
        "label": "RandomCurriculum",
        "importPath": "metta.mettagrid.curriculum.random",
        "description": "metta.mettagrid.curriculum.random",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.random",
        "documentation": {}
    },
    {
        "label": "RandomCurriculum",
        "importPath": "metta.mettagrid.curriculum.random",
        "description": "metta.mettagrid.curriculum.random",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.random",
        "documentation": {}
    },
    {
        "label": "MultiTaskCurriculum",
        "importPath": "metta.mettagrid.curriculum.multi_task",
        "description": "metta.mettagrid.curriculum.multi_task",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.multi_task",
        "documentation": {}
    },
    {
        "label": "MultiTaskCurriculum",
        "importPath": "metta.mettagrid.curriculum.multi_task",
        "description": "metta.mettagrid.curriculum.multi_task",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.multi_task",
        "documentation": {}
    },
    {
        "label": "compute_positions",
        "importPath": "metta.mettagrid.room.utils",
        "description": "metta.mettagrid.room.utils",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.utils",
        "documentation": {}
    },
    {
        "label": "create_grid",
        "importPath": "metta.mettagrid.room.utils",
        "description": "metta.mettagrid.room.utils",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.utils",
        "documentation": {}
    },
    {
        "label": "draw_border",
        "importPath": "metta.mettagrid.room.utils",
        "description": "metta.mettagrid.room.utils",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.utils",
        "documentation": {}
    },
    {
        "label": "create_grid",
        "importPath": "metta.mettagrid.room.utils",
        "description": "metta.mettagrid.room.utils",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.utils",
        "documentation": {}
    },
    {
        "label": "create_grid",
        "importPath": "metta.mettagrid.room.utils",
        "description": "metta.mettagrid.room.utils",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.utils",
        "documentation": {}
    },
    {
        "label": "sample_position",
        "importPath": "metta.mettagrid.room.utils",
        "description": "metta.mettagrid.room.utils",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.utils",
        "documentation": {}
    },
    {
        "label": "bresenham_line",
        "importPath": "metta.mettagrid.room.utils",
        "description": "metta.mettagrid.room.utils",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.utils",
        "documentation": {}
    },
    {
        "label": "create_grid",
        "importPath": "metta.mettagrid.room.utils",
        "description": "metta.mettagrid.room.utils",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.utils",
        "documentation": {}
    },
    {
        "label": "create_grid",
        "importPath": "metta.mettagrid.room.utils",
        "description": "metta.mettagrid.room.utils",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.utils",
        "documentation": {}
    },
    {
        "label": "draw_border",
        "importPath": "metta.mettagrid.room.utils",
        "description": "metta.mettagrid.room.utils",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.utils",
        "documentation": {}
    },
    {
        "label": "create_grid",
        "importPath": "metta.mettagrid.room.utils",
        "description": "metta.mettagrid.room.utils",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.utils",
        "documentation": {}
    },
    {
        "label": "set_position",
        "importPath": "metta.mettagrid.room.utils",
        "description": "metta.mettagrid.room.utils",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.utils",
        "documentation": {}
    },
    {
        "label": "RoomList",
        "importPath": "metta.mettagrid.room.room_list",
        "description": "metta.mettagrid.room.room_list",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room_list",
        "documentation": {}
    },
    {
        "label": "RoomList",
        "importPath": "metta.mettagrid.room.room_list",
        "description": "metta.mettagrid.room.room_list",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.room_list",
        "documentation": {}
    },
    {
        "label": "NoCredentialsError",
        "importPath": "botocore.exceptions",
        "description": "botocore.exceptions",
        "isExtraImport": true,
        "detail": "botocore.exceptions",
        "documentation": {}
    },
    {
        "label": "ClientError",
        "importPath": "botocore.exceptions",
        "description": "botocore.exceptions",
        "isExtraImport": true,
        "detail": "botocore.exceptions",
        "documentation": {}
    },
    {
        "label": "NoCredentialsError",
        "importPath": "botocore.exceptions",
        "description": "botocore.exceptions",
        "isExtraImport": true,
        "detail": "botocore.exceptions",
        "documentation": {}
    },
    {
        "label": "NoCredentialsError",
        "importPath": "botocore.exceptions",
        "description": "botocore.exceptions",
        "isExtraImport": true,
        "detail": "botocore.exceptions",
        "documentation": {}
    },
    {
        "label": "ProfileNotFound",
        "importPath": "botocore.exceptions",
        "description": "botocore.exceptions",
        "isExtraImport": true,
        "detail": "botocore.exceptions",
        "documentation": {}
    },
    {
        "label": "ClientError",
        "importPath": "botocore.exceptions",
        "description": "botocore.exceptions",
        "isExtraImport": true,
        "detail": "botocore.exceptions",
        "documentation": {}
    },
    {
        "label": "FileLock",
        "importPath": "filelock",
        "description": "filelock",
        "isExtraImport": true,
        "detail": "filelock",
        "documentation": {}
    },
    {
        "label": "MettaGrid",
        "importPath": "metta.mettagrid.mettagrid_c",
        "description": "metta.mettagrid.mettagrid_c",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_c",
        "documentation": {}
    },
    {
        "label": "MettaGrid",
        "importPath": "metta.mettagrid.mettagrid_c",
        "description": "metta.mettagrid.mettagrid_c",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_c",
        "documentation": {}
    },
    {
        "label": "MettaGrid",
        "importPath": "metta.mettagrid.mettagrid_c",
        "description": "metta.mettagrid.mettagrid_c",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_c",
        "documentation": {}
    },
    {
        "label": "MettaGrid",
        "importPath": "metta.mettagrid.mettagrid_c",
        "description": "metta.mettagrid.mettagrid_c",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_c",
        "documentation": {}
    },
    {
        "label": "MettaGrid",
        "importPath": "metta.mettagrid.mettagrid_c",
        "description": "metta.mettagrid.mettagrid_c",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_c",
        "documentation": {}
    },
    {
        "label": "MettaGrid",
        "importPath": "metta.mettagrid.mettagrid_c",
        "description": "metta.mettagrid.mettagrid_c",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_c",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "ConverterConfig",
        "importPath": "metta.mettagrid.mettagrid_config",
        "description": "metta.mettagrid.mettagrid_config",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_config",
        "documentation": {}
    },
    {
        "label": "GameConfig",
        "importPath": "metta.mettagrid.mettagrid_config",
        "description": "metta.mettagrid.mettagrid_config",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_config",
        "documentation": {}
    },
    {
        "label": "WallConfig",
        "importPath": "metta.mettagrid.mettagrid_config",
        "description": "metta.mettagrid.mettagrid_config",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_config",
        "documentation": {}
    },
    {
        "label": "cpp_config_dict",
        "importPath": "metta.mettagrid.mettagrid_c_config",
        "description": "metta.mettagrid.mettagrid_c_config",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_c_config",
        "documentation": {}
    },
    {
        "label": "cpp_config_dict",
        "importPath": "metta.mettagrid.mettagrid_c_config",
        "description": "metta.mettagrid.mettagrid_c_config",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_c_config",
        "documentation": {}
    },
    {
        "label": "cpp_config_dict",
        "importPath": "metta.mettagrid.mettagrid_c_config",
        "description": "metta.mettagrid.mettagrid_c_config",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_c_config",
        "documentation": {}
    },
    {
        "label": "cpp_config_dict",
        "importPath": "metta.mettagrid.mettagrid_c_config",
        "description": "metta.mettagrid.mettagrid_c_config",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_c_config",
        "documentation": {}
    },
    {
        "label": "cpp_config_dict",
        "importPath": "metta.mettagrid.mettagrid_c_config",
        "description": "metta.mettagrid.mettagrid_c_config",
        "isExtraImport": true,
        "detail": "metta.mettagrid.mettagrid_c_config",
        "documentation": {}
    },
    {
        "label": "MiniscopeRenderer",
        "importPath": "metta.mettagrid.renderer.miniscope",
        "description": "metta.mettagrid.renderer.miniscope",
        "isExtraImport": true,
        "detail": "metta.mettagrid.renderer.miniscope",
        "documentation": {}
    },
    {
        "label": "NethackRenderer",
        "importPath": "metta.mettagrid.renderer.nethack",
        "description": "metta.mettagrid.renderer.nethack",
        "isExtraImport": true,
        "detail": "metta.mettagrid.renderer.nethack",
        "documentation": {}
    },
    {
        "label": "BucketedCurriculum",
        "importPath": "metta.mettagrid.curriculum.bucketed",
        "description": "metta.mettagrid.curriculum.bucketed",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.bucketed",
        "documentation": {}
    },
    {
        "label": "_expand_buckets",
        "importPath": "metta.mettagrid.curriculum.bucketed",
        "description": "metta.mettagrid.curriculum.bucketed",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.bucketed",
        "documentation": {}
    },
    {
        "label": "LowRewardCurriculum",
        "importPath": "metta.mettagrid.curriculum.low_reward",
        "description": "metta.mettagrid.curriculum.low_reward",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.low_reward",
        "documentation": {}
    },
    {
        "label": "ProgressiveCurriculum",
        "importPath": "metta.mettagrid.curriculum.progressive",
        "description": "metta.mettagrid.curriculum.progressive",
        "isExtraImport": true,
        "detail": "metta.mettagrid.curriculum.progressive",
        "documentation": {}
    },
    {
        "label": "calculate_diversity_bonus",
        "importPath": "metta.mettagrid.util.diversity",
        "description": "metta.mettagrid.util.diversity",
        "isExtraImport": true,
        "detail": "metta.mettagrid.util.diversity",
        "documentation": {}
    },
    {
        "label": "Random",
        "importPath": "metta.mettagrid.room.random",
        "description": "metta.mettagrid.room.random",
        "isExtraImport": true,
        "detail": "metta.mettagrid.room.random",
        "documentation": {}
    },
    {
        "label": "gc",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gc",
        "description": "gc",
        "detail": "gc",
        "documentation": {}
    },
    {
        "label": "ConfigAttributeError",
        "importPath": "omegaconf.errors",
        "description": "omegaconf.errors",
        "isExtraImport": true,
        "detail": "omegaconf.errors",
        "documentation": {}
    },
    {
        "label": "pixie",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pixie",
        "description": "pixie",
        "detail": "pixie",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_environment",
        "importPath": "metta.common.util.runtime_configuration",
        "description": "metta.common.util.runtime_configuration",
        "isExtraImport": true,
        "detail": "metta.common.util.runtime_configuration",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_environment",
        "importPath": "metta.common.util.runtime_configuration",
        "description": "metta.common.util.runtime_configuration",
        "isExtraImport": true,
        "detail": "metta.common.util.runtime_configuration",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_environment",
        "importPath": "metta.common.util.runtime_configuration",
        "description": "metta.common.util.runtime_configuration",
        "isExtraImport": true,
        "detail": "metta.common.util.runtime_configuration",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_environment",
        "importPath": "metta.common.util.runtime_configuration",
        "description": "metta.common.util.runtime_configuration",
        "isExtraImport": true,
        "detail": "metta.common.util.runtime_configuration",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_environment",
        "importPath": "metta.common.util.runtime_configuration",
        "description": "metta.common.util.runtime_configuration",
        "isExtraImport": true,
        "detail": "metta.common.util.runtime_configuration",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_environment",
        "importPath": "metta.common.util.runtime_configuration",
        "description": "metta.common.util.runtime_configuration",
        "isExtraImport": true,
        "detail": "metta.common.util.runtime_configuration",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_environment",
        "importPath": "metta.common.util.runtime_configuration",
        "description": "metta.common.util.runtime_configuration",
        "isExtraImport": true,
        "detail": "metta.common.util.runtime_configuration",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_environment",
        "importPath": "metta.common.util.runtime_configuration",
        "description": "metta.common.util.runtime_configuration",
        "isExtraImport": true,
        "detail": "metta.common.util.runtime_configuration",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_environment",
        "importPath": "metta.common.util.runtime_configuration",
        "description": "metta.common.util.runtime_configuration",
        "isExtraImport": true,
        "detail": "metta.common.util.runtime_configuration",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_environment",
        "importPath": "metta.common.util.runtime_configuration",
        "description": "metta.common.util.runtime_configuration",
        "isExtraImport": true,
        "detail": "metta.common.util.runtime_configuration",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_environment",
        "importPath": "metta.common.util.runtime_configuration",
        "description": "metta.common.util.runtime_configuration",
        "isExtraImport": true,
        "detail": "metta.common.util.runtime_configuration",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_environment",
        "importPath": "metta.common.util.runtime_configuration",
        "description": "metta.common.util.runtime_configuration",
        "isExtraImport": true,
        "detail": "metta.common.util.runtime_configuration",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_environment",
        "importPath": "metta.common.util.runtime_configuration",
        "description": "metta.common.util.runtime_configuration",
        "isExtraImport": true,
        "detail": "metta.common.util.runtime_configuration",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_environment",
        "importPath": "metta.common.util.runtime_configuration",
        "description": "metta.common.util.runtime_configuration",
        "isExtraImport": true,
        "detail": "metta.common.util.runtime_configuration",
        "documentation": {}
    },
    {
        "label": "StaticFiles",
        "importPath": "fastapi.staticfiles",
        "description": "fastapi.staticfiles",
        "isExtraImport": true,
        "detail": "fastapi.staticfiles",
        "documentation": {}
    },
    {
        "label": "mettascope.replays",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "mettascope.replays",
        "description": "mettascope.replays",
        "detail": "mettascope.replays",
        "documentation": {}
    },
    {
        "label": "metta_script",
        "importPath": "metta.common.util.script_decorators",
        "description": "metta.common.util.script_decorators",
        "isExtraImport": true,
        "detail": "metta.common.util.script_decorators",
        "documentation": {}
    },
    {
        "label": "metta_script",
        "importPath": "metta.common.util.script_decorators",
        "description": "metta.common.util.script_decorators",
        "isExtraImport": true,
        "detail": "metta.common.util.script_decorators",
        "documentation": {}
    },
    {
        "label": "metta_script",
        "importPath": "metta.common.util.script_decorators",
        "description": "metta.common.util.script_decorators",
        "isExtraImport": true,
        "detail": "metta.common.util.script_decorators",
        "documentation": {}
    },
    {
        "label": "metta_script",
        "importPath": "metta.common.util.script_decorators",
        "description": "metta.common.util.script_decorators",
        "isExtraImport": true,
        "detail": "metta.common.util.script_decorators",
        "documentation": {}
    },
    {
        "label": "metta_script",
        "importPath": "metta.common.util.script_decorators",
        "description": "metta.common.util.script_decorators",
        "isExtraImport": true,
        "detail": "metta.common.util.script_decorators",
        "documentation": {}
    },
    {
        "label": "metta_script",
        "importPath": "metta.common.util.script_decorators",
        "description": "metta.common.util.script_decorators",
        "isExtraImport": true,
        "detail": "metta.common.util.script_decorators",
        "documentation": {}
    },
    {
        "label": "metta_script",
        "importPath": "metta.common.util.script_decorators",
        "description": "metta.common.util.script_decorators",
        "isExtraImport": true,
        "detail": "metta.common.util.script_decorators",
        "documentation": {}
    },
    {
        "label": "PolicyEvalMetric",
        "importPath": "metta.eval.dashboard_data",
        "description": "metta.eval.dashboard_data",
        "isExtraImport": true,
        "detail": "metta.eval.dashboard_data",
        "documentation": {}
    },
    {
        "label": "get_policy_eval_metrics",
        "importPath": "metta.eval.dashboard_data",
        "description": "metta.eval.dashboard_data",
        "isExtraImport": true,
        "detail": "metta.eval.dashboard_data",
        "documentation": {}
    },
    {
        "label": "DashboardConfig",
        "importPath": "metta.eval.dashboard_data",
        "description": "metta.eval.dashboard_data",
        "isExtraImport": true,
        "detail": "metta.eval.dashboard_data",
        "documentation": {}
    },
    {
        "label": "write_dashboard_data",
        "importPath": "metta.eval.dashboard_data",
        "description": "metta.eval.dashboard_data",
        "isExtraImport": true,
        "detail": "metta.eval.dashboard_data",
        "documentation": {}
    },
    {
        "label": "Ascii",
        "importPath": "metta.map.scenes.ascii",
        "description": "metta.map.scenes.ascii",
        "isExtraImport": true,
        "detail": "metta.map.scenes.ascii",
        "documentation": {}
    },
    {
        "label": "assert_grid",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "render_scene",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "assert_connected",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "render_scene",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "assert_connected",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "render_scene",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "render_scene",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "assert_grid",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "render_scene",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "assert_connected",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "render_scene",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "assert_connected",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "render_scene",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "assert_grid",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "render_scene",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "render_scene",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "render_scene",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "render_scene",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "render_scene",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "render_scene",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "render_scene",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "assert_grid",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "render_scene",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "assert_grid",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "render_scene",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "render_scene",
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "isExtraImport": true,
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "Auto",
        "importPath": "metta.map.scenes.auto",
        "description": "metta.map.scenes.auto",
        "isExtraImport": true,
        "detail": "metta.map.scenes.auto",
        "documentation": {}
    },
    {
        "label": "ConvChain",
        "importPath": "metta.map.scenes.convchain",
        "description": "metta.map.scenes.convchain",
        "isExtraImport": true,
        "detail": "metta.map.scenes.convchain",
        "documentation": {}
    },
    {
        "label": "MazeKruskal",
        "importPath": "metta.map.scenes.maze",
        "description": "metta.map.scenes.maze",
        "isExtraImport": true,
        "detail": "metta.map.scenes.maze",
        "documentation": {}
    },
    {
        "label": "MazeKruskal",
        "importPath": "metta.map.scenes.maze",
        "description": "metta.map.scenes.maze",
        "isExtraImport": true,
        "detail": "metta.map.scenes.maze",
        "documentation": {}
    },
    {
        "label": "MultiLeftAndRight",
        "importPath": "metta.map.scenes.multi_left_and_right",
        "description": "metta.map.scenes.multi_left_and_right",
        "isExtraImport": true,
        "detail": "metta.map.scenes.multi_left_and_right",
        "documentation": {}
    },
    {
        "label": "Nop",
        "importPath": "metta.map.scenes.nop",
        "description": "metta.map.scenes.nop",
        "isExtraImport": true,
        "detail": "metta.map.scenes.nop",
        "documentation": {}
    },
    {
        "label": "Nop",
        "importPath": "metta.map.scenes.nop",
        "description": "metta.map.scenes.nop",
        "isExtraImport": true,
        "detail": "metta.map.scenes.nop",
        "documentation": {}
    },
    {
        "label": "RandomSceneFromDir",
        "importPath": "metta.map.scenes.random_scene_from_dir",
        "description": "metta.map.scenes.random_scene_from_dir",
        "isExtraImport": true,
        "detail": "metta.map.scenes.random_scene_from_dir",
        "documentation": {}
    },
    {
        "label": "RemoveAgents",
        "importPath": "metta.map.scenes.remove_agents",
        "description": "metta.map.scenes.remove_agents",
        "isExtraImport": true,
        "detail": "metta.map.scenes.remove_agents",
        "documentation": {}
    },
    {
        "label": "WFC",
        "importPath": "metta.map.scenes.wfc",
        "description": "metta.map.scenes.wfc",
        "isExtraImport": true,
        "detail": "metta.map.scenes.wfc",
        "documentation": {}
    },
    {
        "label": "compute_gae",
        "importPath": "metta.rl.fast_gae",
        "description": "metta.rl.fast_gae",
        "isExtraImport": true,
        "detail": "metta.rl.fast_gae",
        "documentation": {}
    },
    {
        "label": "MettaProtein",
        "importPath": "metta.sweep.protein_metta",
        "description": "metta.sweep.protein_metta",
        "isExtraImport": true,
        "detail": "metta.sweep.protein_metta",
        "documentation": {}
    },
    {
        "label": "MettaProtein",
        "importPath": "metta.sweep.protein_metta",
        "description": "metta.sweep.protein_metta",
        "isExtraImport": true,
        "detail": "metta.sweep.protein_metta",
        "documentation": {}
    },
    {
        "label": "WandbProtein",
        "importPath": "metta.sweep.protein_wandb",
        "description": "metta.sweep.protein_wandb",
        "isExtraImport": true,
        "detail": "metta.sweep.protein_wandb",
        "documentation": {}
    },
    {
        "label": "WandbProtein",
        "importPath": "metta.sweep.protein_wandb",
        "description": "metta.sweep.protein_wandb",
        "isExtraImport": true,
        "detail": "metta.sweep.protein_wandb",
        "documentation": {}
    },
    {
        "label": "GlobalHydra",
        "importPath": "hydra.core.global_hydra",
        "description": "hydra.core.global_hydra",
        "isExtraImport": true,
        "detail": "hydra.core.global_hydra",
        "documentation": {}
    },
    {
        "label": "GlobalHydra",
        "importPath": "hydra.core.global_hydra",
        "description": "hydra.core.global_hydra",
        "isExtraImport": true,
        "detail": "hydra.core.global_hydra",
        "documentation": {}
    },
    {
        "label": "GlobalHydra",
        "importPath": "hydra.core.global_hydra",
        "description": "hydra.core.global_hydra",
        "isExtraImport": true,
        "detail": "hydra.core.global_hydra",
        "documentation": {}
    },
    {
        "label": "GlobalHydra",
        "importPath": "hydra.core.global_hydra",
        "description": "hydra.core.global_hydra",
        "isExtraImport": true,
        "detail": "hydra.core.global_hydra",
        "documentation": {}
    },
    {
        "label": "ReplayJob",
        "importPath": "tools.replay",
        "description": "tools.replay",
        "isExtraImport": true,
        "detail": "tools.replay",
        "documentation": {}
    },
    {
        "label": "SimJob",
        "importPath": "tools.sim",
        "description": "tools.sim",
        "isExtraImport": true,
        "detail": "tools.sim",
        "documentation": {}
    },
    {
        "label": "load_and_print_config",
        "importPath": "tools.validate_config",
        "description": "tools.validate_config",
        "isExtraImport": true,
        "detail": "tools.validate_config",
        "documentation": {}
    },
    {
        "label": "string",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "string",
        "description": "string",
        "detail": "string",
        "documentation": {}
    },
    {
        "label": "ShowMode",
        "importPath": "metta.map.utils.show",
        "description": "metta.map.utils.show",
        "isExtraImport": true,
        "detail": "metta.map.utils.show",
        "documentation": {}
    },
    {
        "label": "show_map",
        "importPath": "metta.map.utils.show",
        "description": "metta.map.utils.show",
        "isExtraImport": true,
        "detail": "metta.map.utils.show",
        "documentation": {}
    },
    {
        "label": "ShowMode",
        "importPath": "metta.map.utils.show",
        "description": "metta.map.utils.show",
        "isExtraImport": true,
        "detail": "metta.map.utils.show",
        "documentation": {}
    },
    {
        "label": "show_map",
        "importPath": "metta.map.utils.show",
        "description": "metta.map.utils.show",
        "isExtraImport": true,
        "detail": "metta.map.utils.show",
        "documentation": {}
    },
    {
        "label": "ShowMode",
        "importPath": "metta.map.utils.show",
        "description": "metta.map.utils.show",
        "isExtraImport": true,
        "detail": "metta.map.utils.show",
        "documentation": {}
    },
    {
        "label": "show_map",
        "importPath": "metta.map.utils.show",
        "description": "metta.map.utils.show",
        "isExtraImport": true,
        "detail": "metta.map.utils.show",
        "documentation": {}
    },
    {
        "label": "map_builder_cfg_to_storable_map",
        "importPath": "tools.map.gen",
        "description": "tools.map.gen",
        "isExtraImport": true,
        "detail": "tools.map.gen",
        "documentation": {}
    },
    {
        "label": "uri_is_file",
        "importPath": "tools.map.gen",
        "description": "tools.map.gen",
        "isExtraImport": true,
        "detail": "tools.map.gen",
        "documentation": {}
    },
    {
        "label": "get_random_map_uri",
        "importPath": "metta.map.load_random",
        "description": "metta.map.load_random",
        "isExtraImport": true,
        "detail": "metta.map.load_random",
        "documentation": {}
    },
    {
        "label": "analyze",
        "importPath": "metta.eval.analysis",
        "description": "metta.eval.analysis",
        "isExtraImport": true,
        "detail": "metta.eval.analysis",
        "documentation": {}
    },
    {
        "label": "get_stats_client",
        "importPath": "metta.common.util.stats_client_cfg",
        "description": "metta.common.util.stats_client_cfg",
        "isExtraImport": true,
        "detail": "metta.common.util.stats_client_cfg",
        "documentation": {}
    },
    {
        "label": "get_stats_client",
        "importPath": "metta.common.util.stats_client_cfg",
        "description": "metta.common.util.stats_client_cfg",
        "isExtraImport": true,
        "detail": "metta.common.util.stats_client_cfg",
        "documentation": {}
    },
    {
        "label": "run_once",
        "importPath": "metta.common.util.lock",
        "description": "metta.common.util.lock",
        "isExtraImport": true,
        "detail": "metta.common.util.lock",
        "documentation": {}
    },
    {
        "label": "generate_run_id_for_sweep",
        "importPath": "metta.common.wandb.sweep",
        "description": "metta.common.wandb.sweep",
        "isExtraImport": true,
        "detail": "metta.common.wandb.sweep",
        "documentation": {}
    },
    {
        "label": "sweep_id_from_name",
        "importPath": "metta.common.wandb.sweep",
        "description": "metta.common.wandb.sweep",
        "isExtraImport": true,
        "detail": "metta.common.wandb.sweep",
        "documentation": {}
    },
    {
        "label": "record",
        "importPath": "torch.distributed.elastic.multiprocessing.errors",
        "description": "torch.distributed.elastic.multiprocessing.errors",
        "isExtraImport": true,
        "detail": "torch.distributed.elastic.multiprocessing.errors",
        "documentation": {}
    },
    {
        "label": "load_train_job_config_with_overrides",
        "importPath": "tools.sweep_config_utils",
        "description": "tools.sweep_config_utils",
        "isExtraImport": true,
        "detail": "tools.sweep_config_utils",
        "documentation": {}
    },
    {
        "label": "mimetypes",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "mimetypes",
        "description": "mimetypes",
        "detail": "mimetypes",
        "documentation": {}
    },
    {
        "label": "WandbContext",
        "importPath": "metta.common.util.wandb.wandb_context",
        "description": "metta.common.util.wandb.wandb_context",
        "isExtraImport": true,
        "detail": "metta.common.util.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "WandbContext",
        "importPath": "metta.common.util.wandb.wandb_context",
        "description": "metta.common.util.wandb.wandb_context",
        "isExtraImport": true,
        "detail": "metta.common.util.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "WandbContext",
        "importPath": "metta.common.util.wandb.wandb_context",
        "description": "metta.common.util.wandb.wandb_context",
        "isExtraImport": true,
        "detail": "metta.common.util.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "WandbContext",
        "importPath": "metta.common.util.wandb.wandb_context",
        "description": "metta.common.util.wandb.wandb_context",
        "isExtraImport": true,
        "detail": "metta.common.util.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "WandbContext",
        "importPath": "metta.common.util.wandb.wandb_context",
        "description": "metta.common.util.wandb.wandb_context",
        "isExtraImport": true,
        "detail": "metta.common.util.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "WandbContext",
        "importPath": "metta.common.util.wandb.wandb_context",
        "description": "metta.common.util.wandb.wandb_context",
        "isExtraImport": true,
        "detail": "metta.common.util.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "CARBS",
        "importPath": "carbs",
        "description": "carbs",
        "isExtraImport": true,
        "detail": "carbs",
        "documentation": {}
    },
    {
        "label": "LinearSpace",
        "importPath": "carbs",
        "description": "carbs",
        "isExtraImport": true,
        "detail": "carbs",
        "documentation": {}
    },
    {
        "label": "LogitSpace",
        "importPath": "carbs",
        "description": "carbs",
        "isExtraImport": true,
        "detail": "carbs",
        "documentation": {}
    },
    {
        "label": "LogSpace",
        "importPath": "carbs",
        "description": "carbs",
        "isExtraImport": true,
        "detail": "carbs",
        "documentation": {}
    },
    {
        "label": "ObservationInParam",
        "importPath": "carbs",
        "description": "carbs",
        "isExtraImport": true,
        "detail": "carbs",
        "documentation": {}
    },
    {
        "label": "Param",
        "importPath": "carbs",
        "description": "carbs",
        "isExtraImport": true,
        "detail": "carbs",
        "documentation": {}
    },
    {
        "label": "SuggestionInBasic",
        "importPath": "carbs",
        "description": "carbs",
        "isExtraImport": true,
        "detail": "carbs",
        "documentation": {}
    },
    {
        "label": "extract_asana_urls_from_description",
        "kind": 2,
        "importPath": ".github.actions.asana.ensure-task.main",
        "description": ".github.actions.asana.ensure-task.main",
        "peekOfCode": "def extract_asana_urls_from_description(description: str) -> list[str]:\n    \"\"\"Extract Asana task URLs from the description text.\"\"\"\n    if not description:\n        return []\n    # Pattern to match Asana task URLs in the format used by update-pr-description\n    # Matches: [Asana Task](https://app.asana.com/0/123456789/123456789)\n    asana_pattern = r\"\\[Asana Task\\]\\((https://app\\.asana\\.com/\\d+/\\d+/\\d+(?:\\?[^\\s\\)]*)?)\\)\"\n    urls = re.findall(asana_pattern, description)\n    return urls\ndef validate_asana_task_url(",
        "detail": ".github.actions.asana.ensure-task.main",
        "documentation": {}
    },
    {
        "label": "validate_asana_task_url",
        "kind": 2,
        "importPath": ".github.actions.asana.ensure-task.main",
        "description": ".github.actions.asana.ensure-task.main",
        "peekOfCode": "def validate_asana_task_url(\n    task_url: str, project_id: str, github_url: str, github_url_field_id: str, asana_token: str\n) -> dict | None:\n    \"\"\"Validate that an Asana task URL exists, belongs to the specified project, and has the expected GitHub URL.\"\"\"\n    # Extract task GID from URL\n    # URL format: https://app.asana.com/0/123456789/123456789\n    match = re.search(r\"https://app\\.asana\\.com/\\d+/\\d+/(\\d+)\", task_url)\n    if not match:\n        print(f\"Invalid Asana task URL format: {task_url}\")\n        return None",
        "detail": ".github.actions.asana.ensure-task.main",
        "documentation": {}
    },
    {
        "label": "search_asana_tasks",
        "kind": 2,
        "importPath": ".github.actions.asana.ensure-task.main",
        "description": ".github.actions.asana.ensure-task.main",
        "peekOfCode": "def search_asana_tasks(\n    github_url: str,\n    project_id: str,\n    workspace_id: str,\n    github_url_field_id: str,\n    asana_token: str,\n) -> dict | None:\n    \"\"\"Search for existing Asana tasks with the given GitHub URL in the specified project.\"\"\"\n    # Use workspace search endpoint which supports custom field filtering\n    url = f\"https://app.asana.com/api/1.0/workspaces/{workspace_id}/tasks/search\"",
        "detail": ".github.actions.asana.ensure-task.main",
        "documentation": {}
    },
    {
        "label": "get_asana_users_by_github_logins",
        "kind": 2,
        "importPath": ".github.actions.asana.ensure-task.main",
        "description": ".github.actions.asana.ensure-task.main",
        "peekOfCode": "def get_asana_users_by_github_logins(\n    github_logins: set[str],\n    roster_project_id: str,\n    gh_login_field_id: str,\n    asana_email_field_id: str,\n    asana_token: str,\n) -> dict[str, str]:\n    \"\"\"Get the Asana user IDs for the given GitHub logins.\"\"\"\n    github_login_to_asana_email = {}\n    # Paginate through all tasks in the roster project, since we can't search for multiple github logins at once",
        "detail": ".github.actions.asana.ensure-task.main",
        "documentation": {}
    },
    {
        "label": "create_asana_task",
        "kind": 2,
        "importPath": ".github.actions.asana.ensure-task.main",
        "description": ".github.actions.asana.ensure-task.main",
        "peekOfCode": "def create_asana_task(\n    title: str,\n    description: str,\n    completed: bool,\n    assignee: str | None,\n    collaborators: list[str],\n    project_id: str,\n    workspace_id: str,\n    github_url: str,\n    github_url_field_id: str,",
        "detail": ".github.actions.asana.ensure-task.main",
        "documentation": {}
    },
    {
        "label": "update_asana_task",
        "kind": 2,
        "importPath": ".github.actions.asana.ensure-task.main",
        "description": ".github.actions.asana.ensure-task.main",
        "peekOfCode": "def update_asana_task(\n    task_gid: str,\n    title: str,\n    description: str,\n    completed: bool,\n    assignee: str | None,\n    asana_token: str,\n    github_url: str,\n    github_url_field_id: str,\n    pr_author_field_id: str,",
        "detail": ".github.actions.asana.ensure-task.main",
        "documentation": {}
    },
    {
        "label": "update_task_if_needed",
        "kind": 2,
        "importPath": ".github.actions.asana.ensure-task.main",
        "description": ".github.actions.asana.ensure-task.main",
        "peekOfCode": "def update_task_if_needed(\n    task_data: dict,\n    title: str,\n    description: str,\n    task_completed: bool,\n    asana_assignee: str | None,\n    asana_token: str,\n    github_url: str,\n    github_url_field_id: str,\n    pr_author_field_id: str,",
        "detail": ".github.actions.asana.ensure-task.main",
        "documentation": {}
    },
    {
        "label": "find_and_validate_task",
        "kind": 2,
        "importPath": ".github.actions.asana.ensure-task.main",
        "description": ".github.actions.asana.ensure-task.main",
        "peekOfCode": "def find_and_validate_task(\n    project_id: str,\n    github_url: str,\n    github_url_field_id: str,\n    asana_token: str,\n    workspace_id: str | None = None,\n) -> dict | None:\n    \"\"\"Find a task that matches the project and GitHub URL requirements.\"\"\"\n    # First try to find by searching Asana tasks with the GitHub URL\n    if workspace_id:",
        "detail": ".github.actions.asana.ensure-task.main",
        "documentation": {}
    },
    {
        "label": "ensure_asana_task_exists",
        "kind": 2,
        "importPath": ".github.actions.asana.ensure-task.main",
        "description": ".github.actions.asana.ensure-task.main",
        "peekOfCode": "def ensure_asana_task_exists(\n    title: str,\n    description: str,\n    task_completed: bool,\n    asana_assignee: str | None,\n    asana_collaborators: list[str],\n    project_id: str,\n    workspace_id: str,\n    github_url: str,\n    github_url_field_id: str,",
        "detail": ".github.actions.asana.ensure-task.main",
        "documentation": {}
    },
    {
        "label": "update_pr_description",
        "kind": 2,
        "importPath": ".github.actions.asana.update-pr-description.main",
        "description": ".github.actions.asana.update-pr-description.main",
        "peekOfCode": "def update_pr_description(repo, pr_number, task_url, token):\n    url = f\"https://api.github.com/repos/{repo}/pulls/{pr_number}\"\n    headers = {\n        \"Authorization\": f\"Bearer {token}\",\n        \"Accept\": \"application/vnd.github.v3+json\",\n    }\n    # Fetch the current PR description\n    response = requests.get(url, headers=headers)\n    if response.status_code != 200:\n        print(f\"GitHub API Error: {response.status_code} - {response.text}\")",
        "detail": ".github.actions.asana.update-pr-description.main",
        "documentation": {}
    },
    {
        "label": "safe_load_json",
        "kind": 2,
        "importPath": ".github.actions.combine-all-benchmarks.combine_all_benchmarks",
        "description": ".github.actions.combine-all-benchmarks.combine_all_benchmarks",
        "peekOfCode": "def safe_load_json(file_path):\n    try:\n        if os.path.exists(file_path):\n            with open(file_path, \"r\") as f:\n                content = f.read().strip()\n                if content:\n                    return json.loads(content)\n        return {}\n    except (json.JSONDecodeError, FileNotFoundError):\n        print(f\"Warning: Could not load {file_path}\")",
        "detail": ".github.actions.combine-all-benchmarks.combine_all_benchmarks",
        "documentation": {}
    },
    {
        "label": "convert_pytest_to_bmf_format",
        "kind": 2,
        "importPath": ".github.actions.combine-all-benchmarks.combine_all_benchmarks",
        "description": ".github.actions.combine-all-benchmarks.combine_all_benchmarks",
        "peekOfCode": "def convert_pytest_to_bmf_format(pytest_data):\n    \"\"\"Convert pytest-benchmark to BMF using only 2 KPIs (no latency)\"\"\"\n    bmf_results = {}\n    for bench in pytest_data.get(\"benchmarks\", []):\n        name = bench.get(\"fullname\", bench.get(\"name\", \"unknown\"))\n        extra_info = bench.get(\"extra_info\", {})\n        bench_metrics = {}\n        kpis = [\"agent_rate\", \"env_rate\"]\n        for kpi_name in kpis:\n            if kpi_name in extra_info and isinstance(extra_info[kpi_name], (int, float)):",
        "detail": ".github.actions.combine-all-benchmarks.combine_all_benchmarks",
        "documentation": {}
    },
    {
        "label": "convert_cpp_to_bmf_format",
        "kind": 2,
        "importPath": ".github.actions.combine-all-benchmarks.combine_all_benchmarks",
        "description": ".github.actions.combine-all-benchmarks.combine_all_benchmarks",
        "peekOfCode": "def convert_cpp_to_bmf_format(cpp_data):\n    \"\"\"Convert Google Benchmark to BMF using only custom counters (no latency)\"\"\"\n    bmf_results = {}\n    for bench in cpp_data.get(\"benchmarks\", []):\n        name = bench.get(\"name\", \"unknown\")\n        bench_metrics = {}\n        # Debug: print all keys in the benchmark to understand structure\n        print(f\"Benchmark '{name}' has keys: {list(bench.keys())}\")\n        # Check if counters are in user_counters or directly in bench\n        counters = bench.get(\"user_counters\", bench)",
        "detail": ".github.actions.combine-all-benchmarks.combine_all_benchmarks",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".github.actions.combine-all-benchmarks.combine_all_benchmarks",
        "description": ".github.actions.combine-all-benchmarks.combine_all_benchmarks",
        "peekOfCode": "def main():\n    \"\"\"Main entry point.\"\"\"\n    # Get inputs from environment variables\n    python_files = os.environ.get(\"PYTHON_FILES\", \"\").split(\",\")\n    cpp_pattern = os.environ.get(\"CPP_FILES\", \"\")\n    output_file = os.environ.get(\"OUTPUT_FILE\", \"unified_benchmark_results.json\")\n    # Initialize unified results in BMF format\n    unified_results = {}\n    # Process Python benchmark files\n    for file_path in python_files:",
        "detail": ".github.actions.combine-all-benchmarks.combine_all_benchmarks",
        "documentation": {}
    },
    {
        "label": "split_content",
        "kind": 2,
        "importPath": ".github.actions.discord-webhook.discord_webhook",
        "description": ".github.actions.discord-webhook.discord_webhook",
        "peekOfCode": "def split_content(content: str, max_len: int = DISCORD_MESSAGE_CHARACTER_LIMIT) -> List[str]:\n    \"\"\"Split content into chunks that fit Discord's message limit.\n    Attempts to split at natural boundaries (paragraphs, lines, words) to maintain readability.\n    \"\"\"\n    if not content:\n        return []\n    chunks: List[str] = []\n    remaining_content = content.strip()\n    while remaining_content:\n        if len(remaining_content) <= max_len:",
        "detail": ".github.actions.discord-webhook.discord_webhook",
        "documentation": {}
    },
    {
        "label": "sanitize_discord_content",
        "kind": 2,
        "importPath": ".github.actions.discord-webhook.discord_webhook",
        "description": ".github.actions.discord-webhook.discord_webhook",
        "peekOfCode": "def sanitize_discord_content(content: str) -> str:\n    \"\"\"Sanitize content for Discord to prevent injection attacks.\"\"\"\n    # Remove @everyone and @here mentions\n    content = content.replace(\"@everyone\", \"@\\u200beveryone\")\n    content = content.replace(\"@here\", \"@\\u200bhere\")\n    # Also handle variations with extra spaces\n    content = content.replace(\"@ everyone\", \"@ \\u200beveryone\")\n    content = content.replace(\"@ here\", \"@ \\u200bhere\")\n    return content\ndef send_to_discord(webhook_url: str, content: str, suppress_embeds: bool = True) -> bool:",
        "detail": ".github.actions.discord-webhook.discord_webhook",
        "documentation": {}
    },
    {
        "label": "send_to_discord",
        "kind": 2,
        "importPath": ".github.actions.discord-webhook.discord_webhook",
        "description": ".github.actions.discord-webhook.discord_webhook",
        "peekOfCode": "def send_to_discord(webhook_url: str, content: str, suppress_embeds: bool = True) -> bool:\n    \"\"\"Send content to Discord webhook, handling message splitting.\n    Args:\n        webhook_url: Discord webhook URL\n        content: Content to post\n        suppress_embeds: Whether to suppress link embeds\n    Returns:\n        True if all messages sent successfully, False otherwise\n    \"\"\"\n    # Sanitize content before splitting",
        "detail": ".github.actions.discord-webhook.discord_webhook",
        "documentation": {}
    },
    {
        "label": "get_content",
        "kind": 2,
        "importPath": ".github.actions.discord-webhook.discord_webhook",
        "description": ".github.actions.discord-webhook.discord_webhook",
        "peekOfCode": "def get_content() -> str:\n    \"\"\"Get content from either direct input or file.\"\"\"\n    # Try direct content first\n    content = os.getenv(\"DISCORD_CONTENT\")\n    if content:\n        return content\n    # Try content file\n    content_file = os.getenv(\"DISCORD_CONTENT_FILE\")\n    if content_file:\n        content_path = Path(content_file)",
        "detail": ".github.actions.discord-webhook.discord_webhook",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".github.actions.discord-webhook.discord_webhook",
        "description": ".github.actions.discord-webhook.discord_webhook",
        "peekOfCode": "def main() -> None:\n    \"\"\"Main entry point for the Discord posting action.\"\"\"\n    webhook_url = os.getenv(\"DISCORD_WEBHOOK_URL\")\n    suppress_embeds = os.getenv(\"DISCORD_SUPPRESS_EMBEDS\", \"true\").lower() == \"true\"\n    if not webhook_url:\n        print(\"Error: DISCORD_WEBHOOK_URL not provided\", file=sys.stderr)\n        sys.exit(1)\n    # Get content from either direct input or file\n    content = get_content()\n    if not content.strip():",
        "detail": ".github.actions.discord-webhook.discord_webhook",
        "documentation": {}
    },
    {
        "label": "DISCORD_MESSAGE_CHARACTER_LIMIT",
        "kind": 5,
        "importPath": ".github.actions.discord-webhook.discord_webhook",
        "description": ".github.actions.discord-webhook.discord_webhook",
        "peekOfCode": "DISCORD_MESSAGE_CHARACTER_LIMIT = 2000\nRATE_LIMIT_DELAY = 0.5  # Delay between messages to avoid rate limiting\ndef split_content(content: str, max_len: int = DISCORD_MESSAGE_CHARACTER_LIMIT) -> List[str]:\n    \"\"\"Split content into chunks that fit Discord's message limit.\n    Attempts to split at natural boundaries (paragraphs, lines, words) to maintain readability.\n    \"\"\"\n    if not content:\n        return []\n    chunks: List[str] = []\n    remaining_content = content.strip()",
        "detail": ".github.actions.discord-webhook.discord_webhook",
        "documentation": {}
    },
    {
        "label": "RATE_LIMIT_DELAY",
        "kind": 5,
        "importPath": ".github.actions.discord-webhook.discord_webhook",
        "description": ".github.actions.discord-webhook.discord_webhook",
        "peekOfCode": "RATE_LIMIT_DELAY = 0.5  # Delay between messages to avoid rate limiting\ndef split_content(content: str, max_len: int = DISCORD_MESSAGE_CHARACTER_LIMIT) -> List[str]:\n    \"\"\"Split content into chunks that fit Discord's message limit.\n    Attempts to split at natural boundaries (paragraphs, lines, words) to maintain readability.\n    \"\"\"\n    if not content:\n        return []\n    chunks: List[str] = []\n    remaining_content = content.strip()\n    while remaining_content:",
        "detail": ".github.actions.discord-webhook.discord_webhook",
        "documentation": {}
    },
    {
        "label": "GitHubActionsOutput",
        "kind": 6,
        "importPath": ".github.actions.fetch-artifacts.fetch_artifacts",
        "description": ".github.actions.fetch-artifacts.fetch_artifacts",
        "peekOfCode": "class GitHubActionsOutput:\n    \"\"\"Helper for setting GitHub Actions outputs safely.\"\"\"\n    def __init__(self):\n        self.github_output = os.environ.get(\"GITHUB_OUTPUT\")\n    def set_output(self, name: str, value: str) -> None:\n        \"\"\"Set a GitHub Actions output value.\"\"\"\n        if self.github_output:\n            with open(self.github_output, \"a\", encoding=\"utf-8\") as f:\n                # Use delimiter for multiline content\n                if \"\\n\" in value:",
        "detail": ".github.actions.fetch-artifacts.fetch_artifacts",
        "documentation": {}
    },
    {
        "label": "GitHubAPI",
        "kind": 6,
        "importPath": ".github.actions.fetch-artifacts.fetch_artifacts",
        "description": ".github.actions.fetch-artifacts.fetch_artifacts",
        "peekOfCode": "class GitHubAPI:\n    \"\"\"GitHub API client using PyGithub for fetching workflow runs and artifacts.\"\"\"\n    def __init__(self, token: str, repo: str):\n        self.token = token\n        self.github = Github(token)\n        self.repo = self.github.get_repo(repo)\n    def get_workflow_runs(self, workflow_filename: str, exclude_run_id: Optional[str] = None) -> list[dict[str, Any]]:\n        \"\"\"Get successful workflow runs for the specified workflow.\"\"\"\n        try:\n            workflow = self.repo.get_workflow(workflow_filename)",
        "detail": ".github.actions.fetch-artifacts.fetch_artifacts",
        "documentation": {}
    },
    {
        "label": "ArtifactFetcher",
        "kind": 6,
        "importPath": ".github.actions.fetch-artifacts.fetch_artifacts",
        "description": ".github.actions.fetch-artifacts.fetch_artifacts",
        "peekOfCode": "class ArtifactFetcher:\n    \"\"\"Main class for fetching artifacts and saving them as ZIP files.\"\"\"\n    def __init__(self, config: dict[str, Any]):\n        self.config = config\n        self.github_api = GitHubAPI(config[\"github_token\"], config[\"repo\"])\n        self.output = GitHubActionsOutput()\n        self.current_run_id = os.environ.get(\"GITHUB_RUN_ID\")\n    def matches_pattern(self, artifact_name: str, pattern: str) -> bool:\n        \"\"\"Check if artifact name matches the pattern.\"\"\"\n        return fnmatch.fnmatch(artifact_name.lower(), pattern.lower())",
        "detail": ".github.actions.fetch-artifacts.fetch_artifacts",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".github.actions.fetch-artifacts.fetch_artifacts",
        "description": ".github.actions.fetch-artifacts.fetch_artifacts",
        "peekOfCode": "def main():\n    \"\"\"Main entry point.\"\"\"\n    print(\" Starting Fetch Artifacts action\")\n    # Import parse_config\n    script_dir = Path(__file__).parent.parent.parent / \"scripts\"\n    sys.path.insert(0, str(script_dir))\n    from utils.config import parse_config\n    try:\n        required_vars = [\n            \"GITHUB_TOKEN\",",
        "detail": ".github.actions.fetch-artifacts.fetch_artifacts",
        "documentation": {}
    },
    {
        "label": "parse_comma_separated",
        "kind": 2,
        "importPath": ".github.actions.file-changes.file_changes",
        "description": ".github.actions.file-changes.file_changes",
        "peekOfCode": "def parse_comma_separated(value: str) -> List[str]:\n    \"\"\"Parse comma-separated string into list of non-empty strings.\"\"\"\n    return [item.strip() for item in value.split(\",\") if item.strip()]\ndef pattern_matches(filename: str, pattern: str) -> bool:\n    \"\"\"Check if filename matches the given pattern.\"\"\"\n    if \"*\" in pattern:\n        # Convert glob-like pattern to regex\n        regex_pattern = pattern.replace(\".\", r\"\\.\").replace(\"*\", \".*\")\n        return bool(re.match(regex_pattern, filename))\n    else:",
        "detail": ".github.actions.file-changes.file_changes",
        "documentation": {}
    },
    {
        "label": "pattern_matches",
        "kind": 2,
        "importPath": ".github.actions.file-changes.file_changes",
        "description": ".github.actions.file-changes.file_changes",
        "peekOfCode": "def pattern_matches(filename: str, pattern: str) -> bool:\n    \"\"\"Check if filename matches the given pattern.\"\"\"\n    if \"*\" in pattern:\n        # Convert glob-like pattern to regex\n        regex_pattern = pattern.replace(\".\", r\"\\.\").replace(\"*\", \".*\")\n        return bool(re.match(regex_pattern, filename))\n    else:\n        # Simple substring match\n        return pattern in filename\ndef main():",
        "detail": ".github.actions.file-changes.file_changes",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".github.actions.file-changes.file_changes",
        "description": ".github.actions.file-changes.file_changes",
        "peekOfCode": "def main():\n    \"\"\"Main entry point.\"\"\"\n    # Get inputs from environment\n    github_token = os.environ.get(\"GITHUB_TOKEN\")\n    github_repository = os.environ.get(\"GITHUB_REPOSITORY\")\n    github_event_name = os.environ.get(\"GITHUB_EVENT_NAME\")\n    github_event_path = os.environ.get(\"GITHUB_EVENT_PATH\")\n    patterns = parse_comma_separated(os.environ.get(\"PATTERNS\", \"\"))\n    specific_files = parse_comma_separated(os.environ.get(\"SPECIFIC_FILES\", \"\"))\n    directory_paths = parse_comma_separated(os.environ.get(\"DIRECTORY_PATHS\", \"\"))",
        "detail": ".github.actions.file-changes.file_changes",
        "documentation": {}
    },
    {
        "label": "run_gh_command",
        "kind": 2,
        "importPath": ".github.actions.pr-assignment.pr_assignment",
        "description": ".github.actions.pr-assignment.pr_assignment",
        "peekOfCode": "def run_gh_command(args: List[str]) -> Tuple[bool, str]:\n    \"\"\"Execute GitHub CLI commands with error handling to prevent script failures from non-critical operations.\"\"\"\n    try:\n        result = subprocess.run([\"gh\"] + args, capture_output=True, text=True, check=True)\n        return True, result.stdout.strip()\n    except subprocess.CalledProcessError as e:\n        print(f\"Warning: Command failed: {' '.join(['gh'] + args)}\")\n        print(f\"Error: {e.stderr}\")\n        return False, e.stderr\ndef get_pr_info(pr_number: str, repo: str) -> dict:",
        "detail": ".github.actions.pr-assignment.pr_assignment",
        "documentation": {}
    },
    {
        "label": "get_pr_info",
        "kind": 2,
        "importPath": ".github.actions.pr-assignment.pr_assignment",
        "description": ".github.actions.pr-assignment.pr_assignment",
        "peekOfCode": "def get_pr_info(pr_number: str, repo: str) -> dict:\n    \"\"\"Fetch PR metadata to understand current state before making changes.\"\"\"\n    success, output = run_gh_command(\n        [\"pr\", \"view\", pr_number, \"--repo\", repo, \"--json\", \"author,assignees,reviewRequests,labels,title\"]\n    )\n    if not success:\n        return {}\n    try:\n        return json.loads(output)\n    except json.JSONDecodeError:",
        "detail": ".github.actions.pr-assignment.pr_assignment",
        "documentation": {}
    },
    {
        "label": "is_empty",
        "kind": 2,
        "importPath": ".github.actions.pr-assignment.pr_assignment",
        "description": ".github.actions.pr-assignment.pr_assignment",
        "peekOfCode": "def is_empty(value: Optional[str]) -> bool:\n    \"\"\"Safely handle potentially None values from configuration parsing.\"\"\"\n    return not value or not value.strip()\ndef is_true(value: str) -> bool:\n    \"\"\"Normalize boolean string inputs from action parameters to handle case variations.\"\"\"\n    return value.lower() == \"true\"\ndef parse_list(value: str) -> List[str]:\n    \"\"\"Convert action input strings to usable lists, filtering empty values from malformed input.\"\"\"\n    if is_empty(value):\n        return []",
        "detail": ".github.actions.pr-assignment.pr_assignment",
        "documentation": {}
    },
    {
        "label": "is_true",
        "kind": 2,
        "importPath": ".github.actions.pr-assignment.pr_assignment",
        "description": ".github.actions.pr-assignment.pr_assignment",
        "peekOfCode": "def is_true(value: str) -> bool:\n    \"\"\"Normalize boolean string inputs from action parameters to handle case variations.\"\"\"\n    return value.lower() == \"true\"\ndef parse_list(value: str) -> List[str]:\n    \"\"\"Convert action input strings to usable lists, filtering empty values from malformed input.\"\"\"\n    if is_empty(value):\n        return []\n    return [item.strip() for item in value.split(\",\") if item.strip()]\ndef select_random(items: List[str], exclude: Optional[str] = None) -> Optional[str]:\n    \"\"\"Ensure fair distribution of assignments while preventing self-assignment to PR authors.\"\"\"",
        "detail": ".github.actions.pr-assignment.pr_assignment",
        "documentation": {}
    },
    {
        "label": "parse_list",
        "kind": 2,
        "importPath": ".github.actions.pr-assignment.pr_assignment",
        "description": ".github.actions.pr-assignment.pr_assignment",
        "peekOfCode": "def parse_list(value: str) -> List[str]:\n    \"\"\"Convert action input strings to usable lists, filtering empty values from malformed input.\"\"\"\n    if is_empty(value):\n        return []\n    return [item.strip() for item in value.split(\",\") if item.strip()]\ndef select_random(items: List[str], exclude: Optional[str] = None) -> Optional[str]:\n    \"\"\"Ensure fair distribution of assignments while preventing self-assignment to PR authors.\"\"\"\n    if not items:\n        return None\n    filtered_items = [item for item in items if item != exclude]",
        "detail": ".github.actions.pr-assignment.pr_assignment",
        "documentation": {}
    },
    {
        "label": "select_random",
        "kind": 2,
        "importPath": ".github.actions.pr-assignment.pr_assignment",
        "description": ".github.actions.pr-assignment.pr_assignment",
        "peekOfCode": "def select_random(items: List[str], exclude: Optional[str] = None) -> Optional[str]:\n    \"\"\"Ensure fair distribution of assignments while preventing self-assignment to PR authors.\"\"\"\n    if not items:\n        return None\n    filtered_items = [item for item in items if item != exclude]\n    if not filtered_items:\n        return None\n    return random.choice(filtered_items)\ndef clear_assignees(pr_number: str, repo: str, current_assignees: List[str]) -> bool:\n    \"\"\"Remove existing assignments to reset state before applying new assignment logic.\"\"\"",
        "detail": ".github.actions.pr-assignment.pr_assignment",
        "documentation": {}
    },
    {
        "label": "clear_assignees",
        "kind": 2,
        "importPath": ".github.actions.pr-assignment.pr_assignment",
        "description": ".github.actions.pr-assignment.pr_assignment",
        "peekOfCode": "def clear_assignees(pr_number: str, repo: str, current_assignees: List[str]) -> bool:\n    \"\"\"Remove existing assignments to reset state before applying new assignment logic.\"\"\"\n    if not current_assignees:\n        print(\"No existing assignees to clear\")\n        return False\n    cleared = False\n    for assignee in current_assignees:\n        success, _ = run_gh_command([\"pr\", \"edit\", pr_number, \"--remove-assignee\", assignee, \"--repo\", repo])\n        if success:\n            print(f\"Removed assignee: {assignee}\")",
        "detail": ".github.actions.pr-assignment.pr_assignment",
        "documentation": {}
    },
    {
        "label": "clear_reviewers",
        "kind": 2,
        "importPath": ".github.actions.pr-assignment.pr_assignment",
        "description": ".github.actions.pr-assignment.pr_assignment",
        "peekOfCode": "def clear_reviewers(pr_number: str, repo: str, current_reviewers: List[str]) -> bool:\n    \"\"\"Reset review state to prevent accumulation of stale review requests.\"\"\"\n    if not current_reviewers:\n        print(\"No existing review requests to clear\")\n        return False\n    cleared = False\n    for reviewer in current_reviewers:\n        success, _ = run_gh_command([\"pr\", \"edit\", pr_number, \"--remove-reviewer\", reviewer, \"--repo\", repo])\n        if success:\n            print(f\"Removed review request from: {reviewer}\")",
        "detail": ".github.actions.pr-assignment.pr_assignment",
        "documentation": {}
    },
    {
        "label": "clear_labels",
        "kind": 2,
        "importPath": ".github.actions.pr-assignment.pr_assignment",
        "description": ".github.actions.pr-assignment.pr_assignment",
        "peekOfCode": "def clear_labels(pr_number: str, repo: str, current_labels: List[str]) -> bool:\n    \"\"\"Remove existing labels to ensure clean state for forced label application.\"\"\"\n    if not current_labels:\n        print(\"No existing labels to clear\")\n        return False\n    cleared = False\n    for label in current_labels:\n        success, _ = run_gh_command([\"pr\", \"edit\", pr_number, \"--remove-label\", label, \"--repo\", repo])\n        if success:\n            print(f\"Removed label: {label}\")",
        "detail": ".github.actions.pr-assignment.pr_assignment",
        "documentation": {}
    },
    {
        "label": "add_assignees",
        "kind": 2,
        "importPath": ".github.actions.pr-assignment.pr_assignment",
        "description": ".github.actions.pr-assignment.pr_assignment",
        "peekOfCode": "def add_assignees(pr_number: str, repo: str, assignees: List[str]) -> Set[str]:\n    \"\"\"Track successful assignments to build accurate summary comments and handle partial failures.\"\"\"\n    added = set()\n    for assignee in assignees:\n        success, _ = run_gh_command([\"pr\", \"edit\", pr_number, \"--add-assignee\", assignee, \"--repo\", repo])\n        if success:\n            added.add(assignee)\n    return added\ndef add_reviewers(pr_number: str, repo: str, reviewers: List[str]) -> Set[str]:\n    \"\"\"Track successful review requests to build accurate summary comments and handle partial failures.\"\"\"",
        "detail": ".github.actions.pr-assignment.pr_assignment",
        "documentation": {}
    },
    {
        "label": "add_reviewers",
        "kind": 2,
        "importPath": ".github.actions.pr-assignment.pr_assignment",
        "description": ".github.actions.pr-assignment.pr_assignment",
        "peekOfCode": "def add_reviewers(pr_number: str, repo: str, reviewers: List[str]) -> Set[str]:\n    \"\"\"Track successful review requests to build accurate summary comments and handle partial failures.\"\"\"\n    added = set()\n    for reviewer in reviewers:\n        success, _ = run_gh_command([\"pr\", \"edit\", pr_number, \"--add-reviewer\", reviewer, \"--repo\", repo])\n        if success:\n            added.add(reviewer)\n    return added\ndef add_labels(pr_number: str, repo: str, labels: List[str]) -> Set[str]:\n    \"\"\"Track successful label applications to build accurate summary comments and handle partial failures.\"\"\"",
        "detail": ".github.actions.pr-assignment.pr_assignment",
        "documentation": {}
    },
    {
        "label": "add_labels",
        "kind": 2,
        "importPath": ".github.actions.pr-assignment.pr_assignment",
        "description": ".github.actions.pr-assignment.pr_assignment",
        "peekOfCode": "def add_labels(pr_number: str, repo: str, labels: List[str]) -> Set[str]:\n    \"\"\"Track successful label applications to build accurate summary comments and handle partial failures.\"\"\"\n    added = set()\n    for label in labels:\n        success, _ = run_gh_command([\"pr\", \"edit\", pr_number, \"--add-label\", label, \"--repo\", repo])\n        if success:\n            added.add(label)\n    return added\ndef post_comment(pr_number: str, repo: str, comment: str) -> None:\n    \"\"\"Provide visibility into automated actions taken by the workflow.\"\"\"",
        "detail": ".github.actions.pr-assignment.pr_assignment",
        "documentation": {}
    },
    {
        "label": "post_comment",
        "kind": 2,
        "importPath": ".github.actions.pr-assignment.pr_assignment",
        "description": ".github.actions.pr-assignment.pr_assignment",
        "peekOfCode": "def post_comment(pr_number: str, repo: str, comment: str) -> None:\n    \"\"\"Provide visibility into automated actions taken by the workflow.\"\"\"\n    run_gh_command([\"pr\", \"comment\", pr_number, \"--body\", comment, \"--repo\", repo])\ndef detect_version_change(pr_title: str) -> Optional[str]:\n    \"\"\"\n    Detect version change type from Dependabot PR title.\n    Returns 'major', 'minor', 'patch', or None.\n    \"\"\"\n    # Common patterns in Dependabot PR titles:\n    # \"Bump webpack from 5.1.0 to 5.2.0\"",
        "detail": ".github.actions.pr-assignment.pr_assignment",
        "documentation": {}
    },
    {
        "label": "detect_version_change",
        "kind": 2,
        "importPath": ".github.actions.pr-assignment.pr_assignment",
        "description": ".github.actions.pr-assignment.pr_assignment",
        "peekOfCode": "def detect_version_change(pr_title: str) -> Optional[str]:\n    \"\"\"\n    Detect version change type from Dependabot PR title.\n    Returns 'major', 'minor', 'patch', or None.\n    \"\"\"\n    # Common patterns in Dependabot PR titles:\n    # \"Bump webpack from 5.1.0 to 5.2.0\"\n    # \"Update rails requirement from ~> 6.1.0 to ~> 7.0.0\"\n    # \"Bump @types/node from 14.14.37 to 16.0.0\"\n    # Look for version patterns",
        "detail": ".github.actions.pr-assignment.pr_assignment",
        "documentation": {}
    },
    {
        "label": "ensure_version_labels_exist",
        "kind": 2,
        "importPath": ".github.actions.pr-assignment.pr_assignment",
        "description": ".github.actions.pr-assignment.pr_assignment",
        "peekOfCode": "def ensure_version_labels_exist(repo: str) -> None:\n    \"\"\"Pre-create semantic version labels for Dependabot PRs to avoid label creation failures.\"\"\"\n    labels = [\n        (\"major\", \"FF0000\", \"Major version update\"),\n        (\"minor\", \"FFFF00\", \"Minor version update\"),\n        (\"patch\", \"00FF00\", \"Patch version update\"),\n    ]\n    for name, color, description in labels:\n        run_gh_command([\"label\", \"create\", name, \"--color\", color, \"--description\", description, \"--force\"])\ndef main():",
        "detail": ".github.actions.pr-assignment.pr_assignment",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".github.actions.pr-assignment.pr_assignment",
        "description": ".github.actions.pr-assignment.pr_assignment",
        "peekOfCode": "def main():\n    \"\"\"Main function to process PR assignments.\"\"\"\n    # Get arguments from environment variables instead of sys.argv\n    pr_number = os.environ.get(\"PR_NUMBER\", \"\")\n    possible_assignees = os.environ.get(\"POSSIBLE_ASSIGNEES\", \"\")\n    possible_reviewers = os.environ.get(\"POSSIBLE_REVIEWERS\", \"\")\n    forced_assignees = os.environ.get(\"FORCED_ASSIGNEES\", \"\")\n    forced_reviewers = os.environ.get(\"FORCED_REVIEWERS\", \"\")\n    forced_labels = os.environ.get(\"FORCED_LABELS\", \"\")\n    clear_existing_assignees = os.environ.get(\"CLEAR_EXISTING_ASSIGNEES\", \"false\")",
        "detail": ".github.actions.pr-assignment.pr_assignment",
        "documentation": {}
    },
    {
        "label": "PullRequestDigest",
        "kind": 6,
        "importPath": ".github.actions.pr-digest.fetch_pr_digest",
        "description": ".github.actions.pr-digest.fetch_pr_digest",
        "peekOfCode": "class PullRequestDigest:\n    \"\"\"PR information for digest.\"\"\"\n    number: int\n    title: str\n    body: str\n    merged_at: str\n    html_url: str\n    diff: str\n    author: str\n    labels: List[str]",
        "detail": ".github.actions.pr-digest.fetch_pr_digest",
        "documentation": {}
    },
    {
        "label": "CacheData",
        "kind": 6,
        "importPath": ".github.actions.pr-digest.fetch_pr_digest",
        "description": ".github.actions.pr-digest.fetch_pr_digest",
        "peekOfCode": "class CacheData:\n    \"\"\"Cache with metadata.\"\"\"\n    version: str = \"1.0\"\n    repository: str = \"\"\n    pr_digests: List[PullRequestDigest] = None\n    last_updated: str = \"\"\n    last_pr_merged_at: Optional[str] = None\n    def __post_init__(self):\n        if self.pr_digests is None:\n            self.pr_digests = []",
        "detail": ".github.actions.pr-digest.fetch_pr_digest",
        "documentation": {}
    },
    {
        "label": "GitHubClient",
        "kind": 6,
        "importPath": ".github.actions.pr-digest.fetch_pr_digest",
        "description": ".github.actions.pr-digest.fetch_pr_digest",
        "peekOfCode": "class GitHubClient:\n    \"\"\"Handle GitHub API interactions.\"\"\"\n    API_BASE = \"https://api.github.com\"\n    def __init__(self, token: str):\n        self.token = token\n        self.headers = {\"Authorization\": f\"Bearer {token}\", \"Accept\": \"application/vnd.github.v3+json\"}\n    def _make_request(self, url: str, headers: dict | None = None, params: dict | None = None) -> requests.Response:\n        \"\"\"Make a request with rate limit handling.\"\"\"\n        response = requests.get(url, headers=headers or self.headers, params=params)\n        if response.status_code == 403:",
        "detail": ".github.actions.pr-digest.fetch_pr_digest",
        "documentation": {}
    },
    {
        "label": "load_cache",
        "kind": 2,
        "importPath": ".github.actions.pr-digest.fetch_pr_digest",
        "description": ".github.actions.pr-digest.fetch_pr_digest",
        "peekOfCode": "def load_cache(cache_file: Path) -> CacheData | None:\n    \"\"\"Load cache if it exists and is valid.\"\"\"\n    if not cache_file.exists():\n        return None\n    try:\n        with open(cache_file, \"r\") as f:\n            data = json.load(f)\n        # Handle old format (just a list)\n        if isinstance(data, list):\n            print(\"Converting old cache format...\")",
        "detail": ".github.actions.pr-digest.fetch_pr_digest",
        "documentation": {}
    },
    {
        "label": "save_cache",
        "kind": 2,
        "importPath": ".github.actions.pr-digest.fetch_pr_digest",
        "description": ".github.actions.pr-digest.fetch_pr_digest",
        "peekOfCode": "def save_cache(cache_file: Path, cache_data: CacheData) -> None:\n    \"\"\"Save cache data.\"\"\"\n    cache_file.parent.mkdir(parents=True, exist_ok=True)\n    data = {\n        \"version\": cache_data.version,\n        \"repository\": cache_data.repository,\n        \"pr_digests\": [asdict(pr) for pr in cache_data.pr_digests],\n        \"last_updated\": cache_data.last_updated,\n        \"last_pr_merged_at\": cache_data.last_pr_merged_at,\n    }",
        "detail": ".github.actions.pr-digest.fetch_pr_digest",
        "documentation": {}
    },
    {
        "label": "prune_cache",
        "kind": 2,
        "importPath": ".github.actions.pr-digest.fetch_pr_digest",
        "description": ".github.actions.pr-digest.fetch_pr_digest",
        "peekOfCode": "def prune_cache(cache_data: CacheData, max_age_days: int = 60) -> CacheData:\n    \"\"\"Remove cache entries older than max_age_days.\"\"\"\n    if not cache_data.pr_digests:\n        return cache_data\n    cutoff_date = datetime.now(timezone.utc) - timedelta(days=max_age_days)\n    original_count = len(cache_data.pr_digests)\n    cache_data.pr_digests = [\n        pr for pr in cache_data.pr_digests if datetime.fromisoformat(pr.merged_at.replace(\"Z\", \"+00:00\")) >= cutoff_date\n    ]\n    pruned_count = original_count - len(cache_data.pr_digests)",
        "detail": ".github.actions.pr-digest.fetch_pr_digest",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".github.actions.pr-digest.fetch_pr_digest",
        "description": ".github.actions.pr-digest.fetch_pr_digest",
        "peekOfCode": "def main() -> None:\n    \"\"\"Main entry point.\"\"\"\n    # Read inputs\n    repository = os.getenv(\"REPOSITORY\", \"\")\n    github_token = os.getenv(\"GITHUB_TOKEN\", \"\")\n    days_to_scan = int(os.getenv(\"DAYS_TO_SCAN\", \"7\"))\n    diff_limit = int(os.getenv(\"DIFF_LIMIT\", \"20000\"))\n    force_refresh = os.getenv(\"FORCE_REFRESH\", \"false\").lower() == \"true\"\n    cache_file_env = os.getenv(\"CACHE_FILE\", \".pr-digest-cache/cache.json\")\n    if \"{repository}\" in cache_file_env:",
        "detail": ".github.actions.pr-digest.fetch_pr_digest",
        "documentation": {}
    },
    {
        "label": "get_machine_info",
        "kind": 2,
        "importPath": ".github.actions.save-benchmarks.save_benchmarks",
        "description": ".github.actions.save-benchmarks.save_benchmarks",
        "peekOfCode": "def get_machine_info():\n    \"\"\"Get machine information for benchmark metadata.\"\"\"\n    return {\n        \"node\": socket.gethostname(),\n        \"processor\": \"GitHub Actions Runner\",\n        \"machine\": \"GitHub Actions Runner\",\n        \"python_implementation\": platform.python_implementation(),\n        \"python_version\": platform.python_version(),\n        \"python_compiler\": platform.python_compiler(),\n    }",
        "detail": ".github.actions.save-benchmarks.save_benchmarks",
        "documentation": {}
    },
    {
        "label": "get_commit_info",
        "kind": 2,
        "importPath": ".github.actions.save-benchmarks.save_benchmarks",
        "description": ".github.actions.save-benchmarks.save_benchmarks",
        "peekOfCode": "def get_commit_info():\n    \"\"\"Get commit information from GitHub environment.\"\"\"\n    github_sha = os.environ.get(\"GITHUB_SHA\", \"unknown\")\n    github_ref_name = os.environ.get(\"GITHUB_REF_NAME\", \"unknown\")\n    current_time = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n    return {\n        \"id\": github_sha,\n        \"time\": current_time,\n        \"author_time\": current_time,\n        \"dirty\": False,",
        "detail": ".github.actions.save-benchmarks.save_benchmarks",
        "documentation": {}
    },
    {
        "label": "create_benchmark_result",
        "kind": 2,
        "importPath": ".github.actions.save-benchmarks.save_benchmarks",
        "description": ".github.actions.save-benchmarks.save_benchmarks",
        "peekOfCode": "def create_benchmark_result(name: str, metrics: dict, group: str = \"default\"):\n    \"\"\"Create a benchmark result in pytest format.\"\"\"\n    # Extract duration from metrics, default to 0 if not found\n    duration = float(metrics.get(\"duration\", 0))\n    return {\n        \"name\": name,\n        \"fullname\": name,\n        \"group\": group,\n        \"params\": {\"hardware\": \"github\"},\n        \"stats\": {",
        "detail": ".github.actions.save-benchmarks.save_benchmarks",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".github.actions.save-benchmarks.save_benchmarks",
        "description": ".github.actions.save-benchmarks.save_benchmarks",
        "peekOfCode": "def main():\n    \"\"\"Main entry point.\"\"\"\n    # Get inputs from environment variables\n    name = os.environ.get(\"BENCHMARK_NAME\", \"\")\n    metrics_json = os.environ.get(\"BENCHMARK_METRICS\", \"{}\")\n    filename = os.environ.get(\"BENCHMARK_FILENAME\", \"benchmark_results.json\")\n    group = os.environ.get(\"BENCHMARK_GROUP\", \"default\")\n    if not name:\n        print(\"Error: BENCHMARK_NAME environment variable not set\")\n        sys.exit(1)",
        "detail": ".github.actions.save-benchmarks.save_benchmarks",
        "documentation": {}
    },
    {
        "label": "TypeAnalyzer",
        "kind": 6,
        "importPath": ".github.scripts.claude_tools.type_check_file",
        "description": ".github.scripts.claude_tools.type_check_file",
        "peekOfCode": "class TypeAnalyzer(ast.NodeVisitor):\n    \"\"\"Analyze Python AST for missing type annotations.\"\"\"\n    def __init__(self, filename: str):\n        self.filename = filename\n        self.missing_annotations: List[Dict[str, Any]] = []\n        self.current_class: Optional[str] = None\n    def visit_FunctionDef(self, node: ast.FunctionDef) -> None:\n        \"\"\"Check function definitions for missing type annotations.\"\"\"\n        issues = []\n        # Check if this is a private method",
        "detail": ".github.scripts.claude_tools.type_check_file",
        "documentation": {}
    },
    {
        "label": "analyze_file",
        "kind": 2,
        "importPath": ".github.scripts.claude_tools.type_check_file",
        "description": ".github.scripts.claude_tools.type_check_file",
        "peekOfCode": "def analyze_file(filepath: Path) -> Dict[str, Any]:\n    \"\"\"Analyze a Python file for missing type annotations.\"\"\"\n    try:\n        with open(filepath, \"r\") as f:\n            content = f.read()\n        tree = ast.parse(content, filename=str(filepath))\n        analyzer = TypeAnalyzer(str(filepath))\n        analyzer.visit(tree)\n        return {\"file\": str(filepath), \"missing_annotations\": analyzer.missing_annotations, \"error\": None}\n    except Exception as e:",
        "detail": ".github.scripts.claude_tools.type_check_file",
        "documentation": {}
    },
    {
        "label": "run_mypy",
        "kind": 2,
        "importPath": ".github.scripts.claude_tools.type_check_file",
        "description": ".github.scripts.claude_tools.type_check_file",
        "peekOfCode": "def run_mypy(files: List[str]) -> Dict[str, Any]:\n    \"\"\"Run mypy on the specified files.\"\"\"\n    try:\n        result = subprocess.run(\n            [sys.executable, \"-m\", \"mypy\", \"--no-error-summary\", \"--show-column-numbers\"] + files,\n            capture_output=True,\n            text=True,\n        )\n        return {\"tool\": \"mypy\", \"output\": result.stdout, \"errors\": result.stderr, \"return_code\": result.returncode}\n    except Exception as e:",
        "detail": ".github.scripts.claude_tools.type_check_file",
        "documentation": {}
    },
    {
        "label": "run_pyright",
        "kind": 2,
        "importPath": ".github.scripts.claude_tools.type_check_file",
        "description": ".github.scripts.claude_tools.type_check_file",
        "peekOfCode": "def run_pyright(files: List[str]) -> Dict[str, Any]:\n    \"\"\"Run pyright on the specified files.\"\"\"\n    try:\n        result = subprocess.run([\"pyright\", \"--outputjson\"] + files, capture_output=True, text=True)\n        return {\"tool\": \"pyright\", \"output\": result.stdout, \"errors\": result.stderr, \"return_code\": result.returncode}\n    except Exception as e:\n        return {\"tool\": \"pyright\", \"output\": \"\", \"errors\": str(e), \"return_code\": -1}\ndef filter_high_value_annotations(annotations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n    \"\"\"Filter to only include high-value missing annotations.\"\"\"\n    filtered = []",
        "detail": ".github.scripts.claude_tools.type_check_file",
        "documentation": {}
    },
    {
        "label": "filter_high_value_annotations",
        "kind": 2,
        "importPath": ".github.scripts.claude_tools.type_check_file",
        "description": ".github.scripts.claude_tools.type_check_file",
        "peekOfCode": "def filter_high_value_annotations(annotations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n    \"\"\"Filter to only include high-value missing annotations.\"\"\"\n    filtered = []\n    for func_info in annotations:\n        high_value_issues = []\n        for issue in func_info[\"issues\"]:\n            # Always include missing parameter types\n            if issue[\"type\"] == \"missing_param_type\":\n                high_value_issues.append(issue)\n            # Include return types based on priority",
        "detail": ".github.scripts.claude_tools.type_check_file",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".github.scripts.claude_tools.type_check_file",
        "description": ".github.scripts.claude_tools.type_check_file",
        "peekOfCode": "def main():\n    \"\"\"Main entry point.\"\"\"\n    if len(sys.argv) < 2:\n        print(\"Usage: type_check.py <command> [args...]\")\n        print(\"Commands:\")\n        print(\"  analyze <file.py>     - Analyze file for missing annotations\")\n        print(\"  mypy <file.py>        - Run mypy on file\")\n        print(\"  pyright <file.py>     - Run pyright on file\")\n        print(\"  check <file.py>       - Run all checks and summarize\")\n        sys.exit(1)",
        "detail": ".github.scripts.claude_tools.type_check_file",
        "documentation": {}
    },
    {
        "label": "ProcessMonitor",
        "kind": 6,
        "importPath": ".github.scripts.utils.benchmark",
        "description": ".github.scripts.utils.benchmark",
        "peekOfCode": "class ProcessMonitor:\n    \"\"\"Monitor process memory usage and execution time.\"\"\"\n    def __init__(self, process: subprocess.Popen) -> None:\n        self.process = process\n        self.peak_memory_mb = 0\n        self.start_time = time.time()\n        self._monitor_thread = None\n        self._stop_monitoring = threading.Event()\n        self._memory_samples = []\n    def start(self) -> None:",
        "detail": ".github.scripts.utils.benchmark",
        "documentation": {}
    },
    {
        "label": "run_with_benchmark",
        "kind": 2,
        "importPath": ".github.scripts.utils.benchmark",
        "description": ".github.scripts.utils.benchmark",
        "peekOfCode": "def run_with_benchmark(\n    cmd: Union[str, list[str]],\n    name: str = \"process\",\n    timeout: int | None = None,\n    shell: bool = False,\n    env: dict[str, str] | None = None,\n    cwd: str | None = None,\n) -> dict:\n    \"\"\"\n    Run a command with benchmarking.",
        "detail": ".github.scripts.utils.benchmark",
        "documentation": {}
    },
    {
        "label": "write_github_output",
        "kind": 2,
        "importPath": ".github.scripts.utils.benchmark",
        "description": ".github.scripts.utils.benchmark",
        "peekOfCode": "def write_github_output(outputs: dict[str, str]) -> None:\n    \"\"\"Write multiple outputs for GitHub Actions.\"\"\"\n    if \"GITHUB_OUTPUT\" in os.environ:\n        with open(os.environ[\"GITHUB_OUTPUT\"], \"a\") as f:\n            for key, value in outputs.items():\n                f.write(f\"{key}={value}\\n\")",
        "detail": ".github.scripts.utils.benchmark",
        "documentation": {}
    },
    {
        "label": "parse_config",
        "kind": 2,
        "importPath": ".github.scripts.utils.config",
        "description": ".github.scripts.utils.config",
        "peekOfCode": "def parse_config(required_vars: list[str], optional_vars: dict[str, str] | None = None) -> dict[str, str]:\n    \"\"\"\n    Parse and validate environment variables.\n    Args:\n        required_vars: List of `var_name` for required variables\n        optional_vars: Dict of `{var_name: default value}` for optional variables\n    Returns:\n        Dict of {var_name: value} for all available env variables\n    Raises:\n        SystemExit: If any required variables are missing",
        "detail": ".github.scripts.utils.config",
        "documentation": {}
    },
    {
        "label": "SmokeTest",
        "kind": 6,
        "importPath": ".github.scripts.utils.smoke_test",
        "description": ".github.scripts.utils.smoke_test",
        "peekOfCode": "class SmokeTest(ABC):\n    \"\"\"Base class for all smoke tests.\"\"\"\n    def __init__(self) -> None:\n        self.test_name = self.__class__.__name__.replace(\"SmokeTest\", \"\").lower()\n        self.timeout = self.get_timeout()\n    @abstractmethod\n    def get_command(self) -> list[str]:\n        \"\"\"Return the command to run for this test.\"\"\"\n        pass\n    @abstractmethod",
        "detail": ".github.scripts.utils.smoke_test",
        "documentation": {}
    },
    {
        "label": "download_artifact",
        "kind": 2,
        "importPath": ".github.scripts.claude_review",
        "description": ".github.scripts.claude_review",
        "peekOfCode": "def download_artifact(token: str, repo: str, artifact_id: int) -> bytes | None:\n    \"\"\"Download an artifact from GitHub.\"\"\"\n    headers = {\"Authorization\": f\"token {token}\", \"Accept\": \"application/vnd.github.v3+json\"}\n    url = f\"https://api.github.com/repos/{repo}/actions/artifacts/{artifact_id}/zip\"\n    response = requests.get(url, headers=headers)\n    if response.status_code == 200:\n        return response.content\n    else:\n        print(f\"Failed to download artifact {artifact_id}: {response.status_code}\")\n        return None",
        "detail": ".github.scripts.claude_review",
        "documentation": {}
    },
    {
        "label": "extract_json_from_artifact",
        "kind": 2,
        "importPath": ".github.scripts.claude_review",
        "description": ".github.scripts.claude_review",
        "peekOfCode": "def extract_json_from_artifact(artifact_data: bytes) -> dict[str, Any] | None:\n    \"\"\"Extract claude-review-analysis.json from artifact zip.\"\"\"\n    try:\n        with zipfile.ZipFile(BytesIO(artifact_data)) as zip_file:\n            for name in zip_file.namelist():\n                if name == \"claude-review-analysis.json\":\n                    with zip_file.open(name) as f:\n                        return json.load(f)\n    except Exception as e:\n        print(f\"Error extracting JSON from artifact: {e}\")",
        "detail": ".github.scripts.claude_review",
        "documentation": {}
    },
    {
        "label": "consolidate_reviews",
        "kind": 2,
        "importPath": ".github.scripts.claude_review",
        "description": ".github.scripts.claude_review",
        "peekOfCode": "def consolidate_reviews(token: str, repo: str, run_id: int) -> Tuple[dict[str, Any], bool]:\n    \"\"\"Consolidate all review artifacts into a single structure.\"\"\"\n    # Initialize consolidated review\n    consolidated = {\n        \"review_summary\": \"Consolidated review from multiple Claude analyzers\",\n        \"review_status\": \"COMMENT\",\n        \"suggestions\": [],\n        \"tldr\": [],\n        \"review_types\": {},\n    }",
        "detail": ".github.scripts.claude_review",
        "documentation": {}
    },
    {
        "label": "build_future_suggestions_comment",
        "kind": 2,
        "importPath": ".github.scripts.claude_review",
        "description": ".github.scripts.claude_review",
        "peekOfCode": "def build_future_suggestions_comment(suggestions_for_future: list[dict[str, Any]]) -> str:\n    \"\"\"Build a separate comment for suggestions on unchanged code.\"\"\"\n    sections = []\n    # Header\n    sections.append(\"##  Claude Found Additional Issues in Unchanged Code\")\n    sections.append(\"\")\n    sections.append(\n        f\"Claude's review found {len(suggestions_for_future)} suggestion(s) in code that wasn't modified in this PR.\"\n    )\n    sections.append(\"These can be addressed in a future PR or by using Claude assistant in open-PR mode.\")",
        "detail": ".github.scripts.claude_review",
        "documentation": {}
    },
    {
        "label": "create_review_comment",
        "kind": 2,
        "importPath": ".github.scripts.claude_review",
        "description": ".github.scripts.claude_review",
        "peekOfCode": "def create_review_comment(suggestion: dict[str, Any]) -> dict[str, Any]:\n    \"\"\"Create a review comment from a suggestion.\"\"\"\n    comment = {\n        \"path\": suggestion[\"file\"],\n        \"line\": suggestion.get(\"end_line\", suggestion[\"start_line\"]),\n        \"side\": suggestion.get(\"side\", \"RIGHT\"),\n        \"body\": (\n            f\"**{suggestion.get('severity', 'minor')}**: {suggestion['reason']}\\n\\n\"\n            f\"```suggestion\\n{suggestion['suggested_code']}\\n```\"\n        ),",
        "detail": ".github.scripts.claude_review",
        "documentation": {}
    },
    {
        "label": "build_review_body",
        "kind": 2,
        "importPath": ".github.scripts.claude_review",
        "description": ".github.scripts.claude_review",
        "peekOfCode": "def build_review_body(analysis: dict[str, Any], skipped_suggestions: list[str]) -> str:\n    \"\"\"Build the review body markdown.\"\"\"\n    sections = []\n    # Header\n    sections.append(\"##  Claude Unified Code Review\")\n    sections.append(\"\")\n    sections.append(analysis[\"review_summary\"])\n    sections.append(\"\")\n    # Overview\n    sections.append(\"### Overview\")",
        "detail": ".github.scripts.claude_review",
        "documentation": {}
    },
    {
        "label": "create_unified_review",
        "kind": 2,
        "importPath": ".github.scripts.claude_review",
        "description": ".github.scripts.claude_review",
        "peekOfCode": "def create_unified_review(token: str, repo: str, pr_number: int, analysis: dict[str, Any]) -> None:\n    \"\"\"Create a unified GitHub review from the consolidated analysis.\"\"\"\n    # Connect to GitHub\n    g = Github(token)\n    repo_obj = g.get_repo(repo)\n    pr = repo_obj.get_pull(pr_number)\n    # Get PR files and latest commit\n    pr_files = list(pr.get_files())\n    pr_filenames = {f.filename for f in pr_files}\n    # Get the latest commit SHA from the PR",
        "detail": ".github.scripts.claude_review",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".github.scripts.claude_review",
        "description": ".github.scripts.claude_review",
        "peekOfCode": "def main():\n    \"\"\"Main entry point.\"\"\"\n    # Get environment variables\n    token = os.environ.get(\"GITHUB_TOKEN\")\n    repo = os.environ.get(\"GITHUB_REPOSITORY\")\n    run_id = int(os.environ.get(\"GITHUB_RUN_ID\", \"0\"))\n    pr_number = int(os.environ.get(\"PR_NUMBER\", \"0\"))\n    if not all([token, repo, run_id, pr_number]):\n        print(\"Missing required environment variables\")\n        print(f\"  GITHUB_TOKEN: {'' if token else ''}\")",
        "detail": ".github.scripts.claude_review",
        "documentation": {}
    },
    {
        "label": "CachedPRSummary",
        "kind": 6,
        "importPath": ".github.scripts.create_pr_digest",
        "description": ".github.scripts.create_pr_digest",
        "peekOfCode": "class CachedPRSummary:\n    \"\"\"Represents a PR summary loaded from cache.\"\"\"\n    def __init__(self, pr_number: int, summary_file: Path):\n        self.pr_number = pr_number\n        self.summary_file = summary_file\n        self._metadata = None\n    def load_metadata(self) -> Optional[Dict]:\n        \"\"\"Load and parse metadata from the cached summary file.\"\"\"\n        if self._metadata is not None:\n            return self._metadata",
        "detail": ".github.scripts.create_pr_digest",
        "documentation": {}
    },
    {
        "label": "PRDigestCreator",
        "kind": 6,
        "importPath": ".github.scripts.create_pr_digest",
        "description": ".github.scripts.create_pr_digest",
        "peekOfCode": "class PRDigestCreator:\n    \"\"\"Creates a digest of merged PRs, utilizing cache effectively.\"\"\"\n    def __init__(self, token: str, repository: str):\n        self.token = token\n        self.repository = repository\n        self.session = requests.Session()\n        self.session.headers.update(\n            {\n                \"Authorization\": f\"token {token}\",\n                \"Accept\": \"application/vnd.github.v3+json\",",
        "detail": ".github.scripts.create_pr_digest",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".github.scripts.create_pr_digest",
        "description": ".github.scripts.create_pr_digest",
        "peekOfCode": "def main():\n    logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n    # Define required environment variables\n    required_env_vars = {\n        \"GITHUB_TOKEN\": \"GitHub Token\",\n        \"GITHUB_REPOSITORY\": \"GitHub repository name\",\n        \"DAYS_TO_SCAN\": \"Days to process\",\n    }\n    # Validate required environment variables\n    env_values = {}",
        "detail": ".github.scripts.create_pr_digest",
        "documentation": {}
    },
    {
        "label": "EvaluationSmokeTest",
        "kind": 6,
        "importPath": ".github.scripts.eval_smoke_test",
        "description": ".github.scripts.eval_smoke_test",
        "peekOfCode": "class EvaluationSmokeTest(SmokeTest):\n    \"\"\"Evaluation smoke test with reward checking.\"\"\"\n    def __init__(self):\n        self.policy = os.environ[\"POLICY\"]\n        self.min_reward = float(os.environ[\"MIN_REWARD\"])\n        self.max_attempts = int(os.environ[\"MAX_ATTEMPTS\"])\n        super().__init__()\n    def get_command(self) -> list[str]:\n        # This is overridden in get_command_for_attempt\n        return []",
        "detail": ".github.scripts.eval_smoke_test",
        "documentation": {}
    },
    {
        "label": "PRSummary",
        "kind": 6,
        "importPath": ".github.scripts.gemini_analyze_pr",
        "description": ".github.scripts.gemini_analyze_pr",
        "peekOfCode": "class PRSummary:\n    \"\"\"Individual PR summary with essential metadata.\"\"\"\n    pr_number: int\n    title: str\n    author: str\n    merged_at: str\n    html_url: str\n    summary: str\n    key_changes: List[str]\n    developer_impact: str",
        "detail": ".github.scripts.gemini_analyze_pr",
        "documentation": {}
    },
    {
        "label": "PRAnalyzer",
        "kind": 6,
        "importPath": ".github.scripts.gemini_analyze_pr",
        "description": ".github.scripts.gemini_analyze_pr",
        "peekOfCode": "class PRAnalyzer:\n    \"\"\"Analyzes a single PR and generates a comprehensive summary.\"\"\"\n    def __init__(self, ai_client: GeminiAIClient):\n        self.ai_client = ai_client\n    def categorize_pr(self, pr_data: Dict) -> str:\n        \"\"\"Enhanced PR categorization based on labels, title, and content.\"\"\"\n        title = pr_data.get(\"title\", \"\").lower()\n        labels = [label.lower() for label in pr_data.get(\"labels\", [])]\n        body = pr_data.get(\"body\", \"\").lower()\n        # Check labels first (most reliable)",
        "detail": ".github.scripts.gemini_analyze_pr",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".github.scripts.gemini_analyze_pr",
        "description": ".github.scripts.gemini_analyze_pr",
        "peekOfCode": "def main():\n    \"\"\"Analyze a single PR from command line arguments or stdin.\"\"\"\n    logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n    # Handle different input methods\n    if len(sys.argv) == 3:\n        # Command line: api_key pr_json_string\n        api_key = sys.argv[1]\n        pr_json = sys.argv[2]\n    elif len(sys.argv) == 2:\n        # API key provided, read PR data from stdin",
        "detail": ".github.scripts.gemini_analyze_pr",
        "documentation": {}
    },
    {
        "label": "PRSummaryData",
        "kind": 6,
        "importPath": ".github.scripts.gemini_analyze_pr_digest",
        "description": ".github.scripts.gemini_analyze_pr_digest",
        "peekOfCode": "class PRSummaryData:\n    \"\"\"Extended PRSummary with source tracking.\"\"\"\n    pr_number: int\n    title: str\n    summary: str\n    key_changes: List[str]\n    developer_impact: str\n    technical_notes: Optional[str]\n    category: str\n    impact_level: str",
        "detail": ".github.scripts.gemini_analyze_pr_digest",
        "documentation": {}
    },
    {
        "label": "CachedSummaryLoader",
        "kind": 6,
        "importPath": ".github.scripts.gemini_analyze_pr_digest",
        "description": ".github.scripts.gemini_analyze_pr_digest",
        "peekOfCode": "class CachedSummaryLoader:\n    \"\"\"Loads PR summaries from cache files.\"\"\"\n    def __init__(self, summaries_dir: Path = Path(\"pr-summaries\")):\n        self.summaries_dir = summaries_dir\n    def load_summary(self, pr_number: int) -> Optional[PRSummaryData]:\n        \"\"\"Load a single PR summary from cache.\"\"\"\n        summary_file = self.summaries_dir / f\"pr_{pr_number}.txt\"\n        if not summary_file.exists():\n            return None\n        try:",
        "detail": ".github.scripts.gemini_analyze_pr_digest",
        "documentation": {}
    },
    {
        "label": "PreviousNewsletterExtractor",
        "kind": 6,
        "importPath": ".github.scripts.gemini_analyze_pr_digest",
        "description": ".github.scripts.gemini_analyze_pr_digest",
        "peekOfCode": "class PreviousNewsletterExtractor:\n    \"\"\"Extracts and processes previous newsletter artifacts.\"\"\"\n    def __init__(self, newsletter_dir: str = \"previous-newsletters\"):\n        self.newsletter_dir = Path(newsletter_dir)\n    def extract_discord_summaries(self) -> List[Dict[str, str]]:\n        \"\"\"Extract discord summaries from previous newsletter artifacts.\"\"\"\n        if not self.newsletter_dir.exists():\n            logging.info(f\"Previous newsletters directory '{self.newsletter_dir}' not found\")\n            return []\n        summaries = []",
        "detail": ".github.scripts.gemini_analyze_pr_digest",
        "documentation": {}
    },
    {
        "label": "CollectionAnalyzer",
        "kind": 6,
        "importPath": ".github.scripts.gemini_analyze_pr_digest",
        "description": ".github.scripts.gemini_analyze_pr_digest",
        "peekOfCode": "class CollectionAnalyzer:\n    \"\"\"Generates collection-level summaries and insights from multiple PR summaries.\"\"\"\n    def __init__(self, ai_client: GeminiAIClient):\n        self.ai_client = ai_client\n        self.newsletter_extractor = PreviousNewsletterExtractor()\n    def prepare_context(self, pr_summaries: List[PRSummary], date_range: str, repository: str) -> str:\n        \"\"\"Prepare context for collection analysis.\"\"\"\n        stats = {\"total_prs\": len(pr_summaries), \"by_category\": {}, \"by_impact\": {}, \"by_author\": {}}\n        for pr in pr_summaries:\n            stats[\"by_category\"][pr.category] = stats[\"by_category\"].get(pr.category, 0) + 1",
        "detail": ".github.scripts.gemini_analyze_pr_digest",
        "documentation": {}
    },
    {
        "label": "OutputFormatter",
        "kind": 6,
        "importPath": ".github.scripts.gemini_analyze_pr_digest",
        "description": ".github.scripts.gemini_analyze_pr_digest",
        "peekOfCode": "class OutputFormatter:\n    \"\"\"Handles various output formats for PR digest analysis.\"\"\"\n    @staticmethod\n    def save_individual_pr_file(pr_summary: PRSummary, output_dir: Path) -> str:\n        \"\"\"Save individual PR summary as a text file.\"\"\"\n        filename = f\"pr_{pr_summary.pr_number}.txt\"\n        filepath = output_dir / filename\n        content = f\"\"\"PR #{pr_summary.pr_number}: {pr_summary.title}\nAuthor: {pr_summary.author}\nMerged: {pr_summary.merged_at}",
        "detail": ".github.scripts.gemini_analyze_pr_digest",
        "documentation": {}
    },
    {
        "label": "PRDigestAnalyzer",
        "kind": 6,
        "importPath": ".github.scripts.gemini_analyze_pr_digest",
        "description": ".github.scripts.gemini_analyze_pr_digest",
        "peekOfCode": "class PRDigestAnalyzer:\n    \"\"\"Main orchestrator for analyzing PR digests.\"\"\"\n    def __init__(self, api_key: str):\n        self.ai_client = GeminiAIClient(api_key)\n        self.pr_analyzer = PRAnalyzer(self.ai_client)\n        self.collection_analyzer = CollectionAnalyzer(self.ai_client)\n        self.output_formatter = OutputFormatter()\n        self.cached_loader = CachedSummaryLoader()\n    def analyze_digest(\n        self, new_prs: List[Dict], cached_pr_numbers: List[int], use_parallel: bool = True, max_workers: int = 5",
        "detail": ".github.scripts.gemini_analyze_pr_digest",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".github.scripts.gemini_analyze_pr_digest",
        "description": ".github.scripts.gemini_analyze_pr_digest",
        "peekOfCode": "def main():\n    \"\"\"Main entry point for PR digest analysis.\"\"\"\n    logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n    # Import parse_config\n    script_dir = Path(__file__).parent.parent.parent / \"scripts\"\n    sys.path.insert(0, str(script_dir))\n    from utils.config import parse_config\n    # Define required and optional environment variables\n    required_vars = [\n        \"GEMINI_API_KEY\",",
        "detail": ".github.scripts.gemini_analyze_pr_digest",
        "documentation": {}
    },
    {
        "label": "GeminiAIClient",
        "kind": 6,
        "importPath": ".github.scripts.gemini_client",
        "description": ".github.scripts.gemini_client",
        "peekOfCode": "class GeminiAIClient:\n    \"\"\"AI client optimized for Gemini 2.5 with rate limiting and retry logic.\"\"\"\n    def __init__(self, api_key: str):\n        self.api_key = api_key\n        self.rate_limit_delay = 0.3  # Fast model, minimal delay\n        self.max_retries = 3\n        self.last_request_time = 0\n        # Configure Gemini\n        genai.configure(api_key=api_key)\n        # Minimal safety settings for code analysis",
        "detail": ".github.scripts.gemini_client",
        "documentation": {}
    },
    {
        "label": "MODEL_CONFIG",
        "kind": 5,
        "importPath": ".github.scripts.gemini_client",
        "description": ".github.scripts.gemini_client",
        "peekOfCode": "MODEL_CONFIG = {\n    \"fast\": \"gemini-2.5-flash-lite-preview-06-17\",  # Most cost-efficient, high throughput\n    \"default\": \"gemini-2.5-flash\",  # Balanced cost and performance\n    \"best\": \"gemini-2.5-pro\",  # Enhanced reasoning and complex analysis\n}\nclass GeminiAIClient:\n    \"\"\"AI client optimized for Gemini 2.5 with rate limiting and retry logic.\"\"\"\n    def __init__(self, api_key: str):\n        self.api_key = api_key\n        self.rate_limit_delay = 0.3  # Fast model, minimal delay",
        "detail": ".github.scripts.gemini_client",
        "documentation": {}
    },
    {
        "label": "ReplaySmokeTest",
        "kind": 6,
        "importPath": ".github.scripts.replay_smoke_test",
        "description": ".github.scripts.replay_smoke_test",
        "peekOfCode": "class ReplaySmokeTest(SmokeTest):\n    \"\"\"Replay smoke test implementation.\"\"\"\n    def get_command(self) -> list[str]:\n        return [\n            \"uv\",\n            \"run\",\n            \"./tools/replay.py\",\n            \"+hardware=github\",\n            \"wandb=off\",\n        ]",
        "detail": ".github.scripts.replay_smoke_test",
        "documentation": {}
    },
    {
        "label": "TrainingSmokeTest",
        "kind": 6,
        "importPath": ".github.scripts.train_smoke_test",
        "description": ".github.scripts.train_smoke_test",
        "peekOfCode": "class TrainingSmokeTest(SmokeTest):\n    \"\"\"Training smoke test implementation.\"\"\"\n    def get_command(self) -> list[str]:\n        return [\n            \"uv\",\n            \"run\",\n            \"./tools/train.py\",\n            \"+hardware=github\",\n            \"wandb=off\",\n        ]",
        "detail": ".github.scripts.train_smoke_test",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".github.scripts.validate-wandb-run",
        "description": ".github.scripts.validate-wandb-run",
        "peekOfCode": "def main() -> None:\n    \"\"\"Check if a W&B run exists for the given policy.\"\"\"\n    # Get environment variables\n    api_key = os.environ.get(\"WANDB_API_KEY\")\n    policy = os.environ.get(\"POLICY\")\n    entity = os.environ.get(\"WANDB_ENTITY\", \"metta-research\")\n    project = os.environ.get(\"WANDB_PROJECT\", \"metta\")\n    # Validate inputs\n    if not api_key:\n        print(\"Error: WANDB_API_KEY environment variable not set\")",
        "detail": ".github.scripts.validate-wandb-run",
        "documentation": {}
    },
    {
        "label": "bin_dir",
        "kind": 5,
        "importPath": ".venv.bin.activate_this",
        "description": ".venv.bin.activate_this",
        "peekOfCode": "bin_dir = os.path.dirname(abs_file)\nbase = bin_dir[: -len(\"bin\") - 1]  # strip away the bin part from the __file__, plus the path separator\n# prepend bin to PATH (this file is inside the bin directory)\nos.environ[\"PATH\"] = os.pathsep.join([bin_dir, *os.environ.get(\"PATH\", \"\").split(os.pathsep)])\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\nos.environ[\"VIRTUAL_ENV_PROMPT\"] = \"\" or os.path.basename(base)  # noqa: SIM222\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))",
        "detail": ".venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "base",
        "kind": 5,
        "importPath": ".venv.bin.activate_this",
        "description": ".venv.bin.activate_this",
        "peekOfCode": "base = bin_dir[: -len(\"bin\") - 1]  # strip away the bin part from the __file__, plus the path separator\n# prepend bin to PATH (this file is inside the bin directory)\nos.environ[\"PATH\"] = os.pathsep.join([bin_dir, *os.environ.get(\"PATH\", \"\").split(os.pathsep)])\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\nos.environ[\"VIRTUAL_ENV_PROMPT\"] = \"\" or os.path.basename(base)  # noqa: SIM222\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path)",
        "detail": ".venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "os.environ[\"PATH\"]",
        "kind": 5,
        "importPath": ".venv.bin.activate_this",
        "description": ".venv.bin.activate_this",
        "peekOfCode": "os.environ[\"PATH\"] = os.pathsep.join([bin_dir, *os.environ.get(\"PATH\", \"\").split(os.pathsep)])\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\nos.environ[\"VIRTUAL_ENV_PROMPT\"] = \"\" or os.path.basename(base)  # noqa: SIM222\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix",
        "detail": ".venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "os.environ[\"VIRTUAL_ENV\"]",
        "kind": 5,
        "importPath": ".venv.bin.activate_this",
        "description": ".venv.bin.activate_this",
        "peekOfCode": "os.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\nos.environ[\"VIRTUAL_ENV_PROMPT\"] = \"\" or os.path.basename(base)  # noqa: SIM222\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": ".venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "os.environ[\"VIRTUAL_ENV_PROMPT\"]",
        "kind": 5,
        "importPath": ".venv.bin.activate_this",
        "description": ".venv.bin.activate_this",
        "peekOfCode": "os.environ[\"VIRTUAL_ENV_PROMPT\"] = \"\" or os.path.basename(base)  # noqa: SIM222\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": ".venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "prev_length",
        "kind": 5,
        "importPath": ".venv.bin.activate_this",
        "description": ".venv.bin.activate_this",
        "peekOfCode": "prev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": ".venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "sys.path[:]",
        "kind": 5,
        "importPath": ".venv.bin.activate_this",
        "description": ".venv.bin.activate_this",
        "peekOfCode": "sys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": ".venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "sys.real_prefix",
        "kind": 5,
        "importPath": ".venv.bin.activate_this",
        "description": ".venv.bin.activate_this",
        "peekOfCode": "sys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": ".venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "sys.prefix",
        "kind": 5,
        "importPath": ".venv.bin.activate_this",
        "description": ".venv.bin.activate_this",
        "peekOfCode": "sys.prefix = base",
        "detail": ".venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".venv.bin.jp",
        "description": ".venv.bin.jp",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('expression')\n    parser.add_argument('-f', '--filename',\n                        help=('The filename containing the input data.  '\n                              'If a filename is not given then data is '\n                              'read from stdin.'))\n    parser.add_argument('--ast', action='store_true',\n                        help=('Pretty print the AST, do not search the data.'))\n    args = parser.parse_args()",
        "detail": ".venv.bin.jp",
        "documentation": {}
    },
    {
        "label": "Recurrent",
        "kind": 6,
        "importPath": "agent.src.metta.agent.external.example",
        "description": "agent.src.metta.agent.external.example",
        "peekOfCode": "class Recurrent(pufferlib.models.LSTMWrapper):\n    def __init__(self, env, policy, cnn_channels=128, input_size=512, hidden_size=512):\n        if policy is None:\n            policy = Policy(env, cnn_channels=cnn_channels, hidden_size=hidden_size)\n        super().__init__(env, policy, input_size, hidden_size)\n    def forward(self, observations, state):\n        \"\"\"Forward function for inference. 3x faster than using LSTM directly\"\"\"\n        if len(observations.shape) == 5:\n            # Training path: B, T, H, W, C -> use forward_train\n            x = rearrange(observations, \"b t h w c -> b t c h w\").float()",
        "detail": "agent.src.metta.agent.external.example",
        "documentation": {}
    },
    {
        "label": "Policy",
        "kind": 6,
        "importPath": "agent.src.metta.agent.external.example",
        "description": "agent.src.metta.agent.external.example",
        "peekOfCode": "class Policy(nn.Module):\n    def __init__(self, env, cnn_channels=128, hidden_size=512, **kwargs):\n        super().__init__()\n        self.hidden_size = hidden_size\n        self.is_continuous = False\n        self.network = nn.Sequential(\n            pufferlib.pytorch.layer_init(nn.Conv2d(21, cnn_channels, 5, stride=3)),\n            nn.ReLU(),\n            pufferlib.pytorch.layer_init(nn.Conv2d(cnn_channels, cnn_channels, 3, stride=1)),\n            nn.ReLU(),",
        "detail": "agent.src.metta.agent.external.example",
        "documentation": {}
    },
    {
        "label": "Recurrent",
        "kind": 6,
        "importPath": "agent.src.metta.agent.external.lstm_transformer",
        "description": "agent.src.metta.agent.external.lstm_transformer",
        "peekOfCode": "class Recurrent(pufferlib.models.LSTMWrapper):\n    def __init__(self, env, policy=None, cnn_channels=128, input_size=384, hidden_size=384):\n        if policy is None:\n            policy = Policy(env, cnn_channels=cnn_channels, hidden_size=hidden_size)\n        super().__init__(env, policy, input_size, hidden_size)\n    def forward(self, observations, state):\n        \"\"\"Forward function for inference. 3x faster than using LSTM directly\"\"\"\n        # Either [B, T, H, W, C] or [B, H, W, C]\n        if len(observations.shape) == 5:\n            x = rearrange(observations, \"b t h w c -> b t c h w\").float()",
        "detail": "agent.src.metta.agent.external.lstm_transformer",
        "documentation": {}
    },
    {
        "label": "Policy",
        "kind": 6,
        "importPath": "agent.src.metta.agent.external.lstm_transformer",
        "description": "agent.src.metta.agent.external.lstm_transformer",
        "peekOfCode": "class Policy(nn.Module):\n    \"\"\"Stronger dropin replacement for the original CNN+MLP policy.\n    **Key ideas**\n    -------------\n    1. **Richer spatial features.**  A small ConvStem extracts lowlevel texture\n       information before patchification.\n    2. **Lightweight ViT encoder.**  A class token summarises the visual scene\n       through multihead selfattention.  Depth/width are modest so it still\n       runs in real time on a single 4090.\n    3. **Separate proprioceptive stream.**  The 34dim agentcentric vector is",
        "detail": "agent.src.metta.agent.external.lstm_transformer",
        "documentation": {}
    },
    {
        "label": "ActionEmbedding",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.action",
        "description": "agent.src.metta.agent.lib.action",
        "peekOfCode": "class ActionEmbedding(nn_layer_library.Embedding):\n    \"\"\"\n    Creates and manages embeddings for available actions in the environment.\n    This class extends the base Embedding layer to specifically handle action embeddings\n    in a reinforcement learning context. It maintains a dictionary mapping action names to\n    embedding indices, and dynamically updates the set of active actions based on what's\n    available in the current environment.\n    Key features:\n    - Maintains a mapping between action names (strings) and embedding indices\n    - Dynamically activates subsets of actions when requested",
        "detail": "agent.src.metta.agent.lib.action",
        "documentation": {}
    },
    {
        "label": "MettaActorBig",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.actor",
        "description": "agent.src.metta.agent.lib.actor",
        "peekOfCode": "class MettaActorBig(LayerBase):\n    \"\"\"\n    Implements a bilinear interaction layer followed by an MLP for action selection.\n    This layer combines agent state and action embeddings through a bilinear interaction,\n    followed by a multi-layer perceptron (MLP) to produce action logits. The implementation\n    uses efficient tensor operations with einsum for the bilinear interaction, which is\n    significantly faster than using nn.Bilinear directly.\n    The layer works by:\n    1) Taking hidden state and action embeddings as inputs\n    2) Computing bilinear interactions between them",
        "detail": "agent.src.metta.agent.lib.actor",
        "documentation": {}
    },
    {
        "label": "MettaActorSingleHead",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.actor",
        "description": "agent.src.metta.agent.lib.actor",
        "peekOfCode": "class MettaActorSingleHead(LayerBase):\n    \"\"\"\n    Implements a simplified bilinear interaction layer for action selection.\n    This class is a lighter version of MettaActorBig, using a single bilinear interaction\n    without the additional MLP. It directly computes action logits from hidden state and\n    action embeddings through an efficient bilinear operation implemented with einsum.\n    The layer works by:\n    1) Taking hidden state and action embeddings as inputs\n    2) Computing a direct bilinear interaction between them\n    3) Applying a tanh activation and adding bias",
        "detail": "agent.src.metta.agent.lib.actor",
        "documentation": {}
    },
    {
        "label": "LSTM",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.lstm",
        "description": "agent.src.metta.agent.lib.lstm",
        "peekOfCode": "class LSTM(LayerBase):\n    \"\"\"\n    LSTM layer that handles tensor reshaping and state management automatically.\n    This class wraps a PyTorch LSTM with proper tensor shape handling, making it easier\n    to integrate LSTMs into neural network policies without dealing with complex tensor\n    manipulations. It handles reshaping inputs/outputs, manages hidden states, and ensures\n    consistent tensor dimensions throughout the forward pass.\n    The layer processes tensors of shape [B, TT, ...] or [B, ...], where:\n    - B is the batch size\n    - TT is an optional time dimension",
        "detail": "agent.src.metta.agent.lib.lstm",
        "documentation": {}
    },
    {
        "label": "MergeLayerBase",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.merge_layer",
        "description": "agent.src.metta.agent.lib.merge_layer",
        "peekOfCode": "class MergeLayerBase(LayerBase):\n    \"\"\"\n    Base class for layers that combine multiple tensors from different sources.\n    This class provides the framework for merging tensors from multiple sources in various ways.\n    Subclasses implement specific merging operations (concatenation, addition, subtraction, averaging).\n    The class handles tensor shape validation, optional slicing of source tensors, and tracking of\n    input/output tensor dimensions.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"",
        "detail": "agent.src.metta.agent.lib.merge_layer",
        "documentation": {}
    },
    {
        "label": "ConcatMergeLayer",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.merge_layer",
        "description": "agent.src.metta.agent.lib.merge_layer",
        "peekOfCode": "class ConcatMergeLayer(MergeLayerBase):\n    \"\"\"\n    Concatenates tensors along a specified dimension.\n    This layer combines multiple tensors by concatenating them along a specified dimension,\n    resulting in a larger tensor with the combined content. For vectors, use dim=1.\n    When used with observations, it can concatenate channels (dim=1) with their associated\n    fields. Note that concatenating along width and height dimensions (dim=2 or dim=3) would\n    lead to non-uniform shapes in the field of view.\n    All input tensors must use the same dimension for concatenation.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent",
        "detail": "agent.src.metta.agent.lib.merge_layer",
        "documentation": {}
    },
    {
        "label": "AddMergeLayer",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.merge_layer",
        "description": "agent.src.metta.agent.lib.merge_layer",
        "peekOfCode": "class AddMergeLayer(MergeLayerBase):\n    \"\"\"\n    Combines tensors by element-wise addition.\n    This layer adds multiple tensors element-wise, requiring that all input tensors have\n    identical shapes. The output tensor maintains the same shape as the inputs.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def _setup_merge_layer(self):\n        if not all(s == self._in_tensor_shapes[0] for s in self._in_tensor_shapes):",
        "detail": "agent.src.metta.agent.lib.merge_layer",
        "documentation": {}
    },
    {
        "label": "SubtractMergeLayer",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.merge_layer",
        "description": "agent.src.metta.agent.lib.merge_layer",
        "peekOfCode": "class SubtractMergeLayer(MergeLayerBase):\n    \"\"\"\n    Subtracts the second tensor from the first tensor element-wise.\n    This layer performs element-wise subtraction between exactly two input tensors,\n    requiring that both tensors have identical shapes. The operation computes\n    outputs[0] - outputs[1], maintaining the same shape as the inputs.\n    Raises ValueError if more or fewer than exactly two sources are provided.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"",
        "detail": "agent.src.metta.agent.lib.merge_layer",
        "documentation": {}
    },
    {
        "label": "MeanMergeLayer",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.merge_layer",
        "description": "agent.src.metta.agent.lib.merge_layer",
        "peekOfCode": "class MeanMergeLayer(MergeLayerBase):\n    \"\"\"\n    Computes the element-wise mean (average) of input tensors.\n    This layer calculates the average of all input tensors element-wise, requiring\n    that all tensors have identical shapes. The output tensor maintains the same\n    shape as the inputs.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def _setup_merge_layer(self):",
        "detail": "agent.src.metta.agent.lib.merge_layer",
        "documentation": {}
    },
    {
        "label": "ExpandLayer",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.merge_layer",
        "description": "agent.src.metta.agent.lib.merge_layer",
        "peekOfCode": "class ExpandLayer(LayerBase):\n    \"\"\"\n    Expands a tensor along a specified dimension.\n    This layer can expand a tensor in one of two ways:\n    1. By a fixed value specified by expand_value parameter\n    2. By deriving the expansion size from another tensor (specified by dims_source and source_dim)\n    The expanded dimension is inserted at the position specified by expand_dim.\n    Args:\n        name (str): Name of the layer\n        expand_dim (int): Dimension along which to expand (0 is batch dimension)",
        "detail": "agent.src.metta.agent.lib.merge_layer",
        "documentation": {}
    },
    {
        "label": "ReshapeLayer",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.merge_layer",
        "description": "agent.src.metta.agent.lib.merge_layer",
        "peekOfCode": "class ReshapeLayer(LayerBase):\n    \"\"\"\n    Multiplies two dimensions together, squeezing them into a single dimension.\n    This layer combines two dimensions of a tensor by multiplying their sizes and\n    placing the result in the squeezed_dim position, while removing the popped_dim.\n    This is useful for flattening or reorganizing tensor dimensions.\n    Args:\n        name (str): Name of the layer\n        popped_dim (int): Dimension to be removed after multiplication\n        squeezed_dim (int): Dimension to place the combined result in",
        "detail": "agent.src.metta.agent.lib.merge_layer",
        "documentation": {}
    },
    {
        "label": "BatchReshapeLayer",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.merge_layer",
        "description": "agent.src.metta.agent.lib.merge_layer",
        "peekOfCode": "class BatchReshapeLayer(LayerBase):\n    \"\"\"\n    Reshapes a tensor to introduce a time dimension from the batch dimension.\n    This layer takes a flattened batch of shape [B*TT, ...] and reshapes it to\n    [B, TT, ...] by inferring B from the \"_BxTT_\" value in the TensorDict.\n    It's typically used to convert between flattened and structured batch-time\n    representations.\n    The layer first expands the tensor at dimension 1, sets it equal to the value\n    at dimension 0 divided by B, sets dimension 0 to B, and finally squeezes\n    the tensor to remove any singleton dimensions.",
        "detail": "agent.src.metta.agent.lib.merge_layer",
        "documentation": {}
    },
    {
        "label": "CenterPixelLayer",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.merge_layer",
        "description": "agent.src.metta.agent.lib.merge_layer",
        "peekOfCode": "class CenterPixelLayer(LayerBase):\n    \"\"\"\n    Extracts the center pixel from a tensor with shape (B, C, H, W).\n    This layer selects only the center pixel from spatial dimensions H and W,\n    resulting in a tensor of shape (B, C). This is useful for focusing on the\n    central part of an image or feature map.\n    Note: H and W must be odd numbers for there to be a clear center pixel.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"",
        "detail": "agent.src.metta.agent.lib.merge_layer",
        "documentation": {}
    },
    {
        "label": "LayerBase",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.metta_layer",
        "description": "agent.src.metta.agent.lib.metta_layer",
        "peekOfCode": "class LayerBase(nn.Module):\n    \"\"\"The base class for components that make up the Metta agent. All components\n    are required to have a name and an input source, although the input source\n    can be None (or null in your YAML). Output size is optional depending on\n    your component.\n    All components must have a method called `setup` and it must accept\n    input_source_components. The setup assigns the output_size if it is not\n    already set. Once it has been called on all components, components can\n    initialize their parameters via `_initialize()`, if necessary. All\n    components must also have a property called `ready` that returns True if",
        "detail": "agent.src.metta.agent.lib.metta_layer",
        "documentation": {}
    },
    {
        "label": "ParamLayer",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.metta_layer",
        "description": "agent.src.metta.agent.lib.metta_layer",
        "peekOfCode": "class ParamLayer(LayerBase):\n    \"\"\"\n    Extension of LayerBase that provides parameter management and regularization functionality.\n    This class adds weight initialization, clipping, and regularization methods to the base layer\n    functionality. It supports multiple initialization schemes (Orthogonal, Xavier, Normal, and custom),\n    weight clipping to prevent exploding gradients, and L2 regularization options.\n    Key features:\n    - Weight initialization with various schemes (Orthogonal, Xavier, Normal, or custom)\n    - Automatic nonlinearity addition (e.g., ReLU) after the weight layer\n    - Weight clipping to prevent exploding gradients",
        "detail": "agent.src.metta.agent.lib.metta_layer",
        "documentation": {}
    },
    {
        "label": "MettaModule",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.metta_module",
        "description": "agent.src.metta.agent.lib.metta_module",
        "peekOfCode": "class MettaModule(nn.Module, ABC):\n    \"\"\"Base class for all modules in the Metta architecture.\n    This abstract base class provides a standardized interface for modules that process\n    TensorDicts. It enforces a clear input/output contract through key-based tensor\n    management and shape validation.\n    Attributes:\n        in_keys: List of keys for input tensors in the TensorDict\n        out_keys: List of keys for output tensors in the TensorDict\n        input_features_shape: Optional expected shape of input features (excluding batch dimension)\n        output_features_shape: Optional expected shape of output features (excluding batch dimension)",
        "detail": "agent.src.metta.agent.lib.metta_module",
        "documentation": {}
    },
    {
        "label": "MettaLinear",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.metta_module",
        "description": "agent.src.metta.agent.lib.metta_module",
        "peekOfCode": "class MettaLinear(MettaModule):\n    def __init__(\n        self,\n        in_keys: List[str],\n        out_keys: List[str],\n        input_features_shape: List[int],\n        output_features_shape: List[int],\n    ):\n        super().__init__(in_keys, out_keys, input_features_shape, output_features_shape)\n        if len(in_keys) != 1 or len(out_keys) != 1:",
        "detail": "agent.src.metta.agent.lib.metta_module",
        "documentation": {}
    },
    {
        "label": "MettaReLU",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.metta_module",
        "description": "agent.src.metta.agent.lib.metta_module",
        "peekOfCode": "class MettaReLU(MettaModule):\n    def __init__(\n        self,\n        in_keys: List[str],\n        out_keys: List[str],\n    ):\n        super().__init__(in_keys, out_keys)\n        if len(in_keys) != 1 or len(out_keys) != 1:\n            raise ValueError(\"MettaReLU requires exactly one input and one output key\")\n        self.relu = nn.ReLU()",
        "detail": "agent.src.metta.agent.lib.metta_module",
        "documentation": {}
    },
    {
        "label": "ModularNetwork",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.modular_network",
        "description": "agent.src.metta.agent.lib.modular_network",
        "peekOfCode": "class ModularNetwork(MettaModule):\n    \"\"\"A network composed of MettaModules that can be dynamically assembled.\n    This class provides a way to build networks by connecting MettaModules together.\n    Each module's output keys are mapped to input keys of subsequent modules through\n    the network's forward pass.\n    The way this works is that each node corresponds to a MettaModule, and the network\n    keeps track of the mapping between output keys and the node that produces them.\n    The network then uses this mapping to route the output tensors to the input keys of\n    the next node in the network.\n    For example, if we have:",
        "detail": "agent.src.metta.agent.lib.modular_network",
        "documentation": {}
    },
    {
        "label": "Linear",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.nn_layer_library",
        "description": "agent.src.metta.agent.lib.nn_layer_library",
        "peekOfCode": "class Linear(ParamLayer):\n    \"\"\"\n    Applies a linear transformation to the incoming data: y = xA^T + b\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def _make_net(self):\n        self._out_tensor_shape = [self._nn_params.out_features]\n        assert len(self._in_tensor_shapes[0]) == 1, (\n            \"_input_tensor_shape for Linear should be 1d (ignoring batch dimension)\"",
        "detail": "agent.src.metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "ReLU",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.nn_layer_library",
        "description": "agent.src.metta.agent.lib.nn_layer_library",
        "peekOfCode": "class ReLU(LayerBase):\n    \"\"\"\n    Applies the rectified linear unit function element-wise: ReLU(x) = max(0, x)\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def _make_net(self):\n        self._out_tensor_shape = self._in_tensor_shapes[0].copy()\n        return nn.ReLU()\nclass LayerNorm(LayerBase):",
        "detail": "agent.src.metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "LayerNorm",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.nn_layer_library",
        "description": "agent.src.metta.agent.lib.nn_layer_library",
        "peekOfCode": "class LayerNorm(LayerBase):\n    \"\"\"\n    Applies Layer Normalization over a mini-batch of inputs\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def _make_net(self):\n        self._out_tensor_shape = self._in_tensor_shapes[0].copy()\n        return nn.LayerNorm(self._in_tensor_shapes[0][0], **self._nn_params)\nclass Bilinear(LayerBase):",
        "detail": "agent.src.metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "Bilinear",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.nn_layer_library",
        "description": "agent.src.metta.agent.lib.nn_layer_library",
        "peekOfCode": "class Bilinear(LayerBase):\n    \"\"\"\n    Applies a bilinear transformation to the incoming data: y = x1 * A * x2^T + b\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def _make_net(self):\n        self._out_tensor_shape = [self._nn_params.out_features]\n        self._nn_params[\"in1_features\"] = self._in_tensor_shapes[0][0]\n        self._nn_params[\"in2_features\"] = self._in_tensor_shapes[1][0]",
        "detail": "agent.src.metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "Embedding",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.nn_layer_library",
        "description": "agent.src.metta.agent.lib.nn_layer_library",
        "peekOfCode": "class Embedding(LayerBase):\n    \"\"\"\n    A lookup table that stores embeddings of fixed dictionary and size.\n    This layer stores embeddings for a fixed dictionary of indices, and retrieves\n    them based on input indices. The embeddings are initialized using an orthogonal\n    initialization and then scaled to have a maximum absolute value of 0.1.\n    The shape of the output embeddings is [num_indices, embedding_dim], where\n    num_indices can vary depending on the forward pass. Child layers should not\n    be sensitive to changes in the first dimension.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent",
        "detail": "agent.src.metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "Conv2d",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.nn_layer_library",
        "description": "agent.src.metta.agent.lib.nn_layer_library",
        "peekOfCode": "class Conv2d(ParamLayer):\n    \"\"\"\n    Applies a 2D convolution over an input signal composed of several input channels.\n    This class automatically calculates output dimensions based on input shape,\n    kernel size, stride, and padding.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def _make_net(self):\n        self._set_conv_dims()",
        "detail": "agent.src.metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "MaxPool1d",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.nn_layer_library",
        "description": "agent.src.metta.agent.lib.nn_layer_library",
        "peekOfCode": "class MaxPool1d(LayerBase):\n    \"\"\"\n    Applies a 1D max pooling over an input signal.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def _make_net(self):\n        self._out_tensor_shape = self._in_tensor_shapes[0].copy()\n        return nn.MaxPool1d(self._in_tensor_shapes[0][0], **self._nn_params)\nclass MaxPool2d(LayerBase):",
        "detail": "agent.src.metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "MaxPool2d",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.nn_layer_library",
        "description": "agent.src.metta.agent.lib.nn_layer_library",
        "peekOfCode": "class MaxPool2d(LayerBase):\n    \"\"\"\n    Applies a 2D max pooling over an input signal.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def _make_net(self):\n        self._out_tensor_shape = self._in_tensor_shapes[0].copy()\n        return nn.MaxPool2d(self._in_tensor_shapes[0][0], **self._nn_params)\nclass AdaptiveAvgPool1d(LayerBase):",
        "detail": "agent.src.metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "AdaptiveAvgPool1d",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.nn_layer_library",
        "description": "agent.src.metta.agent.lib.nn_layer_library",
        "peekOfCode": "class AdaptiveAvgPool1d(LayerBase):\n    \"\"\"\n    Applies a 1D adaptive average pooling over an input signal.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def _make_net(self):\n        self._out_tensor_shape = self._in_tensor_shapes[0].copy()\n        return nn.AdaptiveAvgPool1d(self._in_tensor_shapes[0][0], **self._nn_params)\nclass AdaptiveAvgPool2d(LayerBase):",
        "detail": "agent.src.metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "AdaptiveAvgPool2d",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.nn_layer_library",
        "description": "agent.src.metta.agent.lib.nn_layer_library",
        "peekOfCode": "class AdaptiveAvgPool2d(LayerBase):\n    \"\"\"\n    Applies a 2D adaptive average pooling over an input signal.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def _make_net(self):\n        self._out_tensor_shape = self._in_tensor_shapes[0].copy()\n        return nn.AdaptiveAvgPool2d(self._in_tensor_shapes[0][0], **self._nn_params)\nclass AdaptiveMaxPool1d(LayerBase):",
        "detail": "agent.src.metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "AdaptiveMaxPool1d",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.nn_layer_library",
        "description": "agent.src.metta.agent.lib.nn_layer_library",
        "peekOfCode": "class AdaptiveMaxPool1d(LayerBase):\n    \"\"\"\n    Applies a 1D adaptive max pooling over an input signal.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def _make_net(self):\n        self._out_tensor_shape = self._in_tensor_shapes[0].copy()\n        return nn.AdaptiveMaxPool1d(self._in_tensor_shapes[0][0], **self._nn_params)\nclass AdaptiveMaxPool2d(LayerBase):",
        "detail": "agent.src.metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "AdaptiveMaxPool2d",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.nn_layer_library",
        "description": "agent.src.metta.agent.lib.nn_layer_library",
        "peekOfCode": "class AdaptiveMaxPool2d(LayerBase):\n    \"\"\"\n    Applies a 2D adaptive max pooling over an input signal.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def _make_net(self):\n        self._out_tensor_shape = self._in_tensor_shapes[0].copy()\n        return nn.AdaptiveMaxPool2d(self._in_tensor_shapes[0][0], **self._nn_params)\nclass AvgPool1d(LayerBase):",
        "detail": "agent.src.metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "AvgPool1d",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.nn_layer_library",
        "description": "agent.src.metta.agent.lib.nn_layer_library",
        "peekOfCode": "class AvgPool1d(LayerBase):\n    \"\"\"\n    Applies a 1D average pooling over an input signal.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def _make_net(self):\n        self._out_tensor_shape = self._in_tensor_shapes[0].copy()\n        return nn.AvgPool1d(self._in_tensor_shapes[0][0], **self._nn_params)\nclass AvgPool2d(LayerBase):",
        "detail": "agent.src.metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "AvgPool2d",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.nn_layer_library",
        "description": "agent.src.metta.agent.lib.nn_layer_library",
        "peekOfCode": "class AvgPool2d(LayerBase):\n    \"\"\"\n    Applies a 2D average pooling over an input signal.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def _make_net(self):\n        self._out_tensor_shape = self._in_tensor_shapes[0].copy()\n        return nn.AvgPool2d(self._in_tensor_shapes[0][0], **self._nn_params)\nclass Dropout(LayerBase):",
        "detail": "agent.src.metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "Dropout",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.nn_layer_library",
        "description": "agent.src.metta.agent.lib.nn_layer_library",
        "peekOfCode": "class Dropout(LayerBase):\n    \"\"\"\n    Randomly zeroes some of the elements of the input tensor with probability p.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def _make_net(self):\n        self._out_tensor_shape = self._in_tensor_shapes[0].copy()\n        return nn.Dropout(**self._nn_params)\nclass Dropout2d(LayerBase):",
        "detail": "agent.src.metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "Dropout2d",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.nn_layer_library",
        "description": "agent.src.metta.agent.lib.nn_layer_library",
        "peekOfCode": "class Dropout2d(LayerBase):\n    \"\"\"\n    Randomly zero out entire channels of the input tensor with probability p.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def _make_net(self):\n        self._out_tensor_shape = self._in_tensor_shapes[0].copy()\n        return nn.Dropout2d(**self._nn_params)\nclass AlphaDropout(LayerBase):",
        "detail": "agent.src.metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "AlphaDropout",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.nn_layer_library",
        "description": "agent.src.metta.agent.lib.nn_layer_library",
        "peekOfCode": "class AlphaDropout(LayerBase):\n    \"\"\"\n    Applies Alpha Dropout, which maintains the mean and variance of the inputs.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def _make_net(self):\n        self._out_tensor_shape = self._in_tensor_shapes[0].copy()\n        return nn.AlphaDropout(**self._nn_params)\nclass BatchNorm1d(LayerBase):",
        "detail": "agent.src.metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "BatchNorm1d",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.nn_layer_library",
        "description": "agent.src.metta.agent.lib.nn_layer_library",
        "peekOfCode": "class BatchNorm1d(LayerBase):\n    \"\"\"\n    Applies Batch Normalization over a 2D or 3D input.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def _make_net(self):\n        self._out_tensor_shape = self._in_tensor_shapes[0].copy()\n        return nn.BatchNorm1d(self._in_tensor_shapes[0][0], **self._nn_params)\nclass BatchNorm2d(LayerBase):",
        "detail": "agent.src.metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "BatchNorm2d",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.nn_layer_library",
        "description": "agent.src.metta.agent.lib.nn_layer_library",
        "peekOfCode": "class BatchNorm2d(LayerBase):\n    \"\"\"\n    Applies Batch Normalization over a 4D input.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def _make_net(self):\n        self._out_tensor_shape = self._in_tensor_shapes[0].copy()\n        return nn.BatchNorm2d(self._in_tensor_shapes[0][0], **self._nn_params)\nclass Flatten(LayerBase):",
        "detail": "agent.src.metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "Flatten",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.nn_layer_library",
        "description": "agent.src.metta.agent.lib.nn_layer_library",
        "peekOfCode": "class Flatten(LayerBase):\n    \"\"\"\n    Flattens a contiguous range of dimensions into a single dimension.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def _make_net(self):\n        self._out_tensor_shape = [prod(self._in_tensor_shapes[0])]\n        return nn.Flatten()\nclass Identity(LayerBase):",
        "detail": "agent.src.metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "Identity",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.nn_layer_library",
        "description": "agent.src.metta.agent.lib.nn_layer_library",
        "peekOfCode": "class Identity(LayerBase):\n    \"\"\"\n    A placeholder identity layer that returns the input tensor unchanged.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def _make_net(self):\n        self._out_tensor_shape = self._in_tensor_shapes[0].copy()\n        return nn.Identity()",
        "detail": "agent.src.metta.agent.lib.nn_layer_library",
        "documentation": {}
    },
    {
        "label": "ObsLatentAttn",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.obs_enc",
        "description": "agent.src.metta.agent.lib.obs_enc",
        "peekOfCode": "class ObsLatentAttn(LayerBase):\n    \"\"\"\n    Performs multi-layer cross-attention between learnable query tokens and input features.\n    !!! Note About Output Shape: !!!\n    The output shape depends on the `_use_cls_token` parameter:\n    - If `_use_cls_token == True`, the output tensor shape will be `[B_TT, out_dim]`.\n    - If `_use_cls_token == False`, the output tensor shape will be `[B_TT, num_query_tokens, out_dim]`.\n    So, if true, it's setup to pass directly to the LSTM. But that also means that it will be in an invalid shape to\n    pass to another attention layer. In other words, if _use_cls_token == True, then this should be the last layer of\n    the encoder (because why else use the cls token?).",
        "detail": "agent.src.metta.agent.lib.obs_enc",
        "documentation": {}
    },
    {
        "label": "ObsSelfAttn",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.obs_enc",
        "description": "agent.src.metta.agent.lib.obs_enc",
        "peekOfCode": "class ObsSelfAttn(LayerBase):\n    \"\"\"Future work can go beyond just using the feat dim as the attn qv dim, a single layer and single head,\n    adding a GRU before the out projection...\"\"\"\n    def __init__(\n        self,\n        out_dim: int,\n        use_mask: bool = False,\n        num_layers: int = 1,\n        num_heads: int = 1,\n        use_cls_token: bool = False,",
        "detail": "agent.src.metta.agent.lib.obs_enc",
        "documentation": {}
    },
    {
        "label": "ObsTokenToBoxShaper",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.obs_token_to_box_shaper",
        "description": "agent.src.metta.agent.lib.obs_token_to_box_shaper",
        "peekOfCode": "class ObsTokenToBoxShaper(LayerBase):\n    \"\"\"\n    This class consumes token observations and outputs a box observation.\n    I.e., its output will be a tensor of shape [B*TT, num_layers, obs_width, obs_height].\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent is instantiated\n    and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"\n    def __init__(self, obs_shape, obs_width, obs_height, feature_normalizations, **cfg):\n        super().__init__(**cfg)\n        self._obs_shape = list(obs_shape)  # make sure no Omegaconf types are used in forward passes",
        "detail": "agent.src.metta.agent.lib.obs_token_to_box_shaper",
        "documentation": {}
    },
    {
        "label": "ObsTokenPadStrip",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.obs_tokenizers",
        "description": "agent.src.metta.agent.lib.obs_tokenizers",
        "peekOfCode": "class ObsTokenPadStrip(LayerBase):\n    \"\"\"\n    This is a top-level layer that grabs environment token observations and strips them of padding, returning a tensor\n    of shape [B, M, 3] where M is the maximum number of tokens in _any_ sequence in the batch. It also adds batch size,\n    TT, and B * TT to the tensor dict for downstream layers to use, if necessary.\n    For clarification it does not strip all padding. It finds the sequence (out of all sequences in the batch) with the\n    most dense tokens, gets that index, and then slices the obs tensor at that point. That means that it perfectly\n    eliminates the padding tokens from the the sequence with the fewest padding tokens and also removes that number of\n    padding tokens from all other sequences. In practice, the sequence with the most dense tokens can have many more\n    dense tokens than the average sequence so there is room for improvement by computing attention over ragged tensors.",
        "detail": "agent.src.metta.agent.lib.obs_tokenizers",
        "documentation": {}
    },
    {
        "label": "ObsAttrValNorm",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.obs_tokenizers",
        "description": "agent.src.metta.agent.lib.obs_tokenizers",
        "peekOfCode": "class ObsAttrValNorm(LayerBase):\n    \"\"\"Normalizes attr values based on the attr index.\"\"\"\n    def __init__(\n        self,\n        feature_normalizations: list[float],\n        **cfg,\n    ) -> None:\n        super().__init__(**cfg)\n        self._feature_normalizations = list(feature_normalizations)\n        self._max_embeds = 256",
        "detail": "agent.src.metta.agent.lib.obs_tokenizers",
        "documentation": {}
    },
    {
        "label": "ObsAttrCoordEmbed",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.obs_tokenizers",
        "description": "agent.src.metta.agent.lib.obs_tokenizers",
        "peekOfCode": "class ObsAttrCoordEmbed(LayerBase):\n    \"\"\"Embeds attr index as, separately embeds coords, then adds them together. Finally concatenate attr value to the\n    end of the embedding. Learnable coord embeddings have performed worse than Fourier features as of 6/16/2025.\"\"\"\n    def __init__(\n        self,\n        attr_embed_dim: int,\n        **cfg,\n    ) -> None:\n        super().__init__(**cfg)\n        self._attr_embed_dim = attr_embed_dim  # Dimension of attribute embeddings",
        "detail": "agent.src.metta.agent.lib.obs_tokenizers",
        "documentation": {}
    },
    {
        "label": "ObsAttrEmbedFourier",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.obs_tokenizers",
        "description": "agent.src.metta.agent.lib.obs_tokenizers",
        "peekOfCode": "class ObsAttrEmbedFourier(LayerBase):\n    \"\"\"An alternate to ObsAttrCoordEmbed that concatenates attr embeds w coord representation as Fourier features.\"\"\"\n    def __init__(\n        self,\n        attr_embed_dim: int,\n        num_freqs: int = 3,\n        **cfg,\n    ) -> None:\n        super().__init__(**cfg)\n        self._attr_embed_dim = attr_embed_dim  # Dimension of attribute embeddings",
        "detail": "agent.src.metta.agent.lib.obs_tokenizers",
        "documentation": {}
    },
    {
        "label": "ObsAttrCoordValueEmbed",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.obs_tokenizers",
        "description": "agent.src.metta.agent.lib.obs_tokenizers",
        "peekOfCode": "class ObsAttrCoordValueEmbed(LayerBase):\n    \"\"\"An experiment that embeds attr value as a categorical variable. Using a normalization layer is not\n    recommended.\"\"\"\n    def __init__(\n        self,\n        attr_embed_dim: int,\n        **cfg,\n    ) -> None:\n        super().__init__(**cfg)\n        self._attr_embed_dim = attr_embed_dim  # Dimension of attribute embeddings",
        "detail": "agent.src.metta.agent.lib.obs_tokenizers",
        "documentation": {}
    },
    {
        "label": "ObservationNormalizer",
        "kind": 6,
        "importPath": "agent.src.metta.agent.lib.observation_normalizer",
        "description": "agent.src.metta.agent.lib.observation_normalizer",
        "peekOfCode": "class ObservationNormalizer(LayerBase):\n    \"\"\"\n    Normalizes observation features by dividing each feature by its approximate maximum value.\n    This class scales observation features to a range of approximately [0, 1] by dividing\n    each feature by predefined normalization values from the OBS_NORMALIZATIONS dictionary.\n    Normalization helps stabilize neural network training by preventing features with large\n    magnitudes from dominating the learning process.\n    Note that the __init__ of any layer class and the MettaAgent are only called when the agent\n    is instantiated and never again. I.e., not when it is reloaded from a saved policy.\n    \"\"\"",
        "detail": "agent.src.metta.agent.lib.observation_normalizer",
        "documentation": {}
    },
    {
        "label": "position_embeddings",
        "kind": 2,
        "importPath": "agent.src.metta.agent.lib.position",
        "description": "agent.src.metta.agent.lib.position",
        "peekOfCode": "def position_embeddings(width, height, embedding_dim=128):\n    \"\"\"\n    Creates simple 2D position embeddings with x, y coordinates.\n    Generates a grid of positions where each point has normalized coordinates\n    in the range [-1, 1]. This provides a basic position representation that\n    can be used in neural networks to inject spatial information.\n    Args:\n        width (int): The width of the grid\n        height (int): The height of the grid\n        embedding_dim (int): Not used in this function, included for API consistency",
        "detail": "agent.src.metta.agent.lib.position",
        "documentation": {}
    },
    {
        "label": "sinusoidal_position_embeddings",
        "kind": 2,
        "importPath": "agent.src.metta.agent.lib.position",
        "description": "agent.src.metta.agent.lib.position",
        "peekOfCode": "def sinusoidal_position_embeddings(width, height, embedding_dim=128):\n    \"\"\"\n    Creates sinusoidal position embeddings for a 2D grid.\n    This function implements sinusoidal position embeddings similar to those used\n    in the Transformer architecture, but adapted for 2D spatial positions. It creates\n    embeddings by applying sine and cosine functions at different frequencies to the\n    x and y coordinates, producing a rich representational space that captures both\n    position and relative distances.\n    The embeddings include both frequency-based features and the raw normalized coordinates\n    as the last two dimensions, providing both high-frequency detail and direct positional",
        "detail": "agent.src.metta.agent.lib.position",
        "documentation": {}
    },
    {
        "label": "MockAgent",
        "kind": 6,
        "importPath": "agent.src.metta.agent.mocks.mock_agent",
        "description": "agent.src.metta.agent.mocks.mock_agent",
        "peekOfCode": "class MockAgent(MettaAgent):\n    \"\"\"\n    A fake agent that does nothing, used to run play without requiring a policy to be trained\n    \"\"\"\n    def __init__(self):\n        pass\n    def activate_actions(self, *args):\n        pass\n    def __call__(self, obs, state):\n        num_agents = obs.shape[0]",
        "detail": "agent.src.metta.agent.mocks.mock_agent",
        "documentation": {}
    },
    {
        "label": "MockPolicy",
        "kind": 6,
        "importPath": "agent.src.metta.agent.mocks.mock_policy",
        "description": "agent.src.metta.agent.mocks.mock_policy",
        "peekOfCode": "class MockPolicy(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc = nn.Linear(10, 10)\n        self.components = nn.ModuleDict(\n            {\n                \"_core_\": nn.LSTM(10, 10),\n                \"_value_\": nn.Linear(10, 1),\n                \"_action_\": nn.Linear(10, 5),\n            }",
        "detail": "agent.src.metta.agent.mocks.mock_policy",
        "documentation": {}
    },
    {
        "label": "MockPolicyRecord",
        "kind": 6,
        "importPath": "agent.src.metta.agent.mocks.mock_policy_record",
        "description": "agent.src.metta.agent.mocks.mock_policy_record",
        "peekOfCode": "class MockPolicyRecord(PolicyRecord):\n    \"\"\"Mock implementation of PolicyRecord for testing.\"\"\"\n    def __init__(\n        self,\n        policy_store=None,\n        run_name: str = \"mock_run\",\n        uri: str = \"mock://policy\",\n        metadata: PolicyMetadata = MockPolicyMetadata,\n    ):\n        \"\"\"Initialize a mock policy record.",
        "detail": "agent.src.metta.agent.mocks.mock_policy_record",
        "documentation": {}
    },
    {
        "label": "MockPolicyMetadata",
        "kind": 5,
        "importPath": "agent.src.metta.agent.mocks.mock_policy_record",
        "description": "agent.src.metta.agent.mocks.mock_policy_record",
        "peekOfCode": "MockPolicyMetadata = PolicyMetadata()\nclass MockPolicyRecord(PolicyRecord):\n    \"\"\"Mock implementation of PolicyRecord for testing.\"\"\"\n    def __init__(\n        self,\n        policy_store=None,\n        run_name: str = \"mock_run\",\n        uri: str = \"mock://policy\",\n        metadata: PolicyMetadata = MockPolicyMetadata,\n    ):",
        "detail": "agent.src.metta.agent.mocks.mock_policy_record",
        "documentation": {}
    },
    {
        "label": "assert_shape",
        "kind": 2,
        "importPath": "agent.src.metta.agent.util.debug",
        "description": "agent.src.metta.agent.util.debug",
        "peekOfCode": "def assert_shape(tensor: torch.Tensor, expected_shape: Tuple[Union[int, str], ...], name: Optional[str] = None) -> bool:\n    \"\"\"\n    Assert that a tensor has an expected shape by raising ValueError if the shape doesn't match. This function should\n    be called from within a debug block to allow optimization to skip the checks\n    Args:\n        tensor: The tensor to check\n        expected_shape: A tuple specifying expected dimensions. Each element can be:\n            - An integer: Requires the dimension to have exactly this size\n            - A string: Represents a named dimension (like \"B\", \"T\", \"H\", \"W\") where any\n              positive size is acceptable",
        "detail": "agent.src.metta.agent.util.debug",
        "documentation": {}
    },
    {
        "label": "sample_actions",
        "kind": 2,
        "importPath": "agent.src.metta.agent.util.distribution_utils",
        "description": "agent.src.metta.agent.util.distribution_utils",
        "peekOfCode": "def sample_actions(action_logits: Tensor) -> Tuple[Tensor, Tensor, Tensor, Tensor]:\n    \"\"\"\n    Sample actions from logits during inference.\n    Args:\n        action_logits: Raw logits from policy network of shape [batch_size, num_actions].\n                       These are unnormalized log-probabilities over the action space.\n    Returns:\n        actions: Sampled action indices of shape [batch_size]. Each element is an\n                 integer in [0, num_actions) representing the sampled action.\n        log_probs: Log-probabilities of the sampled actions, shape [batch_size].",
        "detail": "agent.src.metta.agent.util.distribution_utils",
        "documentation": {}
    },
    {
        "label": "evaluate_actions",
        "kind": 2,
        "importPath": "agent.src.metta.agent.util.distribution_utils",
        "description": "agent.src.metta.agent.util.distribution_utils",
        "peekOfCode": "def evaluate_actions(action_logits: Tensor, actions: Tensor) -> Tuple[Tensor, Tensor, Tensor]:\n    \"\"\"\n    Evaluate provided actions against logits during training.\n    Args:\n        action_logits: Current policy logits of shape [batch_size, num_actions].\n                       These may differ from the logits that originally generated\n                       the actions due to policy updates.\n        actions: Previously taken action indices of shape [batch_size].\n                 Each element must be a valid action index in [0, num_actions).\n    Returns:",
        "detail": "agent.src.metta.agent.util.distribution_utils",
        "documentation": {}
    },
    {
        "label": "RunningMeanStdInPlace",
        "kind": 6,
        "importPath": "agent.src.metta.agent.util.running_mean_std",
        "description": "agent.src.metta.agent.util.running_mean_std",
        "peekOfCode": "class RunningMeanStdInPlace(nn.Module):\n    def __init__(self, input_shape, epsilon=_NORM_EPS, clip=_DEFAULT_CLIP, per_channel=False, norm_only=False):\n        super().__init__()\n        logger.debug(\"RunningMeanStd input shape: %r\", input_shape)\n        self.input_shape: Final = input_shape\n        self.eps: Final[float] = epsilon\n        self.clip: Final[float] = clip\n        self.norm_only: Final[bool] = norm_only\n        self.per_channel: Final[bool] = per_channel\n        if per_channel:",
        "detail": "agent.src.metta.agent.util.running_mean_std",
        "documentation": {}
    },
    {
        "label": "RunningMeanStdDictInPlace",
        "kind": 6,
        "importPath": "agent.src.metta.agent.util.running_mean_std",
        "description": "agent.src.metta.agent.util.running_mean_std",
        "peekOfCode": "class RunningMeanStdDictInPlace(nn.Module):\n    def __init__(\n        self,\n        obs_space: gym.spaces.Dict,\n        keys_to_normalize: Optional[List[str]] = None,\n        epsilon=_NORM_EPS,\n        clip=_DEFAULT_CLIP,\n        per_channel=False,\n        norm_only=False,\n    ):",
        "detail": "agent.src.metta.agent.util.running_mean_std",
        "documentation": {}
    },
    {
        "label": "running_mean_std_summaries",
        "kind": 2,
        "importPath": "agent.src.metta.agent.util.running_mean_std",
        "description": "agent.src.metta.agent.util.running_mean_std",
        "peekOfCode": "def running_mean_std_summaries(running_mean_std_module: Union[nn.Module, ScriptModule, RecursiveScriptModule]):\n    m = running_mean_std_module\n    res = dict()\n    for name, buf in m.named_buffers():\n        # converts MODULE_NAME.running_mean_std.obs.running_mean to obs.running_mean\n        name = \"_\".join(name.split(\".\")[-2:])\n        if name.endswith(\"running_mean\"):\n            res[name] = buf.float().mean()\n        elif name.endswith(\"running_var\"):\n            res[name.replace(\"_var\", \"_std\")] = torch.sqrt(buf.float() + _NORM_EPS).mean()",
        "detail": "agent.src.metta.agent.util.running_mean_std",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "agent.src.metta.agent.util.running_mean_std",
        "description": "agent.src.metta.agent.util.running_mean_std",
        "peekOfCode": "logger = logging.getLogger(__name__)\n_NORM_EPS = 1e-5\n_DEFAULT_CLIP = 5.0\n# noinspection PyAttributeOutsideInit,NonAsciiCharacters\nclass RunningMeanStdInPlace(nn.Module):\n    def __init__(self, input_shape, epsilon=_NORM_EPS, clip=_DEFAULT_CLIP, per_channel=False, norm_only=False):\n        super().__init__()\n        logger.debug(\"RunningMeanStd input shape: %r\", input_shape)\n        self.input_shape: Final = input_shape\n        self.eps: Final[float] = epsilon",
        "detail": "agent.src.metta.agent.util.running_mean_std",
        "documentation": {}
    },
    {
        "label": "_NORM_EPS",
        "kind": 5,
        "importPath": "agent.src.metta.agent.util.running_mean_std",
        "description": "agent.src.metta.agent.util.running_mean_std",
        "peekOfCode": "_NORM_EPS = 1e-5\n_DEFAULT_CLIP = 5.0\n# noinspection PyAttributeOutsideInit,NonAsciiCharacters\nclass RunningMeanStdInPlace(nn.Module):\n    def __init__(self, input_shape, epsilon=_NORM_EPS, clip=_DEFAULT_CLIP, per_channel=False, norm_only=False):\n        super().__init__()\n        logger.debug(\"RunningMeanStd input shape: %r\", input_shape)\n        self.input_shape: Final = input_shape\n        self.eps: Final[float] = epsilon\n        self.clip: Final[float] = clip",
        "detail": "agent.src.metta.agent.util.running_mean_std",
        "documentation": {}
    },
    {
        "label": "_DEFAULT_CLIP",
        "kind": 5,
        "importPath": "agent.src.metta.agent.util.running_mean_std",
        "description": "agent.src.metta.agent.util.running_mean_std",
        "peekOfCode": "_DEFAULT_CLIP = 5.0\n# noinspection PyAttributeOutsideInit,NonAsciiCharacters\nclass RunningMeanStdInPlace(nn.Module):\n    def __init__(self, input_shape, epsilon=_NORM_EPS, clip=_DEFAULT_CLIP, per_channel=False, norm_only=False):\n        super().__init__()\n        logger.debug(\"RunningMeanStd input shape: %r\", input_shape)\n        self.input_shape: Final = input_shape\n        self.eps: Final[float] = epsilon\n        self.clip: Final[float] = clip\n        self.norm_only: Final[bool] = norm_only",
        "detail": "agent.src.metta.agent.util.running_mean_std",
        "documentation": {}
    },
    {
        "label": "safe_get_from_obs_space",
        "kind": 2,
        "importPath": "agent.src.metta.agent.util.safe_get",
        "description": "agent.src.metta.agent.util.safe_get",
        "peekOfCode": "def safe_get_from_obs_space(\n    obs_space: Union[gym.spaces.Space, gym.spaces.Dict],\n    obs_key: str,\n    property_name: str,\n) -> Any:\n    \"\"\"\n    Safely extract properties from observation spaces with comprehensive error handling.\n    Args:\n        obs_space: the observation space to search\n        obs_key: The obs_key to access in the observation space",
        "detail": "agent.src.metta.agent.util.safe_get",
        "documentation": {}
    },
    {
        "label": "analyze_weights",
        "kind": 2,
        "importPath": "agent.src.metta.agent.util.weights_analysis",
        "description": "agent.src.metta.agent.util.weights_analysis",
        "peekOfCode": "def analyze_weights(weights: torch.Tensor, delta: float = 0.01) -> dict:\n    \"\"\"Analyze weight matrix properties including singular values, effective rank,\n    weight norms and other dynamics-related metrics.\n    Args:\n        weights: Weight tensor to analyze\n        delta: Threshold for effective rank calculation (default: 0.01)\n    Returns:\n        Dictionary containing all computed metrics including:\n        - Singular value statistics (ratio, largest, mean, collapsed dimensions)\n        - Power law fit metrics (R value, slope)",
        "detail": "agent.src.metta.agent.util.weights_analysis",
        "documentation": {}
    },
    {
        "label": "DistributedMettaAgent",
        "kind": 6,
        "importPath": "agent.src.metta.agent.metta_agent",
        "description": "agent.src.metta.agent.metta_agent",
        "peekOfCode": "class DistributedMettaAgent(DistributedDataParallel):\n    def __init__(self, agent, device):\n        logger.info(\"Converting BatchNorm layers to SyncBatchNorm for distributed training...\")\n        agent = torch.nn.SyncBatchNorm.convert_sync_batchnorm(agent)\n        super().__init__(agent, device_ids=[device], output_device=device)\n    def __getattr__(self, name):\n        try:\n            return super().__getattr__(name)\n        except AttributeError:\n            return getattr(self.module, name)",
        "detail": "agent.src.metta.agent.metta_agent",
        "documentation": {}
    },
    {
        "label": "MettaAgent",
        "kind": 6,
        "importPath": "agent.src.metta.agent.metta_agent",
        "description": "agent.src.metta.agent.metta_agent",
        "peekOfCode": "class MettaAgent(nn.Module):\n    def __init__(\n        self,\n        obs_space: Union[gym.spaces.Space, gym.spaces.Dict],\n        obs_width: int,\n        obs_height: int,\n        action_space: gym.spaces.Space,\n        feature_normalizations: dict[int, float],\n        device: str,\n        **cfg,",
        "detail": "agent.src.metta.agent.metta_agent",
        "documentation": {}
    },
    {
        "label": "make_policy",
        "kind": 2,
        "importPath": "agent.src.metta.agent.metta_agent",
        "description": "agent.src.metta.agent.metta_agent",
        "peekOfCode": "def make_policy(env: \"MettaGridEnv\", cfg: ListConfig | DictConfig) -> \"MettaAgent\":\n    obs_space = gym.spaces.Dict(\n        {\n            \"grid_obs\": env.single_observation_space,\n            \"global_vars\": gym.spaces.Box(low=-np.inf, high=np.inf, shape=[0], dtype=np.int32),\n        }\n    )\n    # Here's where we create MettaAgent. We're including the term MettaAgent here for better\n    # searchability. Otherwise you might only find yaml files.\n    return hydra.utils.instantiate(",
        "detail": "agent.src.metta.agent.metta_agent",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "agent.src.metta.agent.metta_agent",
        "description": "agent.src.metta.agent.metta_agent",
        "peekOfCode": "logger = logging.getLogger(\"metta_agent\")\ndef make_policy(env: \"MettaGridEnv\", cfg: ListConfig | DictConfig) -> \"MettaAgent\":\n    obs_space = gym.spaces.Dict(\n        {\n            \"grid_obs\": env.single_observation_space,\n            \"global_vars\": gym.spaces.Box(low=-np.inf, high=np.inf, shape=[0], dtype=np.int32),\n        }\n    )\n    # Here's where we create MettaAgent. We're including the term MettaAgent here for better\n    # searchability. Otherwise you might only find yaml files.",
        "detail": "agent.src.metta.agent.metta_agent",
        "documentation": {}
    },
    {
        "label": "PolicyCache",
        "kind": 6,
        "importPath": "agent.src.metta.agent.policy_cache",
        "description": "agent.src.metta.agent.policy_cache",
        "peekOfCode": "class PolicyCache:\n    \"\"\"\n    Thread-safe LRU cache for PolicyRecord objects.\n    Automatically evicts least recently used policies when the cache\n    reaches its maximum size, preventing excessive memory usage.\n    \"\"\"\n    def __init__(self, max_size: int = 10):\n        \"\"\"\n        Initialize the policy cache.\n        Args:",
        "detail": "agent.src.metta.agent.policy_cache",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "agent.src.metta.agent.policy_cache",
        "description": "agent.src.metta.agent.policy_cache",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass PolicyCache:\n    \"\"\"\n    Thread-safe LRU cache for PolicyRecord objects.\n    Automatically evicts least recently used policies when the cache\n    reaches its maximum size, preventing excessive memory usage.\n    \"\"\"\n    def __init__(self, max_size: int = 10):\n        \"\"\"\n        Initialize the policy cache.",
        "detail": "agent.src.metta.agent.policy_cache",
        "documentation": {}
    },
    {
        "label": "PolicyMetadata",
        "kind": 6,
        "importPath": "agent.src.metta.agent.policy_metadata",
        "description": "agent.src.metta.agent.policy_metadata",
        "peekOfCode": "class PolicyMetadata(dict[str, Any]):\n    \"\"\"Dict-like metadata with required fields and support for additional arbitrary fields.\"\"\"\n    # Define required field names as class constant\n    _REQUIRED_FIELDS = {\"agent_step\", \"epoch\", \"generation\", \"train_time\"}\n    # Type hints for IDE support\n    agent_step: int\n    epoch: int\n    generation: int\n    train_time: float\n    def __init__(self, agent_step=0, epoch=0, generation=0, train_time=0.0, **kwargs: Any):",
        "detail": "agent.src.metta.agent.policy_metadata",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "agent.src.metta.agent.policy_metadata",
        "description": "agent.src.metta.agent.policy_metadata",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass PolicyMetadata(dict[str, Any]):\n    \"\"\"Dict-like metadata with required fields and support for additional arbitrary fields.\"\"\"\n    # Define required field names as class constant\n    _REQUIRED_FIELDS = {\"agent_step\", \"epoch\", \"generation\", \"train_time\"}\n    # Type hints for IDE support\n    agent_step: int\n    epoch: int\n    generation: int\n    train_time: float",
        "detail": "agent.src.metta.agent.policy_metadata",
        "documentation": {}
    },
    {
        "label": "PolicyRecord",
        "kind": 6,
        "importPath": "agent.src.metta.agent.policy_record",
        "description": "agent.src.metta.agent.policy_record",
        "peekOfCode": "class PolicyRecord:\n    \"\"\"A record containing a policy and its metadata.\"\"\"\n    def __init__(self, policy_store, run_name: str, uri: str, metadata: PolicyMetadata):\n        self._policy_store = policy_store\n        self.run_name = run_name  # Human-readable identifier (e.g., from wandb)\n        self.uri: str = uri\n        # Use the setter to ensure proper type\n        self.metadata = metadata\n        self._cached_policy = None\n    @property",
        "detail": "agent.src.metta.agent.policy_record",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "agent.src.metta.agent.policy_record",
        "description": "agent.src.metta.agent.policy_record",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass PolicyRecord:\n    \"\"\"A record containing a policy and its metadata.\"\"\"\n    def __init__(self, policy_store, run_name: str, uri: str, metadata: PolicyMetadata):\n        self._policy_store = policy_store\n        self.run_name = run_name  # Human-readable identifier (e.g., from wandb)\n        self.uri: str = uri\n        # Use the setter to ensure proper type\n        self.metadata = metadata\n        self._cached_policy = None",
        "detail": "agent.src.metta.agent.policy_record",
        "documentation": {}
    },
    {
        "label": "PolicyState",
        "kind": 6,
        "importPath": "agent.src.metta.agent.policy_state",
        "description": "agent.src.metta.agent.policy_state",
        "peekOfCode": "class PolicyState(TensorClass):\n    lstm_h: Optional[torch.Tensor] = None\n    lstm_c: Optional[torch.Tensor] = None\n    hidden: Optional[torch.Tensor] = None",
        "detail": "agent.src.metta.agent.policy_state",
        "documentation": {}
    },
    {
        "label": "PolicySelectorConfig",
        "kind": 6,
        "importPath": "agent.src.metta.agent.policy_store",
        "description": "agent.src.metta.agent.policy_store",
        "peekOfCode": "class PolicySelectorConfig:\n    \"\"\"Simple config class for policy selection without pydantic dependency.\"\"\"\n    def __init__(self, type: str = \"top\", metric: str = \"score\"):\n        self.type = type\n        self.metric = metric\nclass PolicyStore:\n    def __init__(self, cfg: DictConfig, wandb_run):\n        self._cfg = cfg\n        self._device = cfg.device\n        self._wandb_run = wandb_run",
        "detail": "agent.src.metta.agent.policy_store",
        "documentation": {}
    },
    {
        "label": "PolicyStore",
        "kind": 6,
        "importPath": "agent.src.metta.agent.policy_store",
        "description": "agent.src.metta.agent.policy_store",
        "peekOfCode": "class PolicyStore:\n    def __init__(self, cfg: DictConfig, wandb_run):\n        self._cfg = cfg\n        self._device = cfg.device\n        self._wandb_run = wandb_run\n        cache_size = cfg.get(\"policy_cache_size\", 10)  # Default to 10 if not specified\n        self._cached_prs = PolicyCache(max_size=cache_size)\n        self._made_codebase_backwards_compatible = False\n    def policy_record(\n        self, uri_or_config: Union[str, DictConfig], selector_type: str = \"top\", metric=\"score\"",
        "detail": "agent.src.metta.agent.policy_store",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "agent.src.metta.agent.policy_store",
        "description": "agent.src.metta.agent.policy_store",
        "peekOfCode": "logger = logging.getLogger(\"policy_store\")\nclass PolicySelectorConfig:\n    \"\"\"Simple config class for policy selection without pydantic dependency.\"\"\"\n    def __init__(self, type: str = \"top\", metric: str = \"score\"):\n        self.type = type\n        self.metric = metric\nclass PolicyStore:\n    def __init__(self, cfg: DictConfig, wandb_run):\n        self._cfg = cfg\n        self._device = cfg.device",
        "detail": "agent.src.metta.agent.policy_store",
        "documentation": {}
    },
    {
        "label": "TestLSTMLayer",
        "kind": 6,
        "importPath": "agent.tests.lib.test_lstm",
        "description": "agent.tests.lib.test_lstm",
        "peekOfCode": "class TestLSTMLayer:\n    \"\"\"Tests for the LSTM layer with focus on state handling behavior.\"\"\"\n    def test_lstm_with_none_state(self, simple_lstm_environment):\n        \"\"\"Test LSTM layer behavior with None state.\"\"\"\n        lstm_layer = simple_lstm_environment[\"lstm_layer\"]\n        sample_input = simple_lstm_environment[\"sample_input\"]\n        params = simple_lstm_environment[\"params\"]\n        # Create dict with None state\n        td = {\"x\": sample_input[\"x\"], \"hidden\": sample_input[\"hidden\"], \"state\": None}\n        # Forward pass with None state",
        "detail": "agent.tests.lib.test_lstm",
        "documentation": {}
    },
    {
        "label": "simple_lstm_environment",
        "kind": 2,
        "importPath": "agent.tests.lib.test_lstm",
        "description": "agent.tests.lib.test_lstm",
        "peekOfCode": "def simple_lstm_environment():\n    \"\"\"Create a minimal environment for testing the LSTM layer.\"\"\"\n    # Define the dimensions\n    batch_size = 4\n    seq_length = 3\n    input_size = 10\n    hidden_size = 20\n    num_layers = 2\n    # Create input data\n    sample_input = {",
        "detail": "agent.tests.lib.test_lstm",
        "documentation": {}
    },
    {
        "label": "DummyModule",
        "kind": 6,
        "importPath": "agent.tests.lib.test_metta_module",
        "description": "agent.tests.lib.test_metta_module",
        "peekOfCode": "class DummyModule(MettaModule):\n    \"\"\"A dummy module for testing the base class.\"\"\"\n    def __init__(\n        self,\n        in_keys: list[str],\n        out_keys: list[str],\n        input_features_shape: list[int] | None = None,\n        output_features_shape: list[int] | None = None,\n    ):\n        super().__init__(in_keys, out_keys, input_features_shape, output_features_shape)",
        "detail": "agent.tests.lib.test_metta_module",
        "documentation": {}
    },
    {
        "label": "test_metta_module_initialization",
        "kind": 2,
        "importPath": "agent.tests.lib.test_metta_module",
        "description": "agent.tests.lib.test_metta_module",
        "peekOfCode": "def test_metta_module_initialization():\n    \"\"\"Test MettaModule initialization.\"\"\"\n    module = DummyModule(in_keys=[\"input\"], out_keys=[\"output\"])\n    assert module.in_keys == [\"input\"]\n    assert module.out_keys == [\"output\"]\ndef test_metta_module_forward():\n    \"\"\"Test MettaModule forward pass.\"\"\"\n    module = DummyModule(in_keys=[\"input\"], out_keys=[\"output\"])\n    td = TensorDict({\"input\": torch.tensor([1.0, 2.0])}, batch_size=[])\n    result = module(td)",
        "detail": "agent.tests.lib.test_metta_module",
        "documentation": {}
    },
    {
        "label": "test_metta_module_forward",
        "kind": 2,
        "importPath": "agent.tests.lib.test_metta_module",
        "description": "agent.tests.lib.test_metta_module",
        "peekOfCode": "def test_metta_module_forward():\n    \"\"\"Test MettaModule forward pass.\"\"\"\n    module = DummyModule(in_keys=[\"input\"], out_keys=[\"output\"])\n    td = TensorDict({\"input\": torch.tensor([1.0, 2.0])}, batch_size=[])\n    result = module(td)\n    assert \"output\" in result\n    assert torch.allclose(result[\"output\"], torch.tensor([2.0, 4.0]))\ndef test_metta_module_missing_input():\n    \"\"\"Test MettaModule with missing input key.\"\"\"\n    module = DummyModule(in_keys=[\"input\"], out_keys=[\"output\"])",
        "detail": "agent.tests.lib.test_metta_module",
        "documentation": {}
    },
    {
        "label": "test_metta_module_missing_input",
        "kind": 2,
        "importPath": "agent.tests.lib.test_metta_module",
        "description": "agent.tests.lib.test_metta_module",
        "peekOfCode": "def test_metta_module_missing_input():\n    \"\"\"Test MettaModule with missing input key.\"\"\"\n    module = DummyModule(in_keys=[\"input\"], out_keys=[\"output\"])\n    td = TensorDict({}, batch_size=[])\n    with pytest.raises(KeyError):\n        module(td)\ndef test_metta_module_shape_validation():\n    \"\"\"Test MettaModule shape validation.\"\"\"\n    module = DummyModule(\n        in_keys=[\"input\"],",
        "detail": "agent.tests.lib.test_metta_module",
        "documentation": {}
    },
    {
        "label": "test_metta_module_shape_validation",
        "kind": 2,
        "importPath": "agent.tests.lib.test_metta_module",
        "description": "agent.tests.lib.test_metta_module",
        "peekOfCode": "def test_metta_module_shape_validation():\n    \"\"\"Test MettaModule shape validation.\"\"\"\n    module = DummyModule(\n        in_keys=[\"input\"],\n        out_keys=[\"output\"],\n        input_features_shape=[2],\n        output_features_shape=[2],\n    )\n    # Valid shape\n    td = TensorDict({\"input\": torch.tensor([[1.0, 2.0]])}, batch_size=[1])",
        "detail": "agent.tests.lib.test_metta_module",
        "documentation": {}
    },
    {
        "label": "test_metta_linear_initialization",
        "kind": 2,
        "importPath": "agent.tests.lib.test_metta_modules",
        "description": "agent.tests.lib.test_metta_modules",
        "peekOfCode": "def test_metta_linear_initialization():\n    \"\"\"Test MettaLinear initialization.\"\"\"\n    module = MettaLinear(\n        in_keys=[\"input\"],\n        out_keys=[\"output\"],\n        input_features_shape=[2],\n        output_features_shape=[3],\n    )\n    assert module.in_keys == [\"input\"]\n    assert module.out_keys == [\"output\"]",
        "detail": "agent.tests.lib.test_metta_modules",
        "documentation": {}
    },
    {
        "label": "test_metta_linear_forward",
        "kind": 2,
        "importPath": "agent.tests.lib.test_metta_modules",
        "description": "agent.tests.lib.test_metta_modules",
        "peekOfCode": "def test_metta_linear_forward():\n    \"\"\"Test MettaLinear forward pass.\"\"\"\n    module = MettaLinear(\n        in_keys=[\"input\"],\n        out_keys=[\"output\"],\n        input_features_shape=[2],\n        output_features_shape=[3],\n    )\n    # Initialize weights for deterministic output\n    module.linear.weight.data = torch.ones_like(module.linear.weight)",
        "detail": "agent.tests.lib.test_metta_modules",
        "documentation": {}
    },
    {
        "label": "test_metta_relu_initialization",
        "kind": 2,
        "importPath": "agent.tests.lib.test_metta_modules",
        "description": "agent.tests.lib.test_metta_modules",
        "peekOfCode": "def test_metta_relu_initialization():\n    \"\"\"Test MettaReLU initialization.\"\"\"\n    module = MettaReLU(in_keys=[\"input\"], out_keys=[\"output\"])\n    assert module.in_keys == [\"input\"]\n    assert module.out_keys == [\"output\"]\ndef test_metta_relu_forward():\n    \"\"\"Test MettaReLU forward pass.\"\"\"\n    module = MettaReLU(in_keys=[\"input\"], out_keys=[\"output\"])\n    td = TensorDict({\"input\": torch.tensor([-1.0, 0.0, 1.0])}, batch_size=[])\n    result = module(td)",
        "detail": "agent.tests.lib.test_metta_modules",
        "documentation": {}
    },
    {
        "label": "test_metta_relu_forward",
        "kind": 2,
        "importPath": "agent.tests.lib.test_metta_modules",
        "description": "agent.tests.lib.test_metta_modules",
        "peekOfCode": "def test_metta_relu_forward():\n    \"\"\"Test MettaReLU forward pass.\"\"\"\n    module = MettaReLU(in_keys=[\"input\"], out_keys=[\"output\"])\n    td = TensorDict({\"input\": torch.tensor([-1.0, 0.0, 1.0])}, batch_size=[])\n    result = module(td)\n    assert \"output\" in result\n    assert torch.allclose(result[\"output\"], torch.tensor([0.0, 0.0, 1.0]))",
        "detail": "agent.tests.lib.test_metta_modules",
        "documentation": {}
    },
    {
        "label": "test_modular_network_initialization",
        "kind": 2,
        "importPath": "agent.tests.lib.test_modular_network",
        "description": "agent.tests.lib.test_modular_network",
        "peekOfCode": "def test_modular_network_initialization():\n    \"\"\"Test ModularNetwork initialization.\"\"\"\n    network = ModularNetwork()\n    assert len(network.nodes) == 0\n    assert len(network.out_key_to_node) == 0\ndef test_modular_network_add_component():\n    \"\"\"Test adding components to the network.\"\"\"\n    network = ModularNetwork()\n    linear = MettaLinear(\n        in_keys=[\"input\"],",
        "detail": "agent.tests.lib.test_modular_network",
        "documentation": {}
    },
    {
        "label": "test_modular_network_add_component",
        "kind": 2,
        "importPath": "agent.tests.lib.test_modular_network",
        "description": "agent.tests.lib.test_modular_network",
        "peekOfCode": "def test_modular_network_add_component():\n    \"\"\"Test adding components to the network.\"\"\"\n    network = ModularNetwork()\n    linear = MettaLinear(\n        in_keys=[\"input\"],\n        out_keys=[\"hidden\"],\n        input_features_shape=[2],\n        output_features_shape=[3],\n    )\n    relu = MettaReLU(in_keys=[\"hidden\"], out_keys=[\"output\"])",
        "detail": "agent.tests.lib.test_modular_network",
        "documentation": {}
    },
    {
        "label": "test_modular_network_duplicate_component",
        "kind": 2,
        "importPath": "agent.tests.lib.test_modular_network",
        "description": "agent.tests.lib.test_modular_network",
        "peekOfCode": "def test_modular_network_duplicate_component():\n    \"\"\"Test adding duplicate component names.\"\"\"\n    network = ModularNetwork()\n    linear1 = MettaLinear(\n        in_keys=[\"input\"],\n        out_keys=[\"hidden\"],\n        input_features_shape=[2],\n        output_features_shape=[3],\n    )\n    linear2 = MettaLinear(",
        "detail": "agent.tests.lib.test_modular_network",
        "documentation": {}
    },
    {
        "label": "test_modular_network_forward",
        "kind": 2,
        "importPath": "agent.tests.lib.test_modular_network",
        "description": "agent.tests.lib.test_modular_network",
        "peekOfCode": "def test_modular_network_forward():\n    \"\"\"Test network forward pass.\"\"\"\n    network = ModularNetwork()\n    linear = MettaLinear(\n        in_keys=[\"input\"],\n        out_keys=[\"hidden\"],\n        input_features_shape=[2],\n        output_features_shape=[3],\n    )\n    relu = MettaReLU(in_keys=[\"hidden\"], out_keys=[\"output\"])",
        "detail": "agent.tests.lib.test_modular_network",
        "documentation": {}
    },
    {
        "label": "test_modular_network_missing_input",
        "kind": 2,
        "importPath": "agent.tests.lib.test_modular_network",
        "description": "agent.tests.lib.test_modular_network",
        "peekOfCode": "def test_modular_network_missing_input():\n    \"\"\"Test network with missing input.\"\"\"\n    network = ModularNetwork()\n    linear = MettaLinear(\n        in_keys=[\"input\"],\n        out_keys=[\"hidden\"],\n        input_features_shape=[2],\n        output_features_shape=[3],\n    )\n    network.add_component(\"linear\", linear)",
        "detail": "agent.tests.lib.test_modular_network",
        "documentation": {}
    },
    {
        "label": "test_obs_token_to_box_shaper_forward",
        "kind": 2,
        "importPath": "agent.tests.lib.test_obs_token_to_box_shaper",
        "description": "agent.tests.lib.test_obs_token_to_box_shaper",
        "peekOfCode": "def test_obs_token_to_box_shaper_forward():\n    # Test parameters\n    obs_shape = (128, 3)  # 128 tokens, 3 bytes each\n    obs_width = 11\n    obs_height = 11\n    feature_normalizations = {0: 1, 1: 2, 2: 3}  # 3 layers\n    batch_size = 2\n    # Create the shaper\n    shaper = ObsTokenToBoxShaper(\n        obs_shape=obs_shape,",
        "detail": "agent.tests.lib.test_obs_token_to_box_shaper",
        "documentation": {}
    },
    {
        "label": "TestSampleActions",
        "kind": 6,
        "importPath": "agent.tests.util.test_distribution_utils",
        "description": "agent.tests.util.test_distribution_utils",
        "peekOfCode": "class TestSampleActions:\n    def setup_method(self):\n        torch.manual_seed(SEED)\n    def test_sampling_shape(self, sample_logits_data):\n        single = sample_logits_data[\"single\"]\n        batch = sample_logits_data[\"batch\"]\n        batch_size = batch.shape[0]\n        action, logprob, ent, norm = sample_actions(single)\n        assert action.shape == (1,)\n        assert logprob.shape == (1,)",
        "detail": "agent.tests.util.test_distribution_utils",
        "documentation": {}
    },
    {
        "label": "TestEvaluateActions",
        "kind": 6,
        "importPath": "agent.tests.util.test_distribution_utils",
        "description": "agent.tests.util.test_distribution_utils",
        "peekOfCode": "class TestEvaluateActions:\n    def setup_method(self):\n        torch.manual_seed(SEED)\n    def test_provided_actions(self, sample_logits_data):\n        logits = sample_logits_data[\"batch\"]\n        actions = torch.tensor([0, 1, 2][: logits.shape[0]], dtype=torch.long)\n        logprob, _, norm = evaluate_actions(logits, actions)\n        expected = norm.gather(-1, actions.unsqueeze(-1)).squeeze(-1)\n        assert torch.allclose(logprob, expected)\n    def test_evaluate_shape(self, sample_logits_data):",
        "detail": "agent.tests.util.test_distribution_utils",
        "documentation": {}
    },
    {
        "label": "TestCompatibility",
        "kind": 6,
        "importPath": "agent.tests.util.test_distribution_utils",
        "description": "agent.tests.util.test_distribution_utils",
        "peekOfCode": "class TestCompatibility:\n    def test_sample_then_evaluate_consistency(self, sample_logits_data):\n        logits = sample_logits_data[\"batch\"]\n        act, lp, ent, norm = sample_actions(logits)\n        eval_lp, eval_ent, eval_norm = evaluate_actions(logits, act)\n        assert torch.allclose(lp, eval_lp), \"Logprobs mismatch\"\n        assert torch.allclose(ent, eval_ent), \"Entropy mismatch\"\n        assert torch.allclose(norm, eval_norm), \"Normalized logits mismatch\"",
        "detail": "agent.tests.util.test_distribution_utils",
        "documentation": {}
    },
    {
        "label": "sample_logits_data",
        "kind": 2,
        "importPath": "agent.tests.util.test_distribution_utils",
        "description": "agent.tests.util.test_distribution_utils",
        "peekOfCode": "def sample_logits_data():\n    \"\"\"Create sample logits of various shapes for testing.\"\"\"\n    torch.manual_seed(SEED)\n    batch_size = 3\n    vocab_size = 5\n    single_logits = torch.tensor([[1.0, 2.0, 0.5, -1.0, 0.0]], dtype=torch.float32)\n    batch_logits = torch.randn(batch_size, vocab_size)\n    deterministic_logits = torch.tensor([[-1000.0, 1000.0, -1000.0, -1000.0, -1000.0]], dtype=torch.float32)\n    return {\n        \"single\": single_logits,",
        "detail": "agent.tests.util.test_distribution_utils",
        "documentation": {}
    },
    {
        "label": "benchmark_data",
        "kind": 2,
        "importPath": "agent.tests.util.test_distribution_utils",
        "description": "agent.tests.util.test_distribution_utils",
        "peekOfCode": "def benchmark_data():\n    \"\"\"Create large-scale test data for evaluating scalability and shape handling.\"\"\"\n    torch.manual_seed(SEED)\n    small_batch = torch.randn(36, 10)\n    medium_batch = torch.randn(360, 50)\n    large_batch = torch.randn(3600, 1000)\n    torch.manual_seed(SEED)\n    small_actions = torch.randint(0, 10, (36,))\n    medium_actions = torch.randint(0, 50, (360,))\n    large_actions = torch.randint(0, 1000, (3600,))",
        "detail": "agent.tests.util.test_distribution_utils",
        "documentation": {}
    },
    {
        "label": "run_multiple_sampling_iterations",
        "kind": 2,
        "importPath": "agent.tests.util.test_distribution_utils",
        "description": "agent.tests.util.test_distribution_utils",
        "peekOfCode": "def run_multiple_sampling_iterations(func, data, iterations=10):\n    torch.manual_seed(SEED)\n    for _ in range(iterations - 1):\n        func(data)\n    return func(data)\ndef run_multiple_evaluation_iterations(func, data, actions, iterations=10):\n    torch.manual_seed(SEED)\n    for _ in range(iterations - 1):\n        func(data, actions)\n    return func(data, actions)",
        "detail": "agent.tests.util.test_distribution_utils",
        "documentation": {}
    },
    {
        "label": "run_multiple_evaluation_iterations",
        "kind": 2,
        "importPath": "agent.tests.util.test_distribution_utils",
        "description": "agent.tests.util.test_distribution_utils",
        "peekOfCode": "def run_multiple_evaluation_iterations(func, data, actions, iterations=10):\n    torch.manual_seed(SEED)\n    for _ in range(iterations - 1):\n        func(data, actions)\n    return func(data, actions)\n@pytest.mark.parametrize(\n    \"data_key\",\n    [\"small_batch\", \"medium_batch\", \"large_batch\"],\n)\ndef test_sampling_output_shapes(benchmark_data, data_key):",
        "detail": "agent.tests.util.test_distribution_utils",
        "documentation": {}
    },
    {
        "label": "test_sampling_output_shapes",
        "kind": 2,
        "importPath": "agent.tests.util.test_distribution_utils",
        "description": "agent.tests.util.test_distribution_utils",
        "peekOfCode": "def test_sampling_output_shapes(benchmark_data, data_key):\n    data = benchmark_data[data_key]\n    actions, logprob, entropy, norm = run_multiple_sampling_iterations(sample_actions, data)\n    assert actions.shape[0] == data.shape[0]\n    assert logprob.shape[0] == data.shape[0]\n    assert entropy.shape[0] == data.shape[0]\n    assert norm.shape == data.shape\n@pytest.mark.parametrize(\n    \"data_key,action_key\",\n    [",
        "detail": "agent.tests.util.test_distribution_utils",
        "documentation": {}
    },
    {
        "label": "test_evaluation_output_shapes",
        "kind": 2,
        "importPath": "agent.tests.util.test_distribution_utils",
        "description": "agent.tests.util.test_distribution_utils",
        "peekOfCode": "def test_evaluation_output_shapes(benchmark_data, data_key, action_key):\n    data = benchmark_data[data_key]\n    actions = benchmark_data[action_key]\n    logprob, entropy, norm = run_multiple_evaluation_iterations(evaluate_actions, data, actions)\n    assert logprob.shape[0] == data.shape[0]\n    assert entropy.shape[0] == data.shape[0]\n    assert norm.shape == data.shape\nclass TestCompatibility:\n    def test_sample_then_evaluate_consistency(self, sample_logits_data):\n        logits = sample_logits_data[\"batch\"]",
        "detail": "agent.tests.util.test_distribution_utils",
        "documentation": {}
    },
    {
        "label": "SEED",
        "kind": 5,
        "importPath": "agent.tests.util.test_distribution_utils",
        "description": "agent.tests.util.test_distribution_utils",
        "peekOfCode": "SEED = 42\n@pytest.fixture\ndef sample_logits_data():\n    \"\"\"Create sample logits of various shapes for testing.\"\"\"\n    torch.manual_seed(SEED)\n    batch_size = 3\n    vocab_size = 5\n    single_logits = torch.tensor([[1.0, 2.0, 0.5, -1.0, 0.0]], dtype=torch.float32)\n    batch_logits = torch.randn(batch_size, vocab_size)\n    deterministic_logits = torch.tensor([[-1000.0, 1000.0, -1000.0, -1000.0, -1000.0]], dtype=torch.float32)",
        "detail": "agent.tests.util.test_distribution_utils",
        "documentation": {}
    },
    {
        "label": "MockAgent",
        "kind": 6,
        "importPath": "agent.tests.test_feature_remapping",
        "description": "agent.tests.test_feature_remapping",
        "peekOfCode": "class MockAgent(MettaAgent):\n    \"\"\"Mock agent for testing feature remapping without full setup.\"\"\"\n    def __init__(self):\n        # Initialize nn.Module to get the training attribute\n        import torch.nn as nn\n        nn.Module.__init__(self)\n        # Set up necessary attributes without full MettaAgent.__init__\n        self.device = \"cpu\"\n        self.components = nn.ModuleDict()\n        self._mock_is_training = True",
        "detail": "agent.tests.test_feature_remapping",
        "documentation": {}
    },
    {
        "label": "MockObsComponent",
        "kind": 6,
        "importPath": "agent.tests.test_feature_remapping",
        "description": "agent.tests.test_feature_remapping",
        "peekOfCode": "class MockObsComponent(torch.nn.Module):\n    \"\"\"Mock observation component for testing remapping updates.\"\"\"\n    def __init__(self):\n        super().__init__()\n        self.remap_table = None\n    def update_feature_remapping(self, remap_table):\n        self.remap_table = remap_table\ndef test_obs_token_pad_strip_remapping():\n    \"\"\"Test that ObsTokenPadStrip correctly remaps feature IDs.\"\"\"\n    # Create ObsTokenPadStrip with test shape",
        "detail": "agent.tests.test_feature_remapping",
        "documentation": {}
    },
    {
        "label": "test_obs_token_pad_strip_remapping",
        "kind": 2,
        "importPath": "agent.tests.test_feature_remapping",
        "description": "agent.tests.test_feature_remapping",
        "peekOfCode": "def test_obs_token_pad_strip_remapping():\n    \"\"\"Test that ObsTokenPadStrip correctly remaps feature IDs.\"\"\"\n    # Create ObsTokenPadStrip with test shape\n    obs_shape = (4, 3)  # 4 tokens, 3 channels\n    pad_strip = ObsTokenPadStrip(obs_shape=obs_shape, name=\"test_pad_strip\")\n    pad_strip._out_tensor_shape = [0, 3]  # Set output shape\n    # Create test observations [batch, tokens, 3] where 3 is [coord, feature_id, value]\n    observations = torch.tensor(\n        [\n            # Batch 0",
        "detail": "agent.tests.test_feature_remapping",
        "documentation": {}
    },
    {
        "label": "test_feature_remapping_in_agent",
        "kind": 2,
        "importPath": "agent.tests.test_feature_remapping",
        "description": "agent.tests.test_feature_remapping",
        "peekOfCode": "def test_feature_remapping_in_agent():\n    \"\"\"Test that feature remapping is correctly set up in MettaAgent.\"\"\"\n    agent = MockAgent()\n    # Test _initialize_observations with original features\n    original_features = {\n        \"type_id\": {\"id\": 0, \"type\": \"categorical\"},\n        \"hp\": {\"id\": 2, \"type\": \"scalar\", \"normalization\": 30.0},\n        \"mineral\": {\"id\": 3, \"type\": \"scalar\", \"normalization\": 100.0},\n    }\n    # Set training mode for first initialization",
        "detail": "agent.tests.test_feature_remapping",
        "documentation": {}
    },
    {
        "label": "test_unknown_feature_handling",
        "kind": 2,
        "importPath": "agent.tests.test_feature_remapping",
        "description": "agent.tests.test_feature_remapping",
        "peekOfCode": "def test_unknown_feature_handling():\n    \"\"\"Test that unknown features are mapped to index 255.\"\"\"\n    agent = MockAgent()\n    # First initialization with training features\n    original_features = {\n        \"type_id\": {\"id\": 0, \"type\": \"categorical\"},\n        \"hp\": {\"id\": 2, \"type\": \"scalar\", \"normalization\": 30.0},\n    }\n    # Set training mode for first initialization\n    agent._mock_is_training = True",
        "detail": "agent.tests.test_feature_remapping",
        "documentation": {}
    },
    {
        "label": "test_feature_mapping_persistence_via_metadata",
        "kind": 2,
        "importPath": "agent.tests.test_feature_remapping",
        "description": "agent.tests.test_feature_remapping",
        "peekOfCode": "def test_feature_mapping_persistence_via_metadata():\n    \"\"\"Test that original_feature_mapping can be persisted through metadata.\"\"\"\n    agent = MockAgent()\n    # Test initial feature setup\n    original_features = {\n        \"type_id\": {\"id\": 0, \"type\": \"categorical\"},\n        \"hp\": {\"id\": 2, \"type\": \"scalar\", \"normalization\": 30.0},\n        \"mineral\": {\"id\": 3, \"type\": \"scalar\", \"normalization\": 100.0},\n    }\n    # Initialize the agent",
        "detail": "agent.tests.test_feature_remapping",
        "documentation": {}
    },
    {
        "label": "test_end_to_end_initialize_to_environment_workflow",
        "kind": 2,
        "importPath": "agent.tests.test_feature_remapping",
        "description": "agent.tests.test_feature_remapping",
        "peekOfCode": "def test_end_to_end_initialize_to_environment_workflow():\n    \"\"\"Test the full end-to-end workflow of initialize_to_environment.\"\"\"\n    import tempfile\n    from pathlib import Path\n    import torch\n    from metta.agent.policy_metadata import PolicyMetadata\n    from metta.agent.policy_record import PolicyRecord\n    # Create a temporary directory for saving policies\n    with tempfile.TemporaryDirectory() as tmpdir:\n        # Mock environment class that provides features",
        "detail": "agent.tests.test_feature_remapping",
        "documentation": {}
    },
    {
        "label": "create_metta_agent",
        "kind": 2,
        "importPath": "agent.tests.test_metta_agent",
        "description": "agent.tests.test_metta_agent",
        "peekOfCode": "def create_metta_agent():\n    # Create minimal observation and action spaces for testing\n    obs_space = gym.spaces.Dict(\n        {\n            \"grid_obs\": gym.spaces.Box(\n                low=0,\n                high=1,\n                shape=(3, 5, 5, 3),  # (batch, width, height, features)\n                dtype=np.float32,\n            ),",
        "detail": "agent.tests.test_metta_agent",
        "documentation": {}
    },
    {
        "label": "metta_agent_with_actions",
        "kind": 2,
        "importPath": "agent.tests.test_metta_agent",
        "description": "agent.tests.test_metta_agent",
        "peekOfCode": "def metta_agent_with_actions(create_metta_agent):\n    agent, _, _ = create_metta_agent\n    action_names = [\"action0\", \"action1\", \"action2\"]\n    action_max_params = [1, 2, 0]\n    # Create simple test features\n    features = {\n        \"type_id\": {\"id\": 0, \"type\": \"categorical\"},\n        \"hp\": {\"id\": 1, \"type\": \"scalar\", \"normalization\": 30.0},\n        \"agent:group\": {\"id\": 2, \"type\": \"categorical\"},\n    }",
        "detail": "agent.tests.test_metta_agent",
        "documentation": {}
    },
    {
        "label": "test_initialize_to_environment",
        "kind": 2,
        "importPath": "agent.tests.test_metta_agent",
        "description": "agent.tests.test_metta_agent",
        "peekOfCode": "def test_initialize_to_environment(create_metta_agent):\n    \"\"\"Test the new initialize_to_environment interface.\"\"\"\n    agent, _, _ = create_metta_agent\n    # Create test features dictionary\n    features = {\n        \"type_id\": {\"id\": 0, \"type\": \"categorical\"},\n        \"hp\": {\"id\": 1, \"type\": \"scalar\", \"normalization\": 30.0},\n        \"agent:group\": {\"id\": 2, \"type\": \"categorical\"},\n        \"inv:ore_red\": {\"id\": 12, \"type\": \"scalar\", \"normalization\": 100.0},\n    }",
        "detail": "agent.tests.test_metta_agent",
        "documentation": {}
    },
    {
        "label": "test_activate_actions_backward_compatibility",
        "kind": 2,
        "importPath": "agent.tests.test_metta_agent",
        "description": "agent.tests.test_metta_agent",
        "peekOfCode": "def test_activate_actions_backward_compatibility(create_metta_agent):\n    \"\"\"Test that the old activate_actions method still works for backward compatibility.\"\"\"\n    agent, _, _ = create_metta_agent\n    action_names = [\"move\", \"attack\", \"interact\"]\n    action_max_params = [3, 1, 2]\n    # Call the old activate_actions directly\n    agent.activate_actions(action_names, action_max_params, \"cpu\")\n    # Check that actions were initialized\n    assert agent.action_names == action_names\n    assert agent.action_max_params == action_max_params",
        "detail": "agent.tests.test_metta_agent",
        "documentation": {}
    },
    {
        "label": "test_clip_weights_calls_components",
        "kind": 2,
        "importPath": "agent.tests.test_metta_agent",
        "description": "agent.tests.test_metta_agent",
        "peekOfCode": "def test_clip_weights_calls_components(create_metta_agent):\n    agent, comp1, comp2 = create_metta_agent\n    # Ensure clip_range is positive to enable clipping\n    agent.clip_range = 0.1\n    # Call the method being tested\n    agent.clip_weights()\n    # Verify each component's clip_weights was called\n    assert comp1.clipped\n    assert comp2.clipped\ndef test_clip_weights_disabled(create_metta_agent):",
        "detail": "agent.tests.test_metta_agent",
        "documentation": {}
    },
    {
        "label": "test_clip_weights_disabled",
        "kind": 2,
        "importPath": "agent.tests.test_metta_agent",
        "description": "agent.tests.test_metta_agent",
        "peekOfCode": "def test_clip_weights_disabled(create_metta_agent):\n    agent, comp1, comp2 = create_metta_agent\n    # Disable clipping by setting clip_range to 0\n    agent.clip_range = 0\n    # Call the method being tested\n    agent.clip_weights()\n    # Verify no component's clip_weights was called\n    assert not comp1.clipped\n    assert not comp2.clipped\ndef test_clip_weights_raises_attribute_error(create_metta_agent):",
        "detail": "agent.tests.test_metta_agent",
        "documentation": {}
    },
    {
        "label": "test_clip_weights_raises_attribute_error",
        "kind": 2,
        "importPath": "agent.tests.test_metta_agent",
        "description": "agent.tests.test_metta_agent",
        "peekOfCode": "def test_clip_weights_raises_attribute_error(create_metta_agent):\n    agent, comp1, comp2 = create_metta_agent\n    # Add a component without the clip_weights method\n    class IncompleteComponent(torch.nn.Module):\n        def __init__(self):\n            super().__init__()\n            self.ready = True\n            self._sources = None\n        def setup(self, source_components):\n            pass",
        "detail": "agent.tests.test_metta_agent",
        "documentation": {}
    },
    {
        "label": "test_clip_weights_with_non_callable",
        "kind": 2,
        "importPath": "agent.tests.test_metta_agent",
        "description": "agent.tests.test_metta_agent",
        "peekOfCode": "def test_clip_weights_with_non_callable(create_metta_agent):\n    agent, comp1, comp2 = create_metta_agent\n    # Make clip_weights non-callable on one component\n    comp1.clip_weights = \"Not a function\"\n    # Verify a TypeError is raised\n    with pytest.raises(TypeError) as excinfo:\n        agent.clip_weights()\n    # Check the error message\n    assert \"not callable\" in str(excinfo.value)\ndef test_l2_init_loss_raises_error_for_different_shapes(create_metta_agent):",
        "detail": "agent.tests.test_metta_agent",
        "documentation": {}
    },
    {
        "label": "test_l2_init_loss_raises_error_for_different_shapes",
        "kind": 2,
        "importPath": "agent.tests.test_metta_agent",
        "description": "agent.tests.test_metta_agent",
        "peekOfCode": "def test_l2_init_loss_raises_error_for_different_shapes(create_metta_agent):\n    agent, comp1, comp2 = create_metta_agent\n    # Set up components to return tensors with different shapes\n    comp1.l2_init_loss = lambda: torch.tensor([0.3, 0.2], dtype=torch.float32)  # tensor with shape [2]\n    comp2.l2_init_loss = lambda: torch.tensor(0.5, dtype=torch.float32)  # scalar tensor\n    # Verify that a RuntimeError is raised due to different tensor shapes\n    with pytest.raises(RuntimeError) as excinfo:\n        agent.l2_init_loss()\n    # Check that the error message mentions the tensor shape mismatch\n    assert \"expects each tensor to be equal size\" in str(excinfo.value)",
        "detail": "agent.tests.test_metta_agent",
        "documentation": {}
    },
    {
        "label": "test_convert_action_to_logit_index",
        "kind": 2,
        "importPath": "agent.tests.test_metta_agent",
        "description": "agent.tests.test_metta_agent",
        "peekOfCode": "def test_convert_action_to_logit_index(create_metta_agent):\n    agent, _, _ = create_metta_agent\n    # Setup testing environment with controlled action space\n    action_names = [\"action0\", \"action1\", \"action2\"]\n    action_max_params = [1, 2, 0]  # action0: [0,1], action1: [0,1,2], action2: [0]\n    # Create simple test features\n    features = {\n        \"type_id\": {\"id\": 0, \"type\": \"categorical\"},\n        \"hp\": {\"id\": 1, \"type\": \"scalar\", \"normalization\": 30.0},\n    }",
        "detail": "agent.tests.test_metta_agent",
        "documentation": {}
    },
    {
        "label": "test_convert_logit_index_to_action",
        "kind": 2,
        "importPath": "agent.tests.test_metta_agent",
        "description": "agent.tests.test_metta_agent",
        "peekOfCode": "def test_convert_logit_index_to_action(create_metta_agent):\n    agent, _, _ = create_metta_agent\n    # Setup testing environment\n    action_names = [\"action0\", \"action1\", \"action2\"]\n    action_max_params = [1, 2, 0]  # action0: [0,1], action1: [0,1,2], action2: [0]\n    # Create simple test features\n    features = {\n        \"type_id\": {\"id\": 0, \"type\": \"categorical\"},\n        \"hp\": {\"id\": 1, \"type\": \"scalar\", \"normalization\": 30.0},\n    }",
        "detail": "agent.tests.test_metta_agent",
        "documentation": {}
    },
    {
        "label": "test_bidirectional_action_conversion",
        "kind": 2,
        "importPath": "agent.tests.test_metta_agent",
        "description": "agent.tests.test_metta_agent",
        "peekOfCode": "def test_bidirectional_action_conversion(create_metta_agent):\n    agent, _, _ = create_metta_agent\n    # Setup testing environment\n    action_names = [\"action0\", \"action1\", \"action2\"]\n    action_max_params = [1, 2, 0]  # action0: [0,1], action1: [0,1,2], action2: [0]\n    # Create simple test features\n    features = {\n        \"type_id\": {\"id\": 0, \"type\": \"categorical\"},\n        \"hp\": {\"id\": 1, \"type\": \"scalar\", \"normalization\": 30.0},\n    }",
        "detail": "agent.tests.test_metta_agent",
        "documentation": {}
    },
    {
        "label": "test_action_conversion_edge_cases",
        "kind": 2,
        "importPath": "agent.tests.test_metta_agent",
        "description": "agent.tests.test_metta_agent",
        "peekOfCode": "def test_action_conversion_edge_cases(create_metta_agent):\n    agent, _, _ = create_metta_agent\n    # Setup with empty action space\n    action_names = []\n    action_max_params = []\n    # Create simple test features\n    features = {\n        \"type_id\": {\"id\": 0, \"type\": \"categorical\"},\n    }\n    agent.initialize_to_environment(features, action_names, action_max_params, \"cpu\")",
        "detail": "agent.tests.test_metta_agent",
        "documentation": {}
    },
    {
        "label": "test_convert_logit_index_to_action_invalid",
        "kind": 2,
        "importPath": "agent.tests.test_metta_agent",
        "description": "agent.tests.test_metta_agent",
        "peekOfCode": "def test_convert_logit_index_to_action_invalid(metta_agent_with_actions):\n    agent = metta_agent_with_actions\n    invalid_index = agent.action_index_tensor.shape[0]\n    with pytest.raises((IndexError, RuntimeError)):\n        agent._convert_logit_index_to_action(torch.tensor([invalid_index], dtype=torch.long, device=\"cpu\"))\ndef test_action_use(create_metta_agent):\n    agent, _, _ = create_metta_agent\n    # Set up action space\n    action_names = [\"action0\", \"action1\", \"action2\"]\n    action_max_params = [1, 2, 0]",
        "detail": "agent.tests.test_metta_agent",
        "documentation": {}
    },
    {
        "label": "test_action_use",
        "kind": 2,
        "importPath": "agent.tests.test_metta_agent",
        "description": "agent.tests.test_metta_agent",
        "peekOfCode": "def test_action_use(create_metta_agent):\n    agent, _, _ = create_metta_agent\n    # Set up action space\n    action_names = [\"action0\", \"action1\", \"action2\"]\n    action_max_params = [1, 2, 0]\n    # Create simple test features\n    features = {\n        \"type_id\": {\"id\": 0, \"type\": \"categorical\"},\n        \"hp\": {\"id\": 1, \"type\": \"scalar\", \"normalization\": 30.0},\n    }",
        "detail": "agent.tests.test_metta_agent",
        "documentation": {}
    },
    {
        "label": "test_distribution_utils_compatibility",
        "kind": 2,
        "importPath": "agent.tests.test_metta_agent",
        "description": "agent.tests.test_metta_agent",
        "peekOfCode": "def test_distribution_utils_compatibility(create_metta_agent):\n    \"\"\"Test that sample_actions and evaluate_actions are compatible with each other.\"\"\"\n    agent, _, _ = create_metta_agent\n    # Set up action space\n    action_names = [\"action0\", \"action1\"]\n    action_max_params = [2, 1]  # action0: [0,1,2], action1: [0,1]\n    # Create simple test features\n    features = {\n        \"type_id\": {\"id\": 0, \"type\": \"categorical\"},\n        \"hp\": {\"id\": 1, \"type\": \"scalar\", \"normalization\": 30.0},",
        "detail": "agent.tests.test_metta_agent",
        "documentation": {}
    },
    {
        "label": "test_forward_training_integration",
        "kind": 2,
        "importPath": "agent.tests.test_metta_agent",
        "description": "agent.tests.test_metta_agent",
        "peekOfCode": "def test_forward_training_integration(create_metta_agent):\n    \"\"\"Test that the forward_training method works with the new distribution utils.\"\"\"\n    agent, _, _ = create_metta_agent\n    # Set up action space\n    action_names = [\"move\", \"use_item\"]\n    action_max_params = [2, 3]  # move: [0,1,2], use_item: [0,1,2,3]\n    # Create simple test features\n    features = {\n        \"type_id\": {\"id\": 0, \"type\": \"categorical\"},\n        \"hp\": {\"id\": 1, \"type\": \"scalar\", \"normalization\": 30.0},",
        "detail": "agent.tests.test_metta_agent",
        "documentation": {}
    },
    {
        "label": "TestPolicyCacheBasics",
        "kind": 6,
        "importPath": "agent.tests.test_policy_cache",
        "description": "agent.tests.test_policy_cache",
        "peekOfCode": "class TestPolicyCacheBasics:\n    \"\"\"Test basic cache operations.\"\"\"\n    def test_init_with_invalid_size(self):\n        \"\"\"Test that cache initialization fails with invalid size.\"\"\"\n        with pytest.raises(ValueError, match=\"Cache size must be positive\"):\n            PolicyCache(max_size=0)\n        with pytest.raises(ValueError, match=\"Cache size must be positive\"):\n            PolicyCache(max_size=-1)\n    def test_put_and_get(self, cache, policy_record_with_model):\n        \"\"\"Test basic put and get operations.\"\"\"",
        "detail": "agent.tests.test_policy_cache",
        "documentation": {}
    },
    {
        "label": "TestPolicyCacheLRU",
        "kind": 6,
        "importPath": "agent.tests.test_policy_cache",
        "description": "agent.tests.test_policy_cache",
        "peekOfCode": "class TestPolicyCacheLRU:\n    \"\"\"Test LRU eviction behavior.\"\"\"\n    def test_lru_eviction(self, cache):\n        \"\"\"Test that least recently used items are evicted.\"\"\"\n        # Fill cache to capacity\n        pr1 = create_policy_record(\"model1\", \"file://model1.pt\")\n        pr2 = create_policy_record(\"model2\", \"file://model2.pt\")\n        pr3 = create_policy_record(\"model3\", \"file://model3.pt\")\n        cache.put(\"model1\", pr1)\n        cache.put(\"model2\", pr2)",
        "detail": "agent.tests.test_policy_cache",
        "documentation": {}
    },
    {
        "label": "TestPolicyCacheConcurrency",
        "kind": 6,
        "importPath": "agent.tests.test_policy_cache",
        "description": "agent.tests.test_policy_cache",
        "peekOfCode": "class TestPolicyCacheConcurrency:\n    \"\"\"Test thread safety.\"\"\"\n    def test_concurrent_puts(self):\n        \"\"\"Test concurrent put operations.\"\"\"\n        cache = PolicyCache(max_size=50)\n        errors = []\n        def worker(worker_id):\n            try:\n                for i in range(10):\n                    pr = create_policy_record(f\"w{worker_id}_m{i}\", f\"file://w{worker_id}_m{i}.pt\")",
        "detail": "agent.tests.test_policy_cache",
        "documentation": {}
    },
    {
        "label": "cache",
        "kind": 2,
        "importPath": "agent.tests.test_policy_cache",
        "description": "agent.tests.test_policy_cache",
        "peekOfCode": "def cache():\n    \"\"\"Create a cache instance for testing.\"\"\"\n    return PolicyCache(max_size=3)\n@pytest.fixture\ndef policy_record_with_model():\n    \"\"\"Create a PolicyRecord with a loaded model.\"\"\"\n    metadata = PolicyMetadata(epoch=1, agent_step=100, generation=0, train_time=0.5)\n    pr = PolicyRecord(None, \"test_run\", \"file://test.pt\", metadata)\n    pr._cached_policy = MockPolicy()\n    return pr",
        "detail": "agent.tests.test_policy_cache",
        "documentation": {}
    },
    {
        "label": "policy_record_with_model",
        "kind": 2,
        "importPath": "agent.tests.test_policy_cache",
        "description": "agent.tests.test_policy_cache",
        "peekOfCode": "def policy_record_with_model():\n    \"\"\"Create a PolicyRecord with a loaded model.\"\"\"\n    metadata = PolicyMetadata(epoch=1, agent_step=100, generation=0, train_time=0.5)\n    pr = PolicyRecord(None, \"test_run\", \"file://test.pt\", metadata)\n    pr._cached_policy = MockPolicy()\n    return pr\n@pytest.fixture\ndef policy_record_metadata_only():\n    \"\"\"Create a PolicyRecord without a loaded model (metadata only).\"\"\"\n    metadata = PolicyMetadata(epoch=2, agent_step=200, generation=1, train_time=1.0)",
        "detail": "agent.tests.test_policy_cache",
        "documentation": {}
    },
    {
        "label": "policy_record_metadata_only",
        "kind": 2,
        "importPath": "agent.tests.test_policy_cache",
        "description": "agent.tests.test_policy_cache",
        "peekOfCode": "def policy_record_metadata_only():\n    \"\"\"Create a PolicyRecord without a loaded model (metadata only).\"\"\"\n    metadata = PolicyMetadata(epoch=2, agent_step=200, generation=1, train_time=1.0)\n    pr = PolicyRecord(None, \"metadata_only\", \"file://metadata.pt\", metadata)\n    # No _cached_policy set\n    return pr\ndef create_policy_record(name: str, uri: str, with_model: bool = True) -> PolicyRecord:\n    \"\"\"Helper to create policy records for tests.\"\"\"\n    metadata = PolicyMetadata(\n        epoch=int(name[-1]) if name[-1].isdigit() else 0, agent_step=100, generation=0, train_time=0.5",
        "detail": "agent.tests.test_policy_cache",
        "documentation": {}
    },
    {
        "label": "create_policy_record",
        "kind": 2,
        "importPath": "agent.tests.test_policy_cache",
        "description": "agent.tests.test_policy_cache",
        "peekOfCode": "def create_policy_record(name: str, uri: str, with_model: bool = True) -> PolicyRecord:\n    \"\"\"Helper to create policy records for tests.\"\"\"\n    metadata = PolicyMetadata(\n        epoch=int(name[-1]) if name[-1].isdigit() else 0, agent_step=100, generation=0, train_time=0.5\n    )\n    pr = PolicyRecord(None, name, uri, metadata)\n    if with_model:\n        pr._cached_policy = MockPolicy()\n    return pr\nclass TestPolicyCacheBasics:",
        "detail": "agent.tests.test_policy_cache",
        "documentation": {}
    },
    {
        "label": "test_policy_save_load_without_pydantic",
        "kind": 2,
        "importPath": "agent.tests.test_policy_store",
        "description": "agent.tests.test_policy_store",
        "peekOfCode": "def test_policy_save_load_without_pydantic():\n    \"\"\"Test that we can save and load a policy without pydantic errors\"\"\"\n    # Import PolicyStore and PolicyRecord from their respective modules\n    from metta.agent.policy_metadata import PolicyMetadata\n    from metta.agent.policy_record import PolicyRecord\n    from metta.agent.policy_store import PolicyStore\n    # Create minimal config\n    cfg = OmegaConf.create(\n        {\n            \"device\": \"cpu\",",
        "detail": "agent.tests.test_policy_store",
        "documentation": {}
    },
    {
        "label": "test_policy_save_load_with_dict_metadata",
        "kind": 2,
        "importPath": "agent.tests.test_policy_store",
        "description": "agent.tests.test_policy_store",
        "peekOfCode": "def test_policy_save_load_with_dict_metadata():\n    \"\"\"Test that we can save and load a policy with plain dict metadata\"\"\"\n    from metta.agent.policy_store import PolicyStore\n    # Create minimal config\n    cfg = OmegaConf.create(\n        {\n            \"device\": \"cpu\",\n            \"run\": \"test_run\",\n            \"run_dir\": tempfile.mkdtemp(),\n            \"trainer\": {",
        "detail": "agent.tests.test_policy_store",
        "documentation": {}
    },
    {
        "label": "test_policy_record_backwards_compatibility",
        "kind": 2,
        "importPath": "agent.tests.test_policy_store",
        "description": "agent.tests.test_policy_store",
        "peekOfCode": "def test_policy_record_backwards_compatibility():\n    \"\"\"Test that PolicyRecord can handle old metadata attribute names\"\"\"\n    from metta.agent.policy_metadata import PolicyMetadata\n    from metta.agent.policy_record import PolicyRecord\n    from metta.agent.policy_store import PolicyStore\n    # Create minimal config for PolicyStore\n    cfg = OmegaConf.create(\n        {\n            \"device\": \"cpu\",\n            \"run\": \"test_run\",",
        "detail": "agent.tests.test_policy_store",
        "documentation": {}
    },
    {
        "label": "HeatmapCell",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "description": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "peekOfCode": "class HeatmapCell(BaseModel):\n    evalName: str\n    replayUrl: Optional[str]\n    value: float\nclass HeatmapData(BaseModel):\n    evalNames: List[str]\n    cells: Dict[str, Dict[str, HeatmapCell]]\n    policyAverageScores: Dict[str, float]\n    evalAverageScores: Dict[str, float]\n    evalMaxScores: Dict[str, float]",
        "detail": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "documentation": {}
    },
    {
        "label": "HeatmapData",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "description": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "peekOfCode": "class HeatmapData(BaseModel):\n    evalNames: List[str]\n    cells: Dict[str, Dict[str, HeatmapCell]]\n    policyAverageScores: Dict[str, float]\n    evalAverageScores: Dict[str, float]\n    evalMaxScores: Dict[str, float]\nclass GroupDiff(BaseModel):\n    group_1: str\n    group_2: str\nclass GroupHeatmapMetric(BaseModel):",
        "detail": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "documentation": {}
    },
    {
        "label": "GroupDiff",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "description": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "peekOfCode": "class GroupDiff(BaseModel):\n    group_1: str\n    group_2: str\nclass GroupHeatmapMetric(BaseModel):\n    group_metric: str | GroupDiff\n    policy_selector: Literal[\"latest\", \"best\"] = \"latest\"\nclass SavedDashboardCreate(BaseModel):\n    name: str\n    description: Optional[str] = None\n    type: str",
        "detail": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "documentation": {}
    },
    {
        "label": "GroupHeatmapMetric",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "description": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "peekOfCode": "class GroupHeatmapMetric(BaseModel):\n    group_metric: str | GroupDiff\n    policy_selector: Literal[\"latest\", \"best\"] = \"latest\"\nclass SavedDashboardCreate(BaseModel):\n    name: str\n    description: Optional[str] = None\n    type: str\n    dashboard_state: Dict[str, Any]\nclass SavedDashboardResponse(BaseModel):\n    id: str",
        "detail": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "documentation": {}
    },
    {
        "label": "SavedDashboardCreate",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "description": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "peekOfCode": "class SavedDashboardCreate(BaseModel):\n    name: str\n    description: Optional[str] = None\n    type: str\n    dashboard_state: Dict[str, Any]\nclass SavedDashboardResponse(BaseModel):\n    id: str\n    name: str\n    description: Optional[str]\n    type: str",
        "detail": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "documentation": {}
    },
    {
        "label": "SavedDashboardResponse",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "description": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "peekOfCode": "class SavedDashboardResponse(BaseModel):\n    id: str\n    name: str\n    description: Optional[str]\n    type: str\n    dashboard_state: Dict[str, Any]\n    created_at: str\n    updated_at: str\n    user_id: str\nclass SavedDashboardListResponse(BaseModel):",
        "detail": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "documentation": {}
    },
    {
        "label": "SavedDashboardListResponse",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "description": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "peekOfCode": "class SavedDashboardListResponse(BaseModel):\n    dashboards: List[SavedDashboardResponse]\nclass TrainingRun(BaseModel):\n    id: str\n    name: str\n    created_at: str\n    user_id: str\n    finished_at: Optional[str]\n    status: str\n    url: Optional[str]",
        "detail": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "documentation": {}
    },
    {
        "label": "TrainingRun",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "description": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "peekOfCode": "class TrainingRun(BaseModel):\n    id: str\n    name: str\n    created_at: str\n    user_id: str\n    finished_at: Optional[str]\n    status: str\n    url: Optional[str]\n    description: Optional[str]\n    tags: List[str]",
        "detail": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "documentation": {}
    },
    {
        "label": "TrainingRunListResponse",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "description": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "peekOfCode": "class TrainingRunListResponse(BaseModel):\n    training_runs: List[TrainingRun]\nclass TrainingRunDescriptionUpdate(BaseModel):\n    description: str\nclass TrainingRunTagsUpdate(BaseModel):\n    tags: List[str]\n@dataclass\nclass GroupDataRow:\n    policy_uri: str\n    eval_name: str",
        "detail": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "documentation": {}
    },
    {
        "label": "TrainingRunDescriptionUpdate",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "description": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "peekOfCode": "class TrainingRunDescriptionUpdate(BaseModel):\n    description: str\nclass TrainingRunTagsUpdate(BaseModel):\n    tags: List[str]\n@dataclass\nclass GroupDataRow:\n    policy_uri: str\n    eval_name: str\n    replay_url: str | None\n    num_agents: int",
        "detail": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "documentation": {}
    },
    {
        "label": "TrainingRunTagsUpdate",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "description": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "peekOfCode": "class TrainingRunTagsUpdate(BaseModel):\n    tags: List[str]\n@dataclass\nclass GroupDataRow:\n    policy_uri: str\n    eval_name: str\n    replay_url: str | None\n    num_agents: int\n    total_value: float\n    run_id: str | None = None",
        "detail": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "documentation": {}
    },
    {
        "label": "GroupDataRow",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "description": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "peekOfCode": "class GroupDataRow:\n    policy_uri: str\n    eval_name: str\n    replay_url: str | None\n    num_agents: int\n    total_value: float\n    run_id: str | None = None\n    end_training_epoch: int | None = None\nclass GroupDataRetriever(ABC):\n    \"\"\"",
        "detail": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "documentation": {}
    },
    {
        "label": "GroupDataRetriever",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "description": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "peekOfCode": "class GroupDataRetriever(ABC):\n    \"\"\"\n    Abstract base class for retrieving evaluation data with encapsulated parameters.\n    \"\"\"\n    def __init__(self, suite: str, metric: str, filter_arg: str):\n        self.suite = suite\n        self.metric = metric\n        self.filter_arg = filter_arg\n    @abstractmethod\n    def get_group_data(self, con: Connection, group: str) -> List[GroupDataRow]:",
        "detail": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "documentation": {}
    },
    {
        "label": "PolicySelectorDataRetriever",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "description": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "peekOfCode": "class PolicySelectorDataRetriever(GroupDataRetriever):\n    \"\"\"\n    Retrieves group data with policy selector filtering (\"latest\" or \"best\").\n    Used for the main dashboard heatmap where one policy per training run\n    is selected based on the specified strategy.\n    \"\"\"\n    def get_group_data(self, con: Connection, group: str) -> List[GroupDataRow]:\n        return get_group_data(con, self.suite, self.metric, group, self.filter_arg)\nclass TrainingRunDataRetriever(GroupDataRetriever):\n    \"\"\"",
        "detail": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "documentation": {}
    },
    {
        "label": "TrainingRunDataRetriever",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "description": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "peekOfCode": "class TrainingRunDataRetriever(GroupDataRetriever):\n    \"\"\"\n    Retrieves all policies from a specific training run.\n    Used for training run detail pages where all policies from the\n    specified training run should be included in the heatmap.\n    \"\"\"\n    def get_group_data(self, con: Connection, group: str) -> List[GroupDataRow]:\n        return get_training_run_group_data(con, self.suite, self.metric, group, self.filter_arg)\ndef _get_group_data_with_policy_filter(\n    con: Connection, suite: str, metric: str, group: str, policy_cte: SQL, extra_params: Tuple[Any, ...] = ()",
        "detail": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "documentation": {}
    },
    {
        "label": "get_training_run_group_data",
        "kind": 2,
        "importPath": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "description": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "peekOfCode": "def get_training_run_group_data(\n    con: Connection, suite: str, metric: str, group: str, run_id: str\n) -> List[GroupDataRow]:\n    \"\"\"Get all policies from a specific training run for group data.\"\"\"\n    training_run_policy_cte = SQL(\"\"\"\n        filtered_policies AS (\n          SELECT\n            p.id,\n            p.name,\n            ep.run_id,",
        "detail": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "documentation": {}
    },
    {
        "label": "get_group_data",
        "kind": 2,
        "importPath": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "description": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "peekOfCode": "def get_group_data(\n    con: Connection, suite: str, metric: str, group: str, policy_selector: str = \"latest\"\n) -> List[GroupDataRow]:\n    \"\"\"Get group data for all policies with policy selector filtering.\"\"\"\n    all_policies_cte = SQL(\"\"\"\n        filtered_policies AS (\n          SELECT\n            p.id,\n            p.name,\n            ep.run_id,",
        "detail": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "documentation": {}
    },
    {
        "label": "create_dashboard_router",
        "kind": 2,
        "importPath": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "description": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "peekOfCode": "def create_dashboard_router(metta_repo: MettaRepo) -> APIRouter:\n    \"\"\"Create a dashboard router with the given StatsRepo instance.\"\"\"\n    router = APIRouter(prefix=\"/dashboard\", tags=[\"dashboard\"])\n    # Create the user-or-token authentication dependency\n    user_or_token = Depends(create_user_or_token_dependency(metta_repo))\n    @router.get(\"/suites\")\n    @timed_route(\"get_suites\")\n    async def get_suites() -> List[str]:  # type: ignore[reportUnusedFunction]\n        return metta_repo.get_suites()\n    @router.get(\"/suites/{suite}/metrics\")",
        "detail": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "description": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "peekOfCode": "logger = logging.getLogger(\"dashboard_performance\")\nlogger.setLevel(logging.INFO)\n# Pydantic models for API responses\nclass HeatmapCell(BaseModel):\n    evalName: str\n    replayUrl: Optional[str]\n    value: float\nclass HeatmapData(BaseModel):\n    evalNames: List[str]\n    cells: Dict[str, Dict[str, HeatmapCell]]",
        "detail": "app_backend.src.metta.app_backend.routes.dashboard_routes",
        "documentation": {}
    },
    {
        "label": "SQLQueryRequest",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.sql_routes",
        "description": "app_backend.src.metta.app_backend.routes.sql_routes",
        "peekOfCode": "class SQLQueryRequest(BaseModel):\n    query: str\nclass SQLQueryResponse(BaseModel):\n    columns: List[str]\n    rows: List[List[Any]]\n    row_count: int\nclass TableInfo(BaseModel):\n    table_name: str\n    column_count: int\n    row_count: int",
        "detail": "app_backend.src.metta.app_backend.routes.sql_routes",
        "documentation": {}
    },
    {
        "label": "SQLQueryResponse",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.sql_routes",
        "description": "app_backend.src.metta.app_backend.routes.sql_routes",
        "peekOfCode": "class SQLQueryResponse(BaseModel):\n    columns: List[str]\n    rows: List[List[Any]]\n    row_count: int\nclass TableInfo(BaseModel):\n    table_name: str\n    column_count: int\n    row_count: int\nclass TableSchema(BaseModel):\n    table_name: str",
        "detail": "app_backend.src.metta.app_backend.routes.sql_routes",
        "documentation": {}
    },
    {
        "label": "TableInfo",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.sql_routes",
        "description": "app_backend.src.metta.app_backend.routes.sql_routes",
        "peekOfCode": "class TableInfo(BaseModel):\n    table_name: str\n    column_count: int\n    row_count: int\nclass TableSchema(BaseModel):\n    table_name: str\n    columns: List[Dict[str, Any]]\ndef create_sql_router(metta_repo: MettaRepo) -> APIRouter:\n    \"\"\"Create SQL query router with the provided MettaRepo instance.\"\"\"\n    router = APIRouter(prefix=\"/sql\", tags=[\"sql\"])",
        "detail": "app_backend.src.metta.app_backend.routes.sql_routes",
        "documentation": {}
    },
    {
        "label": "TableSchema",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.sql_routes",
        "description": "app_backend.src.metta.app_backend.routes.sql_routes",
        "peekOfCode": "class TableSchema(BaseModel):\n    table_name: str\n    columns: List[Dict[str, Any]]\ndef create_sql_router(metta_repo: MettaRepo) -> APIRouter:\n    \"\"\"Create SQL query router with the provided MettaRepo instance.\"\"\"\n    router = APIRouter(prefix=\"/sql\", tags=[\"sql\"])\n    user_or_token = Depends(create_user_or_token_dependency(metta_repo))\n    @router.get(\"/tables\", response_model=List[TableInfo])\n    @timed_route(\"list_tables\")\n    async def list_tables(user: str = user_or_token) -> List[TableInfo]:",
        "detail": "app_backend.src.metta.app_backend.routes.sql_routes",
        "documentation": {}
    },
    {
        "label": "create_sql_router",
        "kind": 2,
        "importPath": "app_backend.src.metta.app_backend.routes.sql_routes",
        "description": "app_backend.src.metta.app_backend.routes.sql_routes",
        "peekOfCode": "def create_sql_router(metta_repo: MettaRepo) -> APIRouter:\n    \"\"\"Create SQL query router with the provided MettaRepo instance.\"\"\"\n    router = APIRouter(prefix=\"/sql\", tags=[\"sql\"])\n    user_or_token = Depends(create_user_or_token_dependency(metta_repo))\n    @router.get(\"/tables\", response_model=List[TableInfo])\n    @timed_route(\"list_tables\")\n    async def list_tables(user: str = user_or_token) -> List[TableInfo]:\n        \"\"\"List all available tables in the database (excluding migrations).\"\"\"\n        try:\n            with metta_repo.connect() as con:",
        "detail": "app_backend.src.metta.app_backend.routes.sql_routes",
        "documentation": {}
    },
    {
        "label": "PolicyIdResponse",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.stats_routes",
        "description": "app_backend.src.metta.app_backend.routes.stats_routes",
        "peekOfCode": "class PolicyIdResponse(BaseModel):\n    policy_ids: Dict[str, str]\nclass TrainingRunCreate(BaseModel):\n    name: str\n    attributes: Dict[str, str] = Field(default_factory=dict)\n    url: Optional[str] = None\n    description: Optional[str] = None\n    tags: Optional[List[str]] = None\nclass TrainingRunResponse(BaseModel):\n    id: str",
        "detail": "app_backend.src.metta.app_backend.routes.stats_routes",
        "documentation": {}
    },
    {
        "label": "TrainingRunCreate",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.stats_routes",
        "description": "app_backend.src.metta.app_backend.routes.stats_routes",
        "peekOfCode": "class TrainingRunCreate(BaseModel):\n    name: str\n    attributes: Dict[str, str] = Field(default_factory=dict)\n    url: Optional[str] = None\n    description: Optional[str] = None\n    tags: Optional[List[str]] = None\nclass TrainingRunResponse(BaseModel):\n    id: str\nclass EpochCreate(BaseModel):\n    start_training_epoch: int",
        "detail": "app_backend.src.metta.app_backend.routes.stats_routes",
        "documentation": {}
    },
    {
        "label": "TrainingRunResponse",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.stats_routes",
        "description": "app_backend.src.metta.app_backend.routes.stats_routes",
        "peekOfCode": "class TrainingRunResponse(BaseModel):\n    id: str\nclass EpochCreate(BaseModel):\n    start_training_epoch: int\n    end_training_epoch: int\n    attributes: Dict[str, str] = Field(default_factory=dict)\nclass EpochResponse(BaseModel):\n    id: str\nclass PolicyCreate(BaseModel):\n    name: str",
        "detail": "app_backend.src.metta.app_backend.routes.stats_routes",
        "documentation": {}
    },
    {
        "label": "EpochCreate",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.stats_routes",
        "description": "app_backend.src.metta.app_backend.routes.stats_routes",
        "peekOfCode": "class EpochCreate(BaseModel):\n    start_training_epoch: int\n    end_training_epoch: int\n    attributes: Dict[str, str] = Field(default_factory=dict)\nclass EpochResponse(BaseModel):\n    id: str\nclass PolicyCreate(BaseModel):\n    name: str\n    description: Optional[str] = None\n    url: Optional[str] = None",
        "detail": "app_backend.src.metta.app_backend.routes.stats_routes",
        "documentation": {}
    },
    {
        "label": "EpochResponse",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.stats_routes",
        "description": "app_backend.src.metta.app_backend.routes.stats_routes",
        "peekOfCode": "class EpochResponse(BaseModel):\n    id: str\nclass PolicyCreate(BaseModel):\n    name: str\n    description: Optional[str] = None\n    url: Optional[str] = None\n    epoch_id: Optional[str] = None\nclass PolicyResponse(BaseModel):\n    id: str\nclass EpisodeCreate(BaseModel):",
        "detail": "app_backend.src.metta.app_backend.routes.stats_routes",
        "documentation": {}
    },
    {
        "label": "PolicyCreate",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.stats_routes",
        "description": "app_backend.src.metta.app_backend.routes.stats_routes",
        "peekOfCode": "class PolicyCreate(BaseModel):\n    name: str\n    description: Optional[str] = None\n    url: Optional[str] = None\n    epoch_id: Optional[str] = None\nclass PolicyResponse(BaseModel):\n    id: str\nclass EpisodeCreate(BaseModel):\n    agent_policies: Dict[int, str]\n    agent_metrics: Dict[int, Dict[str, float]]",
        "detail": "app_backend.src.metta.app_backend.routes.stats_routes",
        "documentation": {}
    },
    {
        "label": "PolicyResponse",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.stats_routes",
        "description": "app_backend.src.metta.app_backend.routes.stats_routes",
        "peekOfCode": "class PolicyResponse(BaseModel):\n    id: str\nclass EpisodeCreate(BaseModel):\n    agent_policies: Dict[int, str]\n    agent_metrics: Dict[int, Dict[str, float]]\n    primary_policy_id: str\n    stats_epoch: Optional[str] = None\n    eval_name: Optional[str] = None\n    simulation_suite: Optional[str] = None\n    replay_url: Optional[str] = None",
        "detail": "app_backend.src.metta.app_backend.routes.stats_routes",
        "documentation": {}
    },
    {
        "label": "EpisodeCreate",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.stats_routes",
        "description": "app_backend.src.metta.app_backend.routes.stats_routes",
        "peekOfCode": "class EpisodeCreate(BaseModel):\n    agent_policies: Dict[int, str]\n    agent_metrics: Dict[int, Dict[str, float]]\n    primary_policy_id: str\n    stats_epoch: Optional[str] = None\n    eval_name: Optional[str] = None\n    simulation_suite: Optional[str] = None\n    replay_url: Optional[str] = None\n    attributes: Dict[str, Any] = Field(default_factory=dict)\nclass EpisodeResponse(BaseModel):",
        "detail": "app_backend.src.metta.app_backend.routes.stats_routes",
        "documentation": {}
    },
    {
        "label": "EpisodeResponse",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.stats_routes",
        "description": "app_backend.src.metta.app_backend.routes.stats_routes",
        "peekOfCode": "class EpisodeResponse(BaseModel):\n    id: str\ndef create_stats_router(stats_repo: MettaRepo) -> APIRouter:\n    \"\"\"Create a stats router with the given StatsRepo instance.\"\"\"\n    router = APIRouter(prefix=\"/stats\", tags=[\"stats\"])\n    # Create the user-or-token authentication dependency\n    user_or_token = Depends(create_user_or_token_dependency(stats_repo))\n    @router.get(\"/policies/ids\", response_model=PolicyIdResponse)\n    @timed_route(\"get_policy_ids\")\n    async def get_policy_ids(",
        "detail": "app_backend.src.metta.app_backend.routes.stats_routes",
        "documentation": {}
    },
    {
        "label": "create_stats_router",
        "kind": 2,
        "importPath": "app_backend.src.metta.app_backend.routes.stats_routes",
        "description": "app_backend.src.metta.app_backend.routes.stats_routes",
        "peekOfCode": "def create_stats_router(stats_repo: MettaRepo) -> APIRouter:\n    \"\"\"Create a stats router with the given StatsRepo instance.\"\"\"\n    router = APIRouter(prefix=\"/stats\", tags=[\"stats\"])\n    # Create the user-or-token authentication dependency\n    user_or_token = Depends(create_user_or_token_dependency(stats_repo))\n    @router.get(\"/policies/ids\", response_model=PolicyIdResponse)\n    @timed_route(\"get_policy_ids\")\n    async def get_policy_ids(\n        policy_names: List[str] = Query(default=[]), user: str = user_or_token\n    ) -> PolicyIdResponse:",
        "detail": "app_backend.src.metta.app_backend.routes.stats_routes",
        "documentation": {}
    },
    {
        "label": "TokenCreate",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.token_routes",
        "description": "app_backend.src.metta.app_backend.routes.token_routes",
        "peekOfCode": "class TokenCreate(BaseModel):\n    name: str\nclass TokenResponse(BaseModel):\n    token: str\nclass TokenInfo(BaseModel):\n    id: str\n    name: str\n    created_at: str\n    expiration_time: str\n    last_used_at: str | None",
        "detail": "app_backend.src.metta.app_backend.routes.token_routes",
        "documentation": {}
    },
    {
        "label": "TokenResponse",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.token_routes",
        "description": "app_backend.src.metta.app_backend.routes.token_routes",
        "peekOfCode": "class TokenResponse(BaseModel):\n    token: str\nclass TokenInfo(BaseModel):\n    id: str\n    name: str\n    created_at: str\n    expiration_time: str\n    last_used_at: str | None\nclass TokenListResponse(BaseModel):\n    tokens: List[TokenInfo]",
        "detail": "app_backend.src.metta.app_backend.routes.token_routes",
        "documentation": {}
    },
    {
        "label": "TokenInfo",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.token_routes",
        "description": "app_backend.src.metta.app_backend.routes.token_routes",
        "peekOfCode": "class TokenInfo(BaseModel):\n    id: str\n    name: str\n    created_at: str\n    expiration_time: str\n    last_used_at: str | None\nclass TokenListResponse(BaseModel):\n    tokens: List[TokenInfo]\ndef create_token_router(metta_repo: MettaRepo) -> APIRouter:\n    \"\"\"Create a token management router with the given MettaRepo instance.\"\"\"",
        "detail": "app_backend.src.metta.app_backend.routes.token_routes",
        "documentation": {}
    },
    {
        "label": "TokenListResponse",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.routes.token_routes",
        "description": "app_backend.src.metta.app_backend.routes.token_routes",
        "peekOfCode": "class TokenListResponse(BaseModel):\n    tokens: List[TokenInfo]\ndef create_token_router(metta_repo: MettaRepo) -> APIRouter:\n    \"\"\"Create a token management router with the given MettaRepo instance.\"\"\"\n    router = APIRouter(prefix=\"/tokens\", tags=[\"tokens\"])\n    @router.post(\"\", response_model=TokenResponse)\n    @timed_route(\"create_token\")\n    async def create_token(token_data: TokenCreate, user_email: UserEmail) -> TokenResponse:\n        \"\"\"Create a new machine token for the authenticated user.\"\"\"\n        try:",
        "detail": "app_backend.src.metta.app_backend.routes.token_routes",
        "documentation": {}
    },
    {
        "label": "create_token_router",
        "kind": 2,
        "importPath": "app_backend.src.metta.app_backend.routes.token_routes",
        "description": "app_backend.src.metta.app_backend.routes.token_routes",
        "peekOfCode": "def create_token_router(metta_repo: MettaRepo) -> APIRouter:\n    \"\"\"Create a token management router with the given MettaRepo instance.\"\"\"\n    router = APIRouter(prefix=\"/tokens\", tags=[\"tokens\"])\n    @router.post(\"\", response_model=TokenResponse)\n    @timed_route(\"create_token\")\n    async def create_token(token_data: TokenCreate, user_email: UserEmail) -> TokenResponse:\n        \"\"\"Create a new machine token for the authenticated user.\"\"\"\n        try:\n            token = metta_repo.create_machine_token(user_email, token_data.name)\n            return TokenResponse(token=token)",
        "detail": "app_backend.src.metta.app_backend.routes.token_routes",
        "documentation": {}
    },
    {
        "label": "user_from_header",
        "kind": 2,
        "importPath": "app_backend.src.metta.app_backend.auth",
        "description": "app_backend.src.metta.app_backend.auth",
        "peekOfCode": "def user_from_header(request: Request) -> str | None:\n    \"\"\"Extract user email from request headers.\"\"\"\n    return config.debug_user_email or request.headers.get(\"X-Auth-Request-Email\")\ndef user_from_header_or_token(request: Request, metta_repo: MettaRepo) -> str | None:\n    user_email = user_from_header(request)\n    if user_email:\n        return user_email\n    token = request.headers.get(\"X-Auth-Token\")\n    if not token:\n        return None",
        "detail": "app_backend.src.metta.app_backend.auth",
        "documentation": {}
    },
    {
        "label": "user_from_header_or_token",
        "kind": 2,
        "importPath": "app_backend.src.metta.app_backend.auth",
        "description": "app_backend.src.metta.app_backend.auth",
        "peekOfCode": "def user_from_header_or_token(request: Request, metta_repo: MettaRepo) -> str | None:\n    user_email = user_from_header(request)\n    if user_email:\n        return user_email\n    token = request.headers.get(\"X-Auth-Token\")\n    if not token:\n        return None\n    user_id = metta_repo.validate_machine_token(token)\n    if not user_id:\n        return None",
        "detail": "app_backend.src.metta.app_backend.auth",
        "documentation": {}
    },
    {
        "label": "user_from_header_or_token_or_raise",
        "kind": 2,
        "importPath": "app_backend.src.metta.app_backend.auth",
        "description": "app_backend.src.metta.app_backend.auth",
        "peekOfCode": "def user_from_header_or_token_or_raise(request: Request, metta_repo: MettaRepo) -> str:\n    user_id = user_from_header_or_token(request, metta_repo)\n    if not user_id:\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"Either X-Auth-Request-Email or X-Auth-Token header required\",\n        )\n    return user_id\ndef user_from_email_or_raise(request: Request) -> str:\n    user_email = user_from_header(request)",
        "detail": "app_backend.src.metta.app_backend.auth",
        "documentation": {}
    },
    {
        "label": "user_from_email_or_raise",
        "kind": 2,
        "importPath": "app_backend.src.metta.app_backend.auth",
        "description": "app_backend.src.metta.app_backend.auth",
        "peekOfCode": "def user_from_email_or_raise(request: Request) -> str:\n    user_email = user_from_header(request)\n    if not user_email:\n        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"X-Auth-Request-Email header required\")\n    return user_email\ndef create_user_or_token_dependency(metta_repo: MettaRepo) -> Callable[[Request], str]:\n    \"\"\"Create a dependency function that validates either user email or machine token.\"\"\"\n    def get_user_or_token_user(request: Request) -> str:\n        return user_from_header_or_token_or_raise(request, metta_repo)\n    return get_user_or_token_user",
        "detail": "app_backend.src.metta.app_backend.auth",
        "documentation": {}
    },
    {
        "label": "create_user_or_token_dependency",
        "kind": 2,
        "importPath": "app_backend.src.metta.app_backend.auth",
        "description": "app_backend.src.metta.app_backend.auth",
        "peekOfCode": "def create_user_or_token_dependency(metta_repo: MettaRepo) -> Callable[[Request], str]:\n    \"\"\"Create a dependency function that validates either user email or machine token.\"\"\"\n    def get_user_or_token_user(request: Request) -> str:\n        return user_from_header_or_token_or_raise(request, metta_repo)\n    return get_user_or_token_user\n# Dependency types for use in route decorators\nUserEmail = Annotated[str, Depends(user_from_email_or_raise)]",
        "detail": "app_backend.src.metta.app_backend.auth",
        "documentation": {}
    },
    {
        "label": "UserEmail",
        "kind": 5,
        "importPath": "app_backend.src.metta.app_backend.auth",
        "description": "app_backend.src.metta.app_backend.auth",
        "peekOfCode": "UserEmail = Annotated[str, Depends(user_from_email_or_raise)]",
        "detail": "app_backend.src.metta.app_backend.auth",
        "documentation": {}
    },
    {
        "label": "stats_db_uri",
        "kind": 5,
        "importPath": "app_backend.src.metta.app_backend.config",
        "description": "app_backend.src.metta.app_backend.config",
        "peekOfCode": "stats_db_uri = os.getenv(\"STATS_DB_URI\", \"postgres://postgres:password@127.0.0.1/postgres\")\ndebug_user_email = os.getenv(\"DEBUG_USER_EMAIL\")\nhost = os.getenv(\"HOST\", \"127.0.0.1\")\nport = int(os.getenv(\"PORT\", \"8000\"))",
        "detail": "app_backend.src.metta.app_backend.config",
        "documentation": {}
    },
    {
        "label": "debug_user_email",
        "kind": 5,
        "importPath": "app_backend.src.metta.app_backend.config",
        "description": "app_backend.src.metta.app_backend.config",
        "peekOfCode": "debug_user_email = os.getenv(\"DEBUG_USER_EMAIL\")\nhost = os.getenv(\"HOST\", \"127.0.0.1\")\nport = int(os.getenv(\"PORT\", \"8000\"))",
        "detail": "app_backend.src.metta.app_backend.config",
        "documentation": {}
    },
    {
        "label": "host",
        "kind": 5,
        "importPath": "app_backend.src.metta.app_backend.config",
        "description": "app_backend.src.metta.app_backend.config",
        "peekOfCode": "host = os.getenv(\"HOST\", \"127.0.0.1\")\nport = int(os.getenv(\"PORT\", \"8000\"))",
        "detail": "app_backend.src.metta.app_backend.config",
        "documentation": {}
    },
    {
        "label": "port",
        "kind": 5,
        "importPath": "app_backend.src.metta.app_backend.config",
        "description": "app_backend.src.metta.app_backend.config",
        "peekOfCode": "port = int(os.getenv(\"PORT\", \"8000\"))",
        "detail": "app_backend.src.metta.app_backend.config",
        "documentation": {}
    },
    {
        "label": "MettaRepo",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.metta_repo",
        "description": "app_backend.src.metta.app_backend.metta_repo",
        "peekOfCode": "class MettaRepo:\n    def __init__(self, db_uri: str) -> None:\n        self.db_uri = db_uri\n        with Connection.connect(self.db_uri) as con:\n            run_migrations(con, MIGRATIONS)\n    def connect(self) -> Connection:\n        return Connection.connect(self.db_uri)\n    def get_policy_ids(self, policy_names: List[str]) -> Dict[str, uuid.UUID]:\n        if not policy_names:\n            return {}",
        "detail": "app_backend.src.metta.app_backend.metta_repo",
        "documentation": {}
    },
    {
        "label": "MIGRATIONS",
        "kind": 5,
        "importPath": "app_backend.src.metta.app_backend.metta_repo",
        "description": "app_backend.src.metta.app_backend.metta_repo",
        "peekOfCode": "MIGRATIONS = [\n    SqlMigration(\n        version=0,\n        description=\"Initial eval schema\",\n        sql_statements=[\n            \"\"\"CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\" \"\"\",\n            \"\"\"CREATE TABLE training_runs (\n                id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n                name TEXT NOT NULL,\n                created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,",
        "detail": "app_backend.src.metta.app_backend.metta_repo",
        "documentation": {}
    },
    {
        "label": "timed_query",
        "kind": 2,
        "importPath": "app_backend.src.metta.app_backend.query_logger",
        "description": "app_backend.src.metta.app_backend.query_logger",
        "peekOfCode": "def timed_query(\n    con: Connection, query: Query, params: Tuple[Any, ...] = (), description: str = \"\"\n) -> Generator[Cursor, None, None]:\n    \"\"\"\n    Context manager that executes a database query with timing and logging.\n    Logs all queries with their execution time. If a query takes longer than\n    SLOW_QUERY_THRESHOLD_SECONDS, logs a warning with the query and parameters.\n    Args:\n        con: Database connection\n        query: SQL query string",
        "detail": "app_backend.src.metta.app_backend.query_logger",
        "documentation": {}
    },
    {
        "label": "execute_query_and_log",
        "kind": 2,
        "importPath": "app_backend.src.metta.app_backend.query_logger",
        "description": "app_backend.src.metta.app_backend.query_logger",
        "peekOfCode": "def execute_query_and_log(\n    con: Connection, query: Query, params: Tuple[Any, ...] = (), description: str = \"\"\n) -> list[TupleRow]:\n    \"\"\"\n    Execute a query with timing and logging, returning the results.\n    This is a convenience function for simple queries that just need results.\n    Args:\n        con: Database connection\n        query: SQL query string\n        params: Query parameters",
        "detail": "app_backend.src.metta.app_backend.query_logger",
        "documentation": {}
    },
    {
        "label": "execute_single_row_query_and_log",
        "kind": 2,
        "importPath": "app_backend.src.metta.app_backend.query_logger",
        "description": "app_backend.src.metta.app_backend.query_logger",
        "peekOfCode": "def execute_single_row_query_and_log(\n    con: Connection, query: Query, params: Tuple[Any, ...] = (), description: str = \"\"\n) -> TupleRow | None:\n    \"\"\"\n    Execute a query with timing and logging, returning the first result.\n    Args:\n        con: Database connection\n        query: SQL query string\n        params: Query parameters\n        description: Optional description for the query",
        "detail": "app_backend.src.metta.app_backend.query_logger",
        "documentation": {}
    },
    {
        "label": "query_logger",
        "kind": 5,
        "importPath": "app_backend.src.metta.app_backend.query_logger",
        "description": "app_backend.src.metta.app_backend.query_logger",
        "peekOfCode": "query_logger = logging.getLogger(\"db_performance\")\nquery_logger.setLevel(logging.INFO)\n# Threshold for slow query warnings (1 second)\nSLOW_QUERY_THRESHOLD_SECONDS = 1.0\n@contextmanager\ndef timed_query(\n    con: Connection, query: Query, params: Tuple[Any, ...] = (), description: str = \"\"\n) -> Generator[Cursor, None, None]:\n    \"\"\"\n    Context manager that executes a database query with timing and logging.",
        "detail": "app_backend.src.metta.app_backend.query_logger",
        "documentation": {}
    },
    {
        "label": "SLOW_QUERY_THRESHOLD_SECONDS",
        "kind": 5,
        "importPath": "app_backend.src.metta.app_backend.query_logger",
        "description": "app_backend.src.metta.app_backend.query_logger",
        "peekOfCode": "SLOW_QUERY_THRESHOLD_SECONDS = 1.0\n@contextmanager\ndef timed_query(\n    con: Connection, query: Query, params: Tuple[Any, ...] = (), description: str = \"\"\n) -> Generator[Cursor, None, None]:\n    \"\"\"\n    Context manager that executes a database query with timing and logging.\n    Logs all queries with their execution time. If a query takes longer than\n    SLOW_QUERY_THRESHOLD_SECONDS, logs a warning with the query and parameters.\n    Args:",
        "detail": "app_backend.src.metta.app_backend.query_logger",
        "documentation": {}
    },
    {
        "label": "timed_route",
        "kind": 2,
        "importPath": "app_backend.src.metta.app_backend.route_logger",
        "description": "app_backend.src.metta.app_backend.route_logger",
        "peekOfCode": "def timed_route(route_name: str = \"\"):\n    \"\"\"\n    Decorator that logs the execution time of FastAPI routes.\n    Logs all route executions with their timing. If a route takes longer than\n    SLOW_ROUTE_THRESHOLD_SECONDS, logs a warning.\n    Args:\n        route_name: Optional custom name for the route (defaults to function name)\n    \"\"\"\n    def decorator(func: Callable) -> Callable:\n        @wraps(func)",
        "detail": "app_backend.src.metta.app_backend.route_logger",
        "documentation": {}
    },
    {
        "label": "log_route_timing",
        "kind": 2,
        "importPath": "app_backend.src.metta.app_backend.route_logger",
        "description": "app_backend.src.metta.app_backend.route_logger",
        "peekOfCode": "def log_route_timing(request: Request, response: Response, start_time: float) -> None:\n    \"\"\"\n    Log route timing information. Can be used as middleware or called manually.\n    Args:\n        request: FastAPI request object\n        response: FastAPI response object\n        start_time: Time when the request started processing\n    \"\"\"\n    execution_time = time.time() - start_time\n    route_info = f\"{request.method} {request.url.path}\"",
        "detail": "app_backend.src.metta.app_backend.route_logger",
        "documentation": {}
    },
    {
        "label": "route_logger",
        "kind": 5,
        "importPath": "app_backend.src.metta.app_backend.route_logger",
        "description": "app_backend.src.metta.app_backend.route_logger",
        "peekOfCode": "route_logger = logging.getLogger(\"route_performance\")\nroute_logger.setLevel(logging.INFO)\n# Threshold for slow route warnings (2 seconds)\nSLOW_ROUTE_THRESHOLD_SECONDS = 2.0\ndef timed_route(route_name: str = \"\"):\n    \"\"\"\n    Decorator that logs the execution time of FastAPI routes.\n    Logs all route executions with their timing. If a route takes longer than\n    SLOW_ROUTE_THRESHOLD_SECONDS, logs a warning.\n    Args:",
        "detail": "app_backend.src.metta.app_backend.route_logger",
        "documentation": {}
    },
    {
        "label": "SLOW_ROUTE_THRESHOLD_SECONDS",
        "kind": 5,
        "importPath": "app_backend.src.metta.app_backend.route_logger",
        "description": "app_backend.src.metta.app_backend.route_logger",
        "peekOfCode": "SLOW_ROUTE_THRESHOLD_SECONDS = 2.0\ndef timed_route(route_name: str = \"\"):\n    \"\"\"\n    Decorator that logs the execution time of FastAPI routes.\n    Logs all route executions with their timing. If a route takes longer than\n    SLOW_ROUTE_THRESHOLD_SECONDS, logs a warning.\n    Args:\n        route_name: Optional custom name for the route (defaults to function name)\n    \"\"\"\n    def decorator(func: Callable) -> Callable:",
        "detail": "app_backend.src.metta.app_backend.route_logger",
        "documentation": {}
    },
    {
        "label": "Migration",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.schema_manager",
        "description": "app_backend.src.metta.app_backend.schema_manager",
        "peekOfCode": "class Migration(abc.ABC):\n    @abc.abstractmethod\n    def version(self) -> int:\n        pass\n    @abc.abstractmethod\n    def description(self) -> str:\n        pass\n    @abc.abstractmethod\n    def up(self, conn: Connection) -> None:\n        pass",
        "detail": "app_backend.src.metta.app_backend.schema_manager",
        "documentation": {}
    },
    {
        "label": "SqlMigration",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.schema_manager",
        "description": "app_backend.src.metta.app_backend.schema_manager",
        "peekOfCode": "class SqlMigration(Migration):\n    def __init__(self, version: int, description: str, sql_statements: List[LiteralString]):\n        self._version = version\n        self._description = description\n        self._sql_statements = sql_statements\n    def version(self) -> int:\n        return self._version\n    def description(self) -> str:\n        return self._description\n    def up(self, conn: Connection) -> None:",
        "detail": "app_backend.src.metta.app_backend.schema_manager",
        "documentation": {}
    },
    {
        "label": "MigrationRecord",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.schema_manager",
        "description": "app_backend.src.metta.app_backend.schema_manager",
        "peekOfCode": "class MigrationRecord(BaseModel):\n    version: int\n    description: str\n    applied_at: datetime\ndef validate_migrations(migrations: Sequence[Migration]):\n    for i, migration in enumerate(migrations):\n        if migration.version() != i:\n            raise ValueError(f\"Migration {i} has version {migration.version()}\")\nmigrations_ddl = sql.SQL(\"\"\"\nCREATE TABLE IF NOT EXISTS migrations (",
        "detail": "app_backend.src.metta.app_backend.schema_manager",
        "documentation": {}
    },
    {
        "label": "validate_migrations",
        "kind": 2,
        "importPath": "app_backend.src.metta.app_backend.schema_manager",
        "description": "app_backend.src.metta.app_backend.schema_manager",
        "peekOfCode": "def validate_migrations(migrations: Sequence[Migration]):\n    for i, migration in enumerate(migrations):\n        if migration.version() != i:\n            raise ValueError(f\"Migration {i} has version {migration.version()}\")\nmigrations_ddl = sql.SQL(\"\"\"\nCREATE TABLE IF NOT EXISTS migrations (\n    version INTEGER PRIMARY KEY,\n    description TEXT NOT NULL,\n    applied_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP\n);",
        "detail": "app_backend.src.metta.app_backend.schema_manager",
        "documentation": {}
    },
    {
        "label": "get_last_applied_migration",
        "kind": 2,
        "importPath": "app_backend.src.metta.app_backend.schema_manager",
        "description": "app_backend.src.metta.app_backend.schema_manager",
        "peekOfCode": "def get_last_applied_migration(conn: Connection) -> MigrationRecord | None:\n    with conn.cursor() as cursor:\n        cursor.execute(\"SELECT version, description, applied_at FROM migrations ORDER BY version DESC LIMIT 1\")\n        result = cursor.fetchone()\n        if result:\n            [version, description, applied_at] = result\n            return MigrationRecord(version=version, description=description, applied_at=applied_at)\n        return None\ndef init_migrations_table(conn: Connection):\n    with conn.cursor() as cursor:",
        "detail": "app_backend.src.metta.app_backend.schema_manager",
        "documentation": {}
    },
    {
        "label": "init_migrations_table",
        "kind": 2,
        "importPath": "app_backend.src.metta.app_backend.schema_manager",
        "description": "app_backend.src.metta.app_backend.schema_manager",
        "peekOfCode": "def init_migrations_table(conn: Connection):\n    with conn.cursor() as cursor:\n        cursor.execute(migrations_ddl)\n        conn.commit()\ndef run_migrations(conn: Connection, migrations: Sequence[Migration]) -> None:\n    validate_migrations(migrations)\n    init_migrations_table(conn)\n    last_applied_migration = get_last_applied_migration(conn)\n    last_applied_migration_version = last_applied_migration.version if last_applied_migration else -1\n    for migration in migrations[last_applied_migration_version + 1 :]:",
        "detail": "app_backend.src.metta.app_backend.schema_manager",
        "documentation": {}
    },
    {
        "label": "run_migrations",
        "kind": 2,
        "importPath": "app_backend.src.metta.app_backend.schema_manager",
        "description": "app_backend.src.metta.app_backend.schema_manager",
        "peekOfCode": "def run_migrations(conn: Connection, migrations: Sequence[Migration]) -> None:\n    validate_migrations(migrations)\n    init_migrations_table(conn)\n    last_applied_migration = get_last_applied_migration(conn)\n    last_applied_migration_version = last_applied_migration.version if last_applied_migration else -1\n    for migration in migrations[last_applied_migration_version + 1 :]:\n        with conn.transaction():\n            migration.up(conn)\n            with conn.cursor() as cursor:\n                cursor.execute(",
        "detail": "app_backend.src.metta.app_backend.schema_manager",
        "documentation": {}
    },
    {
        "label": "migrations_ddl",
        "kind": 5,
        "importPath": "app_backend.src.metta.app_backend.schema_manager",
        "description": "app_backend.src.metta.app_backend.schema_manager",
        "peekOfCode": "migrations_ddl = sql.SQL(\"\"\"\nCREATE TABLE IF NOT EXISTS migrations (\n    version INTEGER PRIMARY KEY,\n    description TEXT NOT NULL,\n    applied_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP\n);\n\"\"\")\ndef get_last_applied_migration(conn: Connection) -> MigrationRecord | None:\n    with conn.cursor() as cursor:\n        cursor.execute(\"SELECT version, description, applied_at FROM migrations ORDER BY version DESC LIMIT 1\")",
        "detail": "app_backend.src.metta.app_backend.schema_manager",
        "documentation": {}
    },
    {
        "label": "NoWhoAmIFilter",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.server",
        "description": "app_backend.src.metta.app_backend.server",
        "peekOfCode": "class NoWhoAmIFilter(logging.Filter):\n    \"\"\"Filter out /whoami requests from uvicorn access logs.\"\"\"\n    def filter(self, record):\n        # Filter out /whoami requests from uvicorn access logs\n        if hasattr(record, \"getMessage\"):\n            message = record.getMessage()\n            return not (\"/whoami\" in message and \"GET\" in message)\n        return True\ndef setup_logging():\n    \"\"\"Configure logging for the application, including heatmap performance logging.\"\"\"",
        "detail": "app_backend.src.metta.app_backend.server",
        "documentation": {}
    },
    {
        "label": "setup_logging",
        "kind": 2,
        "importPath": "app_backend.src.metta.app_backend.server",
        "description": "app_backend.src.metta.app_backend.server",
        "peekOfCode": "def setup_logging():\n    \"\"\"Configure logging for the application, including heatmap performance logging.\"\"\"\n    global _logging_configured\n    if _logging_configured:\n        return\n    # Configure root logger\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s [%(name)s] %(levelname)s: %(message)s\",\n        handlers=[logging.StreamHandler(sys.stdout)],",
        "detail": "app_backend.src.metta.app_backend.server",
        "documentation": {}
    },
    {
        "label": "create_app",
        "kind": 2,
        "importPath": "app_backend.src.metta.app_backend.server",
        "description": "app_backend.src.metta.app_backend.server",
        "peekOfCode": "def create_app(stats_repo: MettaRepo) -> fastapi.FastAPI:\n    \"\"\"Create a FastAPI app with the given StatsRepo instance.\"\"\"\n    # Ensure logging is configured\n    setup_logging()\n    app = fastapi.FastAPI()\n    # Add CORS middleware\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=[\"http://localhost:5173\", \"http://localhost:3000\"],  # Frontend URLs\n        allow_credentials=True,",
        "detail": "app_backend.src.metta.app_backend.server",
        "documentation": {}
    },
    {
        "label": "_logging_configured",
        "kind": 5,
        "importPath": "app_backend.src.metta.app_backend.server",
        "description": "app_backend.src.metta.app_backend.server",
        "peekOfCode": "_logging_configured = False\nclass NoWhoAmIFilter(logging.Filter):\n    \"\"\"Filter out /whoami requests from uvicorn access logs.\"\"\"\n    def filter(self, record):\n        # Filter out /whoami requests from uvicorn access logs\n        if hasattr(record, \"getMessage\"):\n            message = record.getMessage()\n            return not (\"/whoami\" in message and \"GET\" in message)\n        return True\ndef setup_logging():",
        "detail": "app_backend.src.metta.app_backend.server",
        "documentation": {}
    },
    {
        "label": "ClientPolicyIdResponse",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.stats_client",
        "description": "app_backend.src.metta.app_backend.stats_client",
        "peekOfCode": "class ClientPolicyIdResponse(BaseModel):\n    policy_ids: Dict[str, uuid.UUID]\nclass ClientTrainingRunResponse(BaseModel):\n    id: uuid.UUID\nclass ClientEpochResponse(BaseModel):\n    id: uuid.UUID\nclass ClientPolicyResponse(BaseModel):\n    id: uuid.UUID\nclass ClientEpisodeResponse(BaseModel):\n    id: uuid.UUID",
        "detail": "app_backend.src.metta.app_backend.stats_client",
        "documentation": {}
    },
    {
        "label": "ClientTrainingRunResponse",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.stats_client",
        "description": "app_backend.src.metta.app_backend.stats_client",
        "peekOfCode": "class ClientTrainingRunResponse(BaseModel):\n    id: uuid.UUID\nclass ClientEpochResponse(BaseModel):\n    id: uuid.UUID\nclass ClientPolicyResponse(BaseModel):\n    id: uuid.UUID\nclass ClientEpisodeResponse(BaseModel):\n    id: uuid.UUID\nclass StatsClient:\n    \"\"\"Client for interacting with the stats API.\"\"\"",
        "detail": "app_backend.src.metta.app_backend.stats_client",
        "documentation": {}
    },
    {
        "label": "ClientEpochResponse",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.stats_client",
        "description": "app_backend.src.metta.app_backend.stats_client",
        "peekOfCode": "class ClientEpochResponse(BaseModel):\n    id: uuid.UUID\nclass ClientPolicyResponse(BaseModel):\n    id: uuid.UUID\nclass ClientEpisodeResponse(BaseModel):\n    id: uuid.UUID\nclass StatsClient:\n    \"\"\"Client for interacting with the stats API.\"\"\"\n    def __init__(self, http_client: httpx.Client, machine_token: str):\n        \"\"\"",
        "detail": "app_backend.src.metta.app_backend.stats_client",
        "documentation": {}
    },
    {
        "label": "ClientPolicyResponse",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.stats_client",
        "description": "app_backend.src.metta.app_backend.stats_client",
        "peekOfCode": "class ClientPolicyResponse(BaseModel):\n    id: uuid.UUID\nclass ClientEpisodeResponse(BaseModel):\n    id: uuid.UUID\nclass StatsClient:\n    \"\"\"Client for interacting with the stats API.\"\"\"\n    def __init__(self, http_client: httpx.Client, machine_token: str):\n        \"\"\"\n        Initialize the stats client.\n        Args:",
        "detail": "app_backend.src.metta.app_backend.stats_client",
        "documentation": {}
    },
    {
        "label": "ClientEpisodeResponse",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.stats_client",
        "description": "app_backend.src.metta.app_backend.stats_client",
        "peekOfCode": "class ClientEpisodeResponse(BaseModel):\n    id: uuid.UUID\nclass StatsClient:\n    \"\"\"Client for interacting with the stats API.\"\"\"\n    def __init__(self, http_client: httpx.Client, machine_token: str):\n        \"\"\"\n        Initialize the stats client.\n        Args:\n            http_client: HTTP client implementation to use for requests\n            machine_token: Machine token for authentication",
        "detail": "app_backend.src.metta.app_backend.stats_client",
        "documentation": {}
    },
    {
        "label": "StatsClient",
        "kind": 6,
        "importPath": "app_backend.src.metta.app_backend.stats_client",
        "description": "app_backend.src.metta.app_backend.stats_client",
        "peekOfCode": "class StatsClient:\n    \"\"\"Client for interacting with the stats API.\"\"\"\n    def __init__(self, http_client: httpx.Client, machine_token: str):\n        \"\"\"\n        Initialize the stats client.\n        Args:\n            http_client: HTTP client implementation to use for requests\n            machine_token: Machine token for authentication\n        \"\"\"\n        self.http_client = http_client",
        "detail": "app_backend.src.metta.app_backend.stats_client",
        "documentation": {}
    },
    {
        "label": "mock_debug_user_email",
        "kind": 2,
        "importPath": "app_backend.tests.conftest",
        "description": "app_backend.tests.conftest",
        "peekOfCode": "def mock_debug_user_email():\n    \"\"\"Mock debug_user_email for all tests to prevent local env interference.\"\"\"\n    with mock.patch(\"metta.app_backend.config.debug_user_email\", None):\n        yield",
        "detail": "app_backend.tests.conftest",
        "documentation": {}
    },
    {
        "label": "EpochConfig",
        "kind": 6,
        "importPath": "app_backend.tests.generate_test_data",
        "description": "app_backend.tests.generate_test_data",
        "peekOfCode": "class EpochConfig(TypedDict):\n    start: int\n    end: int\n    lr: str\n    performance: str\nclass TrainingRunConfig(TypedDict):\n    user: str\n    token: str\n    name: str\n    description: str",
        "detail": "app_backend.tests.generate_test_data",
        "documentation": {}
    },
    {
        "label": "TrainingRunConfig",
        "kind": 6,
        "importPath": "app_backend.tests.generate_test_data",
        "description": "app_backend.tests.generate_test_data",
        "peekOfCode": "class TrainingRunConfig(TypedDict):\n    user: str\n    token: str\n    name: str\n    description: str\n    tags: List[str]\n    url: Optional[str]\n    algorithm: str\n    env_type: str\n    epochs: List[EpochConfig]",
        "detail": "app_backend.tests.generate_test_data",
        "documentation": {}
    },
    {
        "label": "TaskSuite",
        "kind": 6,
        "importPath": "app_backend.tests.generate_test_data",
        "description": "app_backend.tests.generate_test_data",
        "peekOfCode": "class TaskSuite(TypedDict):\n    tasks: List[str]\n    metrics: List[str]\nclass PolicyData(TypedDict):\n    policy: ClientPolicyResponse\n    epoch: ClientEpochResponse\n    config: EpochConfig\n    name: str\nclass CreatedRunData(TypedDict):\n    run: ClientTrainingRunResponse",
        "detail": "app_backend.tests.generate_test_data",
        "documentation": {}
    },
    {
        "label": "PolicyData",
        "kind": 6,
        "importPath": "app_backend.tests.generate_test_data",
        "description": "app_backend.tests.generate_test_data",
        "peekOfCode": "class PolicyData(TypedDict):\n    policy: ClientPolicyResponse\n    epoch: ClientEpochResponse\n    config: EpochConfig\n    name: str\nclass CreatedRunData(TypedDict):\n    run: ClientTrainingRunResponse\n    config: TrainingRunConfig\ndef create_machine_token(base_url: str, user_email: str, token_name: str) -> str:\n    \"\"\"Create a machine token for the given user.\"\"\"",
        "detail": "app_backend.tests.generate_test_data",
        "documentation": {}
    },
    {
        "label": "CreatedRunData",
        "kind": 6,
        "importPath": "app_backend.tests.generate_test_data",
        "description": "app_backend.tests.generate_test_data",
        "peekOfCode": "class CreatedRunData(TypedDict):\n    run: ClientTrainingRunResponse\n    config: TrainingRunConfig\ndef create_machine_token(base_url: str, user_email: str, token_name: str) -> str:\n    \"\"\"Create a machine token for the given user.\"\"\"\n    with httpx.Client(base_url=base_url) as client:\n        response = client.post(\n            \"/tokens\",\n            json={\"name\": token_name},\n            headers={\"X-Auth-Request-Email\": user_email},",
        "detail": "app_backend.tests.generate_test_data",
        "documentation": {}
    },
    {
        "label": "create_machine_token",
        "kind": 2,
        "importPath": "app_backend.tests.generate_test_data",
        "description": "app_backend.tests.generate_test_data",
        "peekOfCode": "def create_machine_token(base_url: str, user_email: str, token_name: str) -> str:\n    \"\"\"Create a machine token for the given user.\"\"\"\n    with httpx.Client(base_url=base_url) as client:\n        response = client.post(\n            \"/tokens\",\n            json={\"name\": token_name},\n            headers={\"X-Auth-Request-Email\": user_email},\n        )\n        response.raise_for_status()\n        return response.json()[\"token\"]",
        "detail": "app_backend.tests.generate_test_data",
        "documentation": {}
    },
    {
        "label": "update_training_run_metadata",
        "kind": 2,
        "importPath": "app_backend.tests.generate_test_data",
        "description": "app_backend.tests.generate_test_data",
        "peekOfCode": "def update_training_run_metadata(\n    base_url: str, token: str, run_id: uuid.UUID, description: str, tags: List[str]\n) -> None:\n    \"\"\"Update training run description and tags.\"\"\"\n    with httpx.Client(base_url=base_url) as client:\n        headers = {\"X-Auth-Token\": token}\n        # Update description\n        desc_response = client.put(\n            f\"/dashboard/training-runs/{run_id}/description\",\n            json={\"description\": description},",
        "detail": "app_backend.tests.generate_test_data",
        "documentation": {}
    },
    {
        "label": "generate_test_data",
        "kind": 2,
        "importPath": "app_backend.tests.generate_test_data",
        "description": "app_backend.tests.generate_test_data",
        "peekOfCode": "def generate_test_data():\n    \"\"\"Generate comprehensive test data for the dashboard application.\"\"\"\n    base_url = \"http://127.0.0.1:8000\"\n    print(\" Starting test data generation...\")\n    # Create machine tokens for different users\n    print(\" Creating machine tokens...\")\n    user1_token = create_machine_token(base_url, \"alice@example.com\", \"test_data_generator_alice\")\n    user2_token = create_machine_token(base_url, \"bob@example.com\", \"test_data_generator_bob\")\n    user3_token = create_machine_token(base_url, \"charlie@example.com\", \"test_data_generator_charlie\")\n    # Training run configurations with rich metadata",
        "detail": "app_backend.tests.generate_test_data",
        "documentation": {}
    },
    {
        "label": "TestDockerIntegration",
        "kind": 6,
        "importPath": "app_backend.tests.test_docker_integration",
        "description": "app_backend.tests.test_docker_integration",
        "peekOfCode": "class TestDockerIntegration:\n    \"\"\"Integration tests for the app_backend Docker container.\"\"\"\n    @classmethod\n    def setup_class(cls):\n        \"\"\"Set up logging for the test class.\"\"\"\n        cls.logger = logging.getLogger(__name__)\n        if not cls.logger.handlers:\n            handler = logging.StreamHandler()\n            formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n            handler.setFormatter(formatter)",
        "detail": "app_backend.tests.test_docker_integration",
        "documentation": {}
    },
    {
        "label": "TestPolicySelector",
        "kind": 6,
        "importPath": "app_backend.tests.test_policy_selector",
        "description": "app_backend.tests.test_policy_selector",
        "peekOfCode": "class TestPolicySelector:\n    \"\"\"Integration tests for the policy_selector functionality in heatmap endpoints.\"\"\"\n    @pytest.fixture(scope=\"class\")\n    def postgres_container(self):\n        \"\"\"Create a PostgreSQL container for testing.\"\"\"\n        try:\n            container = PostgresContainer(\n                image=\"postgres:17\",\n                username=\"test_user\",\n                password=\"test_password\",",
        "detail": "app_backend.tests.test_policy_selector",
        "documentation": {}
    },
    {
        "label": "TestSavedDashboards",
        "kind": 6,
        "importPath": "app_backend.tests.test_saved_dashboards",
        "description": "app_backend.tests.test_saved_dashboards",
        "peekOfCode": "class TestSavedDashboards:\n    \"\"\"Tests for the saved dashboard functionality.\"\"\"\n    @pytest.fixture(scope=\"class\")\n    def postgres_container(self):\n        \"\"\"Create a PostgreSQL container for testing.\"\"\"\n        try:\n            container = PostgresContainer(\n                image=\"postgres:17\",\n                username=\"test_user\",\n                password=\"test_password\",",
        "detail": "app_backend.tests.test_saved_dashboards",
        "documentation": {}
    },
    {
        "label": "TestStatsServerSimple",
        "kind": 6,
        "importPath": "app_backend.tests.test_stats_server",
        "description": "app_backend.tests.test_stats_server",
        "peekOfCode": "class TestStatsServerSimple:\n    \"\"\"Simplified end-to-end tests for the stats server.\"\"\"\n    @pytest.fixture(scope=\"class\")\n    def postgres_container(self):\n        \"\"\"Create a PostgreSQL container for testing.\"\"\"\n        try:\n            container = PostgresContainer(\n                image=\"postgres:17\",\n                username=\"test_user\",\n                password=\"test_password\",",
        "detail": "app_backend.tests.test_stats_server",
        "documentation": {}
    },
    {
        "label": "TestTokenSystem",
        "kind": 6,
        "importPath": "app_backend.tests.test_token_system",
        "description": "app_backend.tests.test_token_system",
        "peekOfCode": "class TestTokenSystem:\n    \"\"\"Tests for the machine token system.\"\"\"\n    @pytest.fixture(scope=\"class\")\n    def postgres_container(self):\n        \"\"\"Create a PostgreSQL container for testing.\"\"\"\n        try:\n            container = PostgresContainer(\n                image=\"postgres:17\",\n                username=\"test_user\",\n                password=\"test_password\",",
        "detail": "app_backend.tests.test_token_system",
        "documentation": {}
    },
    {
        "label": "TestTrainingRunsRoutes",
        "kind": 6,
        "importPath": "app_backend.tests.test_training_runs_routes",
        "description": "app_backend.tests.test_training_runs_routes",
        "peekOfCode": "class TestTrainingRunsRoutes:\n    \"\"\"Tests for the training runs API routes.\"\"\"\n    @pytest.fixture(scope=\"class\")\n    def postgres_container(self):\n        \"\"\"Create a PostgreSQL container for testing.\"\"\"\n        try:\n            container = PostgresContainer(\n                image=\"postgres:17\",\n                username=\"test_user\",\n                password=\"test_password\",",
        "detail": "app_backend.tests.test_training_runs_routes",
        "documentation": {}
    },
    {
        "label": "MemoryMonitor",
        "kind": 6,
        "importPath": "common.src.metta.common.profiling.memory_monitor",
        "description": "common.src.metta.common.profiling.memory_monitor",
        "peekOfCode": "class MemoryMonitor:\n    \"\"\"Monitor memory usage of tracked objects using weak references.\"\"\"\n    def __init__(self):\n        self._tracked_objects: dict[str, dict[str, Any]] = {}\n    def add(self, obj: Any, name: str | None = None, track_attributes: bool = False) -> None:\n        \"\"\"Add object to monitor using weak references.\n        Args:\n            obj: The object to track\n            name: Optional name for the object. If None, auto-generated.\n            track_attributes: If True, also track individual attributes separately",
        "detail": "common.src.metta.common.profiling.memory_monitor",
        "documentation": {}
    },
    {
        "label": "get_object_size",
        "kind": 2,
        "importPath": "common.src.metta.common.profiling.memory_monitor",
        "description": "common.src.metta.common.profiling.memory_monitor",
        "peekOfCode": "def get_object_size(obj: Any, visited: Set[int] | None = None) -> int:\n    \"\"\"Get the deep memory usage of an object in bytes, handling circular references.\"\"\"\n    if visited is None:\n        visited = set()\n    obj_id = id(obj)\n    if obj_id in visited:\n        return 0\n    visited.add(obj_id)\n    size = 0\n    try:",
        "detail": "common.src.metta.common.profiling.memory_monitor",
        "documentation": {}
    },
    {
        "label": "Checkpoint",
        "kind": 6,
        "importPath": "common.src.metta.common.profiling.stopwatch",
        "description": "common.src.metta.common.profiling.stopwatch",
        "peekOfCode": "class Checkpoint(TypedDict):\n    \"\"\"A checkpoint/lap marker in a timer.\"\"\"\n    elapsed_time: float\n    steps: int\n@dataclass\nclass Timer:\n    \"\"\"State and statistics for a single timer.\"\"\"\n    name: str\n    start_time: float | None = None\n    total_elapsed: float = 0.0",
        "detail": "common.src.metta.common.profiling.stopwatch",
        "documentation": {}
    },
    {
        "label": "Timer",
        "kind": 6,
        "importPath": "common.src.metta.common.profiling.stopwatch",
        "description": "common.src.metta.common.profiling.stopwatch",
        "peekOfCode": "class Timer:\n    \"\"\"State and statistics for a single timer.\"\"\"\n    name: str\n    start_time: float | None = None\n    total_elapsed: float = 0.0\n    last_elapsed: float = 0.0\n    checkpoints: dict[str, Checkpoint] = field(default_factory=dict)\n    lap_counter: int = 0\n    references: set[tuple[str, int]] = field(default_factory=set)  # Changed to set of tuples\n    max_laps: int = 4",
        "detail": "common.src.metta.common.profiling.stopwatch",
        "documentation": {}
    },
    {
        "label": "Stopwatch",
        "kind": 6,
        "importPath": "common.src.metta.common.profiling.stopwatch",
        "description": "common.src.metta.common.profiling.stopwatch",
        "peekOfCode": "class Stopwatch:\n    \"\"\"A thread-safe utility class for timing code execution with support for multiple named timers.\"\"\"\n    _GLOBAL_TIMER_NAME: Final[str] = \"global\"  # Reserved name for the global timer\n    def __init__(self, logger: logging.Logger | None = None, max_laps: int = 4):\n        self.logger = logger or logging.getLogger(\"Stopwatch\")\n        self.max_laps = max_laps\n        self._timers: dict[str, Timer] = {}\n        # Create global timer but don't start it automatically\n        self._timers[self.GLOBAL_TIMER_NAME] = self._create_timer(self.GLOBAL_TIMER_NAME)\n        # Add a lock for thread safety",
        "detail": "common.src.metta.common.profiling.stopwatch",
        "documentation": {}
    },
    {
        "label": "with_timer",
        "kind": 2,
        "importPath": "common.src.metta.common.profiling.stopwatch",
        "description": "common.src.metta.common.profiling.stopwatch",
        "peekOfCode": "def with_timer(timer: \"Stopwatch\", name: str, log_level: int | None = None):\n    \"\"\"Decorator that wraps function execution in a timer context.\n    Args:\n        timer: The Stopwatch instance to use\n        name: Name of the timer\n        log_level: Optional logging level to automatically log elapsed time\n    Usage:\n        @with_timer(my_timer, \"reset\")\n        def reset(self, seed=None):\n            # method content",
        "detail": "common.src.metta.common.profiling.stopwatch",
        "documentation": {}
    },
    {
        "label": "with_instance_timer",
        "kind": 2,
        "importPath": "common.src.metta.common.profiling.stopwatch",
        "description": "common.src.metta.common.profiling.stopwatch",
        "peekOfCode": "def with_instance_timer(name: str, log_level: int | None = None, timer_attr: str = \"timer\"):\n    \"\"\"Decorator that uses a timer from the instance.\n    Args:\n        name: Name of the timer\n        log_level: Optional logging level\n        timer_attr: Name of the timer attribute on the instance (default: \"timer\")\n    Usage:\n        class MyClass:\n            def __init__(self):\n                self.timer = Stopwatch()",
        "detail": "common.src.metta.common.profiling.stopwatch",
        "documentation": {}
    },
    {
        "label": "with_lock",
        "kind": 2,
        "importPath": "common.src.metta.common.profiling.stopwatch",
        "description": "common.src.metta.common.profiling.stopwatch",
        "peekOfCode": "def with_lock(func: F) -> F:\n    \"\"\"Decorator that acquires the instance lock before executing the method.\n    Usage:\n        @with_lock\n        def my_method(self, ...):\n            # method content - automatically thread-safe\n    \"\"\"\n    @functools.wraps(func)\n    def wrapper(self, *args, **kwargs):\n        with self._lock:",
        "detail": "common.src.metta.common.profiling.stopwatch",
        "documentation": {}
    },
    {
        "label": "F",
        "kind": 5,
        "importPath": "common.src.metta.common.profiling.stopwatch",
        "description": "common.src.metta.common.profiling.stopwatch",
        "peekOfCode": "F = TypeVar(\"F\", bound=Callable[..., Any])\nclass Checkpoint(TypedDict):\n    \"\"\"A checkpoint/lap marker in a timer.\"\"\"\n    elapsed_time: float\n    steps: int\n@dataclass\nclass Timer:\n    \"\"\"State and statistics for a single timer.\"\"\"\n    name: str\n    start_time: float | None = None",
        "detail": "common.src.metta.common.profiling.stopwatch",
        "documentation": {}
    },
    {
        "label": "get_user_confirmation",
        "kind": 2,
        "importPath": "common.src.metta.common.util.cli",
        "description": "common.src.metta.common.util.cli",
        "peekOfCode": "def get_user_confirmation(prompt: str = \"Should we proceed?\") -> bool:\n    \"\"\"Get user confirmation before proceeding with an action.\"\"\"\n    response = input(f\"{prompt} (Y/n): \").strip().lower()\n    if response not in [\"\", \"y\", \"yes\"]:\n        print(yellow(\"Action cancelled by user.\"))\n        return False\n    return True\ndef sh(cmd: list[str], **kwargs) -> str:\n    \"\"\"Run a command and return its stdout (raises if the command fails).\"\"\"\n    return subprocess.check_output(cmd, text=True, **kwargs).strip()",
        "detail": "common.src.metta.common.util.cli",
        "documentation": {}
    },
    {
        "label": "sh",
        "kind": 2,
        "importPath": "common.src.metta.common.util.cli",
        "description": "common.src.metta.common.util.cli",
        "peekOfCode": "def sh(cmd: list[str], **kwargs) -> str:\n    \"\"\"Run a command and return its stdout (raises if the command fails).\"\"\"\n    return subprocess.check_output(cmd, text=True, **kwargs).strip()\ndef die(msg: str, code: int = 1):\n    print(msg, file=sys.stderr)\n    sys.exit(code)",
        "detail": "common.src.metta.common.util.cli",
        "documentation": {}
    },
    {
        "label": "die",
        "kind": 2,
        "importPath": "common.src.metta.common.util.cli",
        "description": "common.src.metta.common.util.cli",
        "peekOfCode": "def die(msg: str, code: int = 1):\n    print(msg, file=sys.stderr)\n    sys.exit(code)",
        "detail": "common.src.metta.common.util.cli",
        "documentation": {}
    },
    {
        "label": "colorize",
        "kind": 2,
        "importPath": "common.src.metta.common.util.colorama",
        "description": "common.src.metta.common.util.colorama",
        "peekOfCode": "def colorize(text, color):\n    if not USE_COLORAMA_COLORS:\n        return text\n    return f\"{color}{text}{Style.RESET_ALL}\"\ndef red(text):\n    return colorize(text, Fore.RED)\ndef green(text):\n    return colorize(text, Fore.GREEN)\ndef yellow(text):\n    return colorize(text, Fore.YELLOW)",
        "detail": "common.src.metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "red",
        "kind": 2,
        "importPath": "common.src.metta.common.util.colorama",
        "description": "common.src.metta.common.util.colorama",
        "peekOfCode": "def red(text):\n    return colorize(text, Fore.RED)\ndef green(text):\n    return colorize(text, Fore.GREEN)\ndef yellow(text):\n    return colorize(text, Fore.YELLOW)\ndef cyan(text):\n    return colorize(text, Fore.CYAN)\ndef blue(text):\n    return colorize(text, Fore.BLUE)",
        "detail": "common.src.metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "green",
        "kind": 2,
        "importPath": "common.src.metta.common.util.colorama",
        "description": "common.src.metta.common.util.colorama",
        "peekOfCode": "def green(text):\n    return colorize(text, Fore.GREEN)\ndef yellow(text):\n    return colorize(text, Fore.YELLOW)\ndef cyan(text):\n    return colorize(text, Fore.CYAN)\ndef blue(text):\n    return colorize(text, Fore.BLUE)\ndef bold(text):\n    return colorize(text, Style.BRIGHT)",
        "detail": "common.src.metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "yellow",
        "kind": 2,
        "importPath": "common.src.metta.common.util.colorama",
        "description": "common.src.metta.common.util.colorama",
        "peekOfCode": "def yellow(text):\n    return colorize(text, Fore.YELLOW)\ndef cyan(text):\n    return colorize(text, Fore.CYAN)\ndef blue(text):\n    return colorize(text, Fore.BLUE)\ndef bold(text):\n    return colorize(text, Style.BRIGHT)\ndef magenta(text):\n    return colorize(text, Fore.MAGENTA)",
        "detail": "common.src.metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "cyan",
        "kind": 2,
        "importPath": "common.src.metta.common.util.colorama",
        "description": "common.src.metta.common.util.colorama",
        "peekOfCode": "def cyan(text):\n    return colorize(text, Fore.CYAN)\ndef blue(text):\n    return colorize(text, Fore.BLUE)\ndef bold(text):\n    return colorize(text, Style.BRIGHT)\ndef magenta(text):\n    return colorize(text, Fore.MAGENTA)\ndef use_colors(use_colors: bool):\n    global USE_COLORAMA_COLORS",
        "detail": "common.src.metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "blue",
        "kind": 2,
        "importPath": "common.src.metta.common.util.colorama",
        "description": "common.src.metta.common.util.colorama",
        "peekOfCode": "def blue(text):\n    return colorize(text, Fore.BLUE)\ndef bold(text):\n    return colorize(text, Style.BRIGHT)\ndef magenta(text):\n    return colorize(text, Fore.MAGENTA)\ndef use_colors(use_colors: bool):\n    global USE_COLORAMA_COLORS\n    USE_COLORAMA_COLORS = use_colors",
        "detail": "common.src.metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "bold",
        "kind": 2,
        "importPath": "common.src.metta.common.util.colorama",
        "description": "common.src.metta.common.util.colorama",
        "peekOfCode": "def bold(text):\n    return colorize(text, Style.BRIGHT)\ndef magenta(text):\n    return colorize(text, Fore.MAGENTA)\ndef use_colors(use_colors: bool):\n    global USE_COLORAMA_COLORS\n    USE_COLORAMA_COLORS = use_colors",
        "detail": "common.src.metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "magenta",
        "kind": 2,
        "importPath": "common.src.metta.common.util.colorama",
        "description": "common.src.metta.common.util.colorama",
        "peekOfCode": "def magenta(text):\n    return colorize(text, Fore.MAGENTA)\ndef use_colors(use_colors: bool):\n    global USE_COLORAMA_COLORS\n    USE_COLORAMA_COLORS = use_colors",
        "detail": "common.src.metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "use_colors",
        "kind": 2,
        "importPath": "common.src.metta.common.util.colorama",
        "description": "common.src.metta.common.util.colorama",
        "peekOfCode": "def use_colors(use_colors: bool):\n    global USE_COLORAMA_COLORS\n    USE_COLORAMA_COLORS = use_colors",
        "detail": "common.src.metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "USE_COLORAMA_COLORS",
        "kind": 5,
        "importPath": "common.src.metta.common.util.colorama",
        "description": "common.src.metta.common.util.colorama",
        "peekOfCode": "USE_COLORAMA_COLORS = True\ndef colorize(text, color):\n    if not USE_COLORAMA_COLORS:\n        return text\n    return f\"{color}{text}{Style.RESET_ALL}\"\ndef red(text):\n    return colorize(text, Fore.RED)\ndef green(text):\n    return colorize(text, Fore.GREEN)\ndef yellow(text):",
        "detail": "common.src.metta.common.util.colorama",
        "documentation": {}
    },
    {
        "label": "Config",
        "kind": 6,
        "importPath": "common.src.metta.common.util.config",
        "description": "common.src.metta.common.util.config",
        "peekOfCode": "class Config(BaseModel):\n    \"\"\"\n    Pydantic-backed config base.\n    - extra keys are ignored\n    - you can do `MyConfig(cfg_node)` where cfg_node is a DictConfig or dict\n    - .dictconfig()  OmegaConf.DictConfig\n    - .yaml()  YAML string\n    \"\"\"\n    model_config = {\"extra\": \"forbid\"}\n    # Sub-classes of Config class should use the `__init__ = Config.__init__` trick to satisfy Pylance.",
        "detail": "common.src.metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "config_from_path",
        "kind": 2,
        "importPath": "common.src.metta.common.util.config",
        "description": "common.src.metta.common.util.config",
        "peekOfCode": "def config_from_path(config_path: str, overrides: Optional[DictConfig | ListConfig] = None) -> DictConfig | ListConfig:\n    \"\"\"\n    Load configuration from a path, with better error handling\n    Args:\n        config_path: Path to the configuration\n        overrides: Optional overrides to apply to the configuration\n    Returns:\n        The loaded configuration\n    Raises:\n        ValueError: If the config_path is None or if the configuration could not be loaded",
        "detail": "common.src.metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "copy_omegaconf_config",
        "kind": 2,
        "importPath": "common.src.metta.common.util.config",
        "description": "common.src.metta.common.util.config",
        "peekOfCode": "def copy_omegaconf_config(cfg: DictConfig | ListConfig) -> DictConfig | ListConfig:\n    return OmegaConf.create(OmegaConf.to_container(cfg, resolve=False))",
        "detail": "common.src.metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "T",
        "kind": 5,
        "importPath": "common.src.metta.common.util.config",
        "description": "common.src.metta.common.util.config",
        "peekOfCode": "T = TypeVar(\"T\")\nclass Config(BaseModel):\n    \"\"\"\n    Pydantic-backed config base.\n    - extra keys are ignored\n    - you can do `MyConfig(cfg_node)` where cfg_node is a DictConfig or dict\n    - .dictconfig()  OmegaConf.DictConfig\n    - .yaml()  YAML string\n    \"\"\"\n    model_config = {\"extra\": \"forbid\"}",
        "detail": "common.src.metta.common.util.config",
        "documentation": {}
    },
    {
        "label": "flatten_config",
        "kind": 2,
        "importPath": "common.src.metta.common.util.datastruct",
        "description": "common.src.metta.common.util.datastruct",
        "peekOfCode": "def flatten_config(obj, parent_key=\"\", sep=\".\"):\n    \"\"\"\n    Recursively flatten a nested structure of DictConfig, ListConfig, dict, and list\n    using dot notation, including indices for list items.\n    Example:\n      Input:\n        {\n          \"foo\": {\n            \"bar\": [\n              {\"a\": 1},",
        "detail": "common.src.metta.common.util.datastruct",
        "documentation": {}
    },
    {
        "label": "get_repo_root",
        "kind": 2,
        "importPath": "common.src.metta.common.util.fs",
        "description": "common.src.metta.common.util.fs",
        "peekOfCode": "def get_repo_root() -> Path:\n    \"\"\"\n    Get the repository root directory.\n    Returns:\n        Path to the repository root\n    Raises:\n        SystemExit: If repository root cannot be found\n    \"\"\"\n    current = Path.cwd().resolve()\n    search_paths = [current] + list(current.parents)",
        "detail": "common.src.metta.common.util.fs",
        "documentation": {}
    },
    {
        "label": "cd_repo_root",
        "kind": 2,
        "importPath": "common.src.metta.common.util.fs",
        "description": "common.src.metta.common.util.fs",
        "peekOfCode": "def cd_repo_root():\n    \"\"\"\n    Ensure we're running in the repository root.\n    Raises:\n        SystemExit: If repository root cannot be found\n    \"\"\"\n    repo_root = get_repo_root()\n    os.chdir(repo_root)\ndef atomic_write(\n    write_func: Callable[[Path], Any],",
        "detail": "common.src.metta.common.util.fs",
        "documentation": {}
    },
    {
        "label": "atomic_write",
        "kind": 2,
        "importPath": "common.src.metta.common.util.fs",
        "description": "common.src.metta.common.util.fs",
        "peekOfCode": "def atomic_write(\n    write_func: Callable[[Path], Any],\n    target_path: Path | str,\n    suffix: str = \".tmp\",\n) -> None:\n    \"\"\"\n    Write a file atomically by writing to a temporary file and then moving it.\n    This ensures that the target file is either fully written or not written at all,\n    preventing corruption from partial writes or concurrent access.\n    Args:",
        "detail": "common.src.metta.common.util.fs",
        "documentation": {}
    },
    {
        "label": "wait_for_file",
        "kind": 2,
        "importPath": "common.src.metta.common.util.fs",
        "description": "common.src.metta.common.util.fs",
        "peekOfCode": "def wait_for_file(\n    file_path: Path | str,\n    timeout: float = 300.0,\n    check_interval: float = 0.1,\n    stability_duration: float = 0.5,\n    min_size: int = 1,\n    progress_callback: Optional[Callable[[float, str], None]] = None,\n) -> bool:\n    \"\"\"\n    Wait for a file to be created and fully written.",
        "detail": "common.src.metta.common.util.fs",
        "documentation": {}
    },
    {
        "label": "T",
        "kind": 5,
        "importPath": "common.src.metta.common.util.fs",
        "description": "common.src.metta.common.util.fs",
        "peekOfCode": "T = TypeVar(\"T\")\ndef get_repo_root() -> Path:\n    \"\"\"\n    Get the repository root directory.\n    Returns:\n        Path to the repository root\n    Raises:\n        SystemExit: If repository root cannot be found\n    \"\"\"\n    current = Path.cwd().resolve()",
        "detail": "common.src.metta.common.util.fs",
        "documentation": {}
    },
    {
        "label": "GitError",
        "kind": 6,
        "importPath": "common.src.metta.common.util.git",
        "description": "common.src.metta.common.util.git",
        "peekOfCode": "class GitError(Exception):\n    \"\"\"Custom exception for git-related errors.\"\"\"\ndef run_git(*args: str) -> str:\n    \"\"\"Run a git command and return its output.\"\"\"\n    try:\n        result = subprocess.run([\"git\", *args], capture_output=True, text=True, check=True)\n        return result.stdout.strip()\n    except subprocess.CalledProcessError as e:\n        raise GitError(f\"Git command failed ({e.returncode}): {e.stderr.strip()}\") from e\n    except FileNotFoundError as e:",
        "detail": "common.src.metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "run_git",
        "kind": 2,
        "importPath": "common.src.metta.common.util.git",
        "description": "common.src.metta.common.util.git",
        "peekOfCode": "def run_git(*args: str) -> str:\n    \"\"\"Run a git command and return its output.\"\"\"\n    try:\n        result = subprocess.run([\"git\", *args], capture_output=True, text=True, check=True)\n        return result.stdout.strip()\n    except subprocess.CalledProcessError as e:\n        raise GitError(f\"Git command failed ({e.returncode}): {e.stderr.strip()}\") from e\n    except FileNotFoundError as e:\n        raise GitError(\"Git is not installed!\") from e\ndef run_gh(*args: str) -> str:",
        "detail": "common.src.metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "run_gh",
        "kind": 2,
        "importPath": "common.src.metta.common.util.git",
        "description": "common.src.metta.common.util.git",
        "peekOfCode": "def run_gh(*args: str) -> str:\n    \"\"\"Run a GitHub CLI command and return its output.\"\"\"\n    try:\n        result = subprocess.run([\"gh\", *args], capture_output=True, text=True, check=True)\n        return result.stdout.strip()\n    except subprocess.CalledProcessError as e:\n        raise GitError(f\"GitHub CLI command failed ({e.returncode}): {e.stderr.strip()}\") from e\n    except FileNotFoundError as e:\n        raise GitError(\"GitHub CLI (gh) is not installed!\") from e\ndef get_current_branch() -> str:",
        "detail": "common.src.metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "get_current_branch",
        "kind": 2,
        "importPath": "common.src.metta.common.util.git",
        "description": "common.src.metta.common.util.git",
        "peekOfCode": "def get_current_branch() -> str:\n    \"\"\"Get the current git branch name.\"\"\"\n    try:\n        return run_git(\"symbolic-ref\", \"--short\", \"HEAD\")\n    except GitError as e:\n        if \"not a git repository\" in str(e):\n            raise ValueError(\"Not in a git repository\") from e\n        elif \"HEAD is not a symbolic ref\" in str(e):\n            return get_current_commit()\n        raise",
        "detail": "common.src.metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "get_current_commit",
        "kind": 2,
        "importPath": "common.src.metta.common.util.git",
        "description": "common.src.metta.common.util.git",
        "peekOfCode": "def get_current_commit() -> str:\n    \"\"\"Get the current git commit hash.\"\"\"\n    return run_git(\"rev-parse\", \"HEAD\")\ndef get_branch_commit(branch: str) -> str:\n    \"\"\"Get the commit hash for a given branch.\"\"\"\n    # Fetch quietly to ensure we have latest remote data\n    try:\n        run_git(\"fetch\", \"--quiet\")\n    except GitError:\n        # Fetch failure is non-fatal, continue with local data",
        "detail": "common.src.metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "get_branch_commit",
        "kind": 2,
        "importPath": "common.src.metta.common.util.git",
        "description": "common.src.metta.common.util.git",
        "peekOfCode": "def get_branch_commit(branch: str) -> str:\n    \"\"\"Get the commit hash for a given branch.\"\"\"\n    # Fetch quietly to ensure we have latest remote data\n    try:\n        run_git(\"fetch\", \"--quiet\")\n    except GitError:\n        # Fetch failure is non-fatal, continue with local data\n        pass\n    return run_git(\"rev-parse\", branch)\ndef get_commit_message(commit_hash: str) -> str:",
        "detail": "common.src.metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "get_commit_message",
        "kind": 2,
        "importPath": "common.src.metta.common.util.git",
        "description": "common.src.metta.common.util.git",
        "peekOfCode": "def get_commit_message(commit_hash: str) -> str:\n    \"\"\"Get the commit message for a given commit.\"\"\"\n    return run_git(\"log\", \"-1\", \"--pretty=%B\", commit_hash)\ndef has_unstaged_changes() -> bool:\n    \"\"\"Check if there are any unstaged changes.\"\"\"\n    status_output = run_git(\"status\", \"--porcelain\")\n    return bool(status_output)\ndef is_commit_pushed(commit_hash: str) -> bool:\n    \"\"\"Check if a commit has been pushed to any remote branch.\"\"\"\n    # Get all remote branches that contain this commit",
        "detail": "common.src.metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "has_unstaged_changes",
        "kind": 2,
        "importPath": "common.src.metta.common.util.git",
        "description": "common.src.metta.common.util.git",
        "peekOfCode": "def has_unstaged_changes() -> bool:\n    \"\"\"Check if there are any unstaged changes.\"\"\"\n    status_output = run_git(\"status\", \"--porcelain\")\n    return bool(status_output)\ndef is_commit_pushed(commit_hash: str) -> bool:\n    \"\"\"Check if a commit has been pushed to any remote branch.\"\"\"\n    # Get all remote branches that contain this commit\n    remote_branches = run_git(\"branch\", \"-r\", \"--contains\", commit_hash)\n    return bool(remote_branches.strip())\ndef validate_git_ref(ref: str) -> str | None:",
        "detail": "common.src.metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "is_commit_pushed",
        "kind": 2,
        "importPath": "common.src.metta.common.util.git",
        "description": "common.src.metta.common.util.git",
        "peekOfCode": "def is_commit_pushed(commit_hash: str) -> bool:\n    \"\"\"Check if a commit has been pushed to any remote branch.\"\"\"\n    # Get all remote branches that contain this commit\n    remote_branches = run_git(\"branch\", \"-r\", \"--contains\", commit_hash)\n    return bool(remote_branches.strip())\ndef validate_git_ref(ref: str) -> str | None:\n    \"\"\"Validate a git reference exists (locally or in remote).\"\"\"\n    try:\n        commit_hash = run_git(\"rev-parse\", \"--verify\", ref)\n    except GitError:",
        "detail": "common.src.metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "validate_git_ref",
        "kind": 2,
        "importPath": "common.src.metta.common.util.git",
        "description": "common.src.metta.common.util.git",
        "peekOfCode": "def validate_git_ref(ref: str) -> str | None:\n    \"\"\"Validate a git reference exists (locally or in remote).\"\"\"\n    try:\n        commit_hash = run_git(\"rev-parse\", \"--verify\", ref)\n    except GitError:\n        return None\n    return commit_hash\ndef get_matched_pr(commit_hash: str) -> tuple[int, str] | None:\n    \"\"\"\n    Check if a commit is the HEAD of an open PR.",
        "detail": "common.src.metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "get_matched_pr",
        "kind": 2,
        "importPath": "common.src.metta.common.util.git",
        "description": "common.src.metta.common.util.git",
        "peekOfCode": "def get_matched_pr(commit_hash: str) -> tuple[int, str] | None:\n    \"\"\"\n    Check if a commit is the HEAD of an open PR.\n    Returns:\n        tuple(pr_number, pr_title) if commit is HEAD of an open PR, None otherwise\n    \"\"\"\n    # Get ALL open PRs by setting a high limit\n    pr_json = run_gh(\"pr\", \"list\", \"--state\", \"open\", \"--limit\", \"999\", \"--json\", \"number,title,headRefOid\")\n    prs = json.loads(pr_json)\n    for pr in prs:",
        "detail": "common.src.metta.common.util.git",
        "documentation": {}
    },
    {
        "label": "record_heartbeat",
        "kind": 2,
        "importPath": "common.src.metta.common.util.heartbeat",
        "description": "common.src.metta.common.util.heartbeat",
        "peekOfCode": "def record_heartbeat() -> None:\n    \"\"\"Record a heartbeat timestamp to the globally configured file path.\"\"\"\n    heartbeat_file_path = os.environ.get(\"HEARTBEAT_FILE\")\n    if heartbeat_file_path:\n        try:\n            # Ensure the directory for the heartbeat file exists\n            os.makedirs(os.path.dirname(heartbeat_file_path), exist_ok=True)\n            with open(heartbeat_file_path, \"w\") as f:\n                f.write(str(time.time()))\n        except Exception as exc:",
        "detail": "common.src.metta.common.util.heartbeat",
        "documentation": {}
    },
    {
        "label": "monitor_heartbeat",
        "kind": 2,
        "importPath": "common.src.metta.common.util.heartbeat",
        "description": "common.src.metta.common.util.heartbeat",
        "peekOfCode": "def monitor_heartbeat(file_path: str, pid: int, timeout: float = 600.0, check_interval: float = 60.0) -> None:\n    \"\"\"Monitor the heartbeat file and terminate the process group if stale.\"\"\"\n    while True:\n        time.sleep(check_interval)\n        try:\n            last = os.path.getmtime(file_path)\n        except FileNotFoundError:\n            last = 0.0\n        if time.time() - last > timeout:\n            logger.error(\"No heartbeat detected for %s seconds. Terminating job\", timeout)",
        "detail": "common.src.metta.common.util.heartbeat",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "common.src.metta.common.util.heartbeat",
        "description": "common.src.metta.common.util.heartbeat",
        "peekOfCode": "logger = logging.getLogger(__name__)\n# Shared IPC filename, co-located with the heartbeat signal file (must match wandb_context.py)\nWANDB_IPC_FILENAME = \"wandb_ipc.json\"\ndef record_heartbeat() -> None:\n    \"\"\"Record a heartbeat timestamp to the globally configured file path.\"\"\"\n    heartbeat_file_path = os.environ.get(\"HEARTBEAT_FILE\")\n    if heartbeat_file_path:\n        try:\n            # Ensure the directory for the heartbeat file exists\n            os.makedirs(os.path.dirname(heartbeat_file_path), exist_ok=True)",
        "detail": "common.src.metta.common.util.heartbeat",
        "documentation": {}
    },
    {
        "label": "WANDB_IPC_FILENAME",
        "kind": 5,
        "importPath": "common.src.metta.common.util.heartbeat",
        "description": "common.src.metta.common.util.heartbeat",
        "peekOfCode": "WANDB_IPC_FILENAME = \"wandb_ipc.json\"\ndef record_heartbeat() -> None:\n    \"\"\"Record a heartbeat timestamp to the globally configured file path.\"\"\"\n    heartbeat_file_path = os.environ.get(\"HEARTBEAT_FILE\")\n    if heartbeat_file_path:\n        try:\n            # Ensure the directory for the heartbeat file exists\n            os.makedirs(os.path.dirname(heartbeat_file_path), exist_ok=True)\n            with open(heartbeat_file_path, \"w\") as f:\n                f.write(str(time.time()))",
        "detail": "common.src.metta.common.util.heartbeat",
        "documentation": {}
    },
    {
        "label": "_ALERT_SEND_TIMEOUT_SECONDS",
        "kind": 5,
        "importPath": "common.src.metta.common.util.heartbeat",
        "description": "common.src.metta.common.util.heartbeat",
        "peekOfCode": "_ALERT_SEND_TIMEOUT_SECONDS = 30\n# Accepts the explicit path to the IPC file\ndef _send_wandb_alert_with_timeout(title: str, wandb_ipc_file_path: str | None) -> None:\n    \"\"\"Send a W&B alert, reading IPC data from the provided file path.\"\"\"\n    if not wandb_ipc_file_path:\n        logger.warning(f\"W&B IPC file path not provided. Cannot determine W&B run for alert: '{title}'.\")\n        return\n    # ipc_file_to_read is now wandb_ipc_file_path argument\n    run_id_ipc: str | None = None\n    project_ipc: str | None = None",
        "detail": "common.src.metta.common.util.heartbeat",
        "documentation": {}
    },
    {
        "label": "run_once",
        "kind": 2,
        "importPath": "common.src.metta.common.util.lock",
        "description": "common.src.metta.common.util.lock",
        "peekOfCode": "def run_once(fn: Callable[[], T]) -> T:\n    \"\"\"Run ``fn`` only on rank 0 and broadcast the result.\n    If ``torch.distributed`` is not initialized, this function will attempt to\n    initialize it using environment variables typically provided when running\n    multi-node jobs (``WORLD_SIZE``/``NUM_NODES`` and ``RANK``/``NODE_INDEX``).\n    The NCCL backend is used.\n    \"\"\"\n    group_initialized = _init_process_group()\n    if dist.is_initialized():\n        rank = dist.get_rank()",
        "detail": "common.src.metta.common.util.lock",
        "documentation": {}
    },
    {
        "label": "T",
        "kind": 5,
        "importPath": "common.src.metta.common.util.lock",
        "description": "common.src.metta.common.util.lock",
        "peekOfCode": "T = TypeVar(\"T\")\ndef _init_process_group() -> bool:\n    world_size = int(os.environ.get(\"WORLD_SIZE\", os.environ.get(\"NUM_NODES\", \"1\")))\n    if world_size <= 1:\n        return False\n    if dist.is_initialized():\n        return False\n    rank = int(os.environ.get(\"RANK\", os.environ.get(\"NODE_INDEX\", \"0\")))\n    dist.init_process_group(\n        backend=\"nccl\",",
        "detail": "common.src.metta.common.util.lock",
        "documentation": {}
    },
    {
        "label": "MillisecondFormatter",
        "kind": 6,
        "importPath": "common.src.metta.common.util.logging",
        "description": "common.src.metta.common.util.logging",
        "peekOfCode": "class MillisecondFormatter(logging.Formatter):\n    def formatTime(self, record: logging.LogRecord, datefmt: str | None = None) -> str:\n        created = datetime.fromtimestamp(record.created)\n        # Convert microseconds to milliseconds (keep only 3 digits)\n        msec = created.microsecond // 1000\n        if datefmt:\n            # Replace %f with just 3 digits for milliseconds\n            datefmt = datefmt.replace(\"%f\", f\"{msec:03d}\")\n        else:\n            datefmt = \"[%H:%M:%S.%03d]\"",
        "detail": "common.src.metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "AlwaysShowTimeRichHandler",
        "kind": 6,
        "importPath": "common.src.metta.common.util.logging",
        "description": "common.src.metta.common.util.logging",
        "peekOfCode": "class AlwaysShowTimeRichHandler(RichHandler):\n    def emit(self, record: logging.LogRecord) -> None:\n        # Force a unique timestamp for each record\n        record.created = record.created + (record.relativeCreated % 1000) / 1000000\n        super().emit(record)\ndef get_log_level(provided_level: str | None = None) -> str:\n    \"\"\"\n    Determine log level based on priority:\n    1. Environment variable LOG_LEVEL\n    2. Provided level parameter",
        "detail": "common.src.metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "remap_io",
        "kind": 2,
        "importPath": "common.src.metta.common.util.logging",
        "description": "common.src.metta.common.util.logging",
        "peekOfCode": "def remap_io(logs_path: str):\n    os.makedirs(logs_path, exist_ok=True)\n    stdout_log_path = os.path.join(logs_path, \"out.log\")\n    stderr_log_path = os.path.join(logs_path, \"error.log\")\n    stdout = open(stdout_log_path, \"a\")\n    stderr = open(stderr_log_path, \"a\")\n    sys.stderr = stderr\n    sys.stdout = stdout\n    # Remove all handlers from root logger when remapping IO\n    root_logger = logging.getLogger()",
        "detail": "common.src.metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "restore_io",
        "kind": 2,
        "importPath": "common.src.metta.common.util.logging",
        "description": "common.src.metta.common.util.logging",
        "peekOfCode": "def restore_io():\n    sys.stderr = sys.__stderr__\n    sys.stdout = sys.__stdout__\n# Create a custom formatter that supports milliseconds\nclass MillisecondFormatter(logging.Formatter):\n    def formatTime(self, record: logging.LogRecord, datefmt: str | None = None) -> str:\n        created = datetime.fromtimestamp(record.created)\n        # Convert microseconds to milliseconds (keep only 3 digits)\n        msec = created.microsecond // 1000\n        if datefmt:",
        "detail": "common.src.metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "get_log_level",
        "kind": 2,
        "importPath": "common.src.metta.common.util.logging",
        "description": "common.src.metta.common.util.logging",
        "peekOfCode": "def get_log_level(provided_level: str | None = None) -> str:\n    \"\"\"\n    Determine log level based on priority:\n    1. Environment variable LOG_LEVEL\n    2. Provided level parameter\n    3. Default to INFO\n    \"\"\"\n    # Check environment variable first\n    env_level = os.environ.get(\"LOG_LEVEL\")\n    if env_level:",
        "detail": "common.src.metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_logger",
        "kind": 2,
        "importPath": "common.src.metta.common.util.logging",
        "description": "common.src.metta.common.util.logging",
        "peekOfCode": "def setup_mettagrid_logger(name: str, level: str | None = None) -> logging.Logger:\n    # Get the appropriate log level based on priority\n    log_level = get_log_level(level)\n    # Remove all handlers from the root logger\n    root_logger = logging.getLogger()\n    for handler in root_logger.handlers[:]:\n        root_logger.removeHandler(handler)\n    # Add back our custom Rich handler\n    rich_handler = AlwaysShowTimeRichHandler(rich_tracebacks=True)\n    formatter = MillisecondFormatter(\"%(message)s\", datefmt=\"[%H:%M:%S.%f]\")",
        "detail": "common.src.metta.common.util.logging",
        "documentation": {}
    },
    {
        "label": "MettagridCfgFileMetadata",
        "kind": 6,
        "importPath": "common.src.metta.common.util.mettagrid_cfgs",
        "description": "common.src.metta.common.util.mettagrid_cfgs",
        "peekOfCode": "class MettagridCfgFileMetadata:\n    path: str\n    kind: CfgKind\n    @staticmethod\n    def from_path(path: str) -> \"MettagridCfgFileMetadata\":\n        kind = \"unknown\"\n        # Detect config kind with heuristics.\n        # We could load the cfg and parse it, but Hydra takes too long for 150+ configs.\n        if path.startswith(\"game/map_builder/\"):\n            kind = \"map\"",
        "detail": "common.src.metta.common.util.mettagrid_cfgs",
        "documentation": {}
    },
    {
        "label": "MettagridCfgFile",
        "kind": 6,
        "importPath": "common.src.metta.common.util.mettagrid_cfgs",
        "description": "common.src.metta.common.util.mettagrid_cfgs",
        "peekOfCode": "class MettagridCfgFile:\n    metadata: MettagridCfgFileMetadata\n    cfg: DictConfig\n    class AsDict(TypedDict):\n        metadata: dict\n        cfg: dict\n    def to_dict(self) -> AsDict:\n        cfg_dict = OmegaConf.to_container(self.cfg, resolve=False)\n        assert isinstance(cfg_dict, dict)\n        return {",
        "detail": "common.src.metta.common.util.mettagrid_cfgs",
        "documentation": {}
    },
    {
        "label": "METTAGRID_CFG_ROOT",
        "kind": 5,
        "importPath": "common.src.metta.common.util.mettagrid_cfgs",
        "description": "common.src.metta.common.util.mettagrid_cfgs",
        "peekOfCode": "METTAGRID_CFG_ROOT = \"env/mettagrid\"\nCfgKind = Literal[\"env\", \"curriculum\", \"map\", \"unknown\"]\n@dataclass\nclass MettagridCfgFileMetadata:\n    path: str\n    kind: CfgKind\n    @staticmethod\n    def from_path(path: str) -> \"MettagridCfgFileMetadata\":\n        kind = \"unknown\"\n        # Detect config kind with heuristics.",
        "detail": "common.src.metta.common.util.mettagrid_cfgs",
        "documentation": {}
    },
    {
        "label": "CfgKind",
        "kind": 5,
        "importPath": "common.src.metta.common.util.mettagrid_cfgs",
        "description": "common.src.metta.common.util.mettagrid_cfgs",
        "peekOfCode": "CfgKind = Literal[\"env\", \"curriculum\", \"map\", \"unknown\"]\n@dataclass\nclass MettagridCfgFileMetadata:\n    path: str\n    kind: CfgKind\n    @staticmethod\n    def from_path(path: str) -> \"MettagridCfgFileMetadata\":\n        kind = \"unknown\"\n        # Detect config kind with heuristics.\n        # We could load the cfg and parse it, but Hydra takes too long for 150+ configs.",
        "detail": "common.src.metta.common.util.mettagrid_cfgs",
        "documentation": {}
    },
    {
        "label": "clean_numpy_types",
        "kind": 2,
        "importPath": "common.src.metta.common.util.numpy_helpers",
        "description": "common.src.metta.common.util.numpy_helpers",
        "peekOfCode": "def clean_numpy_types(obj: Any) -> Any:\n    \"\"\"Recursively convert numpy types to Python native types.\"\"\"\n    if isinstance(obj, np.ndarray):\n        return obj.item() if obj.size == 1 else obj.tolist()\n    elif isinstance(obj, np.generic):\n        return obj.item()\n    elif isinstance(obj, dict):\n        return {k: clean_numpy_types(v) for k, v in obj.items()}\n    elif isinstance(obj, list):\n        return [clean_numpy_types(v) for v in obj]",
        "detail": "common.src.metta.common.util.numpy_helpers",
        "documentation": {}
    },
    {
        "label": "convert_to_dict",
        "kind": 2,
        "importPath": "common.src.metta.common.util.omegaconf",
        "description": "common.src.metta.common.util.omegaconf",
        "peekOfCode": "def convert_to_dict(config, resolve: bool = True) -> Dict[str, Any]:\n    \"\"\"\n    Convert OmegaConf config to a standard Python dictionary with string keys.\n    Raises ValueError if the config structure resolves to a list or other non-dict type.\n    Args:\n        config: The OmegaConf config to convert\n        resolve: Whether to resolve interpolations\n    Returns:\n        Dict[str, Any]: A standard Python dictionary with string keys\n    Raises:",
        "detail": "common.src.metta.common.util.omegaconf",
        "documentation": {}
    },
    {
        "label": "KT",
        "kind": 5,
        "importPath": "common.src.metta.common.util.omegaconf",
        "description": "common.src.metta.common.util.omegaconf",
        "peekOfCode": "KT = TypeVar(\"KT\")\ndef convert_to_dict(config, resolve: bool = True) -> Dict[str, Any]:\n    \"\"\"\n    Convert OmegaConf config to a standard Python dictionary with string keys.\n    Raises ValueError if the config structure resolves to a list or other non-dict type.\n    Args:\n        config: The OmegaConf config to convert\n        resolve: Whether to resolve interpolations\n    Returns:\n        Dict[str, Any]: A standard Python dictionary with string keys",
        "detail": "common.src.metta.common.util.omegaconf",
        "documentation": {}
    },
    {
        "label": "ResolverRegistrar",
        "kind": 6,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "class ResolverRegistrar(Callback):\n    \"\"\"Class for registering custom OmegaConf resolvers.\"\"\"\n    def __init__(self):\n        self.logger = setup_mettagrid_logger(\"ResolverRegistrar\")\n        self.resolver_count = 0\n        \"\"\"Prepare for registration but don't register yet.\"\"\"\n    def on_run_start(self, config: DictConfig, **kwargs: Any) -> None:\n        \"\"\"Register resolvers at the start of a run.\"\"\"\n        self.register_resolvers()\n        self.logger.info(f\"Registered {self.resolver_count} custom resolvers at the start of a run\")",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_if",
        "kind": 2,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "def oc_if(condition: bool, true_value: T, false_value: T) -> T:\n    return true_value if condition else false_value\ndef oc_uniform(min_val: Numeric, max_val: Numeric) -> float:\n    return float(np.random.uniform(min_val, max_val))\ndef oc_choose(*args: Any) -> Any:\n    return random.choice(args)\ndef oc_divide(a: Numeric, b: Numeric) -> Numeric:\n    \"\"\"\n    Divide a by b, returning an int if both inputs are ints and result is a whole number,\n    otherwise return a float.",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_uniform",
        "kind": 2,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "def oc_uniform(min_val: Numeric, max_val: Numeric) -> float:\n    return float(np.random.uniform(min_val, max_val))\ndef oc_choose(*args: Any) -> Any:\n    return random.choice(args)\ndef oc_divide(a: Numeric, b: Numeric) -> Numeric:\n    \"\"\"\n    Divide a by b, returning an int if both inputs are ints and result is a whole number,\n    otherwise return a float.\n    \"\"\"\n    result = a / b",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_choose",
        "kind": 2,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "def oc_choose(*args: Any) -> Any:\n    return random.choice(args)\ndef oc_divide(a: Numeric, b: Numeric) -> Numeric:\n    \"\"\"\n    Divide a by b, returning an int if both inputs are ints and result is a whole number,\n    otherwise return a float.\n    \"\"\"\n    result = a / b\n    # If both inputs are integers and the result is a whole number, return as int\n    if isinstance(a, int) and isinstance(b, int) and result.is_integer():",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_divide",
        "kind": 2,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "def oc_divide(a: Numeric, b: Numeric) -> Numeric:\n    \"\"\"\n    Divide a by b, returning an int if both inputs are ints and result is a whole number,\n    otherwise return a float.\n    \"\"\"\n    result = a / b\n    # If both inputs are integers and the result is a whole number, return as int\n    if isinstance(a, int) and isinstance(b, int) and result.is_integer():\n        return int(result)\n    return result",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_subtract",
        "kind": 2,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "def oc_subtract(a: Numeric, b: Numeric) -> Numeric:\n    return a - b\ndef oc_multiply(a: Numeric, b: Numeric) -> Numeric:\n    return a * b\ndef oc_add(a: Numeric, b: Numeric) -> Numeric:\n    return a + b\ndef oc_to_odd_min3(a: Numeric) -> int:\n    \"\"\"\n    Ensure a value is odd and at least 3.\n    \"\"\"",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_multiply",
        "kind": 2,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "def oc_multiply(a: Numeric, b: Numeric) -> Numeric:\n    return a * b\ndef oc_add(a: Numeric, b: Numeric) -> Numeric:\n    return a + b\ndef oc_to_odd_min3(a: Numeric) -> int:\n    \"\"\"\n    Ensure a value is odd and at least 3.\n    \"\"\"\n    return max(3, int(a) // 2 * 2 + 1)\ndef oc_clamp(value: Numeric, min_val: Numeric, max_val: Numeric) -> Numeric:",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_add",
        "kind": 2,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "def oc_add(a: Numeric, b: Numeric) -> Numeric:\n    return a + b\ndef oc_to_odd_min3(a: Numeric) -> int:\n    \"\"\"\n    Ensure a value is odd and at least 3.\n    \"\"\"\n    return max(3, int(a) // 2 * 2 + 1)\ndef oc_clamp(value: Numeric, min_val: Numeric, max_val: Numeric) -> Numeric:\n    return max(min_val, min(max_val, value))\ndef oc_make_integer(value: Numeric) -> int:",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_to_odd_min3",
        "kind": 2,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "def oc_to_odd_min3(a: Numeric) -> int:\n    \"\"\"\n    Ensure a value is odd and at least 3.\n    \"\"\"\n    return max(3, int(a) // 2 * 2 + 1)\ndef oc_clamp(value: Numeric, min_val: Numeric, max_val: Numeric) -> Numeric:\n    return max(min_val, min(max_val, value))\ndef oc_make_integer(value: Numeric) -> int:\n    return int(round(value))\ndef oc_equals(a: Any, b: Any) -> bool:",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_clamp",
        "kind": 2,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "def oc_clamp(value: Numeric, min_val: Numeric, max_val: Numeric) -> Numeric:\n    return max(min_val, min(max_val, value))\ndef oc_make_integer(value: Numeric) -> int:\n    return int(round(value))\ndef oc_equals(a: Any, b: Any) -> bool:\n    return a == b\ndef oc_greater_than(a: Any, b: Any) -> bool:\n    return a > b\ndef oc_less_than(a: Any, b: Any) -> bool:\n    return a < b",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_make_integer",
        "kind": 2,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "def oc_make_integer(value: Numeric) -> int:\n    return int(round(value))\ndef oc_equals(a: Any, b: Any) -> bool:\n    return a == b\ndef oc_greater_than(a: Any, b: Any) -> bool:\n    return a > b\ndef oc_less_than(a: Any, b: Any) -> bool:\n    return a < b\ndef oc_greater_than_or_equal(a: Any, b: Any) -> bool:\n    return a >= b",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_equals",
        "kind": 2,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "def oc_equals(a: Any, b: Any) -> bool:\n    return a == b\ndef oc_greater_than(a: Any, b: Any) -> bool:\n    return a > b\ndef oc_less_than(a: Any, b: Any) -> bool:\n    return a < b\ndef oc_greater_than_or_equal(a: Any, b: Any) -> bool:\n    return a >= b\ndef oc_less_than_or_equal(a: Any, b: Any) -> bool:\n    return a <= b",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_greater_than",
        "kind": 2,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "def oc_greater_than(a: Any, b: Any) -> bool:\n    return a > b\ndef oc_less_than(a: Any, b: Any) -> bool:\n    return a < b\ndef oc_greater_than_or_equal(a: Any, b: Any) -> bool:\n    return a >= b\ndef oc_less_than_or_equal(a: Any, b: Any) -> bool:\n    return a <= b\ndef oc_scale(\n    value: Numeric, in_min: Numeric, in_max: Numeric, out_min: Numeric, out_max: Numeric, scale_type: str = \"linear\"",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_less_than",
        "kind": 2,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "def oc_less_than(a: Any, b: Any) -> bool:\n    return a < b\ndef oc_greater_than_or_equal(a: Any, b: Any) -> bool:\n    return a >= b\ndef oc_less_than_or_equal(a: Any, b: Any) -> bool:\n    return a <= b\ndef oc_scale(\n    value: Numeric, in_min: Numeric, in_max: Numeric, out_min: Numeric, out_max: Numeric, scale_type: str = \"linear\"\n) -> Numeric:\n    \"\"\"",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_greater_than_or_equal",
        "kind": 2,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "def oc_greater_than_or_equal(a: Any, b: Any) -> bool:\n    return a >= b\ndef oc_less_than_or_equal(a: Any, b: Any) -> bool:\n    return a <= b\ndef oc_scale(\n    value: Numeric, in_min: Numeric, in_max: Numeric, out_min: Numeric, out_max: Numeric, scale_type: str = \"linear\"\n) -> Numeric:\n    \"\"\"\n    Scale a value from one range to another using different scaling methods.\n    Parameters:",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_less_than_or_equal",
        "kind": 2,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "def oc_less_than_or_equal(a: Any, b: Any) -> bool:\n    return a <= b\ndef oc_scale(\n    value: Numeric, in_min: Numeric, in_max: Numeric, out_min: Numeric, out_max: Numeric, scale_type: str = \"linear\"\n) -> Numeric:\n    \"\"\"\n    Scale a value from one range to another using different scaling methods.\n    Parameters:\n    -----------\n    value : Numeric",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_scale",
        "kind": 2,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "def oc_scale(\n    value: Numeric, in_min: Numeric, in_max: Numeric, out_min: Numeric, out_max: Numeric, scale_type: str = \"linear\"\n) -> Numeric:\n    \"\"\"\n    Scale a value from one range to another using different scaling methods.\n    Parameters:\n    -----------\n    value : Numeric\n        The input value to scale\n    in_min : Numeric",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_scaled_range",
        "kind": 2,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "def oc_scaled_range(lower_limit: Numeric, upper_limit: Numeric, center: Numeric, *, _root_: Dict[str, Any]) -> Numeric:\n    \"\"\"\n    Generates a value centered around a specified point based on a \"sampling\" parameter that controls how\n    widely the distribution spreads between the limiting values.\n    Parameters:\n    -----------\n    lower_limit : Numeric\n        The minimum allowed value (lower boundary).\n    upper_limit : Numeric\n        The maximum allowed value (upper boundary).",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_iir",
        "kind": 2,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "def oc_iir(alpha: Numeric, current_value: Numeric, last_value: Numeric) -> Numeric:\n    \"\"\"\n    Apply an IIR (Infinite Impulse Response) filter.\n    This is a first-order low-pass filter that computes:\n    y[n] = alpha * x[n] + (1-alpha) * y[n-1]\n    Parameters:\n    -----------`\n    alpha : Numeric\n        Filter coefficient (0 < alpha < 1). Lower values create more smoothing.\n    current_value : Numeric",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "oc_date_format",
        "kind": 2,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "def oc_date_format(format_string: str) -> str:\n    \"\"\"\n    Generate a formatted date string using the current date and time.\n    Parameters:\n    -----------\n    format_string : str\n        A format string following either:\n        - Python datetime strftime format codes (starting with %)\n        - Simplified format codes like \"MMDD\", \"YYYYMMDD\", etc.\n    Returns:",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "register_resolvers",
        "kind": 2,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "def register_resolvers():\n    \"\"\"Legacy function that creates a registrar and registers resolvers.\"\"\"\n    registrar = ResolverRegistrar()\n    registrar.register_resolvers()",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "T",
        "kind": 5,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "T = TypeVar(\"T\")  # For generic conditional function\nNumeric = Union[int, float]  # Type alias for numeric types\ndef oc_if(condition: bool, true_value: T, false_value: T) -> T:\n    return true_value if condition else false_value\ndef oc_uniform(min_val: Numeric, max_val: Numeric) -> float:\n    return float(np.random.uniform(min_val, max_val))\ndef oc_choose(*args: Any) -> Any:\n    return random.choice(args)\ndef oc_divide(a: Numeric, b: Numeric) -> Numeric:\n    \"\"\"",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "Numeric",
        "kind": 5,
        "importPath": "common.src.metta.common.util.resolvers",
        "description": "common.src.metta.common.util.resolvers",
        "peekOfCode": "Numeric = Union[int, float]  # Type alias for numeric types\ndef oc_if(condition: bool, true_value: T, false_value: T) -> T:\n    return true_value if condition else false_value\ndef oc_uniform(min_val: Numeric, max_val: Numeric) -> float:\n    return float(np.random.uniform(min_val, max_val))\ndef oc_choose(*args: Any) -> Any:\n    return random.choice(args)\ndef oc_divide(a: Numeric, b: Numeric) -> Numeric:\n    \"\"\"\n    Divide a by b, returning an int if both inputs are ints and result is a whole number,",
        "detail": "common.src.metta.common.util.resolvers",
        "documentation": {}
    },
    {
        "label": "seed_everything",
        "kind": 2,
        "importPath": "common.src.metta.common.util.runtime_configuration",
        "description": "common.src.metta.common.util.runtime_configuration",
        "peekOfCode": "def seed_everything(seed, torch_deterministic, rank: int = 0):\n    # Despite these efforts, we still don't get deterministic behavior. But presumably\n    # this is better than nothing.\n    # https://docs.pytorch.org/docs/stable/notes/randomness.html#reproducibility\n    # Add rank offset to base seed for distributed training to ensure different\n    # processes generate uncorrelated random sequences\n    if seed is not None:\n        rank_specific_seed = seed + rank\n    else:\n        rank_specific_seed = rank",
        "detail": "common.src.metta.common.util.runtime_configuration",
        "documentation": {}
    },
    {
        "label": "setup_mettagrid_environment",
        "kind": 2,
        "importPath": "common.src.metta.common.util.runtime_configuration",
        "description": "common.src.metta.common.util.runtime_configuration",
        "peekOfCode": "def setup_mettagrid_environment(cfg: DictConfig) -> None:\n    \"\"\"\n    Configure the runtime environment for MettagridGrid simulations.\n    Initializes CUDA, sets thread counts, and handles reproducibility settings.\n    Parameters:\n    -----------\n    cfg : DictConfig\n        Configuration containing torch_deterministic flag and other runtime settings\n    \"\"\"\n    # Validate device configuration",
        "detail": "common.src.metta.common.util.runtime_configuration",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "common.src.metta.common.util.runtime_configuration",
        "description": "common.src.metta.common.util.runtime_configuration",
        "peekOfCode": "logger = logging.getLogger(\"runtime_configuration\")\ndef seed_everything(seed, torch_deterministic, rank: int = 0):\n    # Despite these efforts, we still don't get deterministic behavior. But presumably\n    # this is better than nothing.\n    # https://docs.pytorch.org/docs/stable/notes/randomness.html#reproducibility\n    # Add rank offset to base seed for distributed training to ensure different\n    # processes generate uncorrelated random sequences\n    if seed is not None:\n        rank_specific_seed = seed + rank\n    else:",
        "detail": "common.src.metta.common.util.runtime_configuration",
        "documentation": {}
    },
    {
        "label": "metta_script",
        "kind": 2,
        "importPath": "common.src.metta.common.util.script_decorators",
        "description": "common.src.metta.common.util.script_decorators",
        "peekOfCode": "def metta_script(func: Callable[..., T]) -> Callable[..., T]:\n    \"\"\"\n    Decorator for Metta script entry points that performs device validation.\n    This decorator checks that the requested device is available and valid.\n    It will raise an error if CUDA is requested but not available.\n    \"\"\"\n    @functools.wraps(func)\n    def wrapper(cfg: DictConfig | ListConfig, *args, **kwargs) -> T:\n        logger = setup_mettagrid_logger(\"metta_script\")\n        # Get the device from config",
        "detail": "common.src.metta.common.util.script_decorators",
        "documentation": {}
    },
    {
        "label": "T",
        "kind": 5,
        "importPath": "common.src.metta.common.util.script_decorators",
        "description": "common.src.metta.common.util.script_decorators",
        "peekOfCode": "T = TypeVar(\"T\")\ndef metta_script(func: Callable[..., T]) -> Callable[..., T]:\n    \"\"\"\n    Decorator for Metta script entry points that performs device validation.\n    This decorator checks that the requested device is available and valid.\n    It will raise an error if CUDA is requested but not available.\n    \"\"\"\n    @functools.wraps(func)\n    def wrapper(cfg: DictConfig | ListConfig, *args, **kwargs) -> T:\n        logger = setup_mettagrid_logger(\"metta_script\")",
        "detail": "common.src.metta.common.util.script_decorators",
        "documentation": {}
    },
    {
        "label": "get_machine_token",
        "kind": 2,
        "importPath": "common.src.metta.common.util.stats_client_cfg",
        "description": "common.src.metta.common.util.stats_client_cfg",
        "peekOfCode": "def get_machine_token() -> str | None:\n    env_token = os.getenv(\"METTA_API_KEY\")\n    if env_token is not None:\n        token = env_token\n    else:\n        token_file = os.path.expanduser(\"~/.metta/observatory_token\")\n        if os.path.exists(token_file):\n            with open(token_file) as f:\n                token = f.read().strip()\n        else:",
        "detail": "common.src.metta.common.util.stats_client_cfg",
        "documentation": {}
    },
    {
        "label": "get_stats_client",
        "kind": 2,
        "importPath": "common.src.metta.common.util.stats_client_cfg",
        "description": "common.src.metta.common.util.stats_client_cfg",
        "peekOfCode": "def get_stats_client(cfg: DictConfig | ListConfig, logger: Logger) -> StatsClient | None:\n    if isinstance(cfg, DictConfig):\n        stats_server_uri: str | None = cfg.get(\"stats_server_uri\", None)\n        machine_token = get_machine_token()\n        if stats_server_uri is not None and machine_token is not None:\n            logger.info(f\"Using stats client at {stats_server_uri}\")\n            http_client = Client(base_url=stats_server_uri)\n            return StatsClient(http_client=http_client, machine_token=machine_token)\n        else:\n            if stats_server_uri is None:",
        "detail": "common.src.metta.common.util.stats_client_cfg",
        "documentation": {}
    },
    {
        "label": "SystemMonitor",
        "kind": 6,
        "importPath": "common.src.metta.common.util.system_monitor",
        "description": "common.src.metta.common.util.system_monitor",
        "peekOfCode": "class SystemMonitor:\n    \"\"\"A utility class for monitoring system statistics with support for multiple metrics.\n    Monitors CPU, memory, GPU (if available), and process metrics with configurable\n    sampling intervals and history retention. Cross-platform compatible and designed\n    for both local development and containerized environments.\n    \"\"\"\n    def __init__(\n        self,\n        sampling_interval_sec: float = 1.0,\n        history_size: int = 100,",
        "detail": "common.src.metta.common.util.system_monitor",
        "documentation": {}
    },
    {
        "label": "Tracer",
        "kind": 6,
        "importPath": "common.src.metta.common.util.tracing",
        "description": "common.src.metta.common.util.tracing",
        "peekOfCode": "class Tracer:\n    \"\"\"Helper class for with tracer(\"my_section\"):\"\"\"\n    def __init__(self, name: str):\n        self.name = name\n        self.start = 0\n    def __enter__(self):\n        self.start = time.time()\n    def __exit__(self, exc_type, exc_value, traceback):\n        self.end = time.time()\n        self.duration = self.end - self.start",
        "detail": "common.src.metta.common.util.tracing",
        "documentation": {}
    },
    {
        "label": "trace",
        "kind": 2,
        "importPath": "common.src.metta.common.util.tracing",
        "description": "common.src.metta.common.util.tracing",
        "peekOfCode": "def trace(fn):\n    \"\"\"Adds tracing to a function.\n    Usage:\n    @trace\n    def my_function(a, b):\n        return a + b\n    my_function(1, 2)\n    \"\"\"\n    def trace_wrapper(*args, **kwargs):\n        name = fn.__name__",
        "detail": "common.src.metta.common.util.tracing",
        "documentation": {}
    },
    {
        "label": "tracer",
        "kind": 2,
        "importPath": "common.src.metta.common.util.tracing",
        "description": "common.src.metta.common.util.tracing",
        "peekOfCode": "def tracer(name: str):\n    \"\"\"Tracing a block with statement\n    Usage:\n    with tracer(\"my_section\"):\n        # Your code here\n    \"\"\"\n    return Tracer(name)\ndef save_trace(filename):\n    ## Saves the trace to a file.\n    with open(filename, \"w\") as f:",
        "detail": "common.src.metta.common.util.tracing",
        "documentation": {}
    },
    {
        "label": "save_trace",
        "kind": 2,
        "importPath": "common.src.metta.common.util.tracing",
        "description": "common.src.metta.common.util.tracing",
        "peekOfCode": "def save_trace(filename):\n    ## Saves the trace to a file.\n    with open(filename, \"w\") as f:\n        data = {\n            \"traceEvents\": trace_events,\n            \"displayTimeUnit\": \"ms\",\n        }\n        json.dump(data, f)\nif __name__ == \"__main__\":\n    @trace",
        "detail": "common.src.metta.common.util.tracing",
        "documentation": {}
    },
    {
        "label": "start_time",
        "kind": 5,
        "importPath": "common.src.metta.common.util.tracing",
        "description": "common.src.metta.common.util.tracing",
        "peekOfCode": "start_time = time.time()\ntrace_events = []\ndef trace(fn):\n    \"\"\"Adds tracing to a function.\n    Usage:\n    @trace\n    def my_function(a, b):\n        return a + b\n    my_function(1, 2)\n    \"\"\"",
        "detail": "common.src.metta.common.util.tracing",
        "documentation": {}
    },
    {
        "label": "trace_events",
        "kind": 5,
        "importPath": "common.src.metta.common.util.tracing",
        "description": "common.src.metta.common.util.tracing",
        "peekOfCode": "trace_events = []\ndef trace(fn):\n    \"\"\"Adds tracing to a function.\n    Usage:\n    @trace\n    def my_function(a, b):\n        return a + b\n    my_function(1, 2)\n    \"\"\"\n    def trace_wrapper(*args, **kwargs):",
        "detail": "common.src.metta.common.util.tracing",
        "documentation": {}
    },
    {
        "label": "BaseModelWithForbidExtra",
        "kind": 6,
        "importPath": "common.src.metta.common.util.typed_config",
        "description": "common.src.metta.common.util.typed_config",
        "peekOfCode": "class BaseModelWithForbidExtra(BaseModel):\n    model_config: ClassVar[ConfigDict] = ConfigDict(extra=\"forbid\")",
        "detail": "common.src.metta.common.util.typed_config",
        "documentation": {}
    },
    {
        "label": "get_run_metrics",
        "kind": 2,
        "importPath": "common.src.metta.common.wandb.collect_metrics",
        "description": "common.src.metta.common.wandb.collect_metrics",
        "peekOfCode": "def get_run_metrics(entity: str, project: str, run_id: str) -> set[str] | None:\n    \"\"\"Fetch all metrics from a wandb run.\"\"\"\n    # Initialize wandb API\n    api = wandb.Api()\n    try:\n        run = api.run(f\"{entity}/{project}/{run_id}\")\n    except Exception as e:\n        print(f\"Error accessing run: {e}\")\n        return None\n    metrics = set()",
        "detail": "common.src.metta.common.wandb.collect_metrics",
        "documentation": {}
    },
    {
        "label": "load_existing_metrics",
        "kind": 2,
        "importPath": "common.src.metta.common.wandb.collect_metrics",
        "description": "common.src.metta.common.wandb.collect_metrics",
        "peekOfCode": "def load_existing_metrics(filepath: str) -> set[str]:\n    \"\"\"Load existing metrics from CSV file.\"\"\"\n    metrics = set()\n    if os.path.exists(filepath):\n        print(f\"Loading existing metrics from {filepath}...\")\n        with open(filepath, \"r\") as f:\n            for line in f:\n                line = line.strip()\n                if line:\n                    metrics.add(line)",
        "detail": "common.src.metta.common.wandb.collect_metrics",
        "documentation": {}
    },
    {
        "label": "save_metrics_to_csv",
        "kind": 2,
        "importPath": "common.src.metta.common.wandb.collect_metrics",
        "description": "common.src.metta.common.wandb.collect_metrics",
        "peekOfCode": "def save_metrics_to_csv(metrics: set[str], filepath: str) -> None:\n    \"\"\"Save metrics to CSV file, one per line, alphabetically sorted.\"\"\"\n    sorted_metrics = sorted(metrics)\n    with open(filepath, \"w\") as f:\n        for metric in sorted_metrics:\n            f.write(metric + \"\\n\")\n    print(f\"Saved {len(sorted_metrics)} total metrics to {filepath}\")\ndef main() -> None:\n    # Defaults\n    entity = \"metta-research\"",
        "detail": "common.src.metta.common.wandb.collect_metrics",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "common.src.metta.common.wandb.collect_metrics",
        "description": "common.src.metta.common.wandb.collect_metrics",
        "peekOfCode": "def main() -> None:\n    # Defaults\n    entity = \"metta-research\"\n    project = \"metta\"\n    default_run_names = [\n        \"github.sky.main.f634b79.20250701_203512\",\n        \"daphne.moretime.nav_memory_sequence.navigation_finetuned.06-25\",\n        # Add more default run IDs here\n    ]\n    # Command line arguments",
        "detail": "common.src.metta.common.wandb.collect_metrics",
        "documentation": {}
    },
    {
        "label": "parse_metrics_file",
        "kind": 2,
        "importPath": "common.src.metta.common.wandb.generate_docs",
        "description": "common.src.metta.common.wandb.generate_docs",
        "peekOfCode": "def parse_metrics_file(filepath):\n    \"\"\"Parse the wandb_metrics.csv file and return organized metrics.\"\"\"\n    sections = defaultdict(lambda: defaultdict(list))\n    with open(filepath, \"r\") as f:\n        lines = f.readlines()\n    # Parse metrics - each line is a metric\n    for line in lines:\n        line = line.strip()\n        # Skip empty lines\n        if not line:",
        "detail": "common.src.metta.common.wandb.generate_docs",
        "documentation": {}
    },
    {
        "label": "analyze_metric_patterns",
        "kind": 2,
        "importPath": "common.src.metta.common.wandb.generate_docs",
        "description": "common.src.metta.common.wandb.generate_docs",
        "peekOfCode": "def analyze_metric_patterns(metrics):\n    \"\"\"Analyze common patterns in metrics.\"\"\"\n    patterns = {\n        \"statistics\": [\".avg\", \".std_dev\", \".min\", \".max\", \".first_step\", \".last_step\", \".rate\", \".updates\"],\n        \"activity\": [\".activity_rate\", \".activity_rate.std_dev\"],\n        \"agent_specific\": [\".agent\", \".agent.agent\"],\n        \"outcomes\": [\".success\", \".failed\", \".won\", \".lost\"],\n        \"timing\": [\"msec/\", \"frac/\", \"active_frac/\"],\n    }\n    categorized = defaultdict(list)",
        "detail": "common.src.metta.common.wandb.generate_docs",
        "documentation": {}
    },
    {
        "label": "generate_aggregation_section",
        "kind": 2,
        "importPath": "common.src.metta.common.wandb.generate_docs",
        "description": "common.src.metta.common.wandb.generate_docs",
        "peekOfCode": "def generate_aggregation_section():\n    \"\"\"Generate the metric aggregation documentation section.\"\"\"\n    aggregation_section = \"\"\"\n## Metric Aggregation Strategy\nMetta uses a multi-stage aggregation pipeline to produce the final metrics logged to WandB:\n### Aggregation Pipeline\n```\nPer-Agent Values  Per-Episode Means  Cross-Episode Means  WandB Logs\n```\n### Detailed Aggregation Table",
        "detail": "common.src.metta.common.wandb.generate_docs",
        "documentation": {}
    },
    {
        "label": "generate_main_readme",
        "kind": 2,
        "importPath": "common.src.metta.common.wandb.generate_docs",
        "description": "common.src.metta.common.wandb.generate_docs",
        "peekOfCode": "def generate_main_readme(sections, output_dir, descriptions):\n    \"\"\"Generate the main README.md file.\"\"\"\n    content = \"\"\"# WandB Metrics Documentation\nThis directory contains comprehensive documentation for all metrics logged to Weights & Biases (WandB) during\nMetta training runs.\n## Overview\nOur WandB logging captures detailed metrics across multiple categories to monitor training progress, agent\nbehavior, environment dynamics, and system performance.\n## Metric Categories\n| Section | Description | Metric Count |",
        "detail": "common.src.metta.common.wandb.generate_docs",
        "documentation": {}
    },
    {
        "label": "get_section_description",
        "kind": 2,
        "importPath": "common.src.metta.common.wandb.generate_docs",
        "description": "common.src.metta.common.wandb.generate_docs",
        "peekOfCode": "def get_section_description(section, descriptions=None):\n    \"\"\"Get a description for each section.\"\"\"\n    # Check if we have a custom description in the YAML\n    if descriptions and \"sections\" in descriptions and section in descriptions[\"sections\"]:\n        return descriptions[\"sections\"][section][\"description\"].strip()\n    # Fall back to default descriptions\n    default_descriptions = {\n        \"env_agent\": \"Agent actions, rewards, and item interactions\",\n        \"env_attributes\": \"Environment configuration and episode attributes\",\n        \"env_game\": \"Game object counts and token tracking\",",
        "detail": "common.src.metta.common.wandb.generate_docs",
        "documentation": {}
    },
    {
        "label": "group_related_metrics",
        "kind": 2,
        "importPath": "common.src.metta.common.wandb.generate_docs",
        "description": "common.src.metta.common.wandb.generate_docs",
        "peekOfCode": "def group_related_metrics(metrics):\n    \"\"\"Group metrics by their base name, consolidating all related statistics.\"\"\"\n    groups = defaultdict(list)\n    for metric in metrics:\n        # Remove the section prefix to get the metric path\n        parts = metric.split(\"/\")\n        if len(parts) > 2:\n            metric_path = \"/\".join(parts[2:])\n        else:\n            metric_path = parts[-1]",
        "detail": "common.src.metta.common.wandb.generate_docs",
        "documentation": {}
    },
    {
        "label": "generate_section_readme",
        "kind": 2,
        "importPath": "common.src.metta.common.wandb.generate_docs",
        "description": "common.src.metta.common.wandb.generate_docs",
        "peekOfCode": "def generate_section_readme(section, subsections, output_dir, descriptions):\n    \"\"\"Generate README for a specific section.\"\"\"\n    section_dir = Path(output_dir) / section\n    section_dir.mkdir(parents=True, exist_ok=True)\n    # Analyze all metrics in this section\n    all_metrics = []\n    for metrics in subsections.values():\n        all_metrics.extend(metrics)\n    content = f\"\"\"# {section.replace(\"_\", \" \").title()} Metrics\n## Overview",
        "detail": "common.src.metta.common.wandb.generate_docs",
        "documentation": {}
    },
    {
        "label": "load_metric_descriptions",
        "kind": 2,
        "importPath": "common.src.metta.common.wandb.generate_docs",
        "description": "common.src.metta.common.wandb.generate_docs",
        "peekOfCode": "def load_metric_descriptions(script_dir):\n    \"\"\"Load metric descriptions from YAML file.\"\"\"\n    yaml_path = os.path.join(script_dir, \"metric_descriptions.yaml\")\n    if os.path.exists(yaml_path):\n        with open(yaml_path, \"r\") as f:\n            return yaml.safe_load(f)\n    return {}\ndef get_metric_description(metric, descriptions):\n    \"\"\"Get description for a specific metric.\"\"\"\n    metrics_section = descriptions.get(\"metrics\", {})",
        "detail": "common.src.metta.common.wandb.generate_docs",
        "documentation": {}
    },
    {
        "label": "get_metric_description",
        "kind": 2,
        "importPath": "common.src.metta.common.wandb.generate_docs",
        "description": "common.src.metta.common.wandb.generate_docs",
        "peekOfCode": "def get_metric_description(metric, descriptions):\n    \"\"\"Get description for a specific metric.\"\"\"\n    metrics_section = descriptions.get(\"metrics\", {})\n    if metric in metrics_section and \"description\" in metrics_section[metric]:\n        desc = metrics_section[metric][\"description\"].strip()\n        # Add unit if specified\n        if \"unit\" in metrics_section[metric]:\n            desc += f\" (Unit: {metrics_section[metric]['unit']})\"\n        # Add interpretation if specified\n        if \"interpretation\" in metrics_section[metric]:",
        "detail": "common.src.metta.common.wandb.generate_docs",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "common.src.metta.common.wandb.generate_docs",
        "description": "common.src.metta.common.wandb.generate_docs",
        "peekOfCode": "def main():\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n    metrics_file = os.path.join(script_dir, \"wandb_metrics.csv\")\n    root_dir = get_repo_root()\n    output_dir = os.path.join(root_dir, \"docs\", \"wandb\", \"metrics\")\n    if not os.path.exists(metrics_file):\n        print(f\"Error: {metrics_file} not found!\")\n        print(\"Please run collect_metrics.py first to generate the metrics file.\")\n        return\n    print(f\"Parsing metrics from {metrics_file}...\")",
        "detail": "common.src.metta.common.wandb.generate_docs",
        "documentation": {}
    },
    {
        "label": "sweep_id_from_name",
        "kind": 2,
        "importPath": "common.src.metta.common.wandb.sweep",
        "description": "common.src.metta.common.wandb.sweep",
        "peekOfCode": "def sweep_id_from_name(project: str, entity: str, name: str) -> str:\n    api = wandb.Api()\n    sweeps = api.project(project, entity).sweeps()\n    for sweep in sweeps:\n        if sweep.name == name:\n            return sweep.id\n    return None\ndef generate_run_id_for_sweep(sweep_id: str, sweep_runs_dir: str) -> str:\n    api = wandb.Api()\n    sweep = api.sweep(sweep_id)",
        "detail": "common.src.metta.common.wandb.sweep",
        "documentation": {}
    },
    {
        "label": "generate_run_id_for_sweep",
        "kind": 2,
        "importPath": "common.src.metta.common.wandb.sweep",
        "description": "common.src.metta.common.wandb.sweep",
        "peekOfCode": "def generate_run_id_for_sweep(sweep_id: str, sweep_runs_dir: str) -> str:\n    api = wandb.Api()\n    sweep = api.sweep(sweep_id)\n    used_ids = set()\n    used_names = set(run.name for run in sweep.runs).union(set(os.listdir(sweep_runs_dir)))\n    for name in used_names:\n        try:\n            id = int(name.split(\".\")[-1])\n            used_ids.add(id)\n        except ValueError:",
        "detail": "common.src.metta.common.wandb.sweep",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "common.src.metta.common.wandb.sweep",
        "description": "common.src.metta.common.wandb.sweep",
        "peekOfCode": "logger = logging.getLogger(\"sweep\")\ndef sweep_id_from_name(project: str, entity: str, name: str) -> str:\n    api = wandb.Api()\n    sweeps = api.project(project, entity).sweeps()\n    for sweep in sweeps:\n        if sweep.name == name:\n            return sweep.id\n    return None\ndef generate_run_id_for_sweep(sweep_id: str, sweep_runs_dir: str) -> str:\n    api = wandb.Api()",
        "detail": "common.src.metta.common.wandb.sweep",
        "documentation": {}
    },
    {
        "label": "WandbConfigOn",
        "kind": 6,
        "importPath": "common.src.metta.common.wandb.wandb_context",
        "description": "common.src.metta.common.wandb.wandb_context",
        "peekOfCode": "class WandbConfigOn(Config):\n    enabled: Literal[True] = True\n    project: str\n    entity: str\n    group: str\n    name: str\n    run_id: str\n    data_dir: str\n    job_type: str\n    tags: list[str] = []",
        "detail": "common.src.metta.common.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "WandbConfigOff",
        "kind": 6,
        "importPath": "common.src.metta.common.wandb.wandb_context",
        "description": "common.src.metta.common.wandb.wandb_context",
        "peekOfCode": "class WandbConfigOff(Config, extra=\"allow\"):\n    enabled: Literal[False] = False\nWandbConfig = Annotated[Union[WandbConfigOff, WandbConfigOn], Field(discriminator=\"enabled\")]\nclass WandbContext:\n    \"\"\"\n    Context manager for Wandb.\n    Usually initialized in the following way:\n        with WandbContext(cfg.wandb, cfg) as wandb_run:\n            ...\n    \"\"\"",
        "detail": "common.src.metta.common.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "WandbContext",
        "kind": 6,
        "importPath": "common.src.metta.common.wandb.wandb_context",
        "description": "common.src.metta.common.wandb.wandb_context",
        "peekOfCode": "class WandbContext:\n    \"\"\"\n    Context manager for Wandb.\n    Usually initialized in the following way:\n        with WandbContext(cfg.wandb, cfg) as wandb_run:\n            ...\n    \"\"\"\n    def __init__(\n        self,\n        # Either a `DictConfig` from Hydra, or already validated `WandbConfig` object.",
        "detail": "common.src.metta.common.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "common.src.metta.common.wandb.wandb_context",
        "description": "common.src.metta.common.wandb.wandb_context",
        "peekOfCode": "logger = logging.getLogger(__name__)\n# Alias type for easier usage (other modules can import this type)\nWandbRun = wandb.sdk.wandb_run.Run\n# Shared IPC filename, co-located with the heartbeat signal file\nWANDB_IPC_FILENAME = \"wandb_ipc.json\"\nclass WandbConfigOn(Config):\n    enabled: Literal[True] = True\n    project: str\n    entity: str\n    group: str",
        "detail": "common.src.metta.common.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "WandbRun",
        "kind": 5,
        "importPath": "common.src.metta.common.wandb.wandb_context",
        "description": "common.src.metta.common.wandb.wandb_context",
        "peekOfCode": "WandbRun = wandb.sdk.wandb_run.Run\n# Shared IPC filename, co-located with the heartbeat signal file\nWANDB_IPC_FILENAME = \"wandb_ipc.json\"\nclass WandbConfigOn(Config):\n    enabled: Literal[True] = True\n    project: str\n    entity: str\n    group: str\n    name: str\n    run_id: str",
        "detail": "common.src.metta.common.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "WANDB_IPC_FILENAME",
        "kind": 5,
        "importPath": "common.src.metta.common.wandb.wandb_context",
        "description": "common.src.metta.common.wandb.wandb_context",
        "peekOfCode": "WANDB_IPC_FILENAME = \"wandb_ipc.json\"\nclass WandbConfigOn(Config):\n    enabled: Literal[True] = True\n    project: str\n    entity: str\n    group: str\n    name: str\n    run_id: str\n    data_dir: str\n    job_type: str",
        "detail": "common.src.metta.common.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "WandbConfig",
        "kind": 5,
        "importPath": "common.src.metta.common.wandb.wandb_context",
        "description": "common.src.metta.common.wandb.wandb_context",
        "peekOfCode": "WandbConfig = Annotated[Union[WandbConfigOff, WandbConfigOn], Field(discriminator=\"enabled\")]\nclass WandbContext:\n    \"\"\"\n    Context manager for Wandb.\n    Usually initialized in the following way:\n        with WandbContext(cfg.wandb, cfg) as wandb_run:\n            ...\n    \"\"\"\n    def __init__(\n        self,",
        "detail": "common.src.metta.common.wandb.wandb_context",
        "documentation": {}
    },
    {
        "label": "test_basic_memory_calculation",
        "kind": 2,
        "importPath": "common.tests.profiling.test_memory_monitor",
        "description": "common.tests.profiling.test_memory_monitor",
        "peekOfCode": "def test_basic_memory_calculation():\n    \"\"\"Test that memory size calculation works for basic types.\"\"\"\n    # Simple types\n    assert get_object_size(42) == sys.getsizeof(42)\n    assert get_object_size(\"hello\") == sys.getsizeof(\"hello\")\n    # List with items\n    test_list = [1, 2, 3, 4, 5]\n    expected = sys.getsizeof(test_list) + sum(sys.getsizeof(i) for i in test_list)\n    assert get_object_size(test_list) == expected\n    # Dict with items",
        "detail": "common.tests.profiling.test_memory_monitor",
        "documentation": {}
    },
    {
        "label": "test_object_with_attributes",
        "kind": 2,
        "importPath": "common.tests.profiling.test_memory_monitor",
        "description": "common.tests.profiling.test_memory_monitor",
        "peekOfCode": "def test_object_with_attributes():\n    \"\"\"Test memory calculation for objects with __dict__.\"\"\"\n    class TestObj:\n        def __init__(self):\n            self.x = 100\n            self.y = \"test\"\n    obj = TestObj()\n    size = get_object_size(obj)\n    # Should include object + __dict__ + attributes\n    min_expected = sys.getsizeof(obj) + sys.getsizeof(obj.__dict__)",
        "detail": "common.tests.profiling.test_memory_monitor",
        "documentation": {}
    },
    {
        "label": "test_memory_growth",
        "kind": 2,
        "importPath": "common.tests.profiling.test_memory_monitor",
        "description": "common.tests.profiling.test_memory_monitor",
        "peekOfCode": "def test_memory_growth():\n    \"\"\"Test that memory grows with data size.\"\"\"\n    small = list(range(10))\n    large = list(range(10000))\n    assert get_object_size(small) < get_object_size(large)\n    assert get_object_size(large) > 100000  # Should be > 100KB",
        "detail": "common.tests.profiling.test_memory_monitor",
        "documentation": {}
    },
    {
        "label": "TestStopwatch",
        "kind": 6,
        "importPath": "common.tests.profiling.test_stopwatch",
        "description": "common.tests.profiling.test_stopwatch",
        "peekOfCode": "class TestStopwatch:\n    \"\"\"Test suite for Stopwatch class.\"\"\"\n    def test_initialization(self):\n        \"\"\"Test stopwatch initialization.\"\"\"\n        # Test with default logger\n        sw = Stopwatch()\n        assert isinstance(sw.logger, logging.Logger)\n        assert sw.logger.name == \"Stopwatch\"\n        assert sw.GLOBAL_TIMER_NAME == \"global\"\n        assert sw.GLOBAL_TIMER_NAME in sw._timers",
        "detail": "common.tests.profiling.test_stopwatch",
        "documentation": {}
    },
    {
        "label": "TestStopwatchIntegration",
        "kind": 6,
        "importPath": "common.tests.profiling.test_stopwatch",
        "description": "common.tests.profiling.test_stopwatch",
        "peekOfCode": "class TestStopwatchIntegration:\n    \"\"\"Integration tests for more complex scenarios.\"\"\"\n    def test_multiple_concurrent_timers(self):\n        \"\"\"Test managing multiple concurrent timers.\"\"\"\n        sw = Stopwatch()\n        # Start multiple timers in sequence\n        sw.start(\"download\")\n        time.sleep(0.05)\n        sw.start(\"processing\")\n        time.sleep(0.05)",
        "detail": "common.tests.profiling.test_stopwatch",
        "documentation": {}
    },
    {
        "label": "TestStopwatchSaveLoad",
        "kind": 6,
        "importPath": "common.tests.profiling.test_stopwatch",
        "description": "common.tests.profiling.test_stopwatch",
        "peekOfCode": "class TestStopwatchSaveLoad:\n    \"\"\"Test save/load functionality of Stopwatch.\"\"\"\n    def test_save_load_basic(self, stopwatch):\n        \"\"\"Test basic save and load functionality.\"\"\"\n        # Create some timer state\n        stopwatch.start(\"timer1\")\n        time.sleep(0.1)\n        stopwatch.stop(\"timer1\")\n        stopwatch.start(\"timer2\")\n        time.sleep(0.05)",
        "detail": "common.tests.profiling.test_stopwatch",
        "documentation": {}
    },
    {
        "label": "stopwatch",
        "kind": 2,
        "importPath": "common.tests.profiling.test_stopwatch",
        "description": "common.tests.profiling.test_stopwatch",
        "peekOfCode": "def stopwatch():\n    \"\"\"Stopwatch fixture with default logger.\"\"\"\n    return Stopwatch()\n@pytest.fixture(autouse=True)\ndef cleanup():\n    \"\"\"Ensure clean state between tests.\"\"\"\n    yield\n    # Cleanup after each test if needed\nclass TestStopwatch:\n    \"\"\"Test suite for Stopwatch class.\"\"\"",
        "detail": "common.tests.profiling.test_stopwatch",
        "documentation": {}
    },
    {
        "label": "cleanup",
        "kind": 2,
        "importPath": "common.tests.profiling.test_stopwatch",
        "description": "common.tests.profiling.test_stopwatch",
        "peekOfCode": "def cleanup():\n    \"\"\"Ensure clean state between tests.\"\"\"\n    yield\n    # Cleanup after each test if needed\nclass TestStopwatch:\n    \"\"\"Test suite for Stopwatch class.\"\"\"\n    def test_initialization(self):\n        \"\"\"Test stopwatch initialization.\"\"\"\n        # Test with default logger\n        sw = Stopwatch()",
        "detail": "common.tests.profiling.test_stopwatch",
        "documentation": {}
    },
    {
        "label": "test_cleanup_old_checkpoints_preserves_order",
        "kind": 2,
        "importPath": "common.tests.profiling.test_stopwatch",
        "description": "common.tests.profiling.test_stopwatch",
        "peekOfCode": "def test_cleanup_old_checkpoints_preserves_order():\n    \"\"\"Test that _cleanup_old_checkpoints maintains chronological order.\"\"\"\n    stopwatch = Stopwatch(max_laps=3)\n    timer_name = \"test_timer\"\n    # Create a timer and add checkpoints in chronological order\n    timer = stopwatch._get_timer(timer_name)\n    # Manually add checkpoints to ensure we know the exact order and timing\n    checkpoints_data = [\n        (\"checkpoint_1\", 1.0, 100),\n        (\"checkpoint_2\", 2.0, 200),",
        "detail": "common.tests.profiling.test_stopwatch",
        "documentation": {}
    },
    {
        "label": "test_multiple_laps_after_cleanup",
        "kind": 2,
        "importPath": "common.tests.profiling.test_stopwatch",
        "description": "common.tests.profiling.test_stopwatch",
        "peekOfCode": "def test_multiple_laps_after_cleanup():\n    \"\"\"Test multiple lap indices after cleanup.\"\"\"\n    stopwatch = Stopwatch(max_laps=2)  # Very restrictive to force cleanup\n    timer = stopwatch._get_timer()\n    # Add more checkpoints than max_laps allows\n    checkpoints_data = [\n        (\"_lap_1\", 1.0, 100),\n        (\"_lap_2\", 2.0, 250),  # 150 step lap\n        (\"_lap_3\", 3.0, 400),  # 150 step lap\n        (\"_lap_4\", 4.0, 600),  # 200 step lap",
        "detail": "common.tests.profiling.test_stopwatch",
        "documentation": {}
    },
    {
        "label": "TestGetUserConfirmation",
        "kind": 6,
        "importPath": "common.tests.util.test_cli",
        "description": "common.tests.util.test_cli",
        "peekOfCode": "class TestGetUserConfirmation:\n    \"\"\"Test cases for the get_user_confirmation function.\"\"\"\n    @patch(\"builtins.input\")\n    @patch(\"builtins.print\")\n    def test_confirmation_yes_responses(self, mock_print, mock_input):\n        \"\"\"Test that various 'yes' responses return True.\"\"\"\n        yes_responses = [\"\", \"y\", \"Y\", \"yes\", \"YES\", \"Yes\"]\n        for response in yes_responses:\n            mock_input.return_value = response\n            result = get_user_confirmation(\"Test prompt\")",
        "detail": "common.tests.util.test_cli",
        "documentation": {}
    },
    {
        "label": "TestSh",
        "kind": 6,
        "importPath": "common.tests.util.test_cli",
        "description": "common.tests.util.test_cli",
        "peekOfCode": "class TestSh:\n    \"\"\"Test cases for the sh function.\"\"\"\n    @patch(\"subprocess.check_output\")\n    def test_sh_successful_command(self, mock_check_output):\n        \"\"\"Test sh function with a successful command.\"\"\"\n        mock_check_output.return_value = \"command output\\n\"\n        result = sh([\"echo\", \"hello\"])\n        assert result == \"command output\"\n        mock_check_output.assert_called_once_with([\"echo\", \"hello\"], text=True)\n    @patch(\"subprocess.check_output\")",
        "detail": "common.tests.util.test_cli",
        "documentation": {}
    },
    {
        "label": "TestDie",
        "kind": 6,
        "importPath": "common.tests.util.test_cli",
        "description": "common.tests.util.test_cli",
        "peekOfCode": "class TestDie:\n    \"\"\"Test cases for the die function.\"\"\"\n    @patch(\"sys.exit\")\n    @patch(\"builtins.print\")\n    def test_die_default_exit_code(self, mock_print, mock_exit):\n        \"\"\"Test die function with default exit code.\"\"\"\n        die(\"Error message\")\n        mock_print.assert_called_once_with(\"Error message\", file=sys.stderr)\n        mock_exit.assert_called_once_with(1)\n    @patch(\"sys.exit\")",
        "detail": "common.tests.util.test_cli",
        "documentation": {}
    },
    {
        "label": "TestCliIntegration",
        "kind": 6,
        "importPath": "common.tests.util.test_cli",
        "description": "common.tests.util.test_cli",
        "peekOfCode": "class TestCliIntegration:\n    \"\"\"Integration tests for CLI utility functions.\"\"\"\n    @patch(\"builtins.input\")\n    @patch(\"subprocess.check_output\")\n    def test_confirmation_and_command_execution(self, mock_check_output, mock_input):\n        \"\"\"Test integration of confirmation and command execution.\"\"\"\n        mock_input.return_value = \"y\"\n        mock_check_output.return_value = \"success\\n\"\n        # Simulate a workflow where user confirms and then command runs\n        if get_user_confirmation(\"Run command?\"):",
        "detail": "common.tests.util.test_cli",
        "documentation": {}
    },
    {
        "label": "TestColoramaUtils",
        "kind": 6,
        "importPath": "common.tests.util.test_colorama",
        "description": "common.tests.util.test_colorama",
        "peekOfCode": "class TestColoramaUtils:\n    \"\"\"Test cases for colorama utility functions.\"\"\"\n    def setup_method(self):\n        \"\"\"Reset color settings before each test.\"\"\"\n        use_colors(True)\n    def test_colorize_with_colors_enabled(self):\n        \"\"\"Test colorize function when colors are enabled.\"\"\"\n        text = \"test text\"\n        color = Fore.RED\n        result = colorize(text, color)",
        "detail": "common.tests.util.test_colorama",
        "documentation": {}
    },
    {
        "label": "TestFlattenConfig",
        "kind": 6,
        "importPath": "common.tests.util.test_datastruct",
        "description": "common.tests.util.test_datastruct",
        "peekOfCode": "class TestFlattenConfig:\n    \"\"\"Test cases for the flatten_config function.\"\"\"\n    def test_flatten_simple_dict(self):\n        \"\"\"Test flattening a simple dictionary.\"\"\"\n        input_dict = {\"a\": 1, \"b\": 2, \"c\": 3}\n        expected = {\"a\": 1, \"b\": 2, \"c\": 3}\n        result = flatten_config(input_dict)\n        assert result == expected\n    def test_flatten_nested_dict(self):\n        \"\"\"Test flattening a nested dictionary.\"\"\"",
        "detail": "common.tests.util.test_datastruct",
        "documentation": {}
    },
    {
        "label": "test_get_current_branch",
        "kind": 2,
        "importPath": "common.tests.util.test_git",
        "description": "common.tests.util.test_git",
        "peekOfCode": "def test_get_current_branch():\n    branch = get_current_branch()\n    assert isinstance(branch, str)\n    assert len(branch) > 0\ndef test_get_current_commit():\n    commit = get_current_commit()\n    assert isinstance(commit, str)\n    assert len(commit) == 40  # SHA-1 hash\ndef test_run_git_error_propagation():\n    with pytest.raises(GitError) as e:",
        "detail": "common.tests.util.test_git",
        "documentation": {}
    },
    {
        "label": "test_get_current_commit",
        "kind": 2,
        "importPath": "common.tests.util.test_git",
        "description": "common.tests.util.test_git",
        "peekOfCode": "def test_get_current_commit():\n    commit = get_current_commit()\n    assert isinstance(commit, str)\n    assert len(commit) == 40  # SHA-1 hash\ndef test_run_git_error_propagation():\n    with pytest.raises(GitError) as e:\n        run_git(\"branch\", \"--contains\", \"invalid-invalid-invalid\")\n    assert \"malformed object name\" in str(e.value).lower()\ndef test_get_branch_commit():\n    # Test with current branch",
        "detail": "common.tests.util.test_git",
        "documentation": {}
    },
    {
        "label": "test_run_git_error_propagation",
        "kind": 2,
        "importPath": "common.tests.util.test_git",
        "description": "common.tests.util.test_git",
        "peekOfCode": "def test_run_git_error_propagation():\n    with pytest.raises(GitError) as e:\n        run_git(\"branch\", \"--contains\", \"invalid-invalid-invalid\")\n    assert \"malformed object name\" in str(e.value).lower()\ndef test_get_branch_commit():\n    # Test with current branch\n    current_branch = get_current_branch()\n    branch_commit = get_branch_commit(current_branch)\n    assert isinstance(branch_commit, str)\n    assert len(branch_commit) == 40",
        "detail": "common.tests.util.test_git",
        "documentation": {}
    },
    {
        "label": "test_get_branch_commit",
        "kind": 2,
        "importPath": "common.tests.util.test_git",
        "description": "common.tests.util.test_git",
        "peekOfCode": "def test_get_branch_commit():\n    # Test with current branch\n    current_branch = get_current_branch()\n    branch_commit = get_branch_commit(current_branch)\n    assert isinstance(branch_commit, str)\n    assert len(branch_commit) == 40\n    assert branch_commit == get_current_commit()\n    # Test with invalid branch\n    with pytest.raises(GitError):\n        get_branch_commit(\"non-existent-branch-name\")",
        "detail": "common.tests.util.test_git",
        "documentation": {}
    },
    {
        "label": "test_get_commit_message",
        "kind": 2,
        "importPath": "common.tests.util.test_git",
        "description": "common.tests.util.test_git",
        "peekOfCode": "def test_get_commit_message():\n    # Get message for current commit\n    current_commit = get_current_commit()\n    message = get_commit_message(current_commit)\n    assert isinstance(message, str)\n    assert len(message) > 0\n    # Test with invalid commit\n    with pytest.raises(GitError):\n        get_commit_message(\"invalid-commit-hash\")\ndef test_has_unstaged_changes():",
        "detail": "common.tests.util.test_git",
        "documentation": {}
    },
    {
        "label": "test_has_unstaged_changes",
        "kind": 2,
        "importPath": "common.tests.util.test_git",
        "description": "common.tests.util.test_git",
        "peekOfCode": "def test_has_unstaged_changes():\n    # First, ensure we have a clean state\n    had_changes = has_unstaged_changes()\n    if had_changes:\n        subprocess.run([\"git\", \"stash\", \"push\", \"-m\", \"test_stash\"], check=True)\n    try:\n        # Test clean state\n        assert not has_unstaged_changes()\n        # Create a temporary file to test unstaged changes\n        test_file = \"test_temp_file.txt\"",
        "detail": "common.tests.util.test_git",
        "documentation": {}
    },
    {
        "label": "test_is_commit_pushed",
        "kind": 2,
        "importPath": "common.tests.util.test_git",
        "description": "common.tests.util.test_git",
        "peekOfCode": "def test_is_commit_pushed():\n    # Test with current commit\n    current_commit = get_current_commit()\n    result = is_commit_pushed(current_commit)\n    assert isinstance(result, bool)\n    # Test with invalid commit - should raise GitError\n    with pytest.raises(GitError):\n        is_commit_pushed(\"invalid-commit-hash\")\n@pytest.mark.parametrize(\n    \"ref,expected_valid\",",
        "detail": "common.tests.util.test_git",
        "documentation": {}
    },
    {
        "label": "test_validate_git_ref",
        "kind": 2,
        "importPath": "common.tests.util.test_git",
        "description": "common.tests.util.test_git",
        "peekOfCode": "def test_validate_git_ref(ref, expected_valid):\n    commit_hash = validate_git_ref(ref)\n    if expected_valid:\n        assert commit_hash is not None\n        assert len(commit_hash) == 40  # SHA-1 hashes are 40 chars\n    else:\n        assert commit_hash is None\ndef test_validate_git_ref_with_commit():\n    # Test with current commit and short version\n    current_commit = get_current_commit()",
        "detail": "common.tests.util.test_git",
        "documentation": {}
    },
    {
        "label": "test_validate_git_ref_with_commit",
        "kind": 2,
        "importPath": "common.tests.util.test_git",
        "description": "common.tests.util.test_git",
        "peekOfCode": "def test_validate_git_ref_with_commit():\n    # Test with current commit and short version\n    current_commit = get_current_commit()\n    # Test with full commit hash\n    commit_hash = validate_git_ref(current_commit)\n    assert commit_hash == current_commit\n    # Test with short commit hash\n    commit_hash = validate_git_ref(current_commit[:8])\n    assert commit_hash == current_commit  # Git should resolve short hash to full hash\ndef test_remote_operations():",
        "detail": "common.tests.util.test_git",
        "documentation": {}
    },
    {
        "label": "test_remote_operations",
        "kind": 2,
        "importPath": "common.tests.util.test_git",
        "description": "common.tests.util.test_git",
        "peekOfCode": "def test_remote_operations():\n    # Test operations with remote branches if available\n    for remote_ref in [\"origin/HEAD\", \"origin/main\", \"origin/master\"]:\n        try:\n            # Test get_branch_commit with remote\n            commit = get_branch_commit(remote_ref)\n            assert isinstance(commit, str)\n            assert len(commit) == 40\n            # Test validate_git_ref with remote\n            commit_hash = validate_git_ref(remote_ref)",
        "detail": "common.tests.util.test_git",
        "documentation": {}
    },
    {
        "label": "test_validate_git_ref_returns_commit_hash",
        "kind": 2,
        "importPath": "common.tests.util.test_git",
        "description": "common.tests.util.test_git",
        "peekOfCode": "def test_validate_git_ref_returns_commit_hash():\n    # Test that validate_git_ref returns the commit hash\n    commit_hash = validate_git_ref(\"HEAD\")\n    assert commit_hash == get_current_commit()\n    # Test invalid ref returns None\n    commit_hash = validate_git_ref(\"invalid-ref\")\n    assert commit_hash is None\ndef test_detached_head_fallback():\n    # Save current state\n    original_branch = get_current_branch()",
        "detail": "common.tests.util.test_git",
        "documentation": {}
    },
    {
        "label": "test_detached_head_fallback",
        "kind": 2,
        "importPath": "common.tests.util.test_git",
        "description": "common.tests.util.test_git",
        "peekOfCode": "def test_detached_head_fallback():\n    # Save current state\n    original_branch = get_current_branch()\n    try:\n        # Detach HEAD\n        run_git(\"checkout\", \"--detach\")\n        # Should return commit hash when detached\n        result = get_current_branch()\n        assert result == get_current_commit()\n        assert len(result) == 40",
        "detail": "common.tests.util.test_git",
        "documentation": {}
    },
    {
        "label": "TestCleanNumpyTypes",
        "kind": 6,
        "importPath": "common.tests.util.test_numpy_helpers",
        "description": "common.tests.util.test_numpy_helpers",
        "peekOfCode": "class TestCleanNumpyTypes:\n    \"\"\"Test cases for clean_numpy_types function.\"\"\"\n    def test_numpy_scalar_conversion(self):\n        \"\"\"Test conversion of numpy scalar types to Python types.\"\"\"\n        # Test various numpy scalar types\n        assert clean_numpy_types(np.int32(42)) == 42\n        assert isinstance(clean_numpy_types(np.int32(42)), int)\n        assert clean_numpy_types(np.float64(3.14)) == 3.14\n        assert isinstance(clean_numpy_types(np.float64(3.14)), float)\n        assert clean_numpy_types(np.bool_(True)) is True",
        "detail": "common.tests.util.test_numpy_helpers",
        "documentation": {}
    },
    {
        "label": "add",
        "kind": 2,
        "importPath": "common.tests.util.test_pydantic_validation",
        "description": "common.tests.util.test_pydantic_validation",
        "peekOfCode": "def add(x: int, y: int) -> int:\n    return x + y\ndef test_validate_correct_types():\n    assert add(1, 2) == 3\ndef test_validate_incorrect_types():\n    # Note: Pydantic will try to coerce types, so \"1\" would be converted to 1\n    # We need to use a value that can't be coerced to test validation\n    with pytest.raises(ValidationError):\n        add(\"not_a_number\", 2)",
        "detail": "common.tests.util.test_pydantic_validation",
        "documentation": {}
    },
    {
        "label": "test_validate_correct_types",
        "kind": 2,
        "importPath": "common.tests.util.test_pydantic_validation",
        "description": "common.tests.util.test_pydantic_validation",
        "peekOfCode": "def test_validate_correct_types():\n    assert add(1, 2) == 3\ndef test_validate_incorrect_types():\n    # Note: Pydantic will try to coerce types, so \"1\" would be converted to 1\n    # We need to use a value that can't be coerced to test validation\n    with pytest.raises(ValidationError):\n        add(\"not_a_number\", 2)",
        "detail": "common.tests.util.test_pydantic_validation",
        "documentation": {}
    },
    {
        "label": "test_validate_incorrect_types",
        "kind": 2,
        "importPath": "common.tests.util.test_pydantic_validation",
        "description": "common.tests.util.test_pydantic_validation",
        "peekOfCode": "def test_validate_incorrect_types():\n    # Note: Pydantic will try to coerce types, so \"1\" would be converted to 1\n    # We need to use a value that can't be coerced to test validation\n    with pytest.raises(ValidationError):\n        add(\"not_a_number\", 2)",
        "detail": "common.tests.util.test_pydantic_validation",
        "documentation": {}
    },
    {
        "label": "TestBasicResolvers",
        "kind": 6,
        "importPath": "common.tests.util.test_resolvers",
        "description": "common.tests.util.test_resolvers",
        "peekOfCode": "class TestBasicResolvers:\n    \"\"\"Tests for basic resolver functionality\"\"\"\n    @pytest.mark.parametrize(\n        \"condition,true_value,false_value,expected\",\n        [\n            (True, \"yes\", \"no\", \"yes\"),\n            (False, \"yes\", \"no\", \"no\"),\n            (True, 10, 20, 10),\n            (False, 10, 20, 20),\n        ],",
        "detail": "common.tests.util.test_resolvers",
        "documentation": {}
    },
    {
        "label": "TestComparisonResolvers",
        "kind": 6,
        "importPath": "common.tests.util.test_resolvers",
        "description": "common.tests.util.test_resolvers",
        "peekOfCode": "class TestComparisonResolvers:\n    \"\"\"Tests for comparison resolver functionality\"\"\"\n    @pytest.mark.parametrize(\n        \"a,b,expected\",\n        [\n            (5, 3, True),\n            (3, 5, False),\n            (4, 4, False),\n        ],\n    )",
        "detail": "common.tests.util.test_resolvers",
        "documentation": {}
    },
    {
        "label": "TestAdvancedResolvers",
        "kind": 6,
        "importPath": "common.tests.util.test_resolvers",
        "description": "common.tests.util.test_resolvers",
        "peekOfCode": "class TestAdvancedResolvers:\n    \"\"\"Tests for advanced resolver functionality\"\"\"\n    @pytest.mark.parametrize(\n        \"alpha,new_value,last_value,expected\",\n        [\n            (0.9, 10.0, 5.0, pytest.approx(9.5)),  # 0.9*10 + 0.1*5\n            (0.5, 8.0, 4.0, pytest.approx(6.0)),  # 0.5*8 + 0.5*4\n            (1.0, 7.0, 3.0, pytest.approx(7.0)),  # 1.0*7 + 0.0*3\n            (0.0, 7.0, 3.0, pytest.approx(3.0)),  # 0.0*7 + 1.0*3\n        ],",
        "detail": "common.tests.util.test_resolvers",
        "documentation": {}
    },
    {
        "label": "TestScaledRange",
        "kind": 6,
        "importPath": "common.tests.util.test_resolvers",
        "description": "common.tests.util.test_resolvers",
        "peekOfCode": "class TestScaledRange:\n    \"\"\"Tests for the sampling (scaled range) resolver\"\"\"\n    @pytest.mark.parametrize(\n        \"min_val,max_val,center,expected\",\n        [\n            (1, 100, 50, 50),  # Integer center\n            (1.0, 100.0, 50.5, 50.5),  # Float center\n            (-10, 10, 0, 0),  # Zero center\n        ],\n    )",
        "detail": "common.tests.util.test_resolvers",
        "documentation": {}
    },
    {
        "label": "TestConfigIntegration",
        "kind": 6,
        "importPath": "common.tests.util.test_resolvers",
        "description": "common.tests.util.test_resolvers",
        "peekOfCode": "class TestConfigIntegration:\n    \"\"\"Tests for resolvers integrated with OmegaConf\"\"\"\n    def test_resolver_registration(self, omega_conf_with_resolvers):\n        \"\"\"Test that resolvers are properly registered with OmegaConf\"\"\"\n        # Explicitly resolve all interpolations\n        OmegaConf.resolve(omega_conf_with_resolvers)\n        assert OmegaConf.to_container(omega_conf_with_resolvers) == {\n            \"add_result\": 5,\n            \"sub_result\": 5,\n            \"if_result\": \"yes\",",
        "detail": "common.tests.util.test_resolvers",
        "documentation": {}
    },
    {
        "label": "TestDateResolver",
        "kind": 6,
        "importPath": "common.tests.util.test_resolvers",
        "description": "common.tests.util.test_resolvers",
        "peekOfCode": "class TestDateResolver:\n    \"\"\"Tests for the date resolver functionality\"\"\"\n    def test_date_resolver_basic(self):\n        \"\"\"Test the date resolver with basic formats\"\"\"\n        now = datetime.datetime.now()\n        # Test basic formats\n        assert oc_date_format(\"YYYYMMDD\") == now.strftime(\"%Y%m%d\")\n        assert oc_date_format(\"MMDD\") == now.strftime(\"%m%d\")\n    def test_date_resolver_with_separators(self):\n        \"\"\"Test the date resolver with formats containing separators\"\"\"",
        "detail": "common.tests.util.test_resolvers",
        "documentation": {}
    },
    {
        "label": "omega_conf_with_resolvers",
        "kind": 2,
        "importPath": "common.tests.util.test_resolvers",
        "description": "common.tests.util.test_resolvers",
        "peekOfCode": "def omega_conf_with_resolvers():\n    \"\"\"Fixture providing an OmegaConf with resolvers registered\"\"\"\n    register_resolvers()\n    return OmegaConf.create(\n        {\n            \"add_result\": \"${add:2,3}\",\n            \"sub_result\": \"${sub:10,5}\",\n            \"if_result\": \"${if:true,'yes','no'}\",\n            \"eq_result\": \"${eq:'test','test'}\",\n        }",
        "detail": "common.tests.util.test_resolvers",
        "documentation": {}
    },
    {
        "label": "omega_conf_with_sampling",
        "kind": 2,
        "importPath": "common.tests.util.test_resolvers",
        "description": "common.tests.util.test_resolvers",
        "peekOfCode": "def omega_conf_with_sampling():\n    \"\"\"Fixture providing an OmegaConf with sampling parameter\"\"\"\n    register_resolvers()\n    return OmegaConf.create(\n        {\n            \"sampling\": 0,  # Deterministic mode\n            \"param1\": \"${sampling:1,100,50}\",\n            \"param2\": \"${sampling:1,100,25}\",\n        }\n    )",
        "detail": "common.tests.util.test_resolvers",
        "documentation": {}
    },
    {
        "label": "test_date_format_resolver",
        "kind": 2,
        "importPath": "common.tests.util.test_resolvers",
        "description": "common.tests.util.test_resolvers",
        "peekOfCode": "def test_date_format_resolver():\n    \"\"\"Test the date_format resolver with various formats\"\"\"\n    import datetime\n    from metta.common.util.resolvers import oc_date_format\n    # Get the current date for verification\n    now = datetime.datetime.now()\n    # Test standard Python format codes\n    assert oc_date_format(\"%Y%m%d\") == now.strftime(\"%Y%m%d\")\n    assert oc_date_format(\"%m%d\") == now.strftime(\"%m%d\")\n    assert oc_date_format(\"%Y-%m-%d\") == now.strftime(\"%Y-%m-%d\")",
        "detail": "common.tests.util.test_resolvers",
        "documentation": {}
    },
    {
        "label": "test_date_resolver_frozen_time",
        "kind": 2,
        "importPath": "common.tests.util.test_resolvers",
        "description": "common.tests.util.test_resolvers",
        "peekOfCode": "def test_date_resolver_frozen_time(monkeypatch):\n    \"\"\"Test the date resolver with a fixed datetime for deterministic testing\"\"\"\n    # Create a fixed datetime (2025-05-13 12:34:56)\n    fixed_now = datetime.datetime(2025, 5, 13, 12, 34, 56)\n    # Mock datetime.now to return our fixed datetime\n    datetime_mock = Mock()\n    datetime_mock.now.return_value = fixed_now\n    monkeypatch.setattr(\"datetime.datetime\", datetime_mock)\n    # Test with our frozen time\n    assert oc_date_format(\"YYYYMMDD\") == \"20250513\"",
        "detail": "common.tests.util.test_resolvers",
        "documentation": {}
    },
    {
        "label": "FakeProcess",
        "kind": 6,
        "importPath": "common.tests.util.test_system_monitor",
        "description": "common.tests.util.test_system_monitor",
        "peekOfCode": "class FakeProcess:\n    \"\"\"Simple test double for psutil.Process\"\"\"\n    def __init__(self, memory_rss=100 * 1024 * 1024, cpu_percent=25.0, num_threads=4):\n        self._memory_rss = memory_rss\n        self._cpu_percent = cpu_percent\n        self._num_threads = num_threads\n        self._first_call = True\n    def memory_info(self):\n        return type(\"MemInfo\", (), {\"rss\": self._memory_rss})()\n    def cpu_percent(self, interval=None):",
        "detail": "common.tests.util.test_system_monitor",
        "documentation": {}
    },
    {
        "label": "FakeVirtualMemory",
        "kind": 6,
        "importPath": "common.tests.util.test_system_monitor",
        "description": "common.tests.util.test_system_monitor",
        "peekOfCode": "class FakeVirtualMemory:\n    \"\"\"Simple test double for psutil virtual memory\"\"\"\n    def __init__(self, total=8192, available=4096, used=4096, percent=50.0):\n        self.total = total * 1024 * 1024  # Convert to bytes\n        self.available = available * 1024 * 1024\n        self.used = used * 1024 * 1024\n        self.percent = percent\n# Fixtures\n@pytest.fixture\ndef monitor() -> Generator[SystemMonitor, None, None]:",
        "detail": "common.tests.util.test_system_monitor",
        "documentation": {}
    },
    {
        "label": "TestInitialization",
        "kind": 6,
        "importPath": "common.tests.util.test_system_monitor",
        "description": "common.tests.util.test_system_monitor",
        "peekOfCode": "class TestInitialization:\n    def test_init_default_params(self, mock_psutil):\n        \"\"\"Test initialization with default parameters\"\"\"\n        monitor = SystemMonitor(auto_start=False)\n        assert monitor.sampling_interval_sec == 1.0\n        assert monitor.history_size == 100\n        assert not monitor.is_running()\n        assert len(monitor.get_available_metrics()) > 0\n    def test_init_custom_params(self, mock_psutil):\n        \"\"\"Test initialization with custom parameters\"\"\"",
        "detail": "common.tests.util.test_system_monitor",
        "documentation": {}
    },
    {
        "label": "TestMetricCollection",
        "kind": 6,
        "importPath": "common.tests.util.test_system_monitor",
        "description": "common.tests.util.test_system_monitor",
        "peekOfCode": "class TestMetricCollection:\n    \"\"\"Tests for basic metric collection functionality\"\"\"\n    def test_cpu_metrics(self, monitor, mock_psutil):\n        \"\"\"Test CPU metric collection\"\"\"\n        monitor._collect_sample()\n        latest = monitor.get_latest()\n        assert latest[\"cpu_percent\"] == 50.0\n        assert latest[\"cpu_count\"] == 8\n        assert latest[\"cpu_count_logical\"] == 8\n        assert latest[\"cpu_count_physical\"] == 4",
        "detail": "common.tests.util.test_system_monitor",
        "documentation": {}
    },
    {
        "label": "TestMonitoringControl",
        "kind": 6,
        "importPath": "common.tests.util.test_system_monitor",
        "description": "common.tests.util.test_system_monitor",
        "peekOfCode": "class TestMonitoringControl:\n    def test_start_stop(self, monitor, mock_psutil):\n        \"\"\"Test starting and stopping monitoring\"\"\"\n        assert not monitor.is_running()\n        monitor.start()\n        assert monitor.is_running()\n        monitor.stop()\n        assert not monitor.is_running()\n    def test_double_start(self, monitor, mock_psutil, caplog):\n        \"\"\"Test starting when already running\"\"\"",
        "detail": "common.tests.util.test_system_monitor",
        "documentation": {}
    },
    {
        "label": "TestDataRetrieval",
        "kind": 6,
        "importPath": "common.tests.util.test_system_monitor",
        "description": "common.tests.util.test_system_monitor",
        "peekOfCode": "class TestDataRetrieval:\n    def test_get_latest_single_metric(self, monitor, mock_psutil):\n        \"\"\"Test getting latest value for single metric\"\"\"\n        monitor._collect_sample()\n        cpu_percent = monitor.get_latest(\"cpu_percent\")\n        assert cpu_percent == 50.0\n    def test_get_latest_all_metrics(self, monitor, mock_psutil):\n        \"\"\"Test getting all latest values\"\"\"\n        monitor._collect_sample()\n        latest = monitor.get_latest()",
        "detail": "common.tests.util.test_system_monitor",
        "documentation": {}
    },
    {
        "label": "TestSummaryAndReporting",
        "kind": 6,
        "importPath": "common.tests.util.test_system_monitor",
        "description": "common.tests.util.test_system_monitor",
        "peekOfCode": "class TestSummaryAndReporting:\n    def test_get_summary(self, monitor, mock_psutil):\n        \"\"\"Test getting comprehensive summary\"\"\"\n        # Collect samples with varying values\n        cpu_values = [30.0, 50.0, 70.0, 40.0, 60.0]\n        for val in cpu_values:\n            mock_psutil[\"cpu_percent\"] = val\n            monitor._collect_sample()\n        summary = monitor.get_summary()\n        assert \"timestamp\" in summary",
        "detail": "common.tests.util.test_system_monitor",
        "documentation": {}
    },
    {
        "label": "TestContextManager",
        "kind": 6,
        "importPath": "common.tests.util.test_system_monitor",
        "description": "common.tests.util.test_system_monitor",
        "peekOfCode": "class TestContextManager:\n    def test_monitor_context(self, monitor, mock_psutil, caplog):\n        \"\"\"Test monitor context manager\"\"\"\n        monitor._collect_sample()\n        with caplog.at_level(logging.INFO):\n            with monitor.monitor_context(\"test_operation\"):\n                time.sleep(0.1)\n        assert \"Monitor context 'test_operation' completed\" in caplog.text\n        assert \"System Monitor Summary\" in caplog.text\n    def test_monitor_context_without_tag(self, monitor, mock_psutil, caplog):",
        "detail": "common.tests.util.test_system_monitor",
        "documentation": {}
    },
    {
        "label": "TestErrorHandling",
        "kind": 6,
        "importPath": "common.tests.util.test_system_monitor",
        "description": "common.tests.util.test_system_monitor",
        "peekOfCode": "class TestErrorHandling:\n    def test_metric_collection_error(self, monitor, mock_psutil, monkeypatch, caplog):\n        \"\"\"Test handling of errors during metric collection\"\"\"\n        def failing_collector():\n            raise RuntimeError(\"Collection failed\")\n        # Add a failing collector\n        monitor._metric_collectors[\"failing_metric\"] = failing_collector\n        monitor._metrics[\"failing_metric\"] = deque(maxlen=monitor.history_size)\n        with caplog.at_level(logging.WARNING):\n            monitor._collect_sample()",
        "detail": "common.tests.util.test_system_monitor",
        "documentation": {}
    },
    {
        "label": "TestIntegration",
        "kind": 6,
        "importPath": "common.tests.util.test_system_monitor",
        "description": "common.tests.util.test_system_monitor",
        "peekOfCode": "class TestIntegration:\n    def test_full_monitoring_cycle(self, mock_psutil):\n        \"\"\"Test full monitoring lifecycle\"\"\"\n        monitor = SystemMonitor(sampling_interval_sec=0.05, history_size=5, auto_start=True)\n        # Let it collect some samples\n        time.sleep(0.2)\n        # Check we have data\n        latest = monitor.get_latest()\n        assert len(latest) > 0\n        # Check history",
        "detail": "common.tests.util.test_system_monitor",
        "documentation": {}
    },
    {
        "label": "TestPlatformSpecific",
        "kind": 6,
        "importPath": "common.tests.util.test_system_monitor",
        "description": "common.tests.util.test_system_monitor",
        "peekOfCode": "class TestPlatformSpecific:\n    def test_no_gpu_available(self, mock_psutil, monkeypatch):\n        \"\"\"Test behavior when no GPU is available\"\"\"\n        # Save original state\n        _original_cuda_available = torch.cuda.is_available() if hasattr(torch.cuda, \"is_available\") else False\n        _original_mps_available = torch.backends.mps.is_available() if hasattr(torch.backends, \"mps\") else False\n        # Mock both CUDA and MPS as unavailable\n        monkeypatch.setattr(torch.cuda, \"is_available\", lambda: False)\n        if hasattr(torch.backends, \"mps\"):\n            monkeypatch.setattr(torch.backends.mps, \"is_available\", lambda: False)",
        "detail": "common.tests.util.test_system_monitor",
        "documentation": {}
    },
    {
        "label": "TestRealSystemMonitoring",
        "kind": 6,
        "importPath": "common.tests.util.test_system_monitor",
        "description": "common.tests.util.test_system_monitor",
        "peekOfCode": "class TestRealSystemMonitoring:\n    \"\"\"Tests that use the real system (not mocked)\"\"\"\n    @pytest.mark.slow\n    def test_real_monitoring_memory_pattern(self):\n        \"\"\"Test monitoring memory allocation and deallocation patterns\"\"\"\n        monitor = SystemMonitor(\n            sampling_interval_sec=0.05,\n            history_size=200,\n            auto_start=True,\n        )",
        "detail": "common.tests.util.test_system_monitor",
        "documentation": {}
    },
    {
        "label": "monitor",
        "kind": 2,
        "importPath": "common.tests.util.test_system_monitor",
        "description": "common.tests.util.test_system_monitor",
        "peekOfCode": "def monitor() -> Generator[SystemMonitor, None, None]:\n    \"\"\"Create a SystemMonitor instance with auto_start=False\"\"\"\n    monitor = SystemMonitor(sampling_interval_sec=0.1, history_size=10, auto_start=False)\n    yield monitor\n    # Cleanup\n    if monitor.is_running():\n        monitor.stop()\n@pytest.fixture\ndef mock_psutil(monkeypatch) -> dict:\n    \"\"\"Mock psutil functions with controllable values, platform-aware\"\"\"",
        "detail": "common.tests.util.test_system_monitor",
        "documentation": {}
    },
    {
        "label": "mock_psutil",
        "kind": 2,
        "importPath": "common.tests.util.test_system_monitor",
        "description": "common.tests.util.test_system_monitor",
        "peekOfCode": "def mock_psutil(monkeypatch) -> dict:\n    \"\"\"Mock psutil functions with controllable values, platform-aware\"\"\"\n    mock_data = {\n        \"cpu_percent\": 50.0,\n        \"cpu_count\": 8,\n        \"cpu_count_logical\": 8,\n        \"cpu_count_physical\": 4,\n        \"memory\": FakeVirtualMemory(),\n        \"process\": FakeProcess(),\n        \"temperatures\": {},",
        "detail": "common.tests.util.test_system_monitor",
        "documentation": {}
    },
    {
        "label": "mock_torch_cuda",
        "kind": 2,
        "importPath": "common.tests.util.test_system_monitor",
        "description": "common.tests.util.test_system_monitor",
        "peekOfCode": "def mock_torch_cuda(monkeypatch) -> dict | None:\n    \"\"\"Mock torch CUDA functions - only if CUDA is available on the platform\"\"\"\n    if not HAS_CUDA:\n        # Don't mock CUDA if it's not available\n        return None\n    mock_data = {\n        \"is_available\": True,\n        \"device_count\": 2,\n        \"utilization\": [60.0, 40.0],\n        \"memory_info\": [(2 * 1024**3, 8 * 1024**3), (3 * 1024**3, 8 * 1024**3)],  # (free, total)",
        "detail": "common.tests.util.test_system_monitor",
        "documentation": {}
    },
    {
        "label": "IS_MACOS",
        "kind": 5,
        "importPath": "common.tests.util.test_system_monitor",
        "description": "common.tests.util.test_system_monitor",
        "peekOfCode": "IS_MACOS = platform.system() == \"Darwin\"\nIS_LINUX = platform.system() == \"Linux\"\nIS_WINDOWS = platform.system() == \"Windows\"\nHAS_MPS = hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available()\nHAS_CUDA = torch.cuda.is_available()\n# Test doubles and helpers\nclass FakeProcess:\n    \"\"\"Simple test double for psutil.Process\"\"\"\n    def __init__(self, memory_rss=100 * 1024 * 1024, cpu_percent=25.0, num_threads=4):\n        self._memory_rss = memory_rss",
        "detail": "common.tests.util.test_system_monitor",
        "documentation": {}
    },
    {
        "label": "IS_LINUX",
        "kind": 5,
        "importPath": "common.tests.util.test_system_monitor",
        "description": "common.tests.util.test_system_monitor",
        "peekOfCode": "IS_LINUX = platform.system() == \"Linux\"\nIS_WINDOWS = platform.system() == \"Windows\"\nHAS_MPS = hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available()\nHAS_CUDA = torch.cuda.is_available()\n# Test doubles and helpers\nclass FakeProcess:\n    \"\"\"Simple test double for psutil.Process\"\"\"\n    def __init__(self, memory_rss=100 * 1024 * 1024, cpu_percent=25.0, num_threads=4):\n        self._memory_rss = memory_rss\n        self._cpu_percent = cpu_percent",
        "detail": "common.tests.util.test_system_monitor",
        "documentation": {}
    },
    {
        "label": "IS_WINDOWS",
        "kind": 5,
        "importPath": "common.tests.util.test_system_monitor",
        "description": "common.tests.util.test_system_monitor",
        "peekOfCode": "IS_WINDOWS = platform.system() == \"Windows\"\nHAS_MPS = hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available()\nHAS_CUDA = torch.cuda.is_available()\n# Test doubles and helpers\nclass FakeProcess:\n    \"\"\"Simple test double for psutil.Process\"\"\"\n    def __init__(self, memory_rss=100 * 1024 * 1024, cpu_percent=25.0, num_threads=4):\n        self._memory_rss = memory_rss\n        self._cpu_percent = cpu_percent\n        self._num_threads = num_threads",
        "detail": "common.tests.util.test_system_monitor",
        "documentation": {}
    },
    {
        "label": "HAS_MPS",
        "kind": 5,
        "importPath": "common.tests.util.test_system_monitor",
        "description": "common.tests.util.test_system_monitor",
        "peekOfCode": "HAS_MPS = hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available()\nHAS_CUDA = torch.cuda.is_available()\n# Test doubles and helpers\nclass FakeProcess:\n    \"\"\"Simple test double for psutil.Process\"\"\"\n    def __init__(self, memory_rss=100 * 1024 * 1024, cpu_percent=25.0, num_threads=4):\n        self._memory_rss = memory_rss\n        self._cpu_percent = cpu_percent\n        self._num_threads = num_threads\n        self._first_call = True",
        "detail": "common.tests.util.test_system_monitor",
        "documentation": {}
    },
    {
        "label": "HAS_CUDA",
        "kind": 5,
        "importPath": "common.tests.util.test_system_monitor",
        "description": "common.tests.util.test_system_monitor",
        "peekOfCode": "HAS_CUDA = torch.cuda.is_available()\n# Test doubles and helpers\nclass FakeProcess:\n    \"\"\"Simple test double for psutil.Process\"\"\"\n    def __init__(self, memory_rss=100 * 1024 * 1024, cpu_percent=25.0, num_threads=4):\n        self._memory_rss = memory_rss\n        self._cpu_percent = cpu_percent\n        self._num_threads = num_threads\n        self._first_call = True\n    def memory_info(self):",
        "detail": "common.tests.util.test_system_monitor",
        "documentation": {}
    },
    {
        "label": "DummyRun",
        "kind": 6,
        "importPath": "common.tests.wandb.test_wandb_context",
        "description": "common.tests.wandb.test_wandb_context",
        "peekOfCode": "class DummyRun:\n    id: str\n    job_type: str\n    project: str\n    entity: str\n    config: dict\n    group: str\n    allow_val_change: bool\n    name: str\n    monitor_gym: bool",
        "detail": "common.tests.wandb.test_wandb_context",
        "documentation": {}
    },
    {
        "label": "patch_dependencies",
        "kind": 2,
        "importPath": "common.tests.wandb.test_wandb_context",
        "description": "common.tests.wandb.test_wandb_context",
        "peekOfCode": "def patch_dependencies(monkeypatch):\n    # Patch wandb.save to no-op\n    monkeypatch.setattr(wandb, \"save\", lambda *args, **kwargs: None)\n    # Dummy socket to bypass real network calls\n    class DummySock:\n        def settimeout(self, timeout):\n            pass\n        def connect(self, addr):\n            pass\n    monkeypatch.setattr(socket, \"socket\", lambda *args, **kwargs: DummySock())",
        "detail": "common.tests.wandb.test_wandb_context",
        "documentation": {}
    },
    {
        "label": "dummy_init",
        "kind": 2,
        "importPath": "common.tests.wandb.test_wandb_context",
        "description": "common.tests.wandb.test_wandb_context",
        "peekOfCode": "def dummy_init(monkeypatch):\n    monkeypatch.setattr(wandb, \"init\", lambda *args, **kwargs: DummyRun(*args, **kwargs))\n    yield\ndef test_enter_disabled_does_not_init(monkeypatch):\n    # Prepare disabled config\n    cfg_off = OmegaConf.create(dict(enabled=False))\n    # Spy on wandb.init\n    init_called = False\n    def fake_init(*args, **kwargs):\n        nonlocal init_called",
        "detail": "common.tests.wandb.test_wandb_context",
        "documentation": {}
    },
    {
        "label": "test_enter_disabled_does_not_init",
        "kind": 2,
        "importPath": "common.tests.wandb.test_wandb_context",
        "description": "common.tests.wandb.test_wandb_context",
        "peekOfCode": "def test_enter_disabled_does_not_init(monkeypatch):\n    # Prepare disabled config\n    cfg_off = OmegaConf.create(dict(enabled=False))\n    # Spy on wandb.init\n    init_called = False\n    def fake_init(*args, **kwargs):\n        nonlocal init_called\n        init_called = True\n    monkeypatch.setattr(wandb, \"init\", fake_init)\n    ctx = WandbContext(cfg_off, global_cfg={\"foo\": \"bar\"})",
        "detail": "common.tests.wandb.test_wandb_context",
        "documentation": {}
    },
    {
        "label": "test_structured_config",
        "kind": 2,
        "importPath": "common.tests.wandb.test_wandb_context",
        "description": "common.tests.wandb.test_wandb_context",
        "peekOfCode": "def test_structured_config(monkeypatch, dummy_init):\n    # Prepare config that's already validated\n    cfg_off = WandbConfigOff(enabled=False)\n    ctx = WandbContext(cfg_off, OmegaConf.create())\n    run = ctx.__enter__()\n    assert run is None\n    assert ctx.cfg == cfg_off\ndef test_run_fields(monkeypatch, dummy_init, tmp_path):\n    # Prepare enabled config\n    cfg_on = OmegaConf.create(",
        "detail": "common.tests.wandb.test_wandb_context",
        "documentation": {}
    },
    {
        "label": "test_run_fields",
        "kind": 2,
        "importPath": "common.tests.wandb.test_wandb_context",
        "description": "common.tests.wandb.test_wandb_context",
        "peekOfCode": "def test_run_fields(monkeypatch, dummy_init, tmp_path):\n    # Prepare enabled config\n    cfg_on = OmegaConf.create(\n        dict(\n            enabled=True,\n            project=\"proj\",\n            entity=\"ent\",\n            group=\"grp\",\n            name=\"nm\",\n            run_id=\"id\",",
        "detail": "common.tests.wandb.test_wandb_context",
        "documentation": {}
    },
    {
        "label": "test_tags_and_notes",
        "kind": 2,
        "importPath": "common.tests.wandb.test_wandb_context",
        "description": "common.tests.wandb.test_wandb_context",
        "peekOfCode": "def test_tags_and_notes(monkeypatch, dummy_init, tmp_path):\n    cfg_on = OmegaConf.create(\n        dict(\n            enabled=True,\n            project=\"p\",\n            entity=\"e\",\n            group=\"g\",\n            name=\"n\",\n            run_id=\"r\",\n            data_dir=str(tmp_path),",
        "detail": "common.tests.wandb.test_wandb_context",
        "documentation": {}
    },
    {
        "label": "test_exit_finishes_run",
        "kind": 2,
        "importPath": "common.tests.wandb.test_wandb_context",
        "description": "common.tests.wandb.test_wandb_context",
        "peekOfCode": "def test_exit_finishes_run(monkeypatch, dummy_init, tmp_path):\n    # Prepare enabled config\n    cfg_on = WandbConfigOn(\n        enabled=True,\n        project=\"p\",\n        entity=\"e\",\n        group=\"g\",\n        name=\"n\",\n        run_id=\"r\",\n        data_dir=str(tmp_path),",
        "detail": "common.tests.wandb.test_wandb_context",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "common.tests.wandb.test_wandb_context",
        "description": "common.tests.wandb.test_wandb_context",
        "peekOfCode": "logger = setup_mettagrid_logger(\"Test\")\n@pytest.fixture(autouse=True)\ndef patch_dependencies(monkeypatch):\n    # Patch wandb.save to no-op\n    monkeypatch.setattr(wandb, \"save\", lambda *args, **kwargs: None)\n    # Dummy socket to bypass real network calls\n    class DummySock:\n        def settimeout(self, timeout):\n            pass\n        def connect(self, addr):",
        "detail": "common.tests.wandb.test_wandb_context",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "devops.docker.build",
        "description": "devops.docker.build",
        "peekOfCode": "def main():\n    cd_repo_root()\n    parser = argparse.ArgumentParser(description=\"Build the metta image\")\n    parser.add_argument(\"--image-name\", default=\"mettaai/metta:latest\")\n    args = parser.parse_args()\n    if not get_user_confirmation(\"Images should normally be built by CI. Do you want to proceed?\"):\n        sys.exit(0)\n    if shutil.which(\"docker\") is None:\n        print(\n            \"Docker is not installed!\\n\\n\"",
        "detail": "devops.docker.build",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "devops.docker.push_image",
        "description": "devops.docker.push_image",
        "peekOfCode": "def main():\n    cd_repo_root()\n    parser = argparse.ArgumentParser(description=\"Upload metta image to ECR\")\n    parser.add_argument(\"--local-image-name\", default=\"mettaai/metta:latest\")\n    parser.add_argument(\"--remote-image-name\", default=\"metta:latest\")\n    parser.add_argument(\"--region\", default=\"us-east-1\")\n    parser.add_argument(\"--account-id\", type=int, help=\"AWS account ID. If omitted, current account is used.\")\n    args = parser.parse_args()\n    account_id = args.account_id or sh([\"aws\", \"sts\", \"get-caller-identity\", \"--query\", \"Account\", \"--output\", \"text\"])\n    if not account_id:",
        "detail": "devops.docker.push_image",
        "documentation": {}
    },
    {
        "label": "bin_dir",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.activate_this",
        "description": "devops.skypilot..venv.bin.activate_this",
        "peekOfCode": "bin_dir = os.path.dirname(abs_file)\nbase = bin_dir[: -len(\"bin\") - 1]  # strip away the bin part from the __file__, plus the path separator\n# prepend bin to PATH (this file is inside the bin directory)\nos.environ[\"PATH\"] = os.pathsep.join([bin_dir, *os.environ.get(\"PATH\", \"\").split(os.pathsep)])\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\nos.environ[\"VIRTUAL_ENV_PROMPT\"] = \"\" or os.path.basename(base)  # noqa: SIM222\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))",
        "detail": "devops.skypilot..venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "base",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.activate_this",
        "description": "devops.skypilot..venv.bin.activate_this",
        "peekOfCode": "base = bin_dir[: -len(\"bin\") - 1]  # strip away the bin part from the __file__, plus the path separator\n# prepend bin to PATH (this file is inside the bin directory)\nos.environ[\"PATH\"] = os.pathsep.join([bin_dir, *os.environ.get(\"PATH\", \"\").split(os.pathsep)])\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\nos.environ[\"VIRTUAL_ENV_PROMPT\"] = \"\" or os.path.basename(base)  # noqa: SIM222\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path)",
        "detail": "devops.skypilot..venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "os.environ[\"PATH\"]",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.activate_this",
        "description": "devops.skypilot..venv.bin.activate_this",
        "peekOfCode": "os.environ[\"PATH\"] = os.pathsep.join([bin_dir, *os.environ.get(\"PATH\", \"\").split(os.pathsep)])\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\nos.environ[\"VIRTUAL_ENV_PROMPT\"] = \"\" or os.path.basename(base)  # noqa: SIM222\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix",
        "detail": "devops.skypilot..venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "os.environ[\"VIRTUAL_ENV\"]",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.activate_this",
        "description": "devops.skypilot..venv.bin.activate_this",
        "peekOfCode": "os.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\nos.environ[\"VIRTUAL_ENV_PROMPT\"] = \"\" or os.path.basename(base)  # noqa: SIM222\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": "devops.skypilot..venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "os.environ[\"VIRTUAL_ENV_PROMPT\"]",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.activate_this",
        "description": "devops.skypilot..venv.bin.activate_this",
        "peekOfCode": "os.environ[\"VIRTUAL_ENV_PROMPT\"] = \"\" or os.path.basename(base)  # noqa: SIM222\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": "devops.skypilot..venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "prev_length",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.activate_this",
        "description": "devops.skypilot..venv.bin.activate_this",
        "peekOfCode": "prev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": "devops.skypilot..venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "sys.path[:]",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.activate_this",
        "description": "devops.skypilot..venv.bin.activate_this",
        "peekOfCode": "sys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": "devops.skypilot..venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "sys.real_prefix",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.activate_this",
        "description": "devops.skypilot..venv.bin.activate_this",
        "peekOfCode": "sys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": "devops.skypilot..venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "sys.prefix",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.activate_this",
        "description": "devops.skypilot..venv.bin.activate_this",
        "peekOfCode": "sys.prefix = base",
        "detail": "devops.skypilot..venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "devops.skypilot..venv.bin.jp",
        "description": "devops.skypilot..venv.bin.jp",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('expression')\n    parser.add_argument('-f', '--filename',\n                        help=('The filename containing the input data.  '\n                              'If a filename is not given then data is '\n                              'read from stdin.'))\n    parser.add_argument('--ast', action='store_true',\n                        help=('Pretty print the AST, do not search the data.'))\n    args = parser.parse_args()",
        "detail": "devops.skypilot..venv.bin.jp",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.rst2html",
        "description": "devops.skypilot..venv.bin.rst2html",
        "peekOfCode": "description = ('Generates (X)HTML documents from standalone reStructuredText '\n               'sources.  ' + default_description)\npublish_cmdline(writer_name='html', description=description)",
        "detail": "devops.skypilot..venv.bin.rst2html",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.rst2html4",
        "description": "devops.skypilot..venv.bin.rst2html4",
        "peekOfCode": "description = ('Generates (X)HTML documents from standalone reStructuredText '\n               'sources.  ' + default_description)\npublish_cmdline(writer_name='html4', description=description)",
        "detail": "devops.skypilot..venv.bin.rst2html4",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.rst2html5",
        "description": "devops.skypilot..venv.bin.rst2html5",
        "peekOfCode": "description = ('Generates HTML5 documents from standalone '\n               'reStructuredText sources.\\n'\n               + default_description)\npublish_cmdline(writer_name='html5', description=description)",
        "detail": "devops.skypilot..venv.bin.rst2html5",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.rst2latex",
        "description": "devops.skypilot..venv.bin.rst2latex",
        "peekOfCode": "description = ('Generates LaTeX documents from standalone reStructuredText '\n               'sources. '\n               'Reads from <source> (default is stdin) and writes to '\n               '<destination> (default is stdout).  See '\n               '<https://docutils.sourceforge.io/docs/user/latex.html> for '\n               'the full reference.')\npublish_cmdline(writer_name='latex', description=description)",
        "detail": "devops.skypilot..venv.bin.rst2latex",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.rst2man",
        "description": "devops.skypilot..venv.bin.rst2man",
        "peekOfCode": "description = (\"Generates plain unix manual documents.  \"\n               + default_description)\npublish_cmdline(writer=manpage.Writer(), description=description)",
        "detail": "devops.skypilot..venv.bin.rst2man",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.rst2odt",
        "description": "devops.skypilot..venv.bin.rst2odt",
        "peekOfCode": "description = ('Generates OpenDocument/OpenOffice/ODF documents from '\n               'standalone reStructuredText sources.  ' + default_description)\nwriter = Writer()\nreader = Reader()\noutput = publish_cmdline_to_binary(reader=reader, writer=writer,\n                                   description=description)",
        "detail": "devops.skypilot..venv.bin.rst2odt",
        "documentation": {}
    },
    {
        "label": "writer",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.rst2odt",
        "description": "devops.skypilot..venv.bin.rst2odt",
        "peekOfCode": "writer = Writer()\nreader = Reader()\noutput = publish_cmdline_to_binary(reader=reader, writer=writer,\n                                   description=description)",
        "detail": "devops.skypilot..venv.bin.rst2odt",
        "documentation": {}
    },
    {
        "label": "reader",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.rst2odt",
        "description": "devops.skypilot..venv.bin.rst2odt",
        "peekOfCode": "reader = Reader()\noutput = publish_cmdline_to_binary(reader=reader, writer=writer,\n                                   description=description)",
        "detail": "devops.skypilot..venv.bin.rst2odt",
        "documentation": {}
    },
    {
        "label": "output",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.rst2odt",
        "description": "devops.skypilot..venv.bin.rst2odt",
        "peekOfCode": "output = publish_cmdline_to_binary(reader=reader, writer=writer,\n                                   description=description)",
        "detail": "devops.skypilot..venv.bin.rst2odt",
        "documentation": {}
    },
    {
        "label": "prepstyle",
        "kind": 2,
        "importPath": "devops.skypilot..venv.bin.rst2odt_prepstyles",
        "description": "devops.skypilot..venv.bin.rst2odt_prepstyles",
        "peekOfCode": "def prepstyle(filename):\n    zin = zipfile.ZipFile(filename)\n    styles = zin.read(\"styles.xml\")\n    root = etree.fromstring(styles)\n    for el in root.xpath(\"//style:page-layout-properties\",\n                         namespaces=NAMESPACES):\n        for attr in el.attrib:\n            if attr.startswith(\"{%s}\" % NAMESPACES[\"fo\"]):\n                del el.attrib[attr]\n    tempname = mkstemp()",
        "detail": "devops.skypilot..venv.bin.rst2odt_prepstyles",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "devops.skypilot..venv.bin.rst2odt_prepstyles",
        "description": "devops.skypilot..venv.bin.rst2odt_prepstyles",
        "peekOfCode": "def main():\n    args = sys.argv[1:]\n    if len(args) != 1 or args[0] in ('-h', '--help'):\n        print(__doc__, file=sys.stderr)\n        print(\"Usage: %s STYLE_FILE.odt\\n\" % sys.argv[0], file=sys.stderr)\n        sys.exit(1)\n    filename = args[0]\n    prepstyle(filename)\nif __name__ == '__main__':\n    main()",
        "detail": "devops.skypilot..venv.bin.rst2odt_prepstyles",
        "documentation": {}
    },
    {
        "label": "NAMESPACES",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.rst2odt_prepstyles",
        "description": "devops.skypilot..venv.bin.rst2odt_prepstyles",
        "peekOfCode": "NAMESPACES = {\n    \"style\": \"urn:oasis:names:tc:opendocument:xmlns:style:1.0\",\n    \"fo\": \"urn:oasis:names:tc:opendocument:xmlns:xsl-fo-compatible:1.0\"\n}\ndef prepstyle(filename):\n    zin = zipfile.ZipFile(filename)\n    styles = zin.read(\"styles.xml\")\n    root = etree.fromstring(styles)\n    for el in root.xpath(\"//style:page-layout-properties\",\n                         namespaces=NAMESPACES):",
        "detail": "devops.skypilot..venv.bin.rst2odt_prepstyles",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.rst2pseudoxml",
        "description": "devops.skypilot..venv.bin.rst2pseudoxml",
        "peekOfCode": "description = ('Generates pseudo-XML from standalone reStructuredText '\n               'sources (for testing purposes).  ' + default_description)\npublish_cmdline(description=description)",
        "detail": "devops.skypilot..venv.bin.rst2pseudoxml",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.rst2s5",
        "description": "devops.skypilot..venv.bin.rst2s5",
        "peekOfCode": "description = ('Generates S5 (X)HTML slideshow documents from standalone '\n               'reStructuredText sources.  ' + default_description)\npublish_cmdline(writer_name='s5', description=description)",
        "detail": "devops.skypilot..venv.bin.rst2s5",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.rst2xetex",
        "description": "devops.skypilot..venv.bin.rst2xetex",
        "peekOfCode": "description = ('Generates LaTeX documents from standalone reStructuredText '\n               'sources for compilation with the Unicode-aware TeX variants '\n               'XeLaTeX or LuaLaTeX. '\n               'Reads from <source> (default is stdin) and writes to '\n               '<destination> (default is stdout).  See '\n               '<https://docutils.sourceforge.io/docs/user/latex.html> for '\n               'the full reference.')\npublish_cmdline(writer_name='xetex', description=description)",
        "detail": "devops.skypilot..venv.bin.rst2xetex",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.rst2xml",
        "description": "devops.skypilot..venv.bin.rst2xml",
        "peekOfCode": "description = ('Generates Docutils-native XML from standalone '\n               'reStructuredText sources.  ' + default_description)\npublish_cmdline(writer_name='xml', description=description)",
        "detail": "devops.skypilot..venv.bin.rst2xml",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "devops.skypilot..venv.bin.rstpep2html",
        "description": "devops.skypilot..venv.bin.rstpep2html",
        "peekOfCode": "description = ('Generates (X)HTML from reStructuredText-format PEP files.  '\n               + default_description)\npublish_cmdline(reader_name='pep', writer_name='pep_html',\n                description=description)",
        "detail": "devops.skypilot..venv.bin.rstpep2html",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "devops.skypilot.configure_jobs_controller",
        "description": "devops.skypilot.configure_jobs_controller",
        "peekOfCode": "def main():\n    controller_name = get_jobs_controller_name()\n    print(f\"Jobs controller: {yellow(controller_name)}\")\n    # Read the crontab file\n    crontab_file = Path(__file__).parent / \"files\" / \"controller.crontab\"\n    if not crontab_file.exists():\n        raise FileNotFoundError(f\"Crontab file not found: {crontab_file}\")\n    print(f\"Reading crontab from: {crontab_file}\")\n    crontab_content = crontab_file.read_text()\n    # Filter out comments and empty lines for display",
        "detail": "devops.skypilot.configure_jobs_controller",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "devops.skypilot.connect",
        "description": "devops.skypilot.connect",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(description=\"Connect to a running skypilot job\")\n    parser.add_argument(\n        \"--mode\",\n        choices=[\"container\", \"host\"],\n        default=\"container\",\n        help=\"Whether to connect to the job container or the host machine where the job is running\",\n    )\n    parser.add_argument(\"job_id\", type=int, help=\"The job ID to connect to\")\n    args = parser.parse_args()",
        "detail": "devops.skypilot.connect",
        "documentation": {}
    },
    {
        "label": "patch_task",
        "kind": 2,
        "importPath": "devops.skypilot.launch",
        "description": "devops.skypilot.launch",
        "peekOfCode": "def patch_task(\n    task: sky.Task,\n    cpus: int | None,\n    gpus: int | None,\n    nodes: int | None,\n    no_spot: bool = False,\n    timeout_hours: float | None = None,\n) -> sky.Task:\n    overrides = {}\n    if cpus:",
        "detail": "devops.skypilot.launch",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "devops.skypilot.launch",
        "description": "devops.skypilot.launch",
        "peekOfCode": "def main():\n    # To match other usage patterns we want to specify the run ID with `run=foo`` somewhere in the args\n    # A named argument with argparse would end up as `--run=foo` which is not quite right\n    run_id = None\n    filtered_args = []\n    for arg in sys.argv[1:]:\n        if arg.startswith(\"run=\"):\n            run_id = arg[4:]  # Remove 'run=' prefix\n        else:\n            filtered_args.append(arg)",
        "detail": "devops.skypilot.launch",
        "documentation": {}
    },
    {
        "label": "get_existing_clusters",
        "kind": 2,
        "importPath": "devops.skypilot.sandbox",
        "description": "devops.skypilot.sandbox",
        "peekOfCode": "def get_existing_clusters():\n    request_id = sky.status()\n    cluster_records = sky.get(request_id)\n    return cluster_records\ndef get_next_name(cluster_records):\n    names = [record[\"name\"] for record in cluster_records]\n    username = os.environ[\"USER\"]\n    for i in range(1, 100):\n        name = f\"{username}-sandbox-{i}\"\n        if name not in names:",
        "detail": "devops.skypilot.sandbox",
        "documentation": {}
    },
    {
        "label": "get_next_name",
        "kind": 2,
        "importPath": "devops.skypilot.sandbox",
        "description": "devops.skypilot.sandbox",
        "peekOfCode": "def get_next_name(cluster_records):\n    names = [record[\"name\"] for record in cluster_records]\n    username = os.environ[\"USER\"]\n    for i in range(1, 100):\n        name = f\"{username}-sandbox-{i}\"\n        if name not in names:\n            return name\n    raise ValueError(\"No available sandbox name found\")\ndef main():\n    parser = argparse.ArgumentParser()",
        "detail": "devops.skypilot.sandbox",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "devops.skypilot.sandbox",
        "description": "devops.skypilot.sandbox",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--git-ref\", type=str, default=None)\n    parser.add_argument(\"--new\", action=\"store_true\")\n    parser.add_argument(\"--gpus\", type=int, default=1, help=\"Number of L4 GPUs to use.\")\n    args = parser.parse_args()\n    existing_clusters = get_existing_clusters()\n    if existing_clusters and not args.new:\n        print(f\"You already have {len(existing_clusters)} sandbox(es) running:\")\n        for cluster in existing_clusters:",
        "detail": "devops.skypilot.sandbox",
        "documentation": {}
    },
    {
        "label": "get_jobs_controller_name",
        "kind": 2,
        "importPath": "devops.skypilot.utils",
        "description": "devops.skypilot.utils",
        "peekOfCode": "def get_jobs_controller_name() -> str:\n    job_clusters = sky.get(sky.status(all_users=True, cluster_names=[\"sky-jobs-controller*\"]))\n    if len(job_clusters) == 0:\n        raise ValueError(\"No job controller cluster found, is it running?\")\n    return job_clusters[0][\"name\"]\ndef print_tip(text: str):\n    print(blue(text), file=sys.stderr)\ndef dashboard_url() -> str:\n    url = sky.server.common.get_server_url()\n    # strip username and password from server_url",
        "detail": "devops.skypilot.utils",
        "documentation": {}
    },
    {
        "label": "print_tip",
        "kind": 2,
        "importPath": "devops.skypilot.utils",
        "description": "devops.skypilot.utils",
        "peekOfCode": "def print_tip(text: str):\n    print(blue(text), file=sys.stderr)\ndef dashboard_url() -> str:\n    url = sky.server.common.get_server_url()\n    # strip username and password from server_url\n    url = re.sub(\"https://.*@\", \"https://\", url)\n    return url\ndef launch_task(task: sky.Task, dry_run=False):\n    if dry_run:\n        print_tip(\"DRY RUN.\")",
        "detail": "devops.skypilot.utils",
        "documentation": {}
    },
    {
        "label": "dashboard_url",
        "kind": 2,
        "importPath": "devops.skypilot.utils",
        "description": "devops.skypilot.utils",
        "peekOfCode": "def dashboard_url() -> str:\n    url = sky.server.common.get_server_url()\n    # strip username and password from server_url\n    url = re.sub(\"https://.*@\", \"https://\", url)\n    return url\ndef launch_task(task: sky.Task, dry_run=False):\n    if dry_run:\n        print_tip(\"DRY RUN.\")\n        print_tip(\"Tip: Pipe this command to `| yq -P .` to get the pretty yaml config.\\n\")\n        print(task.to_yaml_config())",
        "detail": "devops.skypilot.utils",
        "documentation": {}
    },
    {
        "label": "launch_task",
        "kind": 2,
        "importPath": "devops.skypilot.utils",
        "description": "devops.skypilot.utils",
        "peekOfCode": "def launch_task(task: sky.Task, dry_run=False):\n    if dry_run:\n        print_tip(\"DRY RUN.\")\n        print_tip(\"Tip: Pipe this command to `| yq -P .` to get the pretty yaml config.\\n\")\n        print(task.to_yaml_config())\n        return\n    request_id = sky.jobs.launch(task)\n    print(green(f\"Submitted sky.jobs.launch request: {request_id}\"))\n    short_request_id = request_id.split(\"-\")[0]\n    print(f\"- Check logs with: {magenta(f'sky api logs {short_request_id}')}\")",
        "detail": "devops.skypilot.utils",
        "documentation": {}
    },
    {
        "label": "check_git_state",
        "kind": 2,
        "importPath": "devops.skypilot.utils",
        "description": "devops.skypilot.utils",
        "peekOfCode": "def check_git_state(commit_hash: str) -> str | None:\n    \"\"\"Check that the commit has been pushed and there are no staged changes.\"\"\"\n    error_lines = []\n    if has_unstaged_changes():\n        error_lines.append(red(\" You have uncommitted changes that won't be reflected in the cloud job.\"))\n        error_lines.append(\"Options:\")\n        error_lines.append(\"  - Commit: git add . && git commit -m 'your message'\")\n        error_lines.append(\"  - Stash: git stash\")\n        return \"\\n\".join(error_lines)\n    if not is_commit_pushed(commit_hash):",
        "detail": "devops.skypilot.utils",
        "documentation": {}
    },
    {
        "label": "check_config_files",
        "kind": 2,
        "importPath": "devops.skypilot.utils",
        "description": "devops.skypilot.utils",
        "peekOfCode": "def check_config_files(cmd_args: list[str]) -> bool:\n    \"\"\"Check that config files referenced in arguments actually exist.\"\"\"\n    config_files_to_check = []\n    # Mapping of argument prefix to config file path template\n    config_mappings = {\n        \"agent=\": \"./configs/agent/{}.yaml\",\n        \"trainer=\": \"./configs/trainer/{}.yaml\",\n        \"trainer.curriculum=\": \"./configs/{}.yaml\",\n        \"sim=\": \"./configs/sim/{}.yaml\",\n    }",
        "detail": "devops.skypilot.utils",
        "documentation": {}
    },
    {
        "label": "display_job_summary",
        "kind": 2,
        "importPath": "devops.skypilot.utils",
        "description": "devops.skypilot.utils",
        "peekOfCode": "def display_job_summary(\n    job_name: str,\n    cmd: str,\n    task_args: list[str],\n    commit_hash: str,\n    git_ref: str | None = None,\n    timeout_hours: float | None = None,\n    task: sky.Task | None = None,\n    **kwargs,\n) -> None:",
        "detail": "devops.skypilot.utils",
        "documentation": {}
    },
    {
        "label": "RuffError",
        "kind": 6,
        "importPath": "devops.tools.auto_ruff_fix",
        "description": "devops.tools.auto_ruff_fix",
        "peekOfCode": "class RuffError:\n    file_path: str\n    line_number: int\n    column: int\n    error_code: str\n    message: str\n    context_lines: List[str]\nclass AutoRuffFix:\n    def __init__(self, claude_api_key: str, model: str = \"claude-3-7-sonnet-20250219\", context_lines: int = 5):\n        \"\"\"Initialize the AutoRuffFix tool.",
        "detail": "devops.tools.auto_ruff_fix",
        "documentation": {}
    },
    {
        "label": "AutoRuffFix",
        "kind": 6,
        "importPath": "devops.tools.auto_ruff_fix",
        "description": "devops.tools.auto_ruff_fix",
        "peekOfCode": "class AutoRuffFix:\n    def __init__(self, claude_api_key: str, model: str = \"claude-3-7-sonnet-20250219\", context_lines: int = 5):\n        \"\"\"Initialize the AutoRuffFix tool.\n        Args:\n            claude_api_key: Anthropic API key for Claude\n            model: Claude model to use for generating fixes\n            context_lines: Number of lines to include before and after the error line (default: 5)\n        \"\"\"\n        self.client = anthropic.Anthropic(api_key=claude_api_key)\n        self.model = model",
        "detail": "devops.tools.auto_ruff_fix",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "devops.tools.auto_ruff_fix",
        "description": "devops.tools.auto_ruff_fix",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(description=\"Automatically fix Ruff errors using Claude\")\n    parser.add_argument(\"paths\", nargs=\"+\", help=\"File paths or directories to check\")\n    parser.add_argument(\"--config\", help=\"Path to Ruff config file\")\n    parser.add_argument(\"--max-errors\", type=int, help=\"Maximum number of errors to fix\")\n    parser.add_argument(\"--verbose\", \"-v\", action=\"store_true\", help=\"Enable verbose output\")\n    parser.add_argument(\n        \"--model\",\n        default=\"claude-3-7-sonnet-20250219\",\n        help=\"Claude model to use (default: claude-3-7-sonnet-20250219)\",",
        "detail": "devops.tools.auto_ruff_fix",
        "documentation": {}
    },
    {
        "label": "is_dir_empty_or_pycache_only",
        "kind": 2,
        "importPath": "devops.tools.cleanup_repo",
        "description": "devops.tools.cleanup_repo",
        "peekOfCode": "def is_dir_empty_or_pycache_only(dir_path):\n    \"\"\"\n    Check if a directory is empty or contains only __pycache__\n    \"\"\"\n    try:\n        contents = list(os.listdir(dir_path))\n        # Empty directory\n        if not contents:\n            return True\n        # Only contains __pycache__",
        "detail": "devops.tools.cleanup_repo",
        "documentation": {}
    },
    {
        "label": "clean_directory",
        "kind": 2,
        "importPath": "devops.tools.cleanup_repo",
        "description": "devops.tools.cleanup_repo",
        "peekOfCode": "def clean_directory(root_path, dry_run=True):\n    \"\"\"\n    Recursively clean empty directories and those with only __pycache__\n    \"\"\"\n    removed_dirs = []\n    # Walk through directory tree bottom-up\n    for dirpath, _, _ in os.walk(root_path, topdown=False):\n        dir_path = Path(dirpath)\n        # Skip .git directory and its subdirectories\n        if \".git\" in dir_path.parts:",
        "detail": "devops.tools.cleanup_repo",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "devops.tools.cleanup_repo",
        "description": "devops.tools.cleanup_repo",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(description=\"Clean empty directories and directories containing only __pycache__\")\n    parser.add_argument(\"path\", nargs=\"?\", default=\".\", help=\"Path to the repository (default: current directory)\")\n    parser.add_argument(\"--dry-run\", action=\"store_true\", help=\"Show what would be removed without actually removing\")\n    args = parser.parse_args()\n    root_path = os.path.abspath(args.path)\n    if not os.path.exists(root_path):\n        print(red(f\"Error: Path '{root_path}' does not exist\"))\n        return 1\n    if not os.path.isdir(root_path):",
        "detail": "devops.tools.cleanup_repo",
        "documentation": {}
    },
    {
        "label": "find_repo_root",
        "kind": 2,
        "importPath": "devops.tools.merge_cspell",
        "description": "devops.tools.merge_cspell",
        "peekOfCode": "def find_repo_root(start_path=None):\n    \"\"\"Find the repository root by looking for common repo indicators.\"\"\"\n    if start_path is None:\n        start_path = os.getcwd()\n    current_path = os.path.abspath(start_path)\n    # Look for common repository indicators\n    repo_indicators = [\".git\", \".hg\", \".svn\"]\n    while current_path != os.path.dirname(current_path):  # Stop at filesystem root\n        for indicator in repo_indicators:\n            if os.path.exists(os.path.join(current_path, indicator)):",
        "detail": "devops.tools.merge_cspell",
        "documentation": {}
    },
    {
        "label": "process_workspace_file",
        "kind": 2,
        "importPath": "devops.tools.merge_cspell",
        "description": "devops.tools.merge_cspell",
        "peekOfCode": "def process_workspace_file(file_path):\n    \"\"\"\n    Extract words from repository code.workspace file and clear the list.\n    vscode json rules are lax so it's easier to just use regex.\n    \"\"\"\n    assert \"code-workspace\" in file_path\n    try:\n        # Read the file as text\n        with open(file_path, \"r\") as file:\n            content = file.read()",
        "detail": "devops.tools.merge_cspell",
        "documentation": {}
    },
    {
        "label": "merge_spelling_words",
        "kind": 2,
        "importPath": "devops.tools.merge_cspell",
        "description": "devops.tools.merge_cspell",
        "peekOfCode": "def merge_spelling_words(workspace_file_path, cspell_file_path):\n    \"\"\"Merge spelling words from workspace file into cspell json file and resort.\"\"\"\n    # Check if both files exist\n    if not os.path.isfile(workspace_file_path):\n        print(f\"Error: Workspace file {workspace_file_path} not found.\")\n        return False\n    if not os.path.isfile(cspell_file_path):\n        print(f\"Error: CSpell file {cspell_file_path} not found.\")\n        return False\n    print(f\"Processing workspace file: {workspace_file_path}\")",
        "detail": "devops.tools.merge_cspell",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "devops.tools.merge_cspell",
        "description": "devops.tools.merge_cspell",
        "peekOfCode": "def main():\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n    # Find the repository root\n    repo_root = find_repo_root(script_dir)\n    if repo_root:\n        print(f\"Repository root found at: {repo_root}\")\n        # Define paths to files\n        workspace_file = os.path.join(repo_root, \"metta.code-workspace\")\n        cspell_file = os.path.join(repo_root, \".cspell.json\")\n        # Merge and sort the spelling words",
        "detail": "devops.tools.merge_cspell",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "devops.wandb.project",
        "description": "devops.wandb.project",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--wandb_user\", required=True)\n    parser.add_argument(\"--wandb_project\", required=True)\n    parser.add_argument(\"--yaml_path\", required=True)\n    parser.add_argument(\"--load\", action=\"store_true\")\n    parser.add_argument(\"--save\", action=\"store_true\")\n    args = parser.parse_args()\n    api = wandb.Api()\n    run = api.runs(f\"{args.wandb_user}/{args.wandb_project}\")",
        "detail": "devops.wandb.project",
        "documentation": {}
    },
    {
        "label": "apply_ttl_to_artifacts",
        "kind": 2,
        "importPath": "devops.wandb.wandb_ttl",
        "description": "devops.wandb.wandb_ttl",
        "peekOfCode": "def apply_ttl_to_artifacts(artifact_project: str, version_start: int, version_end: int, ttl_days: int) -> None:\n    \"\"\"\n    Update the TTL of a range of artifact versions.\n    \"\"\"\n    run = wandb.init(project=PROJECT_NAME, entity=ENTITY_NAME)\n    version = version_start\n    while version <= version_end:\n        try:\n            artifact_name = f\"{ENTITY_NAME}/{PROJECT_NAME}/{artifact_project}:v{version}\"\n            artifact = run.use_artifact(artifact_name)",
        "detail": "devops.wandb.wandb_ttl",
        "documentation": {}
    },
    {
        "label": "ENTITY_NAME",
        "kind": 5,
        "importPath": "devops.wandb.wandb_ttl",
        "description": "devops.wandb.wandb_ttl",
        "peekOfCode": "ENTITY_NAME = \"metta-research\"\nPROJECT_NAME = \"metta\"\ndef apply_ttl_to_artifacts(artifact_project: str, version_start: int, version_end: int, ttl_days: int) -> None:\n    \"\"\"\n    Update the TTL of a range of artifact versions.\n    \"\"\"\n    run = wandb.init(project=PROJECT_NAME, entity=ENTITY_NAME)\n    version = version_start\n    while version <= version_end:\n        try:",
        "detail": "devops.wandb.wandb_ttl",
        "documentation": {}
    },
    {
        "label": "PROJECT_NAME",
        "kind": 5,
        "importPath": "devops.wandb.wandb_ttl",
        "description": "devops.wandb.wandb_ttl",
        "peekOfCode": "PROJECT_NAME = \"metta\"\ndef apply_ttl_to_artifacts(artifact_project: str, version_start: int, version_end: int, ttl_days: int) -> None:\n    \"\"\"\n    Update the TTL of a range of artifact versions.\n    \"\"\"\n    run = wandb.init(project=PROJECT_NAME, entity=ENTITY_NAME)\n    version = version_start\n    while version <= version_end:\n        try:\n            artifact_name = f\"{ENTITY_NAME}/{PROJECT_NAME}/{artifact_project}:v{version}\"",
        "detail": "devops.wandb.wandb_ttl",
        "documentation": {}
    },
    {
        "label": "check_policy_exists",
        "kind": 2,
        "importPath": "devops.add_to_leaderboard",
        "description": "devops.add_to_leaderboard",
        "peekOfCode": "def check_policy_exists(run_name: str) -> bool:\n    \"\"\"\n    Check if a policy exists in WANDB.\n    Args:\n        run_name: The run name to check\n    Returns:\n        True if policy exists, False otherwise\n    \"\"\"\n    try:\n        api = wandb.Api()",
        "detail": "devops.add_to_leaderboard",
        "documentation": {}
    },
    {
        "label": "run_command",
        "kind": 2,
        "importPath": "devops.add_to_leaderboard",
        "description": "devops.add_to_leaderboard",
        "peekOfCode": "def run_command(cmd: List[str], description: str) -> bool:\n    \"\"\"\n    Run a command and return success status.\n    Args:\n        cmd: Command as list of strings\n        description: Description for logging\n    Returns:\n        True if command succeeded, False otherwise\n    \"\"\"\n    print(f\"Executing: {' '.join(cmd)}\")",
        "detail": "devops.add_to_leaderboard",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "devops.add_to_leaderboard",
        "description": "devops.add_to_leaderboard",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(\n        description=\"Add policy to evaluation leaderboard and update dashboard\",\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        epilog=\"\"\"\nExamples:\n%(prog)s --run b.username.test_run +hardware=macbook\n\"\"\",\n    )\n    parser.add_argument(\"--run\", required=True, help=\"Your run name (e.g., b.$USER.test_run)\")",
        "detail": "devops.add_to_leaderboard",
        "documentation": {}
    },
    {
        "label": "CLIAuthenticator",
        "kind": 6,
        "importPath": "devops.observatory_login",
        "description": "devops.observatory_login",
        "peekOfCode": "class CLIAuthenticator:\n    def __init__(self, auth_server_url: str):\n        self.auth_url = auth_server_url + \"/tokens/cli\"\n        self.token = None\n        self.error = None\n        self.server_started = threading.Event()\n        self.auth_completed = threading.Event()\n        home = Path.home()\n        self.config_dir = home / \".metta\"\n        self.config_dir.mkdir(parents=True, exist_ok=True)",
        "detail": "devops.observatory_login",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "devops.observatory_login",
        "description": "devops.observatory_login",
        "peekOfCode": "def main():\n    \"\"\"Main CLI entry point\"\"\"\n    import argparse\n    parser = argparse.ArgumentParser(description=\"CLI OAuth2 Authentication\")\n    parser.add_argument(\n        \"--auth-server-url\",\n        default=\"https://observatory.softmax-research.net/api\",\n        help=\"OAuth2-proxy protected route URL\",\n    )\n    parser.add_argument(\"--timeout\", type=int, default=300, help=\"Authentication timeout in seconds (default: 300)\")",
        "detail": "devops.observatory_login",
        "documentation": {}
    },
    {
        "label": "analyze",
        "kind": 2,
        "importPath": "metta.eval.analysis",
        "description": "metta.eval.analysis",
        "peekOfCode": "def analyze(policy_record: PolicyRecord, config: AnalysisConfig) -> None:\n    logger = logging.getLogger(__name__)\n    logger.info(f\"Analyzing policy: {policy_record.uri}\")\n    logger.info(f\"Using eval DB: {config.eval_db_uri}\")\n    with local_copy(config.eval_db_uri) as local_path:\n        stats_db = EvalStatsDB(local_path)\n        sample_count = stats_db.sample_count(policy_record, config.suite)\n        if sample_count == 0:\n            pk, pv = stats_db.key_and_version(policy_record)\n            logger.warning(f\"No samples found for key, version = {pk}, {pv}\")",
        "detail": "metta.eval.analysis",
        "documentation": {}
    },
    {
        "label": "get_available_metrics",
        "kind": 2,
        "importPath": "metta.eval.analysis",
        "description": "metta.eval.analysis",
        "peekOfCode": "def get_available_metrics(stats_db: EvalStatsDB, policy_record: PolicyRecord) -> List[str]:\n    pk, pv = stats_db.key_and_version(policy_record)\n    result = stats_db.query(\n        f\"\"\"\n        SELECT DISTINCT metric\n          FROM policy_simulation_agent_metrics\n         WHERE policy_key     = '{pk}'\n           AND policy_version =  {pv}\n         ORDER BY metric\n        \"\"\"",
        "detail": "metta.eval.analysis",
        "documentation": {}
    },
    {
        "label": "filter_metrics",
        "kind": 2,
        "importPath": "metta.eval.analysis",
        "description": "metta.eval.analysis",
        "peekOfCode": "def filter_metrics(available_metrics: List[str], patterns: List[str]) -> List[str]:\n    if not patterns or patterns == [\"*\"]:\n        return available_metrics\n    selected = []\n    for pattern in patterns:\n        selected.extend(m for m in available_metrics if fnmatch.fnmatch(m, pattern))\n    return list(dict.fromkeys(selected))  # dedupe, preserve order\ndef get_metrics_data(\n    stats_db: EvalStatsDB,\n    policy_record: PolicyRecord,",
        "detail": "metta.eval.analysis",
        "documentation": {}
    },
    {
        "label": "get_metrics_data",
        "kind": 2,
        "importPath": "metta.eval.analysis",
        "description": "metta.eval.analysis",
        "peekOfCode": "def get_metrics_data(\n    stats_db: EvalStatsDB,\n    policy_record: PolicyRecord,\n    metrics: List[str],\n    suite: Optional[str] = None,\n) -> Dict[str, Dict[str, float]]:\n    \"\"\"\n    Return {metric: {\"mean\": , \"std\": ,\n                     \"count\": K_recorded,\n                     \"samples\": N_potential}}",
        "detail": "metta.eval.analysis",
        "documentation": {}
    },
    {
        "label": "print_metrics_table",
        "kind": 2,
        "importPath": "metta.eval.analysis",
        "description": "metta.eval.analysis",
        "peekOfCode": "def print_metrics_table(\n    stats_db: EvalStatsDB, metrics_data: Dict[str, Dict[str, float]], policy_record: PolicyRecord\n) -> None:\n    logger = logging.getLogger(__name__)\n    if not metrics_data:\n        pk, pv = stats_db.key_and_version(policy_record)\n        logger.warning(f\"No metrics data available for key, version = {pk}, {pv}\")\n        return\n    headers = [\"Metric\", \"Average\", \"Std Dev\", \"Metric Samples\", \"Agent Samples\"]\n    rows = [",
        "detail": "metta.eval.analysis",
        "documentation": {}
    },
    {
        "label": "AnalysisConfig",
        "kind": 6,
        "importPath": "metta.eval.analysis_config",
        "description": "metta.eval.analysis_config",
        "peekOfCode": "class AnalysisConfig(Config):\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    __init__ = Config.__init__\n    # Policy URI to analyze\n    policy_uri: str | None = None\n    policy_selector: PolicySelectorConfig = Field(default_factory=PolicySelectorConfig)\n    # Metrics to analyze\n    # Supports globs, e.g. *.reward\n    metrics: list[str] = [\"*\"]\n    # Input database",
        "detail": "metta.eval.analysis_config",
        "documentation": {}
    },
    {
        "label": "DashboardConfig",
        "kind": 6,
        "importPath": "metta.eval.dashboard_data",
        "description": "metta.eval.dashboard_data",
        "peekOfCode": "class DashboardConfig(Config):\n    __init__ = Config.__init__\n    eval_db_uri: str\n    output_path: str = \"/tmp/dashboard_data.json\"\nclass PolicyEvalMetric(BaseModel):\n    metric: str\n    group_id: str\n    sum_value: float\nclass PolicyEval(BaseModel):\n    policy_key: str",
        "detail": "metta.eval.dashboard_data",
        "documentation": {}
    },
    {
        "label": "PolicyEvalMetric",
        "kind": 6,
        "importPath": "metta.eval.dashboard_data",
        "description": "metta.eval.dashboard_data",
        "peekOfCode": "class PolicyEvalMetric(BaseModel):\n    metric: str\n    group_id: str\n    sum_value: float\nclass PolicyEval(BaseModel):\n    policy_key: str\n    policy_version: int\n    eval_name: str\n    suite: str\n    replay_url: str | None",
        "detail": "metta.eval.dashboard_data",
        "documentation": {}
    },
    {
        "label": "PolicyEval",
        "kind": 6,
        "importPath": "metta.eval.dashboard_data",
        "description": "metta.eval.dashboard_data",
        "peekOfCode": "class PolicyEval(BaseModel):\n    policy_key: str\n    policy_version: int\n    eval_name: str\n    suite: str\n    replay_url: str | None\n    group_num_agents: Dict[str, int]\n    policy_eval_metrics: List[PolicyEvalMetric]\nclass DashboardData(BaseModel):\n    policy_evals: List[PolicyEval]",
        "detail": "metta.eval.dashboard_data",
        "documentation": {}
    },
    {
        "label": "DashboardData",
        "kind": 6,
        "importPath": "metta.eval.dashboard_data",
        "description": "metta.eval.dashboard_data",
        "peekOfCode": "class DashboardData(BaseModel):\n    policy_evals: List[PolicyEval]\ndef get_policy_eval_metrics(db: SimulationStatsDB) -> List[PolicyEval]:\n    db.con.execute(\n        \"\"\"\n      CREATE VIEW IF NOT EXISTS episode_info AS (\n          SELECT\n            e.id as episode_id,\n            s.name as eval_name,\n            s.suite,",
        "detail": "metta.eval.dashboard_data",
        "documentation": {}
    },
    {
        "label": "get_policy_eval_metrics",
        "kind": 2,
        "importPath": "metta.eval.dashboard_data",
        "description": "metta.eval.dashboard_data",
        "peekOfCode": "def get_policy_eval_metrics(db: SimulationStatsDB) -> List[PolicyEval]:\n    db.con.execute(\n        \"\"\"\n      CREATE VIEW IF NOT EXISTS episode_info AS (\n          SELECT\n            e.id as episode_id,\n            s.name as eval_name,\n            s.suite,\n            s.env,\n            s.policy_key,",
        "detail": "metta.eval.dashboard_data",
        "documentation": {}
    },
    {
        "label": "write_dashboard_data",
        "kind": 2,
        "importPath": "metta.eval.dashboard_data",
        "description": "metta.eval.dashboard_data",
        "peekOfCode": "def write_dashboard_data(dashboard_cfg: DashboardConfig):\n    with SimulationStatsDB.from_uri(dashboard_cfg.eval_db_uri) as db:\n        metrics = get_policy_eval_metrics(db)\n        content = DashboardData(policy_evals=metrics).model_dump_json()\n    write_data(dashboard_cfg.output_path, content, content_type=\"application/json\")",
        "detail": "metta.eval.dashboard_data",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "metta.eval.dashboard_data",
        "description": "metta.eval.dashboard_data",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass DashboardConfig(Config):\n    __init__ = Config.__init__\n    eval_db_uri: str\n    output_path: str = \"/tmp/dashboard_data.json\"\nclass PolicyEvalMetric(BaseModel):\n    metric: str\n    group_id: str\n    sum_value: float\nclass PolicyEval(BaseModel):",
        "detail": "metta.eval.dashboard_data",
        "documentation": {}
    },
    {
        "label": "EvalStatsDB",
        "kind": 6,
        "importPath": "metta.eval.eval_stats_db",
        "description": "metta.eval.eval_stats_db",
        "peekOfCode": "class EvalStatsDB(SimulationStatsDB):\n    def __init__(self, path: Path) -> None:\n        super().__init__(path)\n    @classmethod\n    @contextmanager\n    def from_uri(cls, path: str):\n        \"\"\"Download (if remote), open, and yield an EvalStatsDB.\"\"\"\n        with local_copy(path) as local_path:\n            db = cls(local_path)\n            yield db",
        "detail": "metta.eval.eval_stats_db",
        "documentation": {}
    },
    {
        "label": "AsciiParams",
        "kind": 6,
        "importPath": "metta.map.scenes.ascii",
        "description": "metta.map.scenes.ascii",
        "peekOfCode": "class AsciiParams(Config):\n    uri: str\nclass Ascii(Scene[AsciiParams]):\n    def post_init(self):\n        with open(self.params.uri, \"r\", encoding=\"utf-8\") as f:\n            self.ascii_data = f.read()\n    def get_children(self):\n        return [\n            ChildrenAction(\n                scene=lambda grid: InlineAscii(grid=grid, params={\"data\": self.ascii_data}),",
        "detail": "metta.map.scenes.ascii",
        "documentation": {}
    },
    {
        "label": "Ascii",
        "kind": 6,
        "importPath": "metta.map.scenes.ascii",
        "description": "metta.map.scenes.ascii",
        "peekOfCode": "class Ascii(Scene[AsciiParams]):\n    def post_init(self):\n        with open(self.params.uri, \"r\", encoding=\"utf-8\") as f:\n            self.ascii_data = f.read()\n    def get_children(self):\n        return [\n            ChildrenAction(\n                scene=lambda grid: InlineAscii(grid=grid, params={\"data\": self.ascii_data}),\n                where=\"full\",\n            ),",
        "detail": "metta.map.scenes.ascii",
        "documentation": {}
    },
    {
        "label": "AutoParamsLayout",
        "kind": 6,
        "importPath": "metta.map.scenes.auto",
        "description": "metta.map.scenes.auto",
        "peekOfCode": "class AutoParamsLayout(Config):\n    grid: int\n    bsp: int\nclass AutoParamsGrid(Config):\n    rows: IntDistribution\n    columns: IntDistribution\nclass AutoParamsBSP(Config):\n    area_count: IntDistribution\nclass AutoParamsRoomSymmetry(Config):\n    none: int",
        "detail": "metta.map.scenes.auto",
        "documentation": {}
    },
    {
        "label": "AutoParamsGrid",
        "kind": 6,
        "importPath": "metta.map.scenes.auto",
        "description": "metta.map.scenes.auto",
        "peekOfCode": "class AutoParamsGrid(Config):\n    rows: IntDistribution\n    columns: IntDistribution\nclass AutoParamsBSP(Config):\n    area_count: IntDistribution\nclass AutoParamsRoomSymmetry(Config):\n    none: int\n    horizontal: int\n    vertical: int\n    x4: int",
        "detail": "metta.map.scenes.auto",
        "documentation": {}
    },
    {
        "label": "AutoParamsBSP",
        "kind": 6,
        "importPath": "metta.map.scenes.auto",
        "description": "metta.map.scenes.auto",
        "peekOfCode": "class AutoParamsBSP(Config):\n    area_count: IntDistribution\nclass AutoParamsRoomSymmetry(Config):\n    none: int\n    horizontal: int\n    vertical: int\n    x4: int\nclass AutoParams(Config):\n    num_agents: int = 0\n    layout: AutoParamsLayout",
        "detail": "metta.map.scenes.auto",
        "documentation": {}
    },
    {
        "label": "AutoParamsRoomSymmetry",
        "kind": 6,
        "importPath": "metta.map.scenes.auto",
        "description": "metta.map.scenes.auto",
        "peekOfCode": "class AutoParamsRoomSymmetry(Config):\n    none: int\n    horizontal: int\n    vertical: int\n    x4: int\nclass AutoParams(Config):\n    num_agents: int = 0\n    layout: AutoParamsLayout\n    grid: AutoParamsGrid\n    bsp: AutoParamsBSP",
        "detail": "metta.map.scenes.auto",
        "documentation": {}
    },
    {
        "label": "AutoParams",
        "kind": 6,
        "importPath": "metta.map.scenes.auto",
        "description": "metta.map.scenes.auto",
        "peekOfCode": "class AutoParams(Config):\n    num_agents: int = 0\n    layout: AutoParamsLayout\n    grid: AutoParamsGrid\n    bsp: AutoParamsBSP\n    room_symmetry: AutoParamsRoomSymmetry\n    content: list[RandomSceneCandidate]\n    objects: dict[str, IntDistribution]\n    room_objects: dict[str, FloatDistribution]\nclass Auto(Scene[AutoParams]):",
        "detail": "metta.map.scenes.auto",
        "documentation": {}
    },
    {
        "label": "Auto",
        "kind": 6,
        "importPath": "metta.map.scenes.auto",
        "description": "metta.map.scenes.auto",
        "peekOfCode": "class Auto(Scene[AutoParams]):\n    def get_children(self) -> list[ChildrenAction]:\n        return [\n            ChildrenAction(\n                scene=lambda grid: AutoLayout(grid=grid, params=self.params, seed=self.rng),\n                where=\"full\",\n            ),\n            ChildrenAction(\n                scene=lambda grid: Random(grid=grid, params={\"objects\": self.params.objects}, seed=self.rng),\n                where=\"full\",",
        "detail": "metta.map.scenes.auto",
        "documentation": {}
    },
    {
        "label": "AutoLayout",
        "kind": 6,
        "importPath": "metta.map.scenes.auto",
        "description": "metta.map.scenes.auto",
        "peekOfCode": "class AutoLayout(Scene[AutoParams]):\n    def get_children(self) -> list[ChildrenAction]:\n        weights = np.array([self.params.layout.grid, self.params.layout.bsp], dtype=np.float32)\n        weights /= weights.sum()\n        layout = self.rng.choice([\"grid\", \"bsp\"], p=weights)\n        def children_for_tag(tag: str) -> list[ChildrenAction]:\n            return [\n                ChildrenAction(\n                    scene=lambda grid: AutoSymmetry(grid=grid, params=self.params, seed=self.rng),\n                    where=AreaWhere(tags=[tag]),",
        "detail": "metta.map.scenes.auto",
        "documentation": {}
    },
    {
        "label": "AutoSymmetry",
        "kind": 6,
        "importPath": "metta.map.scenes.auto",
        "description": "metta.map.scenes.auto",
        "peekOfCode": "class AutoSymmetry(Scene[AutoParams]):\n    def get_children(self) -> list[ChildrenAction]:\n        weights = np.array(\n            [\n                self.params.room_symmetry.none,\n                self.params.room_symmetry.horizontal,\n                self.params.room_symmetry.vertical,\n                self.params.room_symmetry.x4,\n            ],\n            dtype=np.float32,",
        "detail": "metta.map.scenes.auto",
        "documentation": {}
    },
    {
        "label": "BSPLayoutParams",
        "kind": 6,
        "importPath": "metta.map.scenes.bsp",
        "description": "metta.map.scenes.bsp",
        "peekOfCode": "class BSPLayoutParams(Config):\n    area_count: int\nclass BSPLayout(Scene[BSPLayoutParams]):\n    \"\"\"\n    This scene doesn't render anything, it just creates areas that can be used by other scenes.\n    \"\"\"\n    def render(self):\n        grid = self.grid\n        tree = BSPTree(\n            width=grid.shape[1],",
        "detail": "metta.map.scenes.bsp",
        "documentation": {}
    },
    {
        "label": "BSPLayout",
        "kind": 6,
        "importPath": "metta.map.scenes.bsp",
        "description": "metta.map.scenes.bsp",
        "peekOfCode": "class BSPLayout(Scene[BSPLayoutParams]):\n    \"\"\"\n    This scene doesn't render anything, it just creates areas that can be used by other scenes.\n    \"\"\"\n    def render(self):\n        grid = self.grid\n        tree = BSPTree(\n            width=grid.shape[1],\n            height=grid.shape[0],\n            leaf_zone_count=self.params.area_count,",
        "detail": "metta.map.scenes.bsp",
        "documentation": {}
    },
    {
        "label": "BSPParams",
        "kind": 6,
        "importPath": "metta.map.scenes.bsp",
        "description": "metta.map.scenes.bsp",
        "peekOfCode": "class BSPParams(Config):\n    rooms: int\n    min_room_size: int\n    min_room_size_ratio: float\n    max_room_size_ratio: float\n    skip_corridors: bool = False\nclass BSP(Scene[BSPParams]):\n    \"\"\"\n    Binary Space Partitioning. (Roguelike dungeon generator)\n    This scene creates a grid of rooms, and then connects them with corridors.",
        "detail": "metta.map.scenes.bsp",
        "documentation": {}
    },
    {
        "label": "BSP",
        "kind": 6,
        "importPath": "metta.map.scenes.bsp",
        "description": "metta.map.scenes.bsp",
        "peekOfCode": "class BSP(Scene[BSPParams]):\n    \"\"\"\n    Binary Space Partitioning. (Roguelike dungeon generator)\n    This scene creates a grid of rooms, and then connects them with corridors.\n    \"\"\"\n    def render(self):\n        grid = self.grid\n        params = self.params\n        grid[:] = \"wall\"\n        bsp_tree = BSPTree(",
        "detail": "metta.map.scenes.bsp",
        "documentation": {}
    },
    {
        "label": "Zone",
        "kind": 6,
        "importPath": "metta.map.scenes.bsp",
        "description": "metta.map.scenes.bsp",
        "peekOfCode": "class Zone:\n    def __init__(self, x: int, y: int, width: int, height: int, rng: np.random.Generator):\n        self.x = x\n        self.y = y\n        self.width = width\n        self.height = height\n        self.rng = rng\n    def split(self) -> Tuple[\"Zone\", \"Zone\"]:\n        # Split in random direction, unless the room is too wide or too tall.\n        if self.width > self.height * 2:",
        "detail": "metta.map.scenes.bsp",
        "documentation": {}
    },
    {
        "label": "Surface",
        "kind": 6,
        "importPath": "metta.map.scenes.bsp",
        "description": "metta.map.scenes.bsp",
        "peekOfCode": "class Surface:\n    \"\"\"\n    When choosing how to connect rooms, or rooms with corridors, we need to represent the surface of possible\n    attachment points.\n    Surface example:\n    #.........##\n    ###......###\n    ###......###\n    ############\n    ############",
        "detail": "metta.map.scenes.bsp",
        "documentation": {}
    },
    {
        "label": "Line",
        "kind": 6,
        "importPath": "metta.map.scenes.bsp",
        "description": "metta.map.scenes.bsp",
        "peekOfCode": "class Line:\n    \"\"\"\n    A line is a straight corridor that can be drawn on the grid.\n    It can be horizontal or vertical.\n    Full corridor between two rooms can be represented as multiple lines.\n    \"\"\"\n    def __init__(self, direction: Direction, start: Tuple[int, int], length: int):\n        self.direction = direction\n        if length < 0:\n            # line of negative length means that the line is reversed (right to left or down to up)",
        "detail": "metta.map.scenes.bsp",
        "documentation": {}
    },
    {
        "label": "BSPTree",
        "kind": 6,
        "importPath": "metta.map.scenes.bsp",
        "description": "metta.map.scenes.bsp",
        "peekOfCode": "class BSPTree:\n    \"\"\"\n    Split the grid into zones, and return the zones and the index of the first leaf zone.\n    This function is used in:\n    1) BSP scene that creates rooms at leaf zones and connects them with corridors.\n    2) BSPLayout scene that just creates a grid of zones, without rooms or corridors.\n    \"\"\"\n    zones: list[Zone]\n    def __init__(\n        self,",
        "detail": "metta.map.scenes.bsp",
        "documentation": {}
    },
    {
        "label": "connect_surfaces",
        "kind": 2,
        "importPath": "metta.map.scenes.bsp",
        "description": "metta.map.scenes.bsp",
        "peekOfCode": "def connect_surfaces(surface1: Surface, surface2: Surface):\n    \"\"\"\n    Connect two surfaces with a corridor.\n    Assumes that the surfaces are adjacent and the surface1 is strictly above of surface2, i.e. all its positions\n    are strictly smaller than all of surface2's positions.\n    Surfaces should have been transposed as needed to make this true.\n    Example:\n    \n    #........###\n    ###......###",
        "detail": "metta.map.scenes.bsp",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "metta.map.scenes.bsp",
        "description": "metta.map.scenes.bsp",
        "peekOfCode": "logger = logging.getLogger(__name__)\nDirection = Literal[\"horizontal\", \"vertical\"]\nclass BSPLayoutParams(Config):\n    area_count: int\nclass BSPLayout(Scene[BSPLayoutParams]):\n    \"\"\"\n    This scene doesn't render anything, it just creates areas that can be used by other scenes.\n    \"\"\"\n    def render(self):\n        grid = self.grid",
        "detail": "metta.map.scenes.bsp",
        "documentation": {}
    },
    {
        "label": "Direction",
        "kind": 5,
        "importPath": "metta.map.scenes.bsp",
        "description": "metta.map.scenes.bsp",
        "peekOfCode": "Direction = Literal[\"horizontal\", \"vertical\"]\nclass BSPLayoutParams(Config):\n    area_count: int\nclass BSPLayout(Scene[BSPLayoutParams]):\n    \"\"\"\n    This scene doesn't render anything, it just creates areas that can be used by other scenes.\n    \"\"\"\n    def render(self):\n        grid = self.grid\n        tree = BSPTree(",
        "detail": "metta.map.scenes.bsp",
        "documentation": {}
    },
    {
        "label": "ConvChainParams",
        "kind": 6,
        "importPath": "metta.map.scenes.convchain",
        "description": "metta.map.scenes.convchain",
        "peekOfCode": "class ConvChainParams(Config):\n    pattern: str\n    pattern_size: int\n    iterations: int\n    temperature: float\n    periodic_input: bool = True\n    symmetry: Symmetry = \"all\"\nclass ConvChain(Scene[ConvChainParams]):\n    \"\"\"\n    ConvChain scene generator, based on https://github.com/mxgmn/ConvChain",
        "detail": "metta.map.scenes.convchain",
        "documentation": {}
    },
    {
        "label": "ConvChain",
        "kind": 6,
        "importPath": "metta.map.scenes.convchain",
        "description": "metta.map.scenes.convchain",
        "peekOfCode": "class ConvChain(Scene[ConvChainParams]):\n    \"\"\"\n    ConvChain scene generator, based on https://github.com/mxgmn/ConvChain\n    (ConvChainFast.cs version).\n    This algorithm generates patterns similar to a given sample pattern.\n    It uses a statistical model to capture local features of the sample\n    and then generates new patterns with similar local characteristics.\n    \"\"\"\n    def post_init(self):\n        self._weights = ascii_to_weights_of_all_patterns(",
        "detail": "metta.map.scenes.convchain",
        "documentation": {}
    },
    {
        "label": "ConvChainSlow",
        "kind": 6,
        "importPath": "metta.map.scenes.convchain",
        "description": "metta.map.scenes.convchain",
        "peekOfCode": "class ConvChainSlow(Scene[ConvChainParams]):\n    \"\"\"\n    ConvChain scene generator, naive & slow implementation.\n    Committed to the repo for the sake of comparison, usually shouldn't be used and can be removed later.\n    \"\"\"\n    def post_init(self):\n        self._weights = ascii_to_weights_of_all_patterns(\n            self.params.pattern,\n            self.params.pattern_size,\n            periodic=self.params.periodic_input,",
        "detail": "metta.map.scenes.convchain",
        "documentation": {}
    },
    {
        "label": "InlineAsciiParams",
        "kind": 6,
        "importPath": "metta.map.scenes.inline_ascii",
        "description": "metta.map.scenes.inline_ascii",
        "peekOfCode": "class InlineAsciiParams(Config):\n    data: str\n    row: int = 0\n    column: int = 0\nclass InlineAscii(Scene[InlineAsciiParams]):\n    def post_init(self):\n        params = self.params\n        lines, _, _ = char_grid_to_lines(params.data)\n        self.ascii_grid = np.array([list(line) for line in lines], dtype=\"U6\")\n        self.ascii_grid = np.vectorize(char_to_grid_object)(self.ascii_grid)",
        "detail": "metta.map.scenes.inline_ascii",
        "documentation": {}
    },
    {
        "label": "InlineAscii",
        "kind": 6,
        "importPath": "metta.map.scenes.inline_ascii",
        "description": "metta.map.scenes.inline_ascii",
        "peekOfCode": "class InlineAscii(Scene[InlineAsciiParams]):\n    def post_init(self):\n        params = self.params\n        lines, _, _ = char_grid_to_lines(params.data)\n        self.ascii_grid = np.array([list(line) for line in lines], dtype=\"U6\")\n        self.ascii_grid = np.vectorize(char_to_grid_object)(self.ascii_grid)\n    def render(self):\n        params = self.params\n        if self.width < self.ascii_grid.shape[1] + params.column or self.height < self.ascii_grid.shape[0] + params.row:\n            raise ValueError(",
        "detail": "metta.map.scenes.inline_ascii",
        "documentation": {}
    },
    {
        "label": "MakeConnectedParams",
        "kind": 6,
        "importPath": "metta.map.scenes.make_connected",
        "description": "metta.map.scenes.make_connected",
        "peekOfCode": "class MakeConnectedParams(Config):\n    pass\nclass MakeConnected(Scene[MakeConnectedParams]):\n    \"\"\"\n    This scene makes the map connected by digging tunnels.\n    It does this by:\n    - Finding all the connected components\n    - Digging shortest tunnels from the largest component to all other components\n    TODO: This can result in some extra tunnels being dug.\n    \"\"\"",
        "detail": "metta.map.scenes.make_connected",
        "documentation": {}
    },
    {
        "label": "MakeConnected",
        "kind": 6,
        "importPath": "metta.map.scenes.make_connected",
        "description": "metta.map.scenes.make_connected",
        "peekOfCode": "class MakeConnected(Scene[MakeConnectedParams]):\n    \"\"\"\n    This scene makes the map connected by digging tunnels.\n    It does this by:\n    - Finding all the connected components\n    - Digging shortest tunnels from the largest component to all other components\n    TODO: This can result in some extra tunnels being dug.\n    \"\"\"\n    def _is_empty(self, symbol: str) -> bool:\n        # TODO - treat agents as empty cells?",
        "detail": "metta.map.scenes.make_connected",
        "documentation": {}
    },
    {
        "label": "DIRECTIONS",
        "kind": 5,
        "importPath": "metta.map.scenes.make_connected",
        "description": "metta.map.scenes.make_connected",
        "peekOfCode": "DIRECTIONS = [(-1, 0), (0, 1), (1, 0), (0, -1)]\nlogger = logging.getLogger(__name__)\nCell = tuple[int, int]\nclass MakeConnectedParams(Config):\n    pass\nclass MakeConnected(Scene[MakeConnectedParams]):\n    \"\"\"\n    This scene makes the map connected by digging tunnels.\n    It does this by:\n    - Finding all the connected components",
        "detail": "metta.map.scenes.make_connected",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "metta.map.scenes.make_connected",
        "description": "metta.map.scenes.make_connected",
        "peekOfCode": "logger = logging.getLogger(__name__)\nCell = tuple[int, int]\nclass MakeConnectedParams(Config):\n    pass\nclass MakeConnected(Scene[MakeConnectedParams]):\n    \"\"\"\n    This scene makes the map connected by digging tunnels.\n    It does this by:\n    - Finding all the connected components\n    - Digging shortest tunnels from the largest component to all other components",
        "detail": "metta.map.scenes.make_connected",
        "documentation": {}
    },
    {
        "label": "Cell",
        "kind": 5,
        "importPath": "metta.map.scenes.make_connected",
        "description": "metta.map.scenes.make_connected",
        "peekOfCode": "Cell = tuple[int, int]\nclass MakeConnectedParams(Config):\n    pass\nclass MakeConnected(Scene[MakeConnectedParams]):\n    \"\"\"\n    This scene makes the map connected by digging tunnels.\n    It does this by:\n    - Finding all the connected components\n    - Digging shortest tunnels from the largest component to all other components\n    TODO: This can result in some extra tunnels being dug.",
        "detail": "metta.map.scenes.make_connected",
        "documentation": {}
    },
    {
        "label": "MazeKruskalParams",
        "kind": 6,
        "importPath": "metta.map.scenes.maze",
        "description": "metta.map.scenes.maze",
        "peekOfCode": "class MazeKruskalParams(Config):\n    room_size: IntDistribution = 1\n    wall_size: IntDistribution = 1\nclass MazeKruskal(Scene[MazeKruskalParams]):\n    \"\"\"\n    Maze generation using Randomized Kruskal's algorithm.\n    The generated maze doesn't have an outer border.\n    Example output:\n    \n             ",
        "detail": "metta.map.scenes.maze",
        "documentation": {}
    },
    {
        "label": "MazeKruskal",
        "kind": 6,
        "importPath": "metta.map.scenes.maze",
        "description": "metta.map.scenes.maze",
        "peekOfCode": "class MazeKruskal(Scene[MazeKruskalParams]):\n    \"\"\"\n    Maze generation using Randomized Kruskal's algorithm.\n    The generated maze doesn't have an outer border.\n    Example output:\n    \n             \n     # ##### \n     # # #   \n    #### ### ",
        "detail": "metta.map.scenes.maze",
        "documentation": {}
    },
    {
        "label": "anchor_to_position",
        "kind": 2,
        "importPath": "metta.map.scenes.maze",
        "description": "metta.map.scenes.maze",
        "peekOfCode": "def anchor_to_position(anchor: Anchor, width: int, height: int) -> Tuple[int, int]:\n    if anchor == \"top-left\":\n        return (0, 0)\n    elif anchor == \"top-right\":\n        return (width - 1, 0)\n    elif anchor == \"bottom-left\":\n        return (0, height - 1)\n    elif anchor == \"bottom-right\":\n        return (width - 1, height - 1)\nclass MazeKruskalParams(Config):",
        "detail": "metta.map.scenes.maze",
        "documentation": {}
    },
    {
        "label": "Anchor",
        "kind": 5,
        "importPath": "metta.map.scenes.maze",
        "description": "metta.map.scenes.maze",
        "peekOfCode": "Anchor = Union[\n    Literal[\"top-left\"],\n    Literal[\"top-right\"],\n    Literal[\"bottom-left\"],\n    Literal[\"bottom-right\"],\n]\nALL_ANCHORS: List[Anchor] = [\"top-left\", \"top-right\", \"bottom-left\", \"bottom-right\"]\ndef anchor_to_position(anchor: Anchor, width: int, height: int) -> Tuple[int, int]:\n    if anchor == \"top-left\":\n        return (0, 0)",
        "detail": "metta.map.scenes.maze",
        "documentation": {}
    },
    {
        "label": "MirrorParams",
        "kind": 6,
        "importPath": "metta.map.scenes.mirror",
        "description": "metta.map.scenes.mirror",
        "peekOfCode": "class MirrorParams(Config):\n    scene: SceneCfg\n    symmetry: Symmetry = \"horizontal\"\nclass Mirror(Scene[MirrorParams]):\n    def render(self):\n        symmetry = self.params.symmetry\n        scene = self.params.scene\n        if symmetry == \"horizontal\":\n            left_width = (self.width + 1) // 2  # take half, plus one for odd width\n            left_grid = self.grid[:, :left_width]",
        "detail": "metta.map.scenes.mirror",
        "documentation": {}
    },
    {
        "label": "Mirror",
        "kind": 6,
        "importPath": "metta.map.scenes.mirror",
        "description": "metta.map.scenes.mirror",
        "peekOfCode": "class Mirror(Scene[MirrorParams]):\n    def render(self):\n        symmetry = self.params.symmetry\n        scene = self.params.scene\n        if symmetry == \"horizontal\":\n            left_width = (self.width + 1) // 2  # take half, plus one for odd width\n            left_grid = self.grid[:, :left_width]\n            child_scene = make_scene(scene, left_grid)\n            child_scene.render_with_children()\n            self.grid[:, self.width - left_width :] = child_scene.grid[:, ::-1]",
        "detail": "metta.map.scenes.mirror",
        "documentation": {}
    },
    {
        "label": "Symmetry",
        "kind": 5,
        "importPath": "metta.map.scenes.mirror",
        "description": "metta.map.scenes.mirror",
        "peekOfCode": "Symmetry = Literal[\"horizontal\", \"vertical\", \"x4\"]\nclass MirrorParams(Config):\n    scene: SceneCfg\n    symmetry: Symmetry = \"horizontal\"\nclass Mirror(Scene[MirrorParams]):\n    def render(self):\n        symmetry = self.params.symmetry\n        scene = self.params.scene\n        if symmetry == \"horizontal\":\n            left_width = (self.width + 1) // 2  # take half, plus one for odd width",
        "detail": "metta.map.scenes.mirror",
        "documentation": {}
    },
    {
        "label": "MultiLeftAndRightParams",
        "kind": 6,
        "importPath": "metta.map.scenes.multi_left_and_right",
        "description": "metta.map.scenes.multi_left_and_right",
        "peekOfCode": "class MultiLeftAndRightParams(Config):\n    rows: int\n    columns: int\n    altar_ratio: float\n    total_altars: int\nclass MultiLeftAndRight(Scene[MultiLeftAndRightParams]):\n    \"\"\"\n    Produce multiple left-or-right maps in a grid, with agents assigned randomly\n    to teams, and rooms all identical otherwise. Altars are placed asymmetrically\n    with configurable total count and ratio between sides. The side with more altars",
        "detail": "metta.map.scenes.multi_left_and_right",
        "documentation": {}
    },
    {
        "label": "MultiLeftAndRight",
        "kind": 6,
        "importPath": "metta.map.scenes.multi_left_and_right",
        "description": "metta.map.scenes.multi_left_and_right",
        "peekOfCode": "class MultiLeftAndRight(Scene[MultiLeftAndRightParams]):\n    \"\"\"\n    Produce multiple left-or-right maps in a grid, with agents assigned randomly\n    to teams, and rooms all identical otherwise. Altars are placed asymmetrically\n    with configurable total count and ratio between sides. The side with more altars\n    is randomly determined at the start of each episode.\n    \"\"\"\n    def get_children(self):\n        # Pregenerate seeds so that we could make rooms deterministic.\n        agent_seed = random.randint(0, int(1e9))",
        "detail": "metta.map.scenes.multi_left_and_right",
        "documentation": {}
    },
    {
        "label": "NopParams",
        "kind": 6,
        "importPath": "metta.map.scenes.nop",
        "description": "metta.map.scenes.nop",
        "peekOfCode": "class NopParams(Config):\n    pass\nclass Nop(Scene[NopParams]):\n    \"\"\"\n    This scene doesn't do anything.\n    \"\"\"\n    def render(self):\n        pass",
        "detail": "metta.map.scenes.nop",
        "documentation": {}
    },
    {
        "label": "Nop",
        "kind": 6,
        "importPath": "metta.map.scenes.nop",
        "description": "metta.map.scenes.nop",
        "peekOfCode": "class Nop(Scene[NopParams]):\n    \"\"\"\n    This scene doesn't do anything.\n    \"\"\"\n    def render(self):\n        pass",
        "detail": "metta.map.scenes.nop",
        "documentation": {}
    },
    {
        "label": "RandomParams",
        "kind": 6,
        "importPath": "metta.map.scenes.random",
        "description": "metta.map.scenes.random",
        "peekOfCode": "class RandomParams(Config):\n    objects: dict = {}\n    agents: int | dict = 0\n    too_many_is_ok: bool = True\nclass Random(Scene[RandomParams]):\n    \"\"\"\n    Fill the grid with random symbols, based on configuration.\n    This scene takes into account the existing grid content, and places objects in empty spaces only.\n    \"\"\"\n    def render(self):",
        "detail": "metta.map.scenes.random",
        "documentation": {}
    },
    {
        "label": "Random",
        "kind": 6,
        "importPath": "metta.map.scenes.random",
        "description": "metta.map.scenes.random",
        "peekOfCode": "class Random(Scene[RandomParams]):\n    \"\"\"\n    Fill the grid with random symbols, based on configuration.\n    This scene takes into account the existing grid content, and places objects in empty spaces only.\n    \"\"\"\n    def render(self):\n        height, width, params = self.height, self.width, self.params\n        if isinstance(params.agents, int):\n            agents = [\"agent.agent\"] * params.agents\n        elif isinstance(params.agents, dict):",
        "detail": "metta.map.scenes.random",
        "documentation": {}
    },
    {
        "label": "RandomObjectsParams",
        "kind": 6,
        "importPath": "metta.map.scenes.random_objects",
        "description": "metta.map.scenes.random_objects",
        "peekOfCode": "class RandomObjectsParams(Config):\n    object_ranges: dict[str, FloatDistribution] = {}\nclass RandomObjects(Scene[RandomObjectsParams]):\n    \"\"\"\n    Fill the grid with random objects. Unlike Random, this scene takes the percentage ranges of objects,\n    not the absolute count.\n    It's rarely useful to pick the random number of agents, so this scene doesn't have that parameter.\n    \"\"\"\n    def get_children(self) -> list[ChildrenAction]:\n        size = self.height * self.width",
        "detail": "metta.map.scenes.random_objects",
        "documentation": {}
    },
    {
        "label": "RandomObjects",
        "kind": 6,
        "importPath": "metta.map.scenes.random_objects",
        "description": "metta.map.scenes.random_objects",
        "peekOfCode": "class RandomObjects(Scene[RandomObjectsParams]):\n    \"\"\"\n    Fill the grid with random objects. Unlike Random, this scene takes the percentage ranges of objects,\n    not the absolute count.\n    It's rarely useful to pick the random number of agents, so this scene doesn't have that parameter.\n    \"\"\"\n    def get_children(self) -> list[ChildrenAction]:\n        size = self.height * self.width\n        objects = {}\n        for obj_name, distribution in self.params.object_ranges.items():",
        "detail": "metta.map.scenes.random_objects",
        "documentation": {}
    },
    {
        "label": "RandomSceneCandidate",
        "kind": 6,
        "importPath": "metta.map.scenes.random_scene",
        "description": "metta.map.scenes.random_scene",
        "peekOfCode": "class RandomSceneCandidate(Config):\n    scene: SceneCfg\n    weight: float = 1\nclass RandomSceneParams(Config):\n    candidates: list[RandomSceneCandidate]\nclass RandomScene(Scene[RandomSceneParams]):\n    def get_children(self) -> list[ChildrenAction]:\n        candidates = self.params.candidates\n        weights = np.array([c.weight for c in candidates], dtype=np.float32)\n        weights /= weights.sum()",
        "detail": "metta.map.scenes.random_scene",
        "documentation": {}
    },
    {
        "label": "RandomSceneParams",
        "kind": 6,
        "importPath": "metta.map.scenes.random_scene",
        "description": "metta.map.scenes.random_scene",
        "peekOfCode": "class RandomSceneParams(Config):\n    candidates: list[RandomSceneCandidate]\nclass RandomScene(Scene[RandomSceneParams]):\n    def get_children(self) -> list[ChildrenAction]:\n        candidates = self.params.candidates\n        weights = np.array([c.weight for c in candidates], dtype=np.float32)\n        weights /= weights.sum()\n        idx = self.rng.choice(len(candidates), p=weights)\n        scene = candidates[idx].scene\n        return [",
        "detail": "metta.map.scenes.random_scene",
        "documentation": {}
    },
    {
        "label": "RandomScene",
        "kind": 6,
        "importPath": "metta.map.scenes.random_scene",
        "description": "metta.map.scenes.random_scene",
        "peekOfCode": "class RandomScene(Scene[RandomSceneParams]):\n    def get_children(self) -> list[ChildrenAction]:\n        candidates = self.params.candidates\n        weights = np.array([c.weight for c in candidates], dtype=np.float32)\n        weights /= weights.sum()\n        idx = self.rng.choice(len(candidates), p=weights)\n        scene = candidates[idx].scene\n        return [\n            ChildrenAction(scene=scene, where=\"full\"),\n            *self.children,",
        "detail": "metta.map.scenes.random_scene",
        "documentation": {}
    },
    {
        "label": "RandomSceneFromDirParams",
        "kind": 6,
        "importPath": "metta.map.scenes.random_scene_from_dir",
        "description": "metta.map.scenes.random_scene_from_dir",
        "peekOfCode": "class RandomSceneFromDirParams(Config):\n    dir: str\nclass RandomSceneFromDir(Scene[RandomSceneFromDirParams]):\n    def post_init(self):\n        self._dir = Path(self.params.dir).resolve()\n        if not self._dir.exists():\n            raise ValueError(f\"Directory {self._dir} does not exist\")\n        self._scenes = []\n        for file in self._dir.iterdir():\n            self._scenes.append(\"/\" + str(file.relative_to(scenes_root)))",
        "detail": "metta.map.scenes.random_scene_from_dir",
        "documentation": {}
    },
    {
        "label": "RandomSceneFromDir",
        "kind": 6,
        "importPath": "metta.map.scenes.random_scene_from_dir",
        "description": "metta.map.scenes.random_scene_from_dir",
        "peekOfCode": "class RandomSceneFromDir(Scene[RandomSceneFromDirParams]):\n    def post_init(self):\n        self._dir = Path(self.params.dir).resolve()\n        if not self._dir.exists():\n            raise ValueError(f\"Directory {self._dir} does not exist\")\n        self._scenes = []\n        for file in self._dir.iterdir():\n            self._scenes.append(\"/\" + str(file.relative_to(scenes_root)))\n        if not self._scenes:\n            raise ValueError(f\"No files found in {self._dir}\")",
        "detail": "metta.map.scenes.random_scene_from_dir",
        "documentation": {}
    },
    {
        "label": "RemoveAgentsParams",
        "kind": 6,
        "importPath": "metta.map.scenes.remove_agents",
        "description": "metta.map.scenes.remove_agents",
        "peekOfCode": "class RemoveAgentsParams(Config):\n    pass\nclass RemoveAgents(Scene[RemoveAgentsParams]):\n    \"\"\"\n    This class solves a frequent problem: `game.num_agents` must match the\n    number of agents in the map.\n    You can use this scene to remove agents from the map. Then apply `Random`\n    scene to place as many agents as you want.\n    (TODO - it might be better to remove `game.num_agents` from the config\n    entirely, and just use the number of agents in the map.)",
        "detail": "metta.map.scenes.remove_agents",
        "documentation": {}
    },
    {
        "label": "RemoveAgents",
        "kind": 6,
        "importPath": "metta.map.scenes.remove_agents",
        "description": "metta.map.scenes.remove_agents",
        "peekOfCode": "class RemoveAgents(Scene[RemoveAgentsParams]):\n    \"\"\"\n    This class solves a frequent problem: `game.num_agents` must match the\n    number of agents in the map.\n    You can use this scene to remove agents from the map. Then apply `Random`\n    scene to place as many agents as you want.\n    (TODO - it might be better to remove `game.num_agents` from the config\n    entirely, and just use the number of agents in the map.)\n    \"\"\"\n    def render(self):",
        "detail": "metta.map.scenes.remove_agents",
        "documentation": {}
    },
    {
        "label": "RoomGridParams",
        "kind": 6,
        "importPath": "metta.map.scenes.room_grid",
        "description": "metta.map.scenes.room_grid",
        "peekOfCode": "class RoomGridParams(Config):\n    rows: Optional[int] = None\n    columns: Optional[int] = None\n    layout: Optional[list[list[str]]] = None\n    # Default value guarantees that agents don't see beyond the walls.\n    # Usually shouldn't be changed.\n    border_width: int = 5\n    border_object: str = \"wall\"\nclass RoomGrid(Scene[RoomGridParams]):\n    \"\"\"",
        "detail": "metta.map.scenes.room_grid",
        "documentation": {}
    },
    {
        "label": "RoomGrid",
        "kind": 6,
        "importPath": "metta.map.scenes.room_grid",
        "description": "metta.map.scenes.room_grid",
        "peekOfCode": "class RoomGrid(Scene[RoomGridParams]):\n    \"\"\"\n    Tile the scene with a grid of equally sized isolated rooms.\n    This scene is destructive: it will overwrite the entire grid.\n    Example when rows=2, columns=3, border_width=1:\n    \n       #   #   #\n       #   #   #\n    ############\n       #   #   #",
        "detail": "metta.map.scenes.room_grid",
        "documentation": {}
    },
    {
        "label": "WFCParams",
        "kind": 6,
        "importPath": "metta.map.scenes.wfc",
        "description": "metta.map.scenes.wfc",
        "peekOfCode": "class WFCParams(Config):\n    pattern: str\n    pattern_size: int = 3\n    next_node_heuristic: NextNodeHeuristic = \"entropy\"\n    periodic_input: bool = True\n    symmetry: Symmetry = \"all\"\n    attempts: int = 1000\nclass WFC(Scene[WFCParams]):\n    def post_init(self):\n        patterns_with_counts = ascii_to_patterns_with_counts(",
        "detail": "metta.map.scenes.wfc",
        "documentation": {}
    },
    {
        "label": "WFC",
        "kind": 6,
        "importPath": "metta.map.scenes.wfc",
        "description": "metta.map.scenes.wfc",
        "peekOfCode": "class WFC(Scene[WFCParams]):\n    def post_init(self):\n        patterns_with_counts = ascii_to_patterns_with_counts(\n            self.params.pattern,\n            self.params.pattern_size,\n            periodic=self.params.periodic_input,\n            symmetry=self.params.symmetry,\n        )\n        self._weights = np.array([p[1] for p in patterns_with_counts], dtype=np.float64)\n        self._patterns = [p[0] for p in patterns_with_counts]",
        "detail": "metta.map.scenes.wfc",
        "documentation": {}
    },
    {
        "label": "WFCRenderSession",
        "kind": 6,
        "importPath": "metta.map.scenes.wfc",
        "description": "metta.map.scenes.wfc",
        "peekOfCode": "class WFCRenderSession:\n    def __init__(self, scene: WFC):\n        self.scene = scene\n        self.pattern_count = len(self.scene._weights)\n        self.width = self.scene.width\n        self.height = self.scene.height\n        self.reset()\n    def reset(self):\n        start = time.time()\n        self.wave = np.full((self.height, self.width, self.pattern_count), True, dtype=np.bool_)",
        "detail": "metta.map.scenes.wfc",
        "documentation": {}
    },
    {
        "label": "opposite_direction",
        "kind": 2,
        "importPath": "metta.map.scenes.wfc",
        "description": "metta.map.scenes.wfc",
        "peekOfCode": "def opposite_direction(d: int) -> int:\n    return (d + 2) % 4\nclass WFCParams(Config):\n    pattern: str\n    pattern_size: int = 3\n    next_node_heuristic: NextNodeHeuristic = \"entropy\"\n    periodic_input: bool = True\n    symmetry: Symmetry = \"all\"\n    attempts: int = 1000\nclass WFC(Scene[WFCParams]):",
        "detail": "metta.map.scenes.wfc",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "metta.map.scenes.wfc",
        "description": "metta.map.scenes.wfc",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndx = [0, 1, 0, -1]\ndy = [-1, 0, 1, 0]\nNextNodeHeuristic = Literal[\"scanline\", \"mrv\", \"entropy\"]\ndef opposite_direction(d: int) -> int:\n    return (d + 2) % 4\nclass WFCParams(Config):\n    pattern: str\n    pattern_size: int = 3\n    next_node_heuristic: NextNodeHeuristic = \"entropy\"",
        "detail": "metta.map.scenes.wfc",
        "documentation": {}
    },
    {
        "label": "dx",
        "kind": 5,
        "importPath": "metta.map.scenes.wfc",
        "description": "metta.map.scenes.wfc",
        "peekOfCode": "dx = [0, 1, 0, -1]\ndy = [-1, 0, 1, 0]\nNextNodeHeuristic = Literal[\"scanline\", \"mrv\", \"entropy\"]\ndef opposite_direction(d: int) -> int:\n    return (d + 2) % 4\nclass WFCParams(Config):\n    pattern: str\n    pattern_size: int = 3\n    next_node_heuristic: NextNodeHeuristic = \"entropy\"\n    periodic_input: bool = True",
        "detail": "metta.map.scenes.wfc",
        "documentation": {}
    },
    {
        "label": "dy",
        "kind": 5,
        "importPath": "metta.map.scenes.wfc",
        "description": "metta.map.scenes.wfc",
        "peekOfCode": "dy = [-1, 0, 1, 0]\nNextNodeHeuristic = Literal[\"scanline\", \"mrv\", \"entropy\"]\ndef opposite_direction(d: int) -> int:\n    return (d + 2) % 4\nclass WFCParams(Config):\n    pattern: str\n    pattern_size: int = 3\n    next_node_heuristic: NextNodeHeuristic = \"entropy\"\n    periodic_input: bool = True\n    symmetry: Symmetry = \"all\"",
        "detail": "metta.map.scenes.wfc",
        "documentation": {}
    },
    {
        "label": "NextNodeHeuristic",
        "kind": 5,
        "importPath": "metta.map.scenes.wfc",
        "description": "metta.map.scenes.wfc",
        "peekOfCode": "NextNodeHeuristic = Literal[\"scanline\", \"mrv\", \"entropy\"]\ndef opposite_direction(d: int) -> int:\n    return (d + 2) % 4\nclass WFCParams(Config):\n    pattern: str\n    pattern_size: int = 3\n    next_node_heuristic: NextNodeHeuristic = \"entropy\"\n    periodic_input: bool = True\n    symmetry: Symmetry = \"all\"\n    attempts: int = 1000",
        "detail": "metta.map.scenes.wfc",
        "documentation": {}
    },
    {
        "label": "add_pretty_border",
        "kind": 2,
        "importPath": "metta.map.utils.ascii_grid",
        "description": "metta.map.utils.ascii_grid",
        "peekOfCode": "def add_pretty_border(lines: list[str]) -> list[str]:\n    width = len(lines[0])\n    border_lines = [\"\" + \"\" * width + \"\"]\n    for row in lines:\n        border_lines.append(\"\" + row + \"\")\n    border_lines.append(\"\" + \"\" * width + \"\")\n    lines = border_lines\n    return lines\ndef grid_to_lines(grid: MapGrid, border: bool = False) -> list[str]:\n    lines: list[str] = []",
        "detail": "metta.map.utils.ascii_grid",
        "documentation": {}
    },
    {
        "label": "grid_to_lines",
        "kind": 2,
        "importPath": "metta.map.utils.ascii_grid",
        "description": "metta.map.utils.ascii_grid",
        "peekOfCode": "def grid_to_lines(grid: MapGrid, border: bool = False) -> list[str]:\n    lines: list[str] = []\n    for r in range(grid.shape[0]):\n        row = []\n        for c in range(grid.shape[1]):\n            row.append(grid_object_to_char(grid[r, c]))\n        lines.append(\"\".join(row))\n    if border:\n        lines = add_pretty_border(lines)\n    return lines",
        "detail": "metta.map.utils.ascii_grid",
        "documentation": {}
    },
    {
        "label": "lines_to_grid",
        "kind": 2,
        "importPath": "metta.map.utils.ascii_grid",
        "description": "metta.map.utils.ascii_grid",
        "peekOfCode": "def lines_to_grid(lines: list[str]) -> MapGrid:\n    grid = np.full((len(lines), len(lines[0])), \"empty\", dtype=\"<U50\")\n    for r, line in enumerate(lines):\n        for c, char in enumerate(line):\n            grid[r, c] = char_to_grid_object(char)\n    return grid\ndef char_grid_to_lines(text: str) -> tuple[list[str], int, int]:\n    lines = []\n    for line in text.strip().split(\"\\n\"):\n        line = line.strip()",
        "detail": "metta.map.utils.ascii_grid",
        "documentation": {}
    },
    {
        "label": "char_grid_to_lines",
        "kind": 2,
        "importPath": "metta.map.utils.ascii_grid",
        "description": "metta.map.utils.ascii_grid",
        "peekOfCode": "def char_grid_to_lines(text: str) -> tuple[list[str], int, int]:\n    lines = []\n    for line in text.strip().split(\"\\n\"):\n        line = line.strip()\n        lines.append(line)\n    height = len(lines)\n    width = max(len(line) for line in lines)\n    if not all(len(line) == width for line in lines):\n        raise ValueError(\"All lines must be the same width\")\n    return (lines, width, height)",
        "detail": "metta.map.utils.ascii_grid",
        "documentation": {}
    },
    {
        "label": "DCSSMap",
        "kind": 6,
        "importPath": "metta.map.utils.dcss",
        "description": "metta.map.utils.dcss",
        "peekOfCode": "class DCSSMap:\n    name: str\n    pattern: str\ndef get_maps() -> list[DCSSMap]:\n    simple = fetch_simple()\n    import re\n    # Split by 'NAME:' but keep the delimiter at the beginning of the subsequent parts using a lookahead assertion.\n    # If the string starts with 'NAME:', the first part will be an empty string.\n    parts = re.split(r\"(?=NAME:)\", simple)\n    maps: list[DCSSMap] = []",
        "detail": "metta.map.utils.dcss",
        "documentation": {}
    },
    {
        "label": "fetch_simple",
        "kind": 2,
        "importPath": "metta.map.utils.dcss",
        "description": "metta.map.utils.dcss",
        "peekOfCode": "def fetch_simple():\n    url = \"https://raw.githubusercontent.com/crawl/crawl/master/crawl-ref/source/dat/des/arrival/simple.des\"\n    with urllib.request.urlopen(url) as response:\n        return response.read().decode(\"utf-8\")\ndef process_map_source(ascii_source):\n    # split into lines\n    lines = ascii_source.split(\"\\n\")\n    # add space padding so that all lines are the same length\n    max_length = max(len(line) for line in lines)\n    lines = [line.ljust(max_length) for line in lines]",
        "detail": "metta.map.utils.dcss",
        "documentation": {}
    },
    {
        "label": "process_map_source",
        "kind": 2,
        "importPath": "metta.map.utils.dcss",
        "description": "metta.map.utils.dcss",
        "peekOfCode": "def process_map_source(ascii_source):\n    # split into lines\n    lines = ascii_source.split(\"\\n\")\n    # add space padding so that all lines are the same length\n    max_length = max(len(line) for line in lines)\n    lines = [line.ljust(max_length) for line in lines]\n    # replace all symbols that are not `x` with spaces; replace `x` with `#`\n    for i in range(len(lines)):\n        original_line = lines[i]\n        new_line = \"\".join([\"#\" if char == \"x\" else \".\" for char in original_line])",
        "detail": "metta.map.utils.dcss",
        "documentation": {}
    },
    {
        "label": "is_trivial",
        "kind": 2,
        "importPath": "metta.map.utils.dcss",
        "description": "metta.map.utils.dcss",
        "peekOfCode": "def is_trivial(ascii_map):\n    # if everything is blank, return true\n    if all(line == \" \" * len(line) for line in ascii_map.split(\"\\n\")):\n        return True\n    return False\n@dataclass\nclass DCSSMap:\n    name: str\n    pattern: str\ndef get_maps() -> list[DCSSMap]:",
        "detail": "metta.map.utils.dcss",
        "documentation": {}
    },
    {
        "label": "get_maps",
        "kind": 2,
        "importPath": "metta.map.utils.dcss",
        "description": "metta.map.utils.dcss",
        "peekOfCode": "def get_maps() -> list[DCSSMap]:\n    simple = fetch_simple()\n    import re\n    # Split by 'NAME:' but keep the delimiter at the beginning of the subsequent parts using a lookahead assertion.\n    # If the string starts with 'NAME:', the first part will be an empty string.\n    parts = re.split(r\"(?=NAME:)\", simple)\n    maps: list[DCSSMap] = []\n    for part in parts:\n        if \"NAME:\" not in part:\n            continue  # preamble before the first map",
        "detail": "metta.map.utils.dcss",
        "documentation": {}
    },
    {
        "label": "process_map_entry",
        "kind": 2,
        "importPath": "metta.map.utils.dcss",
        "description": "metta.map.utils.dcss",
        "peekOfCode": "def process_map_entry(map_entry: DCSSMap):\n    name = map_entry.name\n    pattern = map_entry.pattern\n    logger.info(f\"Processing map: {name}\")\n    # convchain\n    convchain_config = make_convchain_config_from_pattern(pattern)\n    convchain_dir = dir / \"convchain\"\n    convchain_dir.mkdir(parents=True, exist_ok=True)\n    OmegaConf.save(convchain_config, convchain_dir / f\"{name}.yaml\")\n    # wfc",
        "detail": "metta.map.utils.dcss",
        "documentation": {}
    },
    {
        "label": "generate_scenes_from_dcss_maps",
        "kind": 2,
        "importPath": "metta.map.utils.dcss",
        "description": "metta.map.utils.dcss",
        "peekOfCode": "def generate_scenes_from_dcss_maps():\n    maps = get_maps()\n    cpus = os.cpu_count() or 1\n    with Pool(cpus) as pool:\n        pool.map(process_map_entry, maps)\nif __name__ == \"__main__\":\n    generate_scenes_from_dcss_maps()",
        "detail": "metta.map.utils.dcss",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "metta.map.utils.dcss",
        "description": "metta.map.utils.dcss",
        "peekOfCode": "logger = logging.getLogger(__name__)\nlogging.basicConfig(level=logging.INFO)\ndef fetch_simple():\n    url = \"https://raw.githubusercontent.com/crawl/crawl/master/crawl-ref/source/dat/des/arrival/simple.des\"\n    with urllib.request.urlopen(url) as response:\n        return response.read().decode(\"utf-8\")\ndef process_map_source(ascii_source):\n    # split into lines\n    lines = ascii_source.split(\"\\n\")\n    # add space padding so that all lines are the same length",
        "detail": "metta.map.utils.dcss",
        "documentation": {}
    },
    {
        "label": "dir",
        "kind": 5,
        "importPath": "metta.map.utils.dcss",
        "description": "metta.map.utils.dcss",
        "peekOfCode": "dir = scenes_root / \"dcss\"\nwfc_dir = dir / \"wfc\"\ndef process_map_entry(map_entry: DCSSMap):\n    name = map_entry.name\n    pattern = map_entry.pattern\n    logger.info(f\"Processing map: {name}\")\n    # convchain\n    convchain_config = make_convchain_config_from_pattern(pattern)\n    convchain_dir = dir / \"convchain\"\n    convchain_dir.mkdir(parents=True, exist_ok=True)",
        "detail": "metta.map.utils.dcss",
        "documentation": {}
    },
    {
        "label": "wfc_dir",
        "kind": 5,
        "importPath": "metta.map.utils.dcss",
        "description": "metta.map.utils.dcss",
        "peekOfCode": "wfc_dir = dir / \"wfc\"\ndef process_map_entry(map_entry: DCSSMap):\n    name = map_entry.name\n    pattern = map_entry.pattern\n    logger.info(f\"Processing map: {name}\")\n    # convchain\n    convchain_config = make_convchain_config_from_pattern(pattern)\n    convchain_dir = dir / \"convchain\"\n    convchain_dir.mkdir(parents=True, exist_ok=True)\n    OmegaConf.save(convchain_config, convchain_dir / f\"{name}.yaml\")",
        "detail": "metta.map.utils.dcss",
        "documentation": {}
    },
    {
        "label": "with_boundaries",
        "kind": 2,
        "importPath": "metta.map.utils.make_scene_config",
        "description": "metta.map.utils.make_scene_config",
        "peekOfCode": "def with_boundaries(pattern: str):\n    return \"\\n\".join([f\"|{line}|\" for line in pattern.split(\"\\n\")])\ndef make_convchain_config_from_pattern(pattern: str) -> dict:\n    pattern = with_boundaries(pattern)\n    config = {\n        \"type\": \"metta.map.scenes.convchain.ConvChain\",\n        \"params\": {\n            \"pattern_size\": 3,\n            \"iterations\": 10,\n            \"temperature\": 1,",
        "detail": "metta.map.utils.make_scene_config",
        "documentation": {}
    },
    {
        "label": "make_convchain_config_from_pattern",
        "kind": 2,
        "importPath": "metta.map.utils.make_scene_config",
        "description": "metta.map.utils.make_scene_config",
        "peekOfCode": "def make_convchain_config_from_pattern(pattern: str) -> dict:\n    pattern = with_boundaries(pattern)\n    config = {\n        \"type\": \"metta.map.scenes.convchain.ConvChain\",\n        \"params\": {\n            \"pattern_size\": 3,\n            \"iterations\": 10,\n            \"temperature\": 1,\n            \"pattern\": pattern,\n        },",
        "detail": "metta.map.utils.make_scene_config",
        "documentation": {}
    },
    {
        "label": "make_wfc_config_from_pattern",
        "kind": 2,
        "importPath": "metta.map.utils.make_scene_config",
        "description": "metta.map.utils.make_scene_config",
        "peekOfCode": "def make_wfc_config_from_pattern(pattern: str) -> Optional[dict]:\n    pattern = with_boundaries(pattern)\n    config = {\n        \"type\": \"metta.map.scenes.wfc.WFC\",\n        \"params\": {\n            \"pattern_size\": 3,\n            \"pattern\": pattern,\n        },\n    }\n    # Some WFC patterns are invalid, so we need to check that they are valid.",
        "detail": "metta.map.utils.make_scene_config",
        "documentation": {}
    },
    {
        "label": "Pattern",
        "kind": 6,
        "importPath": "metta.map.utils.pattern",
        "description": "metta.map.utils.pattern",
        "peekOfCode": "class Pattern:\n    \"\"\"\n    Helper class for handling patterns in the ConvChain and WFC algorithms.\n    Currently this class supports only boolean patterns (walls or empty).\n    \"\"\"\n    def __init__(self, field: np.ndarray, x: int, y: int, size: int):\n        self.data = np.zeros((size, size), dtype=bool)\n        field_height, field_width = field.shape\n        for j in range(size):\n            for i in range(size):",
        "detail": "metta.map.utils.pattern",
        "documentation": {}
    },
    {
        "label": "parse_ascii_into_grid",
        "kind": 2,
        "importPath": "metta.map.utils.pattern",
        "description": "metta.map.utils.pattern",
        "peekOfCode": "def parse_ascii_into_grid(ascii_source: str) -> npt.NDArray[np.bool_]:\n    \"\"\"\n    Parse an ascii string into a numpy ndarray of booleans.\n    The string must be composed of `#` and `.` characters.\n    `#` will be treated as walls, and `.` as empty.\n    Example source:\n    #.#\n    #.#\n    #.#\n    \"\"\"",
        "detail": "metta.map.utils.pattern",
        "documentation": {}
    },
    {
        "label": "ascii_to_patterns_with_counts",
        "kind": 2,
        "importPath": "metta.map.utils.pattern",
        "description": "metta.map.utils.pattern",
        "peekOfCode": "def ascii_to_patterns_with_counts(\n    ascii_source: str, n: int, periodic: bool, symmetry: Symmetry\n) -> list[tuple[\"Pattern\", int]]:\n    # This function is useful for WFC - we need to get patterns, not just weights.\n    # TODO - support >2 colors?\n    grid = parse_ascii_into_grid(ascii_source)\n    # pattern index -> { pattern, count }\n    seen_patterns = {}\n    # Calculate weights from the sample\n    max_y = grid.shape[0] if periodic else grid.shape[0] - n + 1",
        "detail": "metta.map.utils.pattern",
        "documentation": {}
    },
    {
        "label": "ascii_to_weights_of_all_patterns",
        "kind": 2,
        "importPath": "metta.map.utils.pattern",
        "description": "metta.map.utils.pattern",
        "peekOfCode": "def ascii_to_weights_of_all_patterns(\n    source: str, n: int, periodic: bool, symmetry: Symmetry\n) -> npt.NDArray[np.float64]:\n    # This function is useful for ConvChain. We get weights for all possible patterns, even the ones that\n    # don't exist in the sample. (2^(N*N) patterns)\n    patterns_with_counts = ascii_to_patterns_with_counts(source, n, periodic, symmetry)\n    weights = np.zeros(1 << (n * n))\n    for pattern, count in patterns_with_counts:\n        index = pattern.index()\n        if index >= len(weights):",
        "detail": "metta.map.utils.pattern",
        "documentation": {}
    },
    {
        "label": "Symmetry",
        "kind": 5,
        "importPath": "metta.map.utils.pattern",
        "description": "metta.map.utils.pattern",
        "peekOfCode": "Symmetry = Literal[\"all\", \"horizontal\", \"none\"]\ndef parse_ascii_into_grid(ascii_source: str) -> npt.NDArray[np.bool_]:\n    \"\"\"\n    Parse an ascii string into a numpy ndarray of booleans.\n    The string must be composed of `#` and `.` characters.\n    `#` will be treated as walls, and `.` as empty.\n    Example source:\n    #.#\n    #.#\n    #.#",
        "detail": "metta.map.utils.pattern",
        "documentation": {}
    },
    {
        "label": "lognormal_from_90_percentile",
        "kind": 2,
        "importPath": "metta.map.utils.random",
        "description": "metta.map.utils.random",
        "peekOfCode": "def lognormal_from_90_percentile(low: float, high: float, rng: np.random.Generator) -> float:\n    \"\"\"\n    Calculate the mean and standard deviation of a lognormal distribution that has a 90%\n    probability of being between low and high.\n    \"\"\"\n    if low >= high:\n        raise ValueError(\"Low value must be less than high value\")\n    if low <= 0:\n        raise ValueError(\"Low value must be above 0\")\n    # Default to 90% probability, for now",
        "detail": "metta.map.utils.random",
        "documentation": {}
    },
    {
        "label": "sample_float_distribution",
        "kind": 2,
        "importPath": "metta.map.utils.random",
        "description": "metta.map.utils.random",
        "peekOfCode": "def sample_float_distribution(cfg: FloatDistribution, rng: np.random.Generator) -> float:\n    \"\"\"\n    Valid config values:\n    - `float`: just return the value\n    - `[\"uniform\", low: float, high: float]`: any float in the range\n    - `[\"lognormal\", p5: float, p95: float, max: float]`: any float in the range, max (absolute limit) is optional\n    \"\"\"\n    if isinstance(cfg, float):\n        return cfg\n    elif isinstance(cfg, tuple) or isinstance(cfg, ListConfig):",
        "detail": "metta.map.utils.random",
        "documentation": {}
    },
    {
        "label": "sample_int_distribution",
        "kind": 2,
        "importPath": "metta.map.utils.random",
        "description": "metta.map.utils.random",
        "peekOfCode": "def sample_int_distribution(cfg: IntDistribution, rng: np.random.Generator) -> int:\n    \"\"\"\n    Valid config values:\n    - `int`: just return the value\n    - `[\"uniform\", low: int, high: int]`: any integer in the range, high is inclusive\n    \"\"\"\n    if isinstance(cfg, int):\n        return cfg\n    elif isinstance(cfg, tuple) or isinstance(cfg, ListConfig):\n        (dist_type, *args) = cfg",
        "detail": "metta.map.utils.random",
        "documentation": {}
    },
    {
        "label": "MaybeSeed",
        "kind": 5,
        "importPath": "metta.map.utils.random",
        "description": "metta.map.utils.random",
        "peekOfCode": "MaybeSeed = Union[int, np.random.Generator, None]\ndef lognormal_from_90_percentile(low: float, high: float, rng: np.random.Generator) -> float:\n    \"\"\"\n    Calculate the mean and standard deviation of a lognormal distribution that has a 90%\n    probability of being between low and high.\n    \"\"\"\n    if low >= high:\n        raise ValueError(\"Low value must be less than high value\")\n    if low <= 0:\n        raise ValueError(\"Low value must be above 0\")",
        "detail": "metta.map.utils.random",
        "documentation": {}
    },
    {
        "label": "FloatDistribution",
        "kind": 5,
        "importPath": "metta.map.utils.random",
        "description": "metta.map.utils.random",
        "peekOfCode": "FloatDistribution = Union[\n    float,\n    tuple[Literal[\"uniform\"], float, float],\n    tuple[Literal[\"lognormal\"], float, float, float],\n]\ndef sample_float_distribution(cfg: FloatDistribution, rng: np.random.Generator) -> float:\n    \"\"\"\n    Valid config values:\n    - `float`: just return the value\n    - `[\"uniform\", low: float, high: float]`: any float in the range",
        "detail": "metta.map.utils.random",
        "documentation": {}
    },
    {
        "label": "IntDistribution",
        "kind": 5,
        "importPath": "metta.map.utils.random",
        "description": "metta.map.utils.random",
        "peekOfCode": "IntDistribution = Union[int, tuple[Literal[\"uniform\"], int, int]]\ndef sample_int_distribution(cfg: IntDistribution, rng: np.random.Generator) -> int:\n    \"\"\"\n    Valid config values:\n    - `int`: just return the value\n    - `[\"uniform\", low: int, high: int]`: any integer in the range, high is inclusive\n    \"\"\"\n    if isinstance(cfg, int):\n        return cfg\n    elif isinstance(cfg, tuple) or isinstance(cfg, ListConfig):",
        "detail": "metta.map.utils.random",
        "documentation": {}
    },
    {
        "label": "is_s3_uri",
        "kind": 2,
        "importPath": "metta.map.utils.s3utils",
        "description": "metta.map.utils.s3utils",
        "peekOfCode": "def is_s3_uri(uri: str) -> bool:\n    return uri.startswith(\"s3://\")\ndef parse_s3_uri(uri: str) -> tuple[str, str]:\n    if not uri.startswith(\"s3://\"):\n        raise ValueError(f\"URI {uri} is not an S3 URI\")\n    (bucket, key) = uri[5:].split(\"/\", 1)\n    return bucket, key\ndef get_s3_client():\n    # no strict dependency on boto3 in mettagrid, install if you need it\n    import boto3",
        "detail": "metta.map.utils.s3utils",
        "documentation": {}
    },
    {
        "label": "parse_s3_uri",
        "kind": 2,
        "importPath": "metta.map.utils.s3utils",
        "description": "metta.map.utils.s3utils",
        "peekOfCode": "def parse_s3_uri(uri: str) -> tuple[str, str]:\n    if not uri.startswith(\"s3://\"):\n        raise ValueError(f\"URI {uri} is not an S3 URI\")\n    (bucket, key) = uri[5:].split(\"/\", 1)\n    return bucket, key\ndef get_s3_client():\n    # no strict dependency on boto3 in mettagrid, install if you need it\n    import boto3\n    # AWS_PROFILE won't be necessary for most people, but some environments can have multiple profiles\n    # (Boto3 doesn't pick up the env variable automatically)",
        "detail": "metta.map.utils.s3utils",
        "documentation": {}
    },
    {
        "label": "get_s3_client",
        "kind": 2,
        "importPath": "metta.map.utils.s3utils",
        "description": "metta.map.utils.s3utils",
        "peekOfCode": "def get_s3_client():\n    # no strict dependency on boto3 in mettagrid, install if you need it\n    import boto3\n    # AWS_PROFILE won't be necessary for most people, but some environments can have multiple profiles\n    # (Boto3 doesn't pick up the env variable automatically)\n    session = boto3.Session(profile_name=os.environ.get(\"AWS_PROFILE\", None))\n    return session.client(\"s3\")\ndef list_objects(dir: str) -> list[str]:\n    s3 = get_s3_client()\n    bucket, key = parse_s3_uri(dir)",
        "detail": "metta.map.utils.s3utils",
        "documentation": {}
    },
    {
        "label": "list_objects",
        "kind": 2,
        "importPath": "metta.map.utils.s3utils",
        "description": "metta.map.utils.s3utils",
        "peekOfCode": "def list_objects(dir: str) -> list[str]:\n    s3 = get_s3_client()\n    bucket, key = parse_s3_uri(dir)\n    paginator = s3.get_paginator(\"list_objects_v2\")\n    pages = paginator.paginate(Bucket=bucket, Prefix=key)\n    uri_list: list[str] = []\n    for page in pages:\n        if \"Contents\" not in page:\n            continue\n        for obj in page[\"Contents\"]:",
        "detail": "metta.map.utils.s3utils",
        "documentation": {}
    },
    {
        "label": "show_map",
        "kind": 2,
        "importPath": "metta.map.utils.show",
        "description": "metta.map.utils.show",
        "peekOfCode": "def show_map(storable_map: StorableMap, mode: ShowMode | None):\n    if not mode or mode == \"none\":\n        return\n    if mode == \"mettascope\":\n        num_agents = np.count_nonzero(np.char.startswith(storable_map.grid, \"agent\"))\n        env_cfg = OmegaConf.load(\"./configs/env/mettagrid/full.yaml\")\n        env_cfg.game.num_agents = int(num_agents)\n        OmegaConf.resolve(env_cfg)\n        assert isinstance(env_cfg, DictConfig)\n        level = Level(storable_map.grid, [])",
        "detail": "metta.map.utils.show",
        "documentation": {}
    },
    {
        "label": "ShowMode",
        "kind": 5,
        "importPath": "metta.map.utils.show",
        "description": "metta.map.utils.show",
        "peekOfCode": "ShowMode = Literal[\"mettascope\", \"ascii\", \"ascii_border\", \"none\"]\ndef show_map(storable_map: StorableMap, mode: ShowMode | None):\n    if not mode or mode == \"none\":\n        return\n    if mode == \"mettascope\":\n        num_agents = np.count_nonzero(np.char.startswith(storable_map.grid, \"agent\"))\n        env_cfg = OmegaConf.load(\"./configs/env/mettagrid/full.yaml\")\n        env_cfg.game.num_agents = int(num_agents)\n        OmegaConf.resolve(env_cfg)\n        assert isinstance(env_cfg, DictConfig)",
        "detail": "metta.map.utils.show",
        "documentation": {}
    },
    {
        "label": "FrontmatterDict",
        "kind": 6,
        "importPath": "metta.map.utils.storable_map",
        "description": "metta.map.utils.storable_map",
        "peekOfCode": "class FrontmatterDict(TypedDict):\n    metadata: dict\n    config: dict\nclass StorableMapDict(TypedDict):\n    frontmatter: FrontmatterDict\n    data: str\n@dataclass\nclass StorableMap:\n    \"\"\"\n    Wrapper around a MapGrid that includes information about the config that",
        "detail": "metta.map.utils.storable_map",
        "documentation": {}
    },
    {
        "label": "StorableMapDict",
        "kind": 6,
        "importPath": "metta.map.utils.storable_map",
        "description": "metta.map.utils.storable_map",
        "peekOfCode": "class StorableMapDict(TypedDict):\n    frontmatter: FrontmatterDict\n    data: str\n@dataclass\nclass StorableMap:\n    \"\"\"\n    Wrapper around a MapGrid that includes information about the config that\n    produces the map and can be saved to a file or S3.\n    \"\"\"\n    grid: MapGrid",
        "detail": "metta.map.utils.storable_map",
        "documentation": {}
    },
    {
        "label": "StorableMap",
        "kind": 6,
        "importPath": "metta.map.utils.storable_map",
        "description": "metta.map.utils.storable_map",
        "peekOfCode": "class StorableMap:\n    \"\"\"\n    Wrapper around a MapGrid that includes information about the config that\n    produces the map and can be saved to a file or S3.\n    \"\"\"\n    grid: MapGrid\n    metadata: dict\n    config: DictConfig  # config that was used to generate the map\n    def __str__(self) -> str:\n        frontmatter = OmegaConf.to_yaml(",
        "detail": "metta.map.utils.storable_map",
        "documentation": {}
    },
    {
        "label": "StorableMapIndex",
        "kind": 6,
        "importPath": "metta.map.utils.storable_map",
        "description": "metta.map.utils.storable_map",
        "peekOfCode": "class StorableMapIndex:\n    \"\"\"\n    Inverted index of storable maps in an S3 directory.\n    The index can quickly find all maps that have a particular value for a particular key in their configs.\n    \"\"\"\n    dir: str\n    index_data: dict[str, dict[str, list[str]]]\n    def _flatten_nested_dict(self, obj, parent_key=\"\"):\n        \"\"\"Flatten nested dictionaries and lists into dot-separated keys.\"\"\"\n        items = []",
        "detail": "metta.map.utils.storable_map",
        "documentation": {}
    },
    {
        "label": "map_builder_cfg_to_storable_map",
        "kind": 2,
        "importPath": "metta.map.utils.storable_map",
        "description": "metta.map.utils.storable_map",
        "peekOfCode": "def map_builder_cfg_to_storable_map(cfg: DictConfig) -> StorableMap:\n    # Generate and measure time taken\n    start = time.time()\n    map_builder = hydra.utils.instantiate(cfg, _recursive_=True)\n    level = map_builder.build()\n    gen_time = time.time() - start\n    logger.info(f\"Time taken to build map: {gen_time}s\")\n    storable_map = StorableMap(\n        grid=level.grid,\n        metadata={",
        "detail": "metta.map.utils.storable_map",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "metta.map.utils.storable_map",
        "description": "metta.map.utils.storable_map",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass FrontmatterDict(TypedDict):\n    metadata: dict\n    config: dict\nclass StorableMapDict(TypedDict):\n    frontmatter: FrontmatterDict\n    data: str\n@dataclass\nclass StorableMap:\n    \"\"\"",
        "detail": "metta.map.utils.storable_map",
        "documentation": {}
    },
    {
        "label": "scenes_root",
        "kind": 5,
        "importPath": "metta.map.config",
        "description": "metta.map.config",
        "peekOfCode": "scenes_root = Path(\"./scenes\").resolve()",
        "detail": "metta.map.config",
        "documentation": {}
    },
    {
        "label": "Load",
        "kind": 6,
        "importPath": "metta.map.load",
        "description": "metta.map.load",
        "peekOfCode": "class Load(Room):\n    \"\"\"\n    Load a pregenerated map from a URI (file or S3 object).\n    See also: `FromS3Dir` for picking a random map from a directory of pregenerated maps.\n    \"\"\"\n    _extra_root: dict | None = None\n    def __init__(self, uri: str, extra_root: SceneCfg | DictConfig | None = None):\n        super().__init__()\n        self._uri = uri\n        self._storable_map = StorableMap.from_uri(uri)",
        "detail": "metta.map.load",
        "documentation": {}
    },
    {
        "label": "LoadRandom",
        "kind": 6,
        "importPath": "metta.map.load_random",
        "description": "metta.map.load_random",
        "peekOfCode": "class LoadRandom(Load):\n    \"\"\"\n    Load a random map from a directory, local or S3.\n    See also: `LoadRandomFromIndex` for a version that loads a random map from a pre-generated index.\n    \"\"\"\n    def __init__(self, dir: str, extra_root: SceneCfg | None = None):\n        self._dir_uri = dir\n        random_map_uri = get_random_map_uri(self._dir_uri)\n        super().__init__(random_map_uri, extra_root)",
        "detail": "metta.map.load_random",
        "documentation": {}
    },
    {
        "label": "parse_file_uri",
        "kind": 2,
        "importPath": "metta.map.load_random",
        "description": "metta.map.load_random",
        "peekOfCode": "def parse_file_uri(uri: str) -> str:\n    if uri.startswith(\"file://\"):\n        return uri.split(\"file://\")[1]\n    # we don't support any other schemes\n    if \"://\" in uri:\n        raise ValueError(f\"Invalid URI: {uri}\")\n    # probably a local file name\n    return uri\ndef get_random_map_uri(dir_uri: str) -> str:\n    if dir_uri.startswith(\"s3://\"):",
        "detail": "metta.map.load_random",
        "documentation": {}
    },
    {
        "label": "get_random_map_uri",
        "kind": 2,
        "importPath": "metta.map.load_random",
        "description": "metta.map.load_random",
        "peekOfCode": "def get_random_map_uri(dir_uri: str) -> str:\n    if dir_uri.startswith(\"s3://\"):\n        filenames = s3utils.list_objects(dir_uri)\n        filenames = [uri for uri in filenames if uri.endswith(\".yaml\")]\n        if not filenames:\n            raise ValueError(f\"No maps found in {dir_uri}\")\n        return random.choice(filenames)\n    else:\n        dirname = parse_file_uri(dir_uri)\n        if not os.path.isdir(dirname):",
        "detail": "metta.map.load_random",
        "documentation": {}
    },
    {
        "label": "LoadRandomFromIndex",
        "kind": 6,
        "importPath": "metta.map.load_random_from_index",
        "description": "metta.map.load_random_from_index",
        "peekOfCode": "class LoadRandomFromIndex(Load):\n    \"\"\"\n    Load a random map from a list of pregenerated maps.\n    The index file can be produced with the following command:\n        python -m tools.index_s3_maps --dir=s3://...\n    See also: `LoadRandom` for a version that loads a random map from an S3 directory.\n    \"\"\"\n    def __init__(self, index_uri: str, extra_root: SceneCfg | None = None):\n        self._index_uri = index_uri\n        # For 10k maps in a directory we'd have to fetch 100Kb of index data.",
        "detail": "metta.map.load_random_from_index",
        "documentation": {}
    },
    {
        "label": "MapGen",
        "kind": 6,
        "importPath": "metta.map.mapgen",
        "description": "metta.map.mapgen",
        "peekOfCode": "class MapGen(LevelBuilder):\n    width: int\n    height: int\n    root: SceneCfg\n    # Default value guarantees that agents don't see beyond the outer walls.\n    # Usually shouldn't be changed.\n    border_width: int = 5\n    def __post_init__(self):\n        super().__init__()\n        self.grid: MapGrid = np.full(",
        "detail": "metta.map.mapgen",
        "documentation": {}
    },
    {
        "label": "Area",
        "kind": 6,
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "peekOfCode": "class Area:\n    id: int  # unique for areas in a scene; not unique across scenes.\n    grid: MapGrid\n    tags: list[str]\nParamsT = TypeVar(\"ParamsT\", bound=Config)\nclass Scene(Generic[ParamsT]):\n    \"\"\"\n    Base class for all map scenes.\n    Subclasses must:\n    1. Inherit from Scene[ParamsT], where ParamsT is a subclass of Config.",
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "Scene",
        "kind": 6,
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "peekOfCode": "class Scene(Generic[ParamsT]):\n    \"\"\"\n    Base class for all map scenes.\n    Subclasses must:\n    1. Inherit from Scene[ParamsT], where ParamsT is a subclass of Config.\n    2. Define a `render()` method.\n    If you need to perform additional initialization, override `post_init()` instead of `__init__`.\n    \"\"\"\n    Params: type[ParamsT]\n    params: ParamsT",
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "load_class",
        "kind": 2,
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "peekOfCode": "def load_class(full_class_name: str) -> type[Scene]:\n    module_name, class_name = full_class_name.rsplit(\".\", 1)\n    module = importlib.import_module(module_name)\n    cls = getattr(module, class_name)\n    if not issubclass(cls, Scene):\n        raise ValueError(f\"Class {cls} does not inherit from Scene\")\n    return cls\ndef make_scene(cfg: SceneCfg, grid: MapGrid) -> Scene:\n    if callable(cfg):\n        # useful for dynamically produced scenes in `get_children()`",
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "make_scene",
        "kind": 2,
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "peekOfCode": "def make_scene(cfg: SceneCfg, grid: MapGrid) -> Scene:\n    if callable(cfg):\n        # useful for dynamically produced scenes in `get_children()`\n        scene = cfg(grid)\n        if not isinstance(scene, Scene):\n            raise ValueError(f\"Scene callback didn't return a valid scene: {scene}\")\n        return scene\n    if isinstance(cfg, str):\n        if cfg.startswith(\"/\"):\n            cfg = cfg[1:]",
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "ParamsT",
        "kind": 5,
        "importPath": "metta.map.scene",
        "description": "metta.map.scene",
        "peekOfCode": "ParamsT = TypeVar(\"ParamsT\", bound=Config)\nclass Scene(Generic[ParamsT]):\n    \"\"\"\n    Base class for all map scenes.\n    Subclasses must:\n    1. Inherit from Scene[ParamsT], where ParamsT is a subclass of Config.\n    2. Define a `render()` method.\n    If you need to perform additional initialization, override `post_init()` instead of `__init__`.\n    \"\"\"\n    Params: type[ParamsT]",
        "detail": "metta.map.scene",
        "documentation": {}
    },
    {
        "label": "AreaWhere",
        "kind": 6,
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "peekOfCode": "class AreaWhere(Config):\n    tags: list[str] = []\nclass AreaQuery(Config):\n    limit: int | None = None\n    offset: int | None = None\n    lock: str | None = None\n    where: Literal[\"full\"] | AreaWhere | None = None\n    order_by: Literal[\"random\", \"first\", \"last\"] = \"random\"\n    order_by_seed: int | None = None\nclass ChildrenAction(AreaQuery):",
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "AreaQuery",
        "kind": 6,
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "peekOfCode": "class AreaQuery(Config):\n    limit: int | None = None\n    offset: int | None = None\n    lock: str | None = None\n    where: Literal[\"full\"] | AreaWhere | None = None\n    order_by: Literal[\"random\", \"first\", \"last\"] = \"random\"\n    order_by_seed: int | None = None\nclass ChildrenAction(AreaQuery):\n    scene: SceneCfg",
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "ChildrenAction",
        "kind": 6,
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "peekOfCode": "class ChildrenAction(AreaQuery):\n    scene: SceneCfg",
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "SceneCfg",
        "kind": 5,
        "importPath": "metta.map.types",
        "description": "metta.map.types",
        "peekOfCode": "SceneCfg = Callable[[MapGrid], Any] | dict | str\nclass AreaWhere(Config):\n    tags: list[str] = []\nclass AreaQuery(Config):\n    limit: int | None = None\n    offset: int | None = None\n    lock: str | None = None\n    where: Literal[\"full\"] | AreaWhere | None = None\n    order_by: Literal[\"random\", \"first\", \"last\"] = \"random\"\n    order_by_seed: int | None = None",
        "detail": "metta.map.types",
        "documentation": {}
    },
    {
        "label": "Experience",
        "kind": 6,
        "importPath": "metta.rl.experience",
        "description": "metta.rl.experience",
        "peekOfCode": "class Experience:\n    \"\"\"Segmented tensor storage for RL experience with BPTT support.\"\"\"\n    def __init__(\n        self,\n        total_agents: int,\n        batch_size: int,\n        bptt_horizon: int,\n        minibatch_size: int,\n        max_minibatch_size: int,\n        obs_space,",
        "detail": "metta.rl.experience",
        "documentation": {}
    },
    {
        "label": "perform_rollout_step",
        "kind": 2,
        "importPath": "metta.rl.functions",
        "description": "metta.rl.functions",
        "peekOfCode": "def perform_rollout_step(\n    policy: torch.nn.Module,\n    vecenv: Any,\n    experience: Experience,\n    device: torch.device,\n    timer: Optional[Any] = None,\n) -> Tuple[int, list]:\n    \"\"\"Performs a single step of the rollout, interacting with the environment.\n    Returns:\n        Tuple of (num_steps, info_list)",
        "detail": "metta.rl.functions",
        "documentation": {}
    },
    {
        "label": "compute_ppo_losses",
        "kind": 2,
        "importPath": "metta.rl.functions",
        "description": "metta.rl.functions",
        "peekOfCode": "def compute_ppo_losses(\n    minibatch: Dict[str, Tensor],\n    new_logprobs: Tensor,\n    entropy: Tensor,\n    newvalue: Tensor,\n    importance_sampling_ratio: Tensor,\n    adv: Tensor,\n    trainer_cfg: Any,\n    device: torch.device,\n) -> Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]:",
        "detail": "metta.rl.functions",
        "documentation": {}
    },
    {
        "label": "process_minibatch_update",
        "kind": 2,
        "importPath": "metta.rl.functions",
        "description": "metta.rl.functions",
        "peekOfCode": "def process_minibatch_update(\n    policy: torch.nn.Module,\n    experience: Experience,\n    minibatch: Dict[str, Tensor],\n    advantages: Tensor,\n    trainer_cfg: Any,\n    kickstarter: Any,\n    agent_step: int,\n    losses: Losses,\n    device: torch.device,",
        "detail": "metta.rl.functions",
        "documentation": {}
    },
    {
        "label": "compute_advantage",
        "kind": 2,
        "importPath": "metta.rl.functions",
        "description": "metta.rl.functions",
        "peekOfCode": "def compute_advantage(\n    values: Tensor,\n    rewards: Tensor,\n    dones: Tensor,\n    importance_sampling_ratio: Tensor,\n    advantages: Tensor,\n    gamma: float,\n    gae_lambda: float,\n    vtrace_rho_clip: float,\n    vtrace_c_clip: float,",
        "detail": "metta.rl.functions",
        "documentation": {}
    },
    {
        "label": "normalize_advantage_distributed",
        "kind": 2,
        "importPath": "metta.rl.functions",
        "description": "metta.rl.functions",
        "peekOfCode": "def normalize_advantage_distributed(adv: Tensor, norm_adv: bool = True) -> Tensor:\n    \"\"\"Normalize advantages with distributed training support while preserving shape.\n    This matches the trainer.py implementation exactly.\n    \"\"\"\n    if not norm_adv:\n        return adv\n    if torch.distributed.is_initialized():\n        # Compute local statistics\n        adv_flat = adv.view(-1)\n        local_sum = einops.rearrange(adv_flat.sum(), \"-> 1\")",
        "detail": "metta.rl.functions",
        "documentation": {}
    },
    {
        "label": "calculate_explained_variance",
        "kind": 2,
        "importPath": "metta.rl.functions",
        "description": "metta.rl.functions",
        "peekOfCode": "def calculate_explained_variance(values: Tensor, advantages: Tensor) -> float:\n    \"\"\"Calculate explained variance for value function evaluation.\"\"\"\n    y_pred = values.flatten()\n    y_true = advantages.flatten() + values.flatten()\n    var_y = y_true.var()\n    explained_var = torch.nan if var_y == 0 else 1 - (y_true - y_pred).var() / var_y\n    return explained_var.item() if torch.is_tensor(explained_var) else float(\"nan\")\ndef get_lstm_config(policy: Any) -> Tuple[int, int]:\n    \"\"\"Extract LSTM configuration from policy.\"\"\"\n    hidden_size = getattr(policy, \"hidden_size\", 256)",
        "detail": "metta.rl.functions",
        "documentation": {}
    },
    {
        "label": "get_lstm_config",
        "kind": 2,
        "importPath": "metta.rl.functions",
        "description": "metta.rl.functions",
        "peekOfCode": "def get_lstm_config(policy: Any) -> Tuple[int, int]:\n    \"\"\"Extract LSTM configuration from policy.\"\"\"\n    hidden_size = getattr(policy, \"hidden_size\", 256)\n    num_lstm_layers = 2  # Default value\n    # Try to get actual number of LSTM layers from policy\n    if hasattr(policy, \"components\") and \"_core_\" in policy.components:\n        lstm_module = policy.components[\"_core_\"]\n        if hasattr(lstm_module, \"_net\") and hasattr(lstm_module._net, \"num_layers\"):\n            num_lstm_layers = lstm_module._net.num_layers\n    return hidden_size, num_lstm_layers",
        "detail": "metta.rl.functions",
        "documentation": {}
    },
    {
        "label": "calculate_batch_sizes",
        "kind": 2,
        "importPath": "metta.rl.functions",
        "description": "metta.rl.functions",
        "peekOfCode": "def calculate_batch_sizes(\n    forward_pass_minibatch_target_size: int,\n    num_agents: int,\n    num_workers: int,\n    async_factor: int,\n) -> Tuple[int, int, int]:\n    \"\"\"Calculate target batch size, actual batch size, and number of environments.\n    Returns:\n        Tuple of (target_batch_size, batch_size, num_envs)\n    \"\"\"",
        "detail": "metta.rl.functions",
        "documentation": {}
    },
    {
        "label": "validate_policy_environment_match",
        "kind": 2,
        "importPath": "metta.rl.functions",
        "description": "metta.rl.functions",
        "peekOfCode": "def validate_policy_environment_match(policy: Any, env: Any) -> None:\n    \"\"\"Validate that policy's observation shape matches environment's.\"\"\"\n    from metta.agent.metta_agent import DistributedMettaAgent, MettaAgent\n    # Extract agent from distributed wrapper if needed\n    if isinstance(policy, MettaAgent):\n        agent = policy\n    elif isinstance(policy, DistributedMettaAgent):\n        agent = policy.module\n    else:\n        raise ValueError(f\"Policy must be of type MettaAgent or DistributedMettaAgent, got {type(policy)}\")",
        "detail": "metta.rl.functions",
        "documentation": {}
    },
    {
        "label": "calculate_prioritized_sampling_params",
        "kind": 2,
        "importPath": "metta.rl.functions",
        "description": "metta.rl.functions",
        "peekOfCode": "def calculate_prioritized_sampling_params(\n    epoch: int,\n    total_timesteps: int,\n    batch_size: int,\n    prio_alpha: float,\n    prio_beta0: float,\n) -> float:\n    \"\"\"Calculate annealed beta for prioritized experience replay.\"\"\"\n    total_epochs = max(1, total_timesteps // batch_size)\n    anneal_beta = prio_beta0 + (1 - prio_beta0) * prio_alpha * epoch / total_epochs",
        "detail": "metta.rl.functions",
        "documentation": {}
    },
    {
        "label": "accumulate_rollout_stats",
        "kind": 2,
        "importPath": "metta.rl.functions",
        "description": "metta.rl.functions",
        "peekOfCode": "def accumulate_rollout_stats(\n    raw_infos: list,\n    stats: Dict[str, Any],\n) -> None:\n    \"\"\"Accumulate rollout statistics from info dictionaries.\"\"\"\n    infos = defaultdict(list)\n    # Batch process info dictionaries\n    for i in raw_infos:\n        for k, v in unroll_nested_dict(i):\n            # Detach any tensors before accumulating to prevent memory leaks",
        "detail": "metta.rl.functions",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "metta.rl.functions",
        "description": "metta.rl.functions",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef perform_rollout_step(\n    policy: torch.nn.Module,\n    vecenv: Any,\n    experience: Experience,\n    device: torch.device,\n    timer: Optional[Any] = None,\n) -> Tuple[int, list]:\n    \"\"\"Performs a single step of the rollout, interacting with the environment.\n    Returns:",
        "detail": "metta.rl.functions",
        "documentation": {}
    },
    {
        "label": "Kickstarter",
        "kind": 6,
        "importPath": "metta.rl.kickstarter",
        "description": "metta.rl.kickstarter",
        "peekOfCode": "class Kickstarter:\n    def __init__(self, cfg: KickstartConfig, device: str, policy_store: PolicyStore, action_names, action_max_params):\n        \"\"\"\n        Kickstarting is a technique to initialize a student policy with the knowledge of one or more teacher policies.\n        This is done by adding a loss term that encourages the student's output (action logits and value) to match the\n        teacher's.\n        The kickstarting loss is annealed over a number of steps (`kickstart_steps`).\n        The `anneal_ratio` parameter controls what fraction of the `kickstart_steps` are used for annealing.\n        The annealing is linear and only at the end. For example, if `anneal_ratio` is 0.2, the loss coefficient will\n        be 1.0 for the first 80% of `kickstart_steps`, then anneal linearly from 1.0 down to 0 over the last 20%.",
        "detail": "metta.rl.kickstarter",
        "documentation": {}
    },
    {
        "label": "KickstartTeacherConfig",
        "kind": 6,
        "importPath": "metta.rl.kickstarter_config",
        "description": "metta.rl.kickstarter_config",
        "peekOfCode": "class KickstartTeacherConfig(BaseModelWithForbidExtra):\n    teacher_uri: str\n    # Action loss coefficient: 1.0 gives equal weight to imitating teacher actions\n    action_loss_coef: float = Field(default=1, ge=0)\n    # Value loss coefficient: 1.0 for standard distillation from teacher values\n    value_loss_coef: float = Field(default=1, ge=0)\nclass KickstartConfig(BaseModelWithForbidExtra):\n    teacher_uri: str | None = None\n    # Action loss: Weight 1.0 for standard knowledge distillation from teacher\n    action_loss_coef: float = Field(default=1, ge=0)",
        "detail": "metta.rl.kickstarter_config",
        "documentation": {}
    },
    {
        "label": "KickstartConfig",
        "kind": 6,
        "importPath": "metta.rl.kickstarter_config",
        "description": "metta.rl.kickstarter_config",
        "peekOfCode": "class KickstartConfig(BaseModelWithForbidExtra):\n    teacher_uri: str | None = None\n    # Action loss: Weight 1.0 for standard knowledge distillation from teacher\n    action_loss_coef: float = Field(default=1, ge=0)\n    # Value loss: Weight 1.0 matches action loss for balanced learning\n    value_loss_coef: float = Field(default=1, ge=0)\n    # Anneal ratio 0.65: Type 2 default chosen arbitrarily\n    anneal_ratio: float = Field(default=0.65, ge=0, le=1.0)\n    # Kickstart for 1B steps: Type 2 default chosen arbitrarily\n    kickstart_steps: int = Field(default=1_000_000_000, gt=0)",
        "detail": "metta.rl.kickstarter_config",
        "documentation": {}
    },
    {
        "label": "Losses",
        "kind": 6,
        "importPath": "metta.rl.losses",
        "description": "metta.rl.losses",
        "peekOfCode": "class Losses:\n    def __init__(self):\n        self.zero()\n    def zero(self):\n        \"\"\"Reset all loss values to 0.0\"\"\"\n        self.policy_loss_sum = 0.0\n        self.value_loss_sum = 0.0\n        self.entropy_sum = 0.0\n        self.approx_kl_sum = 0.0\n        self.clipfrac_sum = 0.0",
        "detail": "metta.rl.losses",
        "documentation": {}
    },
    {
        "label": "PytorchAgent",
        "kind": 6,
        "importPath": "metta.rl.policy",
        "description": "metta.rl.policy",
        "peekOfCode": "class PytorchAgent(nn.Module):\n    \"\"\"Adapter to make torch.nn.Module-based policies compatible with MettaAgent interface.\n    This adapter wraps policies loaded from checkpoints and translates their\n    outputs to match the expected MettaAgent interface, handling naming\n    differences like criticvalue, hiddenlogits, etc.\n    \"\"\"\n    def __init__(self, policy: nn.Module):\n        super().__init__()\n        self.policy = policy\n        self.hidden_size = getattr(policy, \"hidden_size\", 256)",
        "detail": "metta.rl.policy",
        "documentation": {}
    },
    {
        "label": "load_pytorch_policy",
        "kind": 2,
        "importPath": "metta.rl.policy",
        "description": "metta.rl.policy",
        "peekOfCode": "def load_pytorch_policy(path: str, device: str = \"cpu\", pytorch_cfg: DictConfig = None):\n    \"\"\"Load a PyTorch policy from checkpoint and wrap it in PytorchAgent.\n    Args:\n        path: Path to the checkpoint file\n        device: Device to load the policy on\n        pytorch_cfg: Configuration for the PyTorch policy (formerly 'puffer')\n    Returns:\n        PytorchAgent wrapping the loaded policy\n    \"\"\"\n    weights = torch.load(path, map_location=device, weights_only=True)",
        "detail": "metta.rl.policy",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "metta.rl.policy",
        "description": "metta.rl.policy",
        "peekOfCode": "logger = logging.getLogger(\"policy\")\ndef load_pytorch_policy(path: str, device: str = \"cpu\", pytorch_cfg: DictConfig = None):\n    \"\"\"Load a PyTorch policy from checkpoint and wrap it in PytorchAgent.\n    Args:\n        path: Path to the checkpoint file\n        device: Device to load the policy on\n        pytorch_cfg: Configuration for the PyTorch policy (formerly 'puffer')\n    Returns:\n        PytorchAgent wrapping the loaded policy\n    \"\"\"",
        "detail": "metta.rl.policy",
        "documentation": {}
    },
    {
        "label": "TorchProfiler",
        "kind": 6,
        "importPath": "metta.rl.torch_profiler",
        "description": "metta.rl.torch_profiler",
        "peekOfCode": "class TorchProfiler:\n    \"\"\"\n    Creates a torch profiler object that can be used as context wherever\n    traces are needed.\n    Profiles are saved as json.gz files locally in\n    train_dir/<your_run>/torch_traces/ and in S3 at\n    torch_traces/<your_run>/. A link to download the S3 file is dropped\n    into wandb under 'torch_traces'. To view traces, go to\n    chrome://tracing (or arc://tracing if you happen to use that browser\n    which is fine) and select 'load'. Navigate traces using WASD on your",
        "detail": "metta.rl.torch_profiler",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "metta.rl.torch_profiler",
        "description": "metta.rl.torch_profiler",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass TorchProfiler:\n    \"\"\"\n    Creates a torch profiler object that can be used as context wherever\n    traces are needed.\n    Profiles are saved as json.gz files locally in\n    train_dir/<your_run>/torch_traces/ and in S3 at\n    torch_traces/<your_run>/. A link to download the S3 file is dropped\n    into wandb under 'torch_traces'. To view traces, go to\n    chrome://tracing (or arc://tracing if you happen to use that browser",
        "detail": "metta.rl.torch_profiler",
        "documentation": {}
    },
    {
        "label": "MettaTrainer",
        "kind": 6,
        "importPath": "metta.rl.trainer",
        "description": "metta.rl.trainer",
        "peekOfCode": "class MettaTrainer:\n    def __init__(\n        self,\n        cfg: DictConfig,\n        wandb_run: WandbRun | None,\n        policy_store: PolicyStore,\n        sim_suite_config: SimulationSuiteConfig,\n        stats_client: StatsClient | None,\n        **kwargs: Any,\n    ):",
        "detail": "metta.rl.trainer",
        "documentation": {}
    },
    {
        "label": "AbortingTrainer",
        "kind": 6,
        "importPath": "metta.rl.trainer",
        "description": "metta.rl.trainer",
        "peekOfCode": "class AbortingTrainer(MettaTrainer):\n    def __init__(self, *args: Any, **kwargs: Any):\n        super().__init__(*args, **kwargs)\n    def _on_train_step(self):\n        if self.wandb_run is None:\n            return\n        if \"abort\" not in wandb.Api().run(self.wandb_run.path).tags:\n            return\n        logger.info(\"Abort tag detected. Stopping the run.\")\n        self.trainer_cfg.total_timesteps = int(self.agent_step)",
        "detail": "metta.rl.trainer",
        "documentation": {}
    },
    {
        "label": "rank",
        "kind": 5,
        "importPath": "metta.rl.trainer",
        "description": "metta.rl.trainer",
        "peekOfCode": "rank = int(os.environ.get(\"RANK\", 0))\nlocal_rank = int(os.environ.get(\"LOCAL_RANK\", 0))\nlogger = logging.getLogger(f\"trainer-{rank}-{local_rank}\")\nclass MettaTrainer:\n    def __init__(\n        self,\n        cfg: DictConfig,\n        wandb_run: WandbRun | None,\n        policy_store: PolicyStore,\n        sim_suite_config: SimulationSuiteConfig,",
        "detail": "metta.rl.trainer",
        "documentation": {}
    },
    {
        "label": "local_rank",
        "kind": 5,
        "importPath": "metta.rl.trainer",
        "description": "metta.rl.trainer",
        "peekOfCode": "local_rank = int(os.environ.get(\"LOCAL_RANK\", 0))\nlogger = logging.getLogger(f\"trainer-{rank}-{local_rank}\")\nclass MettaTrainer:\n    def __init__(\n        self,\n        cfg: DictConfig,\n        wandb_run: WandbRun | None,\n        policy_store: PolicyStore,\n        sim_suite_config: SimulationSuiteConfig,\n        stats_client: StatsClient | None,",
        "detail": "metta.rl.trainer",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "metta.rl.trainer",
        "description": "metta.rl.trainer",
        "peekOfCode": "logger = logging.getLogger(f\"trainer-{rank}-{local_rank}\")\nclass MettaTrainer:\n    def __init__(\n        self,\n        cfg: DictConfig,\n        wandb_run: WandbRun | None,\n        policy_store: PolicyStore,\n        sim_suite_config: SimulationSuiteConfig,\n        stats_client: StatsClient | None,\n        **kwargs: Any,",
        "detail": "metta.rl.trainer",
        "documentation": {}
    },
    {
        "label": "TrainerCheckpoint",
        "kind": 6,
        "importPath": "metta.rl.trainer_checkpoint",
        "description": "metta.rl.trainer_checkpoint",
        "peekOfCode": "class TrainerCheckpoint:\n    def __init__(\n        self,\n        agent_step: int = 0,\n        epoch: int = 0,\n        total_agent_step: Optional[int] = None,\n        optimizer_state_dict: Optional[dict[str, Any]] = None,\n        policy_path: Optional[str] = None,\n        stopwatch_state: Optional[dict[str, Any]] = None,\n        extra_args: Optional[dict[str, Any]] = None,",
        "detail": "metta.rl.trainer_checkpoint",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "metta.rl.trainer_checkpoint",
        "description": "metta.rl.trainer_checkpoint",
        "peekOfCode": "logger = logging.getLogger(\"TrainerCheckpoint\")\nclass TrainerCheckpoint:\n    def __init__(\n        self,\n        agent_step: int = 0,\n        epoch: int = 0,\n        total_agent_step: Optional[int] = None,\n        optimizer_state_dict: Optional[dict[str, Any]] = None,\n        policy_path: Optional[str] = None,\n        stopwatch_state: Optional[dict[str, Any]] = None,",
        "detail": "metta.rl.trainer_checkpoint",
        "documentation": {}
    },
    {
        "label": "OptimizerConfig",
        "kind": 6,
        "importPath": "metta.rl.trainer_config",
        "description": "metta.rl.trainer_config",
        "peekOfCode": "class OptimizerConfig(BaseModelWithForbidExtra):\n    type: Literal[\"adam\", \"muon\"] = \"adam\"\n    # Learning rate: Type 2 default chosen by sweep\n    learning_rate: float = Field(default=0.0004573146765703167, gt=0, le=1.0)\n    # Beta1: Standard Adam default from Kingma & Ba (2014) \"Adam: A Method for Stochastic Optimization\"\n    beta1: float = Field(default=0.9, ge=0, le=1.0)\n    # Beta2: Standard Adam default from Kingma & Ba (2014)\n    beta2: float = Field(default=0.999, ge=0, le=1.0)\n    # Epsilon: Type 2 default chosen arbitrarily\n    eps: float = Field(default=1e-12, gt=0)",
        "detail": "metta.rl.trainer_config",
        "documentation": {}
    },
    {
        "label": "LRSchedulerConfig",
        "kind": 6,
        "importPath": "metta.rl.trainer_config",
        "description": "metta.rl.trainer_config",
        "peekOfCode": "class LRSchedulerConfig(BaseModelWithForbidExtra):\n    # LR scheduling disabled by default: Fixed LR often works well in RL\n    enabled: bool = False\n    # Annealing disabled: Common to use fixed LR for PPO\n    anneal_lr: bool = False\n    # No warmup by default: RL typically doesn't need warmup like supervised learning\n    warmup_steps: int | None = None\n    # Schedule type unset: Various options available when enabled\n    schedule_type: Literal[\"linear\", \"cosine\", \"exponential\"] | None = None\nclass PrioritizedExperienceReplayConfig(BaseModelWithForbidExtra):",
        "detail": "metta.rl.trainer_config",
        "documentation": {}
    },
    {
        "label": "PrioritizedExperienceReplayConfig",
        "kind": 6,
        "importPath": "metta.rl.trainer_config",
        "description": "metta.rl.trainer_config",
        "peekOfCode": "class PrioritizedExperienceReplayConfig(BaseModelWithForbidExtra):\n    # Alpha=0 disables prioritization (uniform sampling), Type 2 default to be updated by sweep\n    prio_alpha: float = Field(default=0.0, ge=0, le=1.0)\n    # Beta0=0.6: From Schaul et al. (2016) \"Prioritized Experience Replay\" paper\n    prio_beta0: float = Field(default=0.6, ge=0, le=1.0)\nclass VTraceConfig(BaseModelWithForbidExtra):\n    # V-trace rho clipping at 1.0: From IMPALA paper (Espeholt et al., 2018), standard for on-policy\n    vtrace_rho_clip: float = Field(default=1.0, gt=0)\n    # V-trace c clipping at 1.0: From IMPALA paper (Espeholt et al., 2018), standard for on-policy\n    vtrace_c_clip: float = Field(default=1.0, gt=0)",
        "detail": "metta.rl.trainer_config",
        "documentation": {}
    },
    {
        "label": "VTraceConfig",
        "kind": 6,
        "importPath": "metta.rl.trainer_config",
        "description": "metta.rl.trainer_config",
        "peekOfCode": "class VTraceConfig(BaseModelWithForbidExtra):\n    # V-trace rho clipping at 1.0: From IMPALA paper (Espeholt et al., 2018), standard for on-policy\n    vtrace_rho_clip: float = Field(default=1.0, gt=0)\n    # V-trace c clipping at 1.0: From IMPALA paper (Espeholt et al., 2018), standard for on-policy\n    vtrace_c_clip: float = Field(default=1.0, gt=0)\nclass InitialPolicyConfig(BaseModelWithForbidExtra):\n    uri: str | None = None\n    # Type=\"top\": Empirical best performing\n    type: Literal[\"top\", \"latest\", \"specific\"] = \"top\"\n    # Range=1: Select single best policy, standard practice",
        "detail": "metta.rl.trainer_config",
        "documentation": {}
    },
    {
        "label": "InitialPolicyConfig",
        "kind": 6,
        "importPath": "metta.rl.trainer_config",
        "description": "metta.rl.trainer_config",
        "peekOfCode": "class InitialPolicyConfig(BaseModelWithForbidExtra):\n    uri: str | None = None\n    # Type=\"top\": Empirical best performing\n    type: Literal[\"top\", \"latest\", \"specific\"] = \"top\"\n    # Range=1: Select single best policy, standard practice\n    range: int = Field(default=1, gt=0)\n    # Metric=\"epoch\": Default sorting by training progress\n    metric: str = \"epoch\"\n    filters: dict[str, Any] = Field(default_factory=dict)\nclass CheckpointConfig(BaseModelWithForbidExtra):",
        "detail": "metta.rl.trainer_config",
        "documentation": {}
    },
    {
        "label": "CheckpointConfig",
        "kind": 6,
        "importPath": "metta.rl.trainer_config",
        "description": "metta.rl.trainer_config",
        "peekOfCode": "class CheckpointConfig(BaseModelWithForbidExtra):\n    # Checkpoint every 60s: Balance between recovery granularity and I/O overhead\n    checkpoint_interval: int = Field(default=60, gt=0)\n    # W&B every 5 min: Less frequent due to network overhead and storage costs\n    wandb_checkpoint_interval: int = Field(default=300, ge=0)  # 0 to disable\n    checkpoint_dir: str = Field(default=\"\")\n    @model_validator(mode=\"after\")\n    def validate_fields(self) -> \"CheckpointConfig\":\n        assert self.checkpoint_dir, \"checkpoint_dir must be set\"\n        return self",
        "detail": "metta.rl.trainer_config",
        "documentation": {}
    },
    {
        "label": "SimulationConfig",
        "kind": 6,
        "importPath": "metta.rl.trainer_config",
        "description": "metta.rl.trainer_config",
        "peekOfCode": "class SimulationConfig(BaseModelWithForbidExtra):\n    # Evaluate interval: Type 2 arbitrary default\n    evaluate_interval: int = Field(default=300, ge=0)  # 0 to disable\n    # Replay interval: Type 2 arbitrary default\n    replay_interval: int = Field(default=300, ge=0)  # 0 to disable\n    replay_dir: str = Field(default=\"\")\n    @model_validator(mode=\"after\")\n    def validate_fields(self) -> \"SimulationConfig\":\n        assert self.replay_dir, \"replay_dir must be set\"\n        return self",
        "detail": "metta.rl.trainer_config",
        "documentation": {}
    },
    {
        "label": "PPOConfig",
        "kind": 6,
        "importPath": "metta.rl.trainer_config",
        "description": "metta.rl.trainer_config",
        "peekOfCode": "class PPOConfig(BaseModelWithForbidExtra):\n    # PPO hyperparameters\n    # Clip coefficient: 0.1 is conservative, common range 0.1-0.3 from PPO paper (Schulman et al., 2017)\n    clip_coef: float = Field(default=0.1, gt=0, le=1.0)\n    # Entropy coefficient: Type 2 default chosen from sweep\n    ent_coef: float = Field(default=0.0021, ge=0)\n    # GAE lambda: Type 2 default chosen from sweep, deviates from typical 0.95, bias/variance tradeoff\n    gae_lambda: float = Field(default=0.916, ge=0, le=1.0)\n    # Gamma: Type 2 default chosen from sweep, deviates from typical 0.99, suggests shorter\n    # effective horizon for multi-agent",
        "detail": "metta.rl.trainer_config",
        "documentation": {}
    },
    {
        "label": "TrainerConfig",
        "kind": 6,
        "importPath": "metta.rl.trainer_config",
        "description": "metta.rl.trainer_config",
        "peekOfCode": "class TrainerConfig(BaseModelWithForbidExtra):\n    # Target for hydra instantiation\n    target: str = Field(default=\"metta.rl.trainer.MettaTrainer\", alias=\"_target_\")\n    # Core training parameters\n    # Total timesteps: Type 2 arbitrary default\n    total_timesteps: int = Field(default=50_000_000_000, gt=0)\n    # PPO configuration\n    ppo: PPOConfig = Field(default_factory=PPOConfig)\n    # Optimizer and scheduler\n    optimizer: OptimizerConfig = Field(default_factory=OptimizerConfig)",
        "detail": "metta.rl.trainer_config",
        "documentation": {}
    },
    {
        "label": "parse_trainer_config",
        "kind": 2,
        "importPath": "metta.rl.trainer_config",
        "description": "metta.rl.trainer_config",
        "peekOfCode": "def parse_trainer_config(\n    cfg: DictConfig,\n) -> TrainerConfig:\n    \"\"\"Parse trainer config from Hydra config.\n    Args:\n        cfg: The complete Hydra config (must contain trainer, run, and run_dir)\n    \"\"\"\n    for key in [\"trainer\", \"run\", \"run_dir\"]:\n        if not hasattr(cfg, key) or cfg[key] is None:\n            raise ValueError(f\"cfg must have a '{key}' field\")",
        "detail": "metta.rl.trainer_config",
        "documentation": {}
    },
    {
        "label": "make_env_func",
        "kind": 2,
        "importPath": "metta.rl.vecenv",
        "description": "metta.rl.vecenv",
        "peekOfCode": "def make_env_func(\n    curriculum: Curriculum,\n    buf=None,\n    render_mode=\"rgb_array\",\n    stats_writer: Optional[StatsWriter] = None,\n    replay_writer: Optional[ReplayWriter] = None,\n    is_training: bool = False,\n    **kwargs,\n):\n    # we are not calling into our configs hierarchy here so we need to manually register the custom resolvers",
        "detail": "metta.rl.vecenv",
        "documentation": {}
    },
    {
        "label": "make_vecenv",
        "kind": 2,
        "importPath": "metta.rl.vecenv",
        "description": "metta.rl.vecenv",
        "peekOfCode": "def make_vecenv(\n    curriculum: Curriculum,\n    vectorization: str,\n    num_envs=1,\n    batch_size=None,\n    num_workers=1,\n    render_mode=None,\n    stats_writer: Optional[StatsWriter] = None,\n    replay_writer: Optional[ReplayWriter] = None,\n    is_training: bool = False,",
        "detail": "metta.rl.vecenv",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "metta.rl.vecenv",
        "description": "metta.rl.vecenv",
        "peekOfCode": "logger = logging.getLogger(\"vecenv\")\n@validate_call(config={\"arbitrary_types_allowed\": True})\ndef make_env_func(\n    curriculum: Curriculum,\n    buf=None,\n    render_mode=\"rgb_array\",\n    stats_writer: Optional[StatsWriter] = None,\n    replay_writer: Optional[ReplayWriter] = None,\n    is_training: bool = False,\n    **kwargs,",
        "detail": "metta.rl.vecenv",
        "documentation": {}
    },
    {
        "label": "AWSSetup",
        "kind": 6,
        "importPath": "metta.setup.components.aws",
        "description": "metta.setup.components.aws",
        "peekOfCode": "class AWSSetup(SetupModule):\n    @property\n    def description(self) -> str:\n        return \"AWS configuration and credentials\"\n    @property\n    def setup_script_location(self) -> str | None:\n        if self.config.user_type.is_softmax:\n            return \"devops/aws/setup_aws_profiles.sh\"\n        return None\n    def is_applicable(self) -> bool:",
        "detail": "metta.setup.components.aws",
        "documentation": {}
    },
    {
        "label": "SetupModule",
        "kind": 6,
        "importPath": "metta.setup.components.base",
        "description": "metta.setup.components.base",
        "peekOfCode": "class SetupModule(ABC):\n    def __init__(self, config: SetupConfig):\n        self.config: SetupConfig = config\n        self.repo_root: Path = Path(__file__).parent.parent.parent.parent\n    @property\n    def name(self) -> str:\n        return self.__class__.__name__.replace(\"Setup\", \"\").lower()\n    @property\n    @abstractmethod\n    def description(self) -> str:",
        "detail": "metta.setup.components.base",
        "documentation": {}
    },
    {
        "label": "CoreSetup",
        "kind": 6,
        "importPath": "metta.setup.components.core",
        "description": "metta.setup.components.core",
        "peekOfCode": "class CoreSetup(SetupModule):\n    @property\n    def description(self) -> str:\n        return \"Core Python dependencies and virtual environment\"\n    def is_applicable(self) -> bool:\n        return True\n    def check_installed(self) -> bool:\n        try:\n            subprocess.run([\"uv\", \"--version\"], check=True, capture_output=True)\n            return True",
        "detail": "metta.setup.components.core",
        "documentation": {}
    },
    {
        "label": "GitHooksSetup",
        "kind": 6,
        "importPath": "metta.setup.components.githooks",
        "description": "metta.setup.components.githooks",
        "peekOfCode": "class GitHooksSetup(SetupModule):\n    @property\n    def description(self) -> str:\n        return \"Git hooks\"\n    @property\n    def setup_script_location(self) -> str | None:\n        return \"devops/setup_git_hooks.sh\"\n    def is_applicable(self) -> bool:\n        return self.config.is_component_enabled(\"githooks\")\n    def check_installed(self) -> bool:",
        "detail": "metta.setup.components.githooks",
        "documentation": {}
    },
    {
        "label": "MettaScopeSetup",
        "kind": 6,
        "importPath": "metta.setup.components.mettascope",
        "description": "metta.setup.components.mettascope",
        "peekOfCode": "class MettaScopeSetup(SetupModule):\n    @property\n    def description(self) -> str:\n        return \"MettaScope visualization and replay tools\"\n    @property\n    def setup_script_location(self) -> str:\n        return \"mettascope/install.sh\"\n    def is_applicable(self) -> bool:\n        return self.config.is_component_enabled(\"mettascope\")\n    def check_installed(self) -> bool:",
        "detail": "metta.setup.components.mettascope",
        "documentation": {}
    },
    {
        "label": "ObservatoryCliSetup",
        "kind": 6,
        "importPath": "metta.setup.components.observatory_cli",
        "description": "metta.setup.components.observatory_cli",
        "peekOfCode": "class ObservatoryCliSetup(SetupModule):\n    @property\n    def name(self) -> str:\n        return \"observatory-cli\"\n    @property\n    def description(self) -> str:\n        return \"Observatory CLI authentication\"\n    def is_applicable(self) -> bool:\n        return self.config.is_component_enabled(\"observatory-cli\")\n    def get_token(self) -> str | None:",
        "detail": "metta.setup.components.observatory_cli",
        "documentation": {}
    },
    {
        "label": "ObservatoryFeSetup",
        "kind": 6,
        "importPath": "metta.setup.components.observatory_fe",
        "description": "metta.setup.components.observatory_fe",
        "peekOfCode": "class ObservatoryFeSetup(SetupModule):\n    @property\n    def name(self) -> str:\n        return \"observatory-fe\"\n    @property\n    def description(self) -> str:\n        return \"Observatory frontend development\"\n    def is_applicable(self) -> bool:\n        return self.config.is_component_enabled(\"observatory-fe\")\n    def check_installed(self) -> bool:",
        "detail": "metta.setup.components.observatory_fe",
        "documentation": {}
    },
    {
        "label": "SkypilotSetup",
        "kind": 6,
        "importPath": "metta.setup.components.skypilot",
        "description": "metta.setup.components.skypilot",
        "peekOfCode": "class SkypilotSetup(SetupModule):\n    @property\n    def description(self) -> str:\n        return \"SkyPilot cloud compute orchestration\"\n    def is_applicable(self) -> bool:\n        return self.config.is_component_enabled(\"skypilot\") and self.config.is_component_enabled(\"aws\")\n    def check_installed(self) -> bool:\n        try:\n            result = subprocess.run([\"sky\", \"--version\"], capture_output=True, text=True)\n            return result.returncode == 0 and self._check_gh_auth()",
        "detail": "metta.setup.components.skypilot",
        "documentation": {}
    },
    {
        "label": "StudioSetup",
        "kind": 6,
        "importPath": "metta.setup.components.studio",
        "description": "metta.setup.components.studio",
        "peekOfCode": "class StudioSetup(SetupModule):\n    @property\n    def name(self) -> str:\n        return \"studio\"\n    @property\n    def description(self) -> str:\n        return \"Studio frontend development\"\n    def is_applicable(self) -> bool:\n        return self.config.is_component_enabled(\"studio\")\n    def check_installed(self) -> bool:",
        "detail": "metta.setup.components.studio",
        "documentation": {}
    },
    {
        "label": "SystemSetup",
        "kind": 6,
        "importPath": "metta.setup.components.system",
        "description": "metta.setup.components.system",
        "peekOfCode": "class SystemSetup(SetupModule):\n    @property\n    @override\n    def description(self) -> str:\n        return \"System dependencies (Homebrew packages, etc.)\"\n    @override\n    def is_applicable(self) -> bool:\n        return self.config.is_component_enabled(\"system\")\n    @property\n    def supported_for_platform(self) -> bool:",
        "detail": "metta.setup.components.system",
        "documentation": {}
    },
    {
        "label": "TailscaleSetup",
        "kind": 6,
        "importPath": "metta.setup.components.tailscale",
        "description": "metta.setup.components.tailscale",
        "peekOfCode": "class TailscaleSetup(SetupModule):\n    @property\n    def description(self) -> str:\n        return \"Tailscale VPN for internal network access\"\n    def is_applicable(self) -> bool:\n        return (\n            platform.system() == \"Darwin\"\n            and self.config.user_type == UserType.SOFTMAX\n            and self.config.is_component_enabled(\"tailscale\")\n        )",
        "detail": "metta.setup.components.tailscale",
        "documentation": {}
    },
    {
        "label": "WandbSetup",
        "kind": 6,
        "importPath": "metta.setup.components.wandb",
        "description": "metta.setup.components.wandb",
        "peekOfCode": "class WandbSetup(SetupModule):\n    @property\n    def description(self) -> str:\n        return \"Weights & Biases experiment tracking\"\n    def is_applicable(self) -> bool:\n        return self.config.is_component_enabled(\"wandb\")\n    def check_installed(self) -> bool:\n        if os.environ.get(\"WANDB_API_KEY\"):\n            return True\n        netrc_path = os.path.expanduser(\"~/.netrc\")",
        "detail": "metta.setup.components.wandb",
        "documentation": {}
    },
    {
        "label": "UserType",
        "kind": 6,
        "importPath": "metta.setup.config",
        "description": "metta.setup.config",
        "peekOfCode": "class UserType(Enum):\n    EXTERNAL = \"external\"\n    CLOUD = \"cloud\"\n    SOFTMAX = \"softmax\"\n    SOFTMAX_DOCKER = \"softmax-docker\"\n    @property\n    def is_softmax(self) -> bool:\n        return self in (UserType.SOFTMAX, UserType.SOFTMAX_DOCKER)\n    def get_description(self) -> str:\n        descriptions = {",
        "detail": "metta.setup.config",
        "documentation": {}
    },
    {
        "label": "ComponentConfig",
        "kind": 6,
        "importPath": "metta.setup.config",
        "description": "metta.setup.config",
        "peekOfCode": "class ComponentConfig(TypedDict):\n    enabled: bool\n    expected_connection: NotRequired[str | None]\nclass ProfileConfig(TypedDict):\n    components: dict[str, ComponentConfig]\nCURRENT_CONFIG_VERSION = 1\nPROFILE_DEFINITIONS: dict[UserType, ProfileConfig] = {\n    UserType.EXTERNAL: {\n        \"components\": {\n            \"system\": {\"enabled\": True},",
        "detail": "metta.setup.config",
        "documentation": {}
    },
    {
        "label": "ProfileConfig",
        "kind": 6,
        "importPath": "metta.setup.config",
        "description": "metta.setup.config",
        "peekOfCode": "class ProfileConfig(TypedDict):\n    components: dict[str, ComponentConfig]\nCURRENT_CONFIG_VERSION = 1\nPROFILE_DEFINITIONS: dict[UserType, ProfileConfig] = {\n    UserType.EXTERNAL: {\n        \"components\": {\n            \"system\": {\"enabled\": True},\n            \"core\": {\"enabled\": True},\n            \"githooks\": {\"enabled\": True},\n            \"mettascope\": {\"enabled\": True},",
        "detail": "metta.setup.config",
        "documentation": {}
    },
    {
        "label": "SetupConfig",
        "kind": 6,
        "importPath": "metta.setup.config",
        "description": "metta.setup.config",
        "peekOfCode": "class SetupConfig:\n    def __init__(self, config_path: Path | None = None):\n        self.config_path: Path = config_path or Path.home() / \".metta\" / \"config.yaml\"\n        self.config_path.parent.mkdir(parents=True, exist_ok=True)\n        self._config: dict = self._load_config()\n    def _load_config(self) -> dict:\n        if self.config_path.exists():\n            with open(self.config_path, \"r\") as f:\n                return yaml.safe_load(f) or {}\n        return {}",
        "detail": "metta.setup.config",
        "documentation": {}
    },
    {
        "label": "CURRENT_CONFIG_VERSION",
        "kind": 5,
        "importPath": "metta.setup.config",
        "description": "metta.setup.config",
        "peekOfCode": "CURRENT_CONFIG_VERSION = 1\nPROFILE_DEFINITIONS: dict[UserType, ProfileConfig] = {\n    UserType.EXTERNAL: {\n        \"components\": {\n            \"system\": {\"enabled\": True},\n            \"core\": {\"enabled\": True},\n            \"githooks\": {\"enabled\": True},\n            \"mettascope\": {\"enabled\": True},\n            \"observatory-fe\": {\"enabled\": False},\n            \"observatory-cli\": {\"enabled\": False},",
        "detail": "metta.setup.config",
        "documentation": {}
    },
    {
        "label": "T",
        "kind": 5,
        "importPath": "metta.setup.config",
        "description": "metta.setup.config",
        "peekOfCode": "T = TypeVar(\"T\")\nclass SetupConfig:\n    def __init__(self, config_path: Path | None = None):\n        self.config_path: Path = config_path or Path.home() / \".metta\" / \"config.yaml\"\n        self.config_path.parent.mkdir(parents=True, exist_ok=True)\n        self._config: dict = self._load_config()\n    def _load_config(self) -> dict:\n        if self.config_path.exists():\n            with open(self.config_path, \"r\") as f:\n                return yaml.safe_load(f) or {}",
        "detail": "metta.setup.config",
        "documentation": {}
    },
    {
        "label": "MettaCLI",
        "kind": 6,
        "importPath": "metta.setup.metta_cli",
        "description": "metta.setup.metta_cli",
        "peekOfCode": "class MettaCLI:\n    def __init__(self):\n        self.repo_root: Path = Path(__file__).parent.parent.parent\n        self.config: SetupConfig = SetupConfig()\n    def setup_wizard(self) -> None:\n        header(\"Welcome to Metta!\\n\\n\")\n        if self.config.config_path.exists():\n            info(\"Current configuration:\")\n            info(f\"Profile: {self.config.user_type.value}\")\n            info(f\"Mode: {'custom' if self.config.is_custom_config else 'profile'}\")",
        "detail": "metta.setup.metta_cli",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "metta.setup.metta_cli",
        "description": "metta.setup.metta_cli",
        "peekOfCode": "def main():\n    cli = MettaCLI()\n    cli.main()\nif __name__ == \"__main__\":\n    main()",
        "detail": "metta.setup.metta_cli",
        "documentation": {}
    },
    {
        "label": "register_module",
        "kind": 2,
        "importPath": "metta.setup.registry",
        "description": "metta.setup.registry",
        "peekOfCode": "def register_module(cls: Type[\"SetupModule\"]) -> Type[\"SetupModule\"]:\n    _REGISTRY.append(cls)\n    return cls\ndef get_all_modules(config) -> list[\"SetupModule\"]:\n    # Import here to avoid circular imports\n    return [cls(config) for cls in _REGISTRY]\ndef get_applicable_modules(config) -> list[\"SetupModule\"]:\n    return [m for m in get_all_modules(config) if m.is_applicable()]",
        "detail": "metta.setup.registry",
        "documentation": {}
    },
    {
        "label": "get_all_modules",
        "kind": 2,
        "importPath": "metta.setup.registry",
        "description": "metta.setup.registry",
        "peekOfCode": "def get_all_modules(config) -> list[\"SetupModule\"]:\n    # Import here to avoid circular imports\n    return [cls(config) for cls in _REGISTRY]\ndef get_applicable_modules(config) -> list[\"SetupModule\"]:\n    return [m for m in get_all_modules(config) if m.is_applicable()]",
        "detail": "metta.setup.registry",
        "documentation": {}
    },
    {
        "label": "get_applicable_modules",
        "kind": 2,
        "importPath": "metta.setup.registry",
        "description": "metta.setup.registry",
        "peekOfCode": "def get_applicable_modules(config) -> list[\"SetupModule\"]:\n    return [m for m in get_all_modules(config) if m.is_applicable()]",
        "detail": "metta.setup.registry",
        "documentation": {}
    },
    {
        "label": "success",
        "kind": 2,
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "peekOfCode": "def success(message: str, **kwargs) -> None:\n    print(green(_format_message(message)), **kwargs)\ndef info(message: str, **kwargs) -> None:\n    print(blue(_format_message(message)), **kwargs)\ndef warning(message: str, **kwargs) -> None:\n    print(yellow(_format_message(message)), **kwargs)\ndef error(message: str, **kwargs) -> None:\n    print(red(_format_message(message)), **kwargs)\ndef header(message: str) -> None:\n    print(f\"\\n{bold(cyan(_format_message(message)))}\")",
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "info",
        "kind": 2,
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "peekOfCode": "def info(message: str, **kwargs) -> None:\n    print(blue(_format_message(message)), **kwargs)\ndef warning(message: str, **kwargs) -> None:\n    print(yellow(_format_message(message)), **kwargs)\ndef error(message: str, **kwargs) -> None:\n    print(red(_format_message(message)), **kwargs)\ndef header(message: str) -> None:\n    print(f\"\\n{bold(cyan(_format_message(message)))}\")\ndef step(message: str) -> None:\n    print(colorize(_format_message(message), Fore.WHITE))",
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "warning",
        "kind": 2,
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "peekOfCode": "def warning(message: str, **kwargs) -> None:\n    print(yellow(_format_message(message)), **kwargs)\ndef error(message: str, **kwargs) -> None:\n    print(red(_format_message(message)), **kwargs)\ndef header(message: str) -> None:\n    print(f\"\\n{bold(cyan(_format_message(message)))}\")\ndef step(message: str) -> None:\n    print(colorize(_format_message(message), Fore.WHITE))\ndef import_all_modules_from_subpackage(package_name: str, subpackage: str) -> None:\n    \"\"\"Import all Python modules from a subpackage directory.",
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "error",
        "kind": 2,
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "peekOfCode": "def error(message: str, **kwargs) -> None:\n    print(red(_format_message(message)), **kwargs)\ndef header(message: str) -> None:\n    print(f\"\\n{bold(cyan(_format_message(message)))}\")\ndef step(message: str) -> None:\n    print(colorize(_format_message(message), Fore.WHITE))\ndef import_all_modules_from_subpackage(package_name: str, subpackage: str) -> None:\n    \"\"\"Import all Python modules from a subpackage directory.\n    This is useful for auto-registering modules that use decorators.\n    Works with PEP 420 namespace packages.",
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "header",
        "kind": 2,
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "peekOfCode": "def header(message: str) -> None:\n    print(f\"\\n{bold(cyan(_format_message(message)))}\")\ndef step(message: str) -> None:\n    print(colorize(_format_message(message), Fore.WHITE))\ndef import_all_modules_from_subpackage(package_name: str, subpackage: str) -> None:\n    \"\"\"Import all Python modules from a subpackage directory.\n    This is useful for auto-registering modules that use decorators.\n    Works with PEP 420 namespace packages.\n    Args:\n        package_name: The parent package name (e.g., 'metta.setup')",
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "step",
        "kind": 2,
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "peekOfCode": "def step(message: str) -> None:\n    print(colorize(_format_message(message), Fore.WHITE))\ndef import_all_modules_from_subpackage(package_name: str, subpackage: str) -> None:\n    \"\"\"Import all Python modules from a subpackage directory.\n    This is useful for auto-registering modules that use decorators.\n    Works with PEP 420 namespace packages.\n    Args:\n        package_name: The parent package name (e.g., 'metta.setup')\n        subpackage: The subpackage name (e.g., 'components')\n    \"\"\"",
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "import_all_modules_from_subpackage",
        "kind": 2,
        "importPath": "metta.setup.utils",
        "description": "metta.setup.utils",
        "peekOfCode": "def import_all_modules_from_subpackage(package_name: str, subpackage: str) -> None:\n    \"\"\"Import all Python modules from a subpackage directory.\n    This is useful for auto-registering modules that use decorators.\n    Works with PEP 420 namespace packages.\n    Args:\n        package_name: The parent package name (e.g., 'metta.setup')\n        subpackage: The subpackage name (e.g., 'components')\n    \"\"\"\n    # Since we're in metta/setup/utils.py, we can use relative path\n    current_file = Path(__file__)",
        "detail": "metta.setup.utils",
        "documentation": {}
    },
    {
        "label": "write_map_preview_file",
        "kind": 2,
        "importPath": "metta.sim.map_preview",
        "description": "metta.sim.map_preview",
        "peekOfCode": "def write_map_preview_file(preview_path: str, env: MettaGridEnv, gzipped: bool):\n    logger.info(\"Building map preview...\")\n    preview = {\n        \"version\": 1,\n        \"action_names\": env.action_names,\n        \"object_types\": env.object_type_names,\n        \"inventory_items\": env.inventory_item_names,\n        \"map_size\": [env.map_width, env.map_height],\n        \"num_agents\": env.num_agents,\n        \"max_steps\": 1,",
        "detail": "metta.sim.map_preview",
        "documentation": {}
    },
    {
        "label": "write_local_map_preview",
        "kind": 2,
        "importPath": "metta.sim.map_preview",
        "description": "metta.sim.map_preview",
        "peekOfCode": "def write_local_map_preview(env: MettaGridEnv):\n    maps_dir = \"./outputs/maps\"\n    os.makedirs(maps_dir, exist_ok=True)\n    with tempfile.NamedTemporaryFile(delete=False, dir=maps_dir, suffix=\".json\") as temp_file:\n        preview_path = os.path.relpath(temp_file.name)\n        # no gzip locally - fastapi doesn't recognize .json.z files\n        write_map_preview_file(preview_path, env, gzipped=False)\n    return preview_path\ndef upload_map_preview(\n    curriculum: Curriculum,",
        "detail": "metta.sim.map_preview",
        "documentation": {}
    },
    {
        "label": "upload_map_preview",
        "kind": 2,
        "importPath": "metta.sim.map_preview",
        "description": "metta.sim.map_preview",
        "peekOfCode": "def upload_map_preview(\n    curriculum: Curriculum,\n    s3_path: str,\n    wandb_run: Optional[wandb_run.Run] = None,\n):\n    \"\"\"\n    Builds a map preview of the simulation environment and uploads it to S3.\n    Args:\n        cfg: Configuration for the simulation\n        s3_path: Path to upload the map preview to",
        "detail": "metta.sim.map_preview",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "metta.sim.map_preview",
        "description": "metta.sim.map_preview",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef write_map_preview_file(preview_path: str, env: MettaGridEnv, gzipped: bool):\n    logger.info(\"Building map preview...\")\n    preview = {\n        \"version\": 1,\n        \"action_names\": env.action_names,\n        \"object_types\": env.object_type_names,\n        \"inventory_items\": env.inventory_item_names,\n        \"map_size\": [env.map_width, env.map_height],\n        \"num_agents\": env.num_agents,",
        "detail": "metta.sim.map_preview",
        "documentation": {}
    },
    {
        "label": "SimulationCompatibilityError",
        "kind": 6,
        "importPath": "metta.sim.simulation",
        "description": "metta.sim.simulation",
        "peekOfCode": "class SimulationCompatibilityError(Exception):\n    \"\"\"Raised when there's a compatibility issue that prevents simulation from running.\"\"\"\n    pass\nclass Simulation:\n    \"\"\"\n    A vectorized batch of MettaGrid environments sharing the same parameters.\n    \"\"\"\n    def __init__(\n        self,\n        name: str,",
        "detail": "metta.sim.simulation",
        "documentation": {}
    },
    {
        "label": "Simulation",
        "kind": 6,
        "importPath": "metta.sim.simulation",
        "description": "metta.sim.simulation",
        "peekOfCode": "class Simulation:\n    \"\"\"\n    A vectorized batch of MettaGrid environments sharing the same parameters.\n    \"\"\"\n    def __init__(\n        self,\n        name: str,\n        config: SingleEnvSimulationConfig,\n        policy_pr: PolicyRecord,\n        policy_store: PolicyStore,",
        "detail": "metta.sim.simulation",
        "documentation": {}
    },
    {
        "label": "SimulationResults",
        "kind": 6,
        "importPath": "metta.sim.simulation",
        "description": "metta.sim.simulation",
        "peekOfCode": "class SimulationResults:\n    \"\"\"\n    Results of a simulation.\n    For now just a stats db. Replay plays can be retrieved from the stats db.\n    \"\"\"\n    stats_db: SimulationStatsDB",
        "detail": "metta.sim.simulation",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "metta.sim.simulation",
        "description": "metta.sim.simulation",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass SimulationCompatibilityError(Exception):\n    \"\"\"Raised when there's a compatibility issue that prevents simulation from running.\"\"\"\n    pass\nclass Simulation:\n    \"\"\"\n    A vectorized batch of MettaGrid environments sharing the same parameters.\n    \"\"\"\n    def __init__(\n        self,",
        "detail": "metta.sim.simulation",
        "documentation": {}
    },
    {
        "label": "SimulationConfig",
        "kind": 6,
        "importPath": "metta.sim.simulation_config",
        "description": "metta.sim.simulation_config",
        "peekOfCode": "class SimulationConfig(Config):\n    \"\"\"Configuration for a single simulation run.\"\"\"\n    __init__ = Config.__init__\n    # Core simulation config\n    num_episodes: int\n    max_time_s: int = 120\n    env_overrides: dict = {}\n    npc_policy_uri: Optional[str] = None\n    policy_agents_pct: float = 1.0\nclass SingleEnvSimulationConfig(SimulationConfig):",
        "detail": "metta.sim.simulation_config",
        "documentation": {}
    },
    {
        "label": "SingleEnvSimulationConfig",
        "kind": 6,
        "importPath": "metta.sim.simulation_config",
        "description": "metta.sim.simulation_config",
        "peekOfCode": "class SingleEnvSimulationConfig(SimulationConfig):\n    \"\"\"Configuration for a single simulation run.\"\"\"\n    __init__ = SimulationConfig.__init__\n    env: str\n    env_overrides: dict = {}\nclass SimulationSuiteConfig(SimulationConfig):\n    \"\"\"A suite of named simulations, with suite-level defaults injected.\"\"\"\n    name: str\n    simulations: Dict[str, SingleEnvSimulationConfig]\n    @model_validator(mode=\"before\")",
        "detail": "metta.sim.simulation_config",
        "documentation": {}
    },
    {
        "label": "SimulationSuiteConfig",
        "kind": 6,
        "importPath": "metta.sim.simulation_config",
        "description": "metta.sim.simulation_config",
        "peekOfCode": "class SimulationSuiteConfig(SimulationConfig):\n    \"\"\"A suite of named simulations, with suite-level defaults injected.\"\"\"\n    name: str\n    simulations: Dict[str, SingleEnvSimulationConfig]\n    @model_validator(mode=\"before\")\n    @classmethod\n    def propagate_suite_fields(cls, values: dict) -> dict:\n        # collect only fields that were explicitly passed (not defaults)\n        # note: in `mode=\"before\"`, `values` is raw user input\n        explicitly_provided = {",
        "detail": "metta.sim.simulation_config",
        "documentation": {}
    },
    {
        "label": "SimulationStatsDB",
        "kind": 6,
        "importPath": "metta.sim.simulation_stats_db",
        "description": "metta.sim.simulation_stats_db",
        "peekOfCode": "class SimulationStatsDB(EpisodeStatsDB):\n    def __init__(self, path: Path) -> None:\n        super().__init__(path)\n    def tables(self) -> Dict[str, str]:\n        \"\"\"Add simulation tables to the parent tables.\n        super().initialize_schema() will read this to initialize the schema.\n        \"\"\"\n        parent_tables = super().tables()\n        return {**parent_tables, **SIMULATION_DB_TABLES}\n    @classmethod",
        "detail": "metta.sim.simulation_stats_db",
        "documentation": {}
    },
    {
        "label": "SIMULATION_DB_TABLES",
        "kind": 5,
        "importPath": "metta.sim.simulation_stats_db",
        "description": "metta.sim.simulation_stats_db",
        "peekOfCode": "SIMULATION_DB_TABLES = {\n    \"simulations\": \"\"\"\n    CREATE TABLE IF NOT EXISTS simulations (\n        id   TEXT PRIMARY KEY,\n        name TEXT NOT NULL,\n        suite TEXT NOT NULL,\n        env TEXT NOT NULL,\n        policy_key     TEXT NOT NULL,\n        policy_version INT NOT NULL,\n        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,",
        "detail": "metta.sim.simulation_stats_db",
        "documentation": {}
    },
    {
        "label": "SimulationSuite",
        "kind": 6,
        "importPath": "metta.sim.simulation_suite",
        "description": "metta.sim.simulation_suite",
        "peekOfCode": "class SimulationSuite:\n    \"\"\"\n    Runs a collection of named simulations and returns **one merged StatsDB**\n    containing the union of their statistics.\n    \"\"\"\n    def __init__(\n        self,\n        config: SimulationSuiteConfig,\n        policy_pr: PolicyRecord,\n        policy_store: PolicyStore,",
        "detail": "metta.sim.simulation_suite",
        "documentation": {}
    },
    {
        "label": "make_app",
        "kind": 2,
        "importPath": "metta.studio.server",
        "description": "metta.studio.server",
        "peekOfCode": "def make_app():\n    register_resolvers()\n    app = FastAPI()\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=[\"http://localhost:3000\"],\n        allow_credentials=True,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )",
        "detail": "metta.studio.server",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "metta.studio.server",
        "description": "metta.studio.server",
        "peekOfCode": "def main():\n    app = make_app()\n    uvicorn.run(app, host=\"0.0.0.0\", port=8001)\nif __name__ == \"__main__\":\n    main()",
        "detail": "metta.studio.server",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "metta.studio.server",
        "description": "metta.studio.server",
        "peekOfCode": "logger = logging.getLogger(\"metta.studio.server\")\ndef make_app():\n    register_resolvers()\n    app = FastAPI()\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=[\"http://localhost:3000\"],\n        allow_credentials=True,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],",
        "detail": "metta.studio.server",
        "documentation": {}
    },
    {
        "label": "Space",
        "kind": 6,
        "importPath": "metta.sweep.protein",
        "description": "metta.sweep.protein",
        "peekOfCode": "class Space:\n    def __init__(self, min, max, scale, mean, is_integer=False):\n        self.min = min\n        self.max = max\n        self.scale = scale\n        self.mean = mean  # TODO: awkward to have just this normalized\n        self.norm_min = self.normalize(min)\n        self.norm_max = self.normalize(max)\n        self.norm_mean = self.normalize(mean)\n        self.is_integer = is_integer",
        "detail": "metta.sweep.protein",
        "documentation": {}
    },
    {
        "label": "Linear",
        "kind": 6,
        "importPath": "metta.sweep.protein",
        "description": "metta.sweep.protein",
        "peekOfCode": "class Linear(Space):\n    def __init__(self, min, max, scale, mean, is_integer=False):\n        if scale == \"auto\":\n            scale = 0.5\n        super().__init__(min, max, scale, mean, is_integer)\n    def normalize(self, value):\n        zero_one = (value - self.min) / (self.max - self.min)\n        return 2 * zero_one - 1\n    def unnormalize(self, value):\n        zero_one = (value + 1) / 2",
        "detail": "metta.sweep.protein",
        "documentation": {}
    },
    {
        "label": "Pow2",
        "kind": 6,
        "importPath": "metta.sweep.protein",
        "description": "metta.sweep.protein",
        "peekOfCode": "class Pow2(Space):\n    def __init__(self, min, max, scale, mean, is_integer=False):\n        if scale == \"auto\":\n            scale = 0.5\n        super().__init__(min, max, scale, mean, is_integer)\n    def normalize(self, value):\n        zero_one = (math.log(value, 2) - math.log(self.min, 2)) / (math.log(self.max, 2) - math.log(self.min, 2))\n        return 2 * zero_one - 1\n    def unnormalize(self, value):\n        zero_one = (value + 1) / 2",
        "detail": "metta.sweep.protein",
        "documentation": {}
    },
    {
        "label": "Log",
        "kind": 6,
        "importPath": "metta.sweep.protein",
        "description": "metta.sweep.protein",
        "peekOfCode": "class Log(Space):\n    base: int = 10\n    def __init__(self, min, max, scale, mean, is_integer=False):\n        if scale == \"time\":\n            scale = 1 / (np.log2(max) - np.log2(min))\n        elif scale == \"auto\":\n            scale = 0.5\n        super().__init__(min, max, scale, mean, is_integer)\n    def normalize(self, value):\n        zero_one = (math.log(value, self.base) - math.log(self.min, self.base)) / (",
        "detail": "metta.sweep.protein",
        "documentation": {}
    },
    {
        "label": "Logit",
        "kind": 6,
        "importPath": "metta.sweep.protein",
        "description": "metta.sweep.protein",
        "peekOfCode": "class Logit(Space):\n    base: int = 10\n    def __init__(self, min, max, scale, mean, is_integer=False):\n        if scale == \"auto\":\n            scale = 0.5\n        super().__init__(min, max, scale, mean, is_integer)\n    def normalize(self, value):\n        zero_one = (math.log(1 - value, self.base) - math.log(1 - self.min, self.base)) / (\n            math.log(1 - self.max, self.base) - math.log(1 - self.min, self.base)\n        )",
        "detail": "metta.sweep.protein",
        "documentation": {}
    },
    {
        "label": "Hyperparameters",
        "kind": 6,
        "importPath": "metta.sweep.protein",
        "description": "metta.sweep.protein",
        "peekOfCode": "class Hyperparameters:\n    def __init__(self, config, verbose=True):\n        self.spaces = _params_from_puffer_sweep(config)\n        self.flat_spaces = dict(pufferlib.unroll_nested_dict(self.spaces))\n        self.num = len(self.flat_spaces)\n        self.metric = config[\"metric\"]\n        goal = config[\"goal\"]\n        assert goal in (\"maximize\", \"minimize\")\n        self.optimize_direction = 1 if goal == \"maximize\" else -1\n        self.search_centers = np.array([e.norm_mean for e in self.flat_spaces.values()])",
        "detail": "metta.sweep.protein",
        "documentation": {}
    },
    {
        "label": "Random",
        "kind": 6,
        "importPath": "metta.sweep.protein",
        "description": "metta.sweep.protein",
        "peekOfCode": "class Random:\n    def __init__(\n        self,\n        sweep_config,\n        global_search_scale=1,\n        random_suggestions=1024,\n    ):\n        self.hyperparameters = Hyperparameters(sweep_config)\n        self.global_search_scale = global_search_scale\n        self.random_suggestions = random_suggestions",
        "detail": "metta.sweep.protein",
        "documentation": {}
    },
    {
        "label": "ParetoGenetic",
        "kind": 6,
        "importPath": "metta.sweep.protein",
        "description": "metta.sweep.protein",
        "peekOfCode": "class ParetoGenetic:\n    def __init__(\n        self,\n        sweep_config,\n        global_search_scale=1,\n        suggestions_per_pareto=1,\n        bias_cost=True,\n        log_bias=False,\n    ):\n        self.hyperparameters = Hyperparameters(sweep_config)",
        "detail": "metta.sweep.protein",
        "documentation": {}
    },
    {
        "label": "Protein",
        "kind": 6,
        "importPath": "metta.sweep.protein",
        "description": "metta.sweep.protein",
        "peekOfCode": "class Protein:\n    def __init__(\n        self,\n        sweep_config,\n        max_suggestion_cost=3600,\n        resample_frequency=0,\n        num_random_samples=50,\n        global_search_scale=1,\n        random_suggestions=1024,\n        suggestions_per_pareto=256,",
        "detail": "metta.sweep.protein",
        "documentation": {}
    },
    {
        "label": "pareto_points",
        "kind": 2,
        "importPath": "metta.sweep.protein",
        "description": "metta.sweep.protein",
        "peekOfCode": "def pareto_points(observations, eps=1e-6):\n    scores = np.array([e[\"output\"] for e in observations])\n    costs = np.array([e[\"cost\"] for e in observations])\n    pareto = []\n    idxs = []\n    for idx, obs in enumerate(observations):\n        try:\n            higher_score = scores + eps > scores[idx]\n        except Exception as e:\n            raise RuntimeError(f\"Failed to compare protein scores: {e}\") from e",
        "detail": "metta.sweep.protein",
        "documentation": {}
    },
    {
        "label": "create_gp",
        "kind": 2,
        "importPath": "metta.sweep.protein",
        "description": "metta.sweep.protein",
        "peekOfCode": "def create_gp(x_dim, scale_length=1.0):\n    X = scale_length * torch.ones((1, x_dim))\n    y = torch.zeros((1,))\n    matern_kernel = gp.kernels.Matern32(input_dim=x_dim, lengthscale=X)\n    linear_kernel = gp.kernels.Polynomial(x_dim, degree=1)\n    kernel = gp.kernels.Sum(linear_kernel, matern_kernel)\n    model = gp.models.GPRegression(X, y, kernel=kernel, jitter=1.0e-4)\n    model.noise = pyro.nn.PyroSample(pyro.distributions.LogNormal(math.log(1e-2), 0.5))\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n    return model, optimizer",
        "detail": "metta.sweep.protein",
        "documentation": {}
    },
    {
        "label": "MettaProtein",
        "kind": 6,
        "importPath": "metta.sweep.protein_metta",
        "description": "metta.sweep.protein_metta",
        "peekOfCode": "class MettaProtein(WandbProtein):\n    def __init__(\n        self,\n        cfg: DictConfig | ListConfig,\n        wandb_run=None,\n    ):\n        parameters_dict = OmegaConf.to_container(cfg.parameters, resolve=True)\n        protein = Protein(\n            parameters_dict,\n            cfg.protein.max_suggestion_cost,",
        "detail": "metta.sweep.protein_metta",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "metta.sweep.protein_metta",
        "description": "metta.sweep.protein_metta",
        "peekOfCode": "logger = logging.getLogger(\"metta_protein\")\nclass MettaProtein(WandbProtein):\n    def __init__(\n        self,\n        cfg: DictConfig | ListConfig,\n        wandb_run=None,\n    ):\n        parameters_dict = OmegaConf.to_container(cfg.parameters, resolve=True)\n        protein = Protein(\n            parameters_dict,",
        "detail": "metta.sweep.protein_metta",
        "documentation": {}
    },
    {
        "label": "WandbProtein",
        "kind": 6,
        "importPath": "metta.sweep.protein_wandb",
        "description": "metta.sweep.protein_wandb",
        "peekOfCode": "class WandbProtein:\n    def __init__(\n        self,\n        protein: Protein,\n        wandb_run: WandbRun | None = None,\n    ):\n        \"\"\"\n        Initialize WandbProtein with a Protein instance and optionally a wandb run.\n        Args:\n            protein (Protein): The Protein instance to use for suggestions.",
        "detail": "metta.sweep.protein_wandb",
        "documentation": {}
    },
    {
        "label": "create_sweep",
        "kind": 2,
        "importPath": "metta.sweep.protein_wandb",
        "description": "metta.sweep.protein_wandb",
        "peekOfCode": "def create_sweep(sweep_name: str, wandb_entity: str, wandb_project: str):\n    \"\"\"\n    Create a new wandb sweep without parameters (Protein will control all suggestions).\n    Args:\n        sweep_name (str): The name of the sweep.\n        wandb_entity (str): The wandb entity (username or team name).\n        wandb_project (str): The wandb project name.\n    Returns:\n        str: The ID of the created sweep.\n    \"\"\"",
        "detail": "metta.sweep.protein_wandb",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "metta.sweep.protein_wandb",
        "description": "metta.sweep.protein_wandb",
        "peekOfCode": "logger = logging.getLogger(\"wandb_protein\")\nclass WandbProtein:\n    def __init__(\n        self,\n        protein: Protein,\n        wandb_run: WandbRun | None = None,\n    ):\n        \"\"\"\n        Initialize WandbProtein with a Protein instance and optionally a wandb run.\n        Args:",
        "detail": "metta.sweep.protein_wandb",
        "documentation": {}
    },
    {
        "label": "bin_dir",
        "kind": 5,
        "importPath": "mettagrid..venv.bin.activate_this",
        "description": "mettagrid..venv.bin.activate_this",
        "peekOfCode": "bin_dir = os.path.dirname(abs_file)\nbase = bin_dir[: -len(\"bin\") - 1]  # strip away the bin part from the __file__, plus the path separator\n# prepend bin to PATH (this file is inside the bin directory)\nos.environ[\"PATH\"] = os.pathsep.join([bin_dir, *os.environ.get(\"PATH\", \"\").split(os.pathsep)])\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\nos.environ[\"VIRTUAL_ENV_PROMPT\"] = \"mettagrid\" or os.path.basename(base)  # noqa: SIM222\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))",
        "detail": "mettagrid..venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "base",
        "kind": 5,
        "importPath": "mettagrid..venv.bin.activate_this",
        "description": "mettagrid..venv.bin.activate_this",
        "peekOfCode": "base = bin_dir[: -len(\"bin\") - 1]  # strip away the bin part from the __file__, plus the path separator\n# prepend bin to PATH (this file is inside the bin directory)\nos.environ[\"PATH\"] = os.pathsep.join([bin_dir, *os.environ.get(\"PATH\", \"\").split(os.pathsep)])\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\nos.environ[\"VIRTUAL_ENV_PROMPT\"] = \"mettagrid\" or os.path.basename(base)  # noqa: SIM222\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path)",
        "detail": "mettagrid..venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "os.environ[\"PATH\"]",
        "kind": 5,
        "importPath": "mettagrid..venv.bin.activate_this",
        "description": "mettagrid..venv.bin.activate_this",
        "peekOfCode": "os.environ[\"PATH\"] = os.pathsep.join([bin_dir, *os.environ.get(\"PATH\", \"\").split(os.pathsep)])\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\nos.environ[\"VIRTUAL_ENV_PROMPT\"] = \"mettagrid\" or os.path.basename(base)  # noqa: SIM222\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix",
        "detail": "mettagrid..venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "os.environ[\"VIRTUAL_ENV\"]",
        "kind": 5,
        "importPath": "mettagrid..venv.bin.activate_this",
        "description": "mettagrid..venv.bin.activate_this",
        "peekOfCode": "os.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\nos.environ[\"VIRTUAL_ENV_PROMPT\"] = \"mettagrid\" or os.path.basename(base)  # noqa: SIM222\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": "mettagrid..venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "os.environ[\"VIRTUAL_ENV_PROMPT\"]",
        "kind": 5,
        "importPath": "mettagrid..venv.bin.activate_this",
        "description": "mettagrid..venv.bin.activate_this",
        "peekOfCode": "os.environ[\"VIRTUAL_ENV_PROMPT\"] = \"mettagrid\" or os.path.basename(base)  # noqa: SIM222\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": "mettagrid..venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "prev_length",
        "kind": 5,
        "importPath": "mettagrid..venv.bin.activate_this",
        "description": "mettagrid..venv.bin.activate_this",
        "peekOfCode": "prev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": "mettagrid..venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "sys.path[:]",
        "kind": 5,
        "importPath": "mettagrid..venv.bin.activate_this",
        "description": "mettagrid..venv.bin.activate_this",
        "peekOfCode": "sys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": "mettagrid..venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "sys.real_prefix",
        "kind": 5,
        "importPath": "mettagrid..venv.bin.activate_this",
        "description": "mettagrid..venv.bin.activate_this",
        "peekOfCode": "sys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": "mettagrid..venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "sys.prefix",
        "kind": 5,
        "importPath": "mettagrid..venv.bin.activate_this",
        "description": "mettagrid..venv.bin.activate_this",
        "peekOfCode": "sys.prefix = base",
        "detail": "mettagrid..venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "mettagrid..venv.bin.jp",
        "description": "mettagrid..venv.bin.jp",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('expression')\n    parser.add_argument('-f', '--filename',\n                        help=('The filename containing the input data.  '\n                              'If a filename is not given then data is '\n                              'read from stdin.'))\n    parser.add_argument('--ast', action='store_true',\n                        help=('Pretty print the AST, do not search the data.'))\n    args = parser.parse_args()",
        "detail": "mettagrid..venv.bin.jp",
        "documentation": {}
    },
    {
        "label": "cfg",
        "kind": 2,
        "importPath": "mettagrid.benchmarks.test_mettagrid_env_benchmark",
        "description": "mettagrid.benchmarks.test_mettagrid_env_benchmark",
        "peekOfCode": "def cfg():\n    \"\"\"Create configuration for the environment.\"\"\"\n    return get_cfg(\"benchmark\")\n@pytest.fixture\ndef environment(cfg, num_agents):\n    \"\"\"Create and initialize the environment with specified number of agents.\"\"\"\n    seed = 42  # Or any fixed seed value\n    random.seed(seed)\n    np.random.seed(seed)\n    # Map from num_agents to expected_hash",
        "detail": "mettagrid.benchmarks.test_mettagrid_env_benchmark",
        "documentation": {}
    },
    {
        "label": "environment",
        "kind": 2,
        "importPath": "mettagrid.benchmarks.test_mettagrid_env_benchmark",
        "description": "mettagrid.benchmarks.test_mettagrid_env_benchmark",
        "peekOfCode": "def environment(cfg, num_agents):\n    \"\"\"Create and initialize the environment with specified number of agents.\"\"\"\n    seed = 42  # Or any fixed seed value\n    random.seed(seed)\n    np.random.seed(seed)\n    # Map from num_agents to expected_hash\n    grid_hash_map = {\n        1: 10198962306018088423,\n        2: 14724462956252883691,\n        4: 17314270363189457391,",
        "detail": "mettagrid.benchmarks.test_mettagrid_env_benchmark",
        "documentation": {}
    },
    {
        "label": "action_generator",
        "kind": 2,
        "importPath": "mettagrid.benchmarks.test_mettagrid_env_benchmark",
        "description": "mettagrid.benchmarks.test_mettagrid_env_benchmark",
        "peekOfCode": "def action_generator(environment):\n    \"\"\"\n    Create a deterministic action generator function.\n    Returns a function that generates different valid actions each call,\n    but the sequence is deterministic across test runs.\n    \"\"\"\n    # Set the global random seed once for deterministic sequences\n    np.random.seed(42)\n    def generate_actions():\n        return generate_valid_random_actions(",
        "detail": "mettagrid.benchmarks.test_mettagrid_env_benchmark",
        "documentation": {}
    },
    {
        "label": "test_step_performance",
        "kind": 2,
        "importPath": "mettagrid.benchmarks.test_mettagrid_env_benchmark",
        "description": "mettagrid.benchmarks.test_mettagrid_env_benchmark",
        "peekOfCode": "def test_step_performance(benchmark, environment, action_generator, num_agents):\n    \"\"\"\n    Benchmark pure step method performance without reset overhead.\n    CRITICAL ASSUMPTION: Episodes last longer than benchmark iterations.\n    This test measures raw step performance by avoiding resets during timing.\n    Uses deterministically random actions.\n    Args:\n        num_agents: Number of agents to test (parametrized: 1, 2, 4, 8, 16)\n    \"\"\"\n    env = environment",
        "detail": "mettagrid.benchmarks.test_mettagrid_env_benchmark",
        "documentation": {}
    },
    {
        "label": "test_create_env_performance",
        "kind": 2,
        "importPath": "mettagrid.benchmarks.test_mettagrid_env_benchmark",
        "description": "mettagrid.benchmarks.test_mettagrid_env_benchmark",
        "peekOfCode": "def test_create_env_performance(benchmark, cfg):\n    \"\"\"\n    Benchmark environment creation.\n    This test measures the time to create a new environment instance\n    and perform a reset operation.\n    \"\"\"\n    def create_and_reset():\n        \"\"\"Create a new environment and reset it.\"\"\"\n        curriculum = SingleTaskCurriculum(\"test\", task_cfg=cfg)\n        env = MettaGridEnv(curriculum, render_mode=\"human\", recursive=False)",
        "detail": "mettagrid.benchmarks.test_mettagrid_env_benchmark",
        "documentation": {}
    },
    {
        "label": "BucketedCurriculum",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.bucketed",
        "description": "mettagrid.src.metta.mettagrid.curriculum.bucketed",
        "peekOfCode": "class BucketedCurriculum(LowRewardCurriculum):\n    def __init__(\n        self,\n        env_cfg_template: str,\n        buckets: Dict[str, Dict[str, Any]],\n        env_overrides: Optional[DictConfig] = None,\n        default_bins: int = 1,\n        moving_avg_decay_rate: float = 0.01,\n    ):\n        expanded_buckets = _expand_buckets(buckets, default_bins)",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.bucketed",
        "documentation": {}
    },
    {
        "label": "get_id",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.bucketed",
        "description": "mettagrid.src.metta.mettagrid.curriculum.bucketed",
        "peekOfCode": "def get_id(parameters, values):\n    curriculum_id = \"\"\n    for k, v in zip(parameters, values, strict=False):\n        if isinstance(v, dict):\n            v = v.get(\"range\", \"values\")\n        if isinstance(v, tuple):\n            v = tuple(round(x, 3) if isinstance(x, float) else x for x in v)\n        elif isinstance(v, float):\n            v = round(v, 3)\n        curriculum_id += f\"{'.'.join(k.split('.')[-3:])}={v};\"",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.bucketed",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.bucketed",
        "description": "mettagrid.src.metta.mettagrid.curriculum.bucketed",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass BucketedCurriculum(LowRewardCurriculum):\n    def __init__(\n        self,\n        env_cfg_template: str,\n        buckets: Dict[str, Dict[str, Any]],\n        env_overrides: Optional[DictConfig] = None,\n        default_bins: int = 1,\n        moving_avg_decay_rate: float = 0.01,\n    ):",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.bucketed",
        "documentation": {}
    },
    {
        "label": "Curriculum",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.core",
        "description": "mettagrid.src.metta.mettagrid.curriculum.core",
        "peekOfCode": "class Curriculum:\n    def get_task(self) -> \"Task\":\n        raise NotImplementedError(\"Subclasses must implement this method\")\n    def complete_task(self, id: str, score: float):\n        # logger.info(f\"Task completed: {id} -> {score:.5f}\")\n        pass\n    def completed_tasks(self) -> List[str]:\n        \"\"\"Return a list of completed task identifiers.\"\"\"\n        return []\n    def get_completion_rates(self):",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "Task",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.core",
        "description": "mettagrid.src.metta.mettagrid.curriculum.core",
        "peekOfCode": "class Task:\n    def __init__(self, id: str, curriculum: \"Curriculum\", env_cfg: Optional[DictConfig] = None):\n        self._id = id\n        self._is_complete = False\n        self._curricula = [(curriculum, id)]\n        self._env_cfg = env_cfg\n        self._name = self._id\n    def complete(self, score: float):\n        assert not self._is_complete, \"Task is already complete\"\n        for curriculum, id in self._curricula:",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "SingleTaskCurriculum",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.core",
        "description": "mettagrid.src.metta.mettagrid.curriculum.core",
        "peekOfCode": "class SingleTaskCurriculum(Curriculum):\n    \"\"\"Curriculum that only contains a single task.\"\"\"\n    def __init__(self, task_id: str, task_cfg: DictConfig):\n        self._task_id = task_id\n        self._task_cfg = task_cfg\n    def get_task(self) -> Task:\n        return Task(self._task_id, self, self._task_cfg)",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.core",
        "description": "mettagrid.src.metta.mettagrid.curriculum.core",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass Curriculum:\n    def get_task(self) -> \"Task\":\n        raise NotImplementedError(\"Subclasses must implement this method\")\n    def complete_task(self, id: str, score: float):\n        # logger.info(f\"Task completed: {id} -> {score:.5f}\")\n        pass\n    def completed_tasks(self) -> List[str]:\n        \"\"\"Return a list of completed task identifiers.\"\"\"\n        return []",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.core",
        "documentation": {}
    },
    {
        "label": "LearningProgressCurriculum",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.learning_progress",
        "description": "mettagrid.src.metta.mettagrid.curriculum.learning_progress",
        "peekOfCode": "class LearningProgressCurriculum(RandomCurriculum):\n    \"\"\"Curriculum that adaptively samples tasks based on learning progress.\"\"\"\n    def __init__(\n        self,\n        tasks: Dict[str, float],\n        env_overrides: DictConfig,\n        ema_timescale: float = 0.001,\n        progress_smoothing: float = 0.05,\n        num_active_tasks: int = 16,\n        rand_task_rate: float = 0.25,",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.learning_progress",
        "documentation": {}
    },
    {
        "label": "BidirectionalLearningProgress",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.learning_progress",
        "description": "mettagrid.src.metta.mettagrid.curriculum.learning_progress",
        "peekOfCode": "class BidirectionalLearningProgress:\n    \"\"\"Tracks bidirectional learning progress using fast and slow exponential moving averages.\"\"\"\n    def __init__(\n        self,\n        search_space: int | Discrete,\n        ema_timescale: float = 0.001,\n        progress_smoothing: float = 0.05,\n        num_active_tasks: int = 16,\n        rand_task_rate: float = 0.25,\n        sample_threshold: int = 10,",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.learning_progress",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.learning_progress",
        "description": "mettagrid.src.metta.mettagrid.curriculum.learning_progress",
        "peekOfCode": "logger = logging.getLogger(__name__)\n# Constants\nDEFAULT_SUCCESS_RATE = 0.0\nDEFAULT_WEIGHT = 1.0\nRANDOM_BASELINE_CAP = 0.75\nclass LearningProgressCurriculum(RandomCurriculum):\n    \"\"\"Curriculum that adaptively samples tasks based on learning progress.\"\"\"\n    def __init__(\n        self,\n        tasks: Dict[str, float],",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.learning_progress",
        "documentation": {}
    },
    {
        "label": "DEFAULT_SUCCESS_RATE",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.learning_progress",
        "description": "mettagrid.src.metta.mettagrid.curriculum.learning_progress",
        "peekOfCode": "DEFAULT_SUCCESS_RATE = 0.0\nDEFAULT_WEIGHT = 1.0\nRANDOM_BASELINE_CAP = 0.75\nclass LearningProgressCurriculum(RandomCurriculum):\n    \"\"\"Curriculum that adaptively samples tasks based on learning progress.\"\"\"\n    def __init__(\n        self,\n        tasks: Dict[str, float],\n        env_overrides: DictConfig,\n        ema_timescale: float = 0.001,",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.learning_progress",
        "documentation": {}
    },
    {
        "label": "DEFAULT_WEIGHT",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.learning_progress",
        "description": "mettagrid.src.metta.mettagrid.curriculum.learning_progress",
        "peekOfCode": "DEFAULT_WEIGHT = 1.0\nRANDOM_BASELINE_CAP = 0.75\nclass LearningProgressCurriculum(RandomCurriculum):\n    \"\"\"Curriculum that adaptively samples tasks based on learning progress.\"\"\"\n    def __init__(\n        self,\n        tasks: Dict[str, float],\n        env_overrides: DictConfig,\n        ema_timescale: float = 0.001,\n        progress_smoothing: float = 0.05,",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.learning_progress",
        "documentation": {}
    },
    {
        "label": "RANDOM_BASELINE_CAP",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.learning_progress",
        "description": "mettagrid.src.metta.mettagrid.curriculum.learning_progress",
        "peekOfCode": "RANDOM_BASELINE_CAP = 0.75\nclass LearningProgressCurriculum(RandomCurriculum):\n    \"\"\"Curriculum that adaptively samples tasks based on learning progress.\"\"\"\n    def __init__(\n        self,\n        tasks: Dict[str, float],\n        env_overrides: DictConfig,\n        ema_timescale: float = 0.001,\n        progress_smoothing: float = 0.05,\n        num_active_tasks: int = 16,",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.learning_progress",
        "documentation": {}
    },
    {
        "label": "LowRewardCurriculum",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.low_reward",
        "description": "mettagrid.src.metta.mettagrid.curriculum.low_reward",
        "peekOfCode": "class LowRewardCurriculum(RandomCurriculum):\n    \"\"\"Curriculum that adaptively samples tasks to focus on low-reward scenarios.\"\"\"\n    def __init__(self, tasks: Dict[str, float], env_overrides: DictConfig, moving_avg_decay_rate: float = 0.01):\n        super().__init__(tasks, env_overrides)\n        self._reward_averages = {task_id: 0.0 for task_id in tasks.keys()}\n        self._reward_maxes = {task_id: 0.0 for task_id in tasks.keys()}\n        self._moving_avg_decay_rate = moving_avg_decay_rate  # Smoothing factor for moving average\n    def complete_task(self, id: str, score: float):\n        # Update moving average for the completed task\n        old_average = self._reward_averages[id]",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.low_reward",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.low_reward",
        "description": "mettagrid.src.metta.mettagrid.curriculum.low_reward",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass LowRewardCurriculum(RandomCurriculum):\n    \"\"\"Curriculum that adaptively samples tasks to focus on low-reward scenarios.\"\"\"\n    def __init__(self, tasks: Dict[str, float], env_overrides: DictConfig, moving_avg_decay_rate: float = 0.01):\n        super().__init__(tasks, env_overrides)\n        self._reward_averages = {task_id: 0.0 for task_id in tasks.keys()}\n        self._reward_maxes = {task_id: 0.0 for task_id in tasks.keys()}\n        self._moving_avg_decay_rate = moving_avg_decay_rate  # Smoothing factor for moving average\n    def complete_task(self, id: str, score: float):\n        # Update moving average for the completed task",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.low_reward",
        "documentation": {}
    },
    {
        "label": "MultiTaskCurriculum",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.multi_task",
        "description": "mettagrid.src.metta.mettagrid.curriculum.multi_task",
        "peekOfCode": "class MultiTaskCurriculum(Curriculum):\n    \"\"\"Base class for curricula with multiple tasks.\"\"\"\n    def __init__(self, curricula: Dict[str, Curriculum], completion_moving_avg_window: int = 500):\n        self._curricula = curricula\n        num_agents = None\n        for task_id, curriculum in self._curricula.items():\n            cfg_num_agents = curriculum.get_task().env_cfg().game.num_agents\n            if num_agents is None:\n                num_agents = cfg_num_agents\n            else:",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.multi_task",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.multi_task",
        "description": "mettagrid.src.metta.mettagrid.curriculum.multi_task",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass MultiTaskCurriculum(Curriculum):\n    \"\"\"Base class for curricula with multiple tasks.\"\"\"\n    def __init__(self, curricula: Dict[str, Curriculum], completion_moving_avg_window: int = 500):\n        self._curricula = curricula\n        num_agents = None\n        for task_id, curriculum in self._curricula.items():\n            cfg_num_agents = curriculum.get_task().env_cfg().game.num_agents\n            if num_agents is None:\n                num_agents = cfg_num_agents",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.multi_task",
        "documentation": {}
    },
    {
        "label": "ProgressiveCurriculum",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.progressive",
        "description": "mettagrid.src.metta.mettagrid.curriculum.progressive",
        "peekOfCode": "class ProgressiveCurriculum(SamplingCurriculum):\n    def __init__(self, env_cfg_template: str, env_overrides: Optional[DictConfig] = None):\n        super().__init__(env_cfg_template, env_overrides)\n        self._width = 10\n        self._height = 10\n    def get_task(self) -> Task:\n        cfg = OmegaConf.create(copy.deepcopy(self._cfg_template))\n        cfg.game.map.width = self._width\n        cfg.game.map.height = self._height\n        OmegaConf.resolve(cfg)",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.progressive",
        "documentation": {}
    },
    {
        "label": "ProgressiveMultiTaskCurriculum",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.progressive",
        "description": "mettagrid.src.metta.mettagrid.curriculum.progressive",
        "peekOfCode": "class ProgressiveMultiTaskCurriculum(RandomCurriculum):\n    \"\"\"Curriculum that blends multiple tasks using gating mechanisms and advances progression based on\n    smoothed performance or time.\"\"\"\n    def __init__(\n        self,\n        tasks: Dict[str, float],\n        env_overrides: Optional[DictConfig] = None,\n        performance_threshold: float = 0.8,\n        smoothing: float = 0.1,\n        progression_rate: float = 0.01,",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.progressive",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.progressive",
        "description": "mettagrid.src.metta.mettagrid.curriculum.progressive",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass ProgressiveCurriculum(SamplingCurriculum):\n    def __init__(self, env_cfg_template: str, env_overrides: Optional[DictConfig] = None):\n        super().__init__(env_cfg_template, env_overrides)\n        self._width = 10\n        self._height = 10\n    def get_task(self) -> Task:\n        cfg = OmegaConf.create(copy.deepcopy(self._cfg_template))\n        cfg.game.map.width = self._width\n        cfg.game.map.height = self._height",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.progressive",
        "documentation": {}
    },
    {
        "label": "RandomCurriculum",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.random",
        "description": "mettagrid.src.metta.mettagrid.curriculum.random",
        "peekOfCode": "class RandomCurriculum(MultiTaskCurriculum):\n    \"\"\"Curriculum that samples from multiple environment types with fixed weights.\"\"\"\n    def __init__(self, curricula_cfgs: Dict[str, float], env_overrides: DictConfig):\n        self.env_overrides = env_overrides\n        curricula = {t: self._curriculum_from_id(t) for t in curricula_cfgs.keys()}\n        self._task_weights = curricula_cfgs\n        super().__init__(curricula)\n    def get_task(self) -> Task:\n        task_id = random.choices(list(self._curricula.keys()), weights=list(self._task_weights.values()))[0]\n        task = self._curricula[task_id].get_task()",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.random",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.random",
        "description": "mettagrid.src.metta.mettagrid.curriculum.random",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass RandomCurriculum(MultiTaskCurriculum):\n    \"\"\"Curriculum that samples from multiple environment types with fixed weights.\"\"\"\n    def __init__(self, curricula_cfgs: Dict[str, float], env_overrides: DictConfig):\n        self.env_overrides = env_overrides\n        curricula = {t: self._curriculum_from_id(t) for t in curricula_cfgs.keys()}\n        self._task_weights = curricula_cfgs\n        super().__init__(curricula)\n    def get_task(self) -> Task:\n        task_id = random.choices(list(self._curricula.keys()), weights=list(self._task_weights.values()))[0]",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.random",
        "documentation": {}
    },
    {
        "label": "SamplingCurriculum",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.sampling",
        "description": "mettagrid.src.metta.mettagrid.curriculum.sampling",
        "peekOfCode": "class SamplingCurriculum(Curriculum):\n    def __init__(self, env_cfg_template: str, env_overrides: Optional[DictConfig] = None):\n        self._cfg_template = config_from_path(env_cfg_template, env_overrides)\n    def get_task(self) -> Task:\n        cfg = OmegaConf.create(copy.deepcopy(self._cfg_template))\n        OmegaConf.resolve(cfg)\n        return Task(f\"sample({self._cfg_template.sampling})\", self, cfg)\n    def get_task_probs(self) -> dict[str, float]:\n        \"\"\"Return the current task probability for logging purposes.\"\"\"\n        task_name = f\"sample({self._cfg_template.sampling})\"",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.sampling",
        "documentation": {}
    },
    {
        "label": "SampledTaskCurriculum",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.sampling",
        "description": "mettagrid.src.metta.mettagrid.curriculum.sampling",
        "peekOfCode": "class SampledTaskCurriculum(Curriculum):\n    \"\"\"Curriculum that contains a single task, but the task is sampled from a distribution.\"\"\"\n    def __init__(\n        self,\n        task_id: str,\n        task_cfg_template: str,\n        bucket_parameters: Dict[str, Dict[str, Any]],\n        bucket_values: List[Any],\n    ):\n        self._task_id = task_id",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.sampling",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.sampling",
        "description": "mettagrid.src.metta.mettagrid.curriculum.sampling",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass SamplingCurriculum(Curriculum):\n    def __init__(self, env_cfg_template: str, env_overrides: Optional[DictConfig] = None):\n        self._cfg_template = config_from_path(env_cfg_template, env_overrides)\n    def get_task(self) -> Task:\n        cfg = OmegaConf.create(copy.deepcopy(self._cfg_template))\n        OmegaConf.resolve(cfg)\n        return Task(f\"sample({self._cfg_template.sampling})\", self, cfg)\n    def get_task_probs(self) -> dict[str, float]:\n        \"\"\"Return the current task probability for logging purposes.\"\"\"",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.sampling",
        "documentation": {}
    },
    {
        "label": "curriculum_from_config_path",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.curriculum.util",
        "description": "mettagrid.src.metta.mettagrid.curriculum.util",
        "peekOfCode": "def curriculum_from_config_path(config_path: str, env_overrides: DictConfig) -> \"Curriculum\":\n    if \"_target_\" in config_from_path(config_path, None):\n        return hydra.utils.instantiate(\n            config_from_path(config_path, OmegaConf.create({\"env_overrides\": env_overrides}))\n        )\n    else:\n        # If this is an environment rather than a curriculum, we need to wrap it in a curriculum\n        # but we have to sample it first.\n        task = SamplingCurriculum(config_path, env_overrides).get_task()\n        return SingleTaskCurriculum(task.id(), task.env_cfg())",
        "detail": "mettagrid.src.metta.mettagrid.curriculum.util",
        "documentation": {}
    },
    {
        "label": "MiniscopeRenderer",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.renderer.miniscope",
        "description": "mettagrid.src.metta.mettagrid.renderer.miniscope",
        "peekOfCode": "class MiniscopeRenderer:\n    \"\"\"Emoji-based renderer for MettaGridEnv with full-width emoji support.\"\"\"\n    # Using emoji that are consistently rendered as double-width characters\n    # These are selected to ensure visual clarity and consistent alignment\n    MINISCOPE_SYMBOLS = {\n        # Basic terrain\n        \"wall\": \"\",  # Wall/barrier (#)\n        \"empty\": \"\",  # Empty space (white square for visibility)\n        # Agents\n        \"agent\": \"\",  # Default agent",
        "detail": "mettagrid.src.metta.mettagrid.renderer.miniscope",
        "documentation": {}
    },
    {
        "label": "NethackRenderer",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.renderer.nethack",
        "description": "mettagrid.src.metta.mettagrid.renderer.nethack",
        "peekOfCode": "class NethackRenderer:\n    \"\"\"Simple NetHack-style renderer for ``MettaGridEnv`` with perfect alignment.\"\"\"\n    def __init__(self, object_type_names: list[str]):\n        self._object_type_names = object_type_names\n        self._bounds_set = False\n        self._min_row = 0\n        self._min_col = 0\n        self._height = 0\n        self._width = 0\n        self._last_buffer = None",
        "detail": "mettagrid.src.metta.mettagrid.renderer.nethack",
        "documentation": {}
    },
    {
        "label": "BarrierMaze",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.cognitive_evals.barriermaze",
        "description": "mettagrid.src.metta.mettagrid.room.cognitive_evals.barriermaze",
        "peekOfCode": "class BarrierMaze(Room):\n    \"\"\"\n    Maze with an outer wall and three barriers separating seven blocks:\n      1. Agent start (\"agent.agent\")\n      2. Barrier 1\n      3. mine (\"mine\")\n      4. Barrier 2\n      5. generator (\"generator\")\n      6. Barrier 3\n      7. Altar (\"altar\")",
        "detail": "mettagrid.src.metta.mettagrid.room.cognitive_evals.barriermaze",
        "documentation": {}
    },
    {
        "label": "CorridorMaze",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.cognitive_evals.corridor_maze",
        "description": "mettagrid.src.metta.mettagrid.room.cognitive_evals.corridor_maze",
        "peekOfCode": "class CorridorMaze(Room):\n    def __init__(\n        self,\n        width: int,\n        height: int,\n        border_width: int = 1,\n        corridor_width: int = 2,\n        arm_length: int = 10,\n        num_mines: int = 0,\n        num_convertors: int = 0,",
        "detail": "mettagrid.src.metta.mettagrid.room.cognitive_evals.corridor_maze",
        "documentation": {}
    },
    {
        "label": "ExploreExploit",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.cognitive_evals.explore_exploit",
        "description": "mettagrid.src.metta.mettagrid.room.cognitive_evals.explore_exploit",
        "peekOfCode": "class ExploreExploit(Room):\n    \"\"\"\n    Maze with two regions:\n      - Left (sparse): rewards are spread out and the agent is placed here.\n      - Right (dense): rewards are clustered.\n    A vertical wall with random gaps divides the grid.\n    \"\"\"\n    def __init__(\n        self,\n        width: int,",
        "detail": "mettagrid.src.metta.mettagrid.room.cognitive_evals.explore_exploit",
        "documentation": {}
    },
    {
        "label": "LabyrinthMaze",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.cognitive_evals.labyrinth",
        "description": "mettagrid.src.metta.mettagrid.room.cognitive_evals.labyrinth",
        "peekOfCode": "class LabyrinthMaze(Room):\n    \"\"\"\n    Generates a labyrinth using recursive backtracking. Maze passages are corridor_widthcorridor_width blocks\n    separated by 1-cell walls. The grid dimensions are computed to exactly fit the maze cells.\n    Rewards (mine, altar, generator) are placed near the center and the agent at the entrance.\n    \"\"\"\n    def __init__(\n        self,\n        width: int,\n        height: int,",
        "detail": "mettagrid.src.metta.mettagrid.room.cognitive_evals.labyrinth",
        "documentation": {}
    },
    {
        "label": "RadialMaze",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.cognitive_evals.radial_maze",
        "description": "mettagrid.src.metta.mettagrid.room.cognitive_evals.radial_maze",
        "peekOfCode": "class RadialMaze(Room):\n    \"\"\"A radial maze with a central starting position.\"\"\"\n    def __init__(\n        self,\n        width: int,\n        height: int,\n        radial_params: DictConfig,\n        seed: Union[int, None] = None,\n        border_width: int = 1,\n        border_object: str = \"wall\",",
        "detail": "mettagrid.src.metta.mettagrid.room.cognitive_evals.radial_maze",
        "documentation": {}
    },
    {
        "label": "RoomWithinRoom",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.cognitive_evals.room_within_room",
        "description": "mettagrid.src.metta.mettagrid.room.cognitive_evals.room_within_room",
        "peekOfCode": "class RoomWithinRoom(Room):\n    \"\"\"\n    Outer room with walls and a centered inner room (with a door gap in its top wall).\n    Specific objects are placed at the inner room corners and in the outer room's top-left.\n    \"\"\"\n    def __init__(\n        self,\n        width: int,\n        height: int,\n        inner_size_min: int,",
        "detail": "mettagrid.src.metta.mettagrid.room.cognitive_evals.room_within_room",
        "documentation": {}
    },
    {
        "label": "CentralTableLayout",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.cooperation.central_table_layout",
        "description": "mettagrid.src.metta.mettagrid.room.cooperation.central_table_layout",
        "peekOfCode": "class CentralTableLayout(Room):\n    STYLE_PARAMETERS = {\n        \"default\": {\n            \"lane_width\": 1,\n            \"num_mines\": 4,\n            \"num_generators\": 2,\n            \"num_altars\": 2,\n        },\n    }\n    def __init__(",
        "detail": "mettagrid.src.metta.mettagrid.room.cooperation.central_table_layout",
        "documentation": {}
    },
    {
        "label": "ConfinedRoomCoord",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.cooperation.confined_room_coord",
        "description": "mettagrid.src.metta.mettagrid.room.cooperation.confined_room_coord",
        "peekOfCode": "class ConfinedRoomCoord(Room):\n    def __init__(\n        self,\n        width: int,\n        height: int,\n        num_mines: int = 1,\n        num_generators: int = 1,\n        num_altars: int = 1,\n        agents: Union[int, DictConfig] = 1,\n        # Pure wall padding around the room (floor + object border)",
        "detail": "mettagrid.src.metta.mettagrid.room.cooperation.confined_room_coord",
        "documentation": {}
    },
    {
        "label": "TwoRoomsCoord",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.cooperation.two_rooms_coord",
        "description": "mettagrid.src.metta.mettagrid.room.cooperation.two_rooms_coord",
        "peekOfCode": "class TwoRoomsCoord(Room):\n    def __init__(\n        self,\n        # (width, height) of empty floor space for EACH room\n        width: int,\n        height: int,\n        num_shared_generators: int,\n        num_altars: int,\n        num_mines: int,\n        agents: Union[int, DictConfig] = 2,",
        "detail": "mettagrid.src.metta.mettagrid.room.cooperation.two_rooms_coord",
        "documentation": {}
    },
    {
        "label": "BoxShare",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.multi_agent.boxshare",
        "description": "mettagrid.src.metta.mettagrid.room.multi_agent.boxshare",
        "peekOfCode": "class BoxShare(Room):\n    def __init__(\n        self,\n        width: int,\n        height: int,\n        objects: DictConfig | None = None,\n        agents: int = 14,\n        seed: Optional[int] = None,\n        border_width: int = 0,\n        border_object: str = \"wall\",",
        "detail": "mettagrid.src.metta.mettagrid.room.multi_agent.boxshare",
        "documentation": {}
    },
    {
        "label": "Boxy",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.multi_agent.boxy",
        "description": "mettagrid.src.metta.mettagrid.room.multi_agent.boxy",
        "peekOfCode": "class Boxy(Room):\n    \"\"\"Multi-agent environment with altar boxes and outer resources.\"\"\"\n    def __init__(\n        self,\n        width: int,\n        height: int,\n        objects: DictConfig | None = None,\n        agents: int = 20,\n        seed: Optional[int] = None,\n        border_width: int = 0,",
        "detail": "mettagrid.src.metta.mettagrid.room.multi_agent.boxy",
        "documentation": {}
    },
    {
        "label": "Manhatten",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.multi_agent.manhatten",
        "description": "mettagrid.src.metta.mettagrid.room.multi_agent.manhatten",
        "peekOfCode": "class Manhatten(Room):\n    \"\"\"Grid-like interlocking corridor environment (Manhatten style).\"\"\"\n    DIRS: list[Tuple[int, int]] = [(-1, 0), (0, 1), (1, 0), (0, -1)]  # N,E,S,W\n    def __init__(\n        self,\n        width: int,\n        height: int,\n        objects: DictConfig,\n        agents: int = 16,\n        seed: Optional[int] = None,",
        "detail": "mettagrid.src.metta.mettagrid.room.multi_agent.manhatten",
        "documentation": {}
    },
    {
        "label": "SnakeyCylinder",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.room.multi_agent.manhatten",
        "description": "mettagrid.src.metta.mettagrid.room.multi_agent.manhatten",
        "peekOfCode": "SnakeyCylinder = Manhatten\nSnakeyCylinderRoom = Manhatten",
        "detail": "mettagrid.src.metta.mettagrid.room.multi_agent.manhatten",
        "documentation": {}
    },
    {
        "label": "SnakeyCylinderRoom",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.room.multi_agent.manhatten",
        "description": "mettagrid.src.metta.mettagrid.room.multi_agent.manhatten",
        "peekOfCode": "SnakeyCylinderRoom = Manhatten",
        "detail": "mettagrid.src.metta.mettagrid.room.multi_agent.manhatten",
        "documentation": {}
    },
    {
        "label": "NarrowWorld",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.multi_agent.narrow_world",
        "description": "mettagrid.src.metta.mettagrid.room.multi_agent.narrow_world",
        "peekOfCode": "class NarrowWorld(Room):\n    def __init__(\n        self,\n        width: int,\n        height: int,\n        objects: DictConfig,\n        agents: int = 15,\n        seed: Optional[int] = None,\n        border_width: int = 0,\n        border_object: str = \"wall\",",
        "detail": "mettagrid.src.metta.mettagrid.room.multi_agent.narrow_world",
        "documentation": {}
    },
    {
        "label": "CylinderWorld",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.navigation.cylinder_world",
        "description": "mettagrid.src.metta.mettagrid.room.navigation.cylinder_world",
        "peekOfCode": "class CylinderWorld(Room):\n    def __init__(\n        self,\n        width: int,\n        height: int,\n        agents: int | dict = 0,\n        seed: Optional[int] = 42,\n        border_width: int = 0,\n        border_object: str = \"wall\",\n        team: str | None = None,",
        "detail": "mettagrid.src.metta.mettagrid.room.navigation.cylinder_world",
        "documentation": {}
    },
    {
        "label": "VariedTerrain",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.navigation.varied_terrain",
        "description": "mettagrid.src.metta.mettagrid.room.navigation.varied_terrain",
        "peekOfCode": "class VariedTerrain(Room):\n    # Base style parameters for a 60x60 (area=3600) grid.\n    # These counts are intentionally moderate.\n    STYLE_PARAMETERS = {\n        \"all-sparse\": {\n            \"large_obstacles\": {\"size_range\": [10, 25], \"count\": [0, 2]},\n            \"small_obstacles\": {\"size_range\": [3, 6], \"count\": [0, 2]},\n            \"crosses\": {\"count\": [0, 2]},\n            \"labyrinths\": {\"count\": [0, 2]},\n            \"scattered_walls\": {\"count\": [0, 2]},",
        "detail": "mettagrid.src.metta.mettagrid.room.navigation.varied_terrain",
        "documentation": {}
    },
    {
        "label": "Ascii",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.ascii",
        "description": "mettagrid.src.metta.mettagrid.room.ascii",
        "peekOfCode": "class Ascii(Room):\n    def __init__(self, uri: str, border_width: int = 0, border_object: str = \"wall\"):\n        super().__init__(border_width=border_width, border_object=border_object)\n        with open(uri, \"r\", encoding=\"utf-8\") as f:\n            ascii_map = f.read()\n        lines = ascii_map.strip().splitlines()\n        self._level = np.array([list(line) for line in lines], dtype=\"U6\")\n        self._level = np.vectorize(char_to_grid_object)(self._level)\n        self.set_size_labels(self._level.shape[1], self._level.shape[0])\n    def _build(self):",
        "detail": "mettagrid.src.metta.mettagrid.room.ascii",
        "documentation": {}
    },
    {
        "label": "MazePrim",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.maze",
        "description": "mettagrid.src.metta.mettagrid.room.maze",
        "peekOfCode": "class MazePrim(Room):\n    EMPTY, WALL = \"empty\", \"wall\"\n    START, END = \"agent.agent\", \"altar\"\n    DIRECTIONS = [(2, 0), (-2, 0), (0, 2), (0, -2)]\n    def __init__(\n        self, width, height, start_pos, end_pos, branching=0.0, seed=None, border_width=0, border_object=\"wall\"\n    ):\n        super().__init__(border_width=border_width, border_object=border_object, labels=[\"maze\"])\n        self._rng = random.Random(seed)\n        self._width = width if width % 2 == 1 else width - 1",
        "detail": "mettagrid.src.metta.mettagrid.room.maze",
        "documentation": {}
    },
    {
        "label": "MazeKruskal",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.maze",
        "description": "mettagrid.src.metta.mettagrid.room.maze",
        "peekOfCode": "class MazeKruskal(Room):\n    EMPTY, WALL = \"empty\", \"wall\"\n    START, END = \"agent.agent\", \"altar\"\n    def __init__(\n        self, width, height, start_pos, end_pos, branching=0.0, seed=None, border_width=0, border_object=\"wall\"\n    ):\n        super().__init__(border_width=border_width, border_object=border_object)\n        self._rng = random.Random(seed)\n        self._width = width if width % 2 == 1 else width - 1\n        self._height = height if height % 2 == 1 else height - 1",
        "detail": "mettagrid.src.metta.mettagrid.room.maze",
        "documentation": {}
    },
    {
        "label": "MeanDistance",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.mean_distance",
        "description": "mettagrid.src.metta.mettagrid.room.mean_distance",
        "peekOfCode": "class MeanDistance(Room):\n    def __init__(\n        self,\n        width: int,\n        height: int,\n        objects: DictConfig,\n        agents: int | DictConfig = 1,\n        mean_distance: float = 5.0,  # Mean distance parameter for objects relative to agent.\n        seed: Optional[int] = None,\n        border_width: int = 0,",
        "detail": "mettagrid.src.metta.mettagrid.room.mean_distance",
        "documentation": {}
    },
    {
        "label": "MultiRoom",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.multi_room",
        "description": "mettagrid.src.metta.mettagrid.room.multi_room",
        "peekOfCode": "class MultiRoom(RoomList):\n    def __init__(\n        self, room: Room, num_rooms: int, layout: str = \"grid\", border_width: int = 0, border_object: str = \"wall\"\n    ):\n        room_cfgs = [room] * num_rooms\n        super().__init__(room_cfgs, layout=layout, border_width=border_width, border_object=border_object)",
        "detail": "mettagrid.src.metta.mettagrid.room.multi_room",
        "documentation": {}
    },
    {
        "label": "Random",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.random",
        "description": "mettagrid.src.metta.mettagrid.room.random",
        "peekOfCode": "class Random(Room):\n    def __init__(\n        self,\n        width: int,\n        height: int,\n        objects: DictConfig,\n        agents: int | DictConfig = 0,\n        seed: Optional[int] = None,\n        border_width: int = 0,\n        border_object: str = \"wall\",",
        "detail": "mettagrid.src.metta.mettagrid.room.random",
        "documentation": {}
    },
    {
        "label": "Room",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.room",
        "description": "mettagrid.src.metta.mettagrid.room.room",
        "peekOfCode": "class Room(LevelBuilder):\n    def __init__(self, border_width: int = 0, border_object: str = \"wall\", labels: Optional[list] = None):\n        self._border_width = border_width\n        self._border_object = border_object\n        self.labels = labels or []\n    def set_size_labels(self, width: int, height: int):\n        area = width * height\n        if area < 4000:\n            self.labels.append(\"small\")\n        elif area < 6000:",
        "detail": "mettagrid.src.metta.mettagrid.room.room",
        "documentation": {}
    },
    {
        "label": "RoomList",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.room_list",
        "description": "mettagrid.src.metta.mettagrid.room.room_list",
        "peekOfCode": "class RoomList(Room):\n    def __init__(self, rooms: List[Room], layout: str = \"grid\", border_width: int = 0, border_object: str = \"wall\"):\n        super().__init__(border_width=border_width, border_object=border_object)\n        self._room_configs = rooms\n        self._layout = layout\n        assert self._layout in [\"grid\", \"column\", \"row\"], (\n            f\"Invalid layout: {self._layout}. Must be 'grid', 'column', or 'row'\"\n        )\n    def _build(self):\n        rooms = []",
        "detail": "mettagrid.src.metta.mettagrid.room.room_list",
        "documentation": {}
    },
    {
        "label": "RoomScene",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.room_scene",
        "description": "mettagrid.src.metta.mettagrid.room.room_scene",
        "peekOfCode": "class RoomScene(RoomList):\n    def __init__(\n        self,\n        rooms: Dict[str, Room],\n        layout: ListConfig,\n        border_width: int = 0,\n        border_object: str = \"wall\",\n        stack_layout: str = \"row\",\n    ):\n        next_stack_layout = \"row\"",
        "detail": "mettagrid.src.metta.mettagrid.room.room_scene",
        "documentation": {}
    },
    {
        "label": "TerrainFromNumpy",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.room.terrain_from_numpy",
        "description": "mettagrid.src.metta.mettagrid.room.terrain_from_numpy",
        "peekOfCode": "class TerrainFromNumpy(Room):\n    \"\"\"\n    This class is used to load a terrain environment from numpy arrays on s3\n    These maps each have 10 agents in them .\n    \"\"\"\n    def __init__(\n        self,\n        objects: DictConfig,\n        agents: int | DictConfig = 10,\n        dir: str = \"terrain_maps_nohearts\",",
        "detail": "mettagrid.src.metta.mettagrid.room.terrain_from_numpy",
        "documentation": {}
    },
    {
        "label": "safe_load",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.room.terrain_from_numpy",
        "description": "mettagrid.src.metta.mettagrid.room.terrain_from_numpy",
        "peekOfCode": "def safe_load(path, retries=5, delay=1.0):\n    for attempt in range(retries):\n        try:\n            return np.load(path, allow_pickle=True)\n        except ValueError:\n            if attempt < retries - 1:\n                time.sleep(delay)\n                continue\n            raise\ndef pick_random_file(path):",
        "detail": "mettagrid.src.metta.mettagrid.room.terrain_from_numpy",
        "documentation": {}
    },
    {
        "label": "pick_random_file",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.room.terrain_from_numpy",
        "description": "mettagrid.src.metta.mettagrid.room.terrain_from_numpy",
        "peekOfCode": "def pick_random_file(path):\n    chosen = None\n    count = 0\n    with os.scandir(path) as it:\n        for entry in it:\n            count += 1\n            # with probability 1/count, pick this entry\n            if random.randrange(count) == 0:\n                chosen = entry.name\n    return chosen",
        "detail": "mettagrid.src.metta.mettagrid.room.terrain_from_numpy",
        "documentation": {}
    },
    {
        "label": "download_from_s3",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.room.terrain_from_numpy",
        "description": "mettagrid.src.metta.mettagrid.room.terrain_from_numpy",
        "peekOfCode": "def download_from_s3(s3_path: str, save_path: str, location: str = \"us-east-1\"):\n    if not s3_path.startswith(\"s3://\"):\n        raise ValueError(f\"Invalid S3 path: {s3_path}. Must start with s3://\")\n    s3_parts = s3_path[5:].split(\"/\", 1)\n    if len(s3_parts) < 2:\n        raise ValueError(f\"Invalid S3 path: {s3_path}. Must be in format s3://bucket/path\")\n    bucket = s3_parts[0]\n    key = s3_parts[1]\n    try:\n        # Create directory if it doesn't exist",
        "detail": "mettagrid.src.metta.mettagrid.room.terrain_from_numpy",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.room.terrain_from_numpy",
        "description": "mettagrid.src.metta.mettagrid.room.terrain_from_numpy",
        "peekOfCode": "logger = logging.getLogger(\"terrain_from_numpy\")\ndef safe_load(path, retries=5, delay=1.0):\n    for attempt in range(retries):\n        try:\n            return np.load(path, allow_pickle=True)\n        except ValueError:\n            if attempt < retries - 1:\n                time.sleep(delay)\n                continue\n            raise",
        "detail": "mettagrid.src.metta.mettagrid.room.terrain_from_numpy",
        "documentation": {}
    },
    {
        "label": "create_grid",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.room.utils",
        "description": "mettagrid.src.metta.mettagrid.room.utils",
        "peekOfCode": "def create_grid(height: int, width: int, fill_value: str = \"empty\", dtype: str = \"<U50\") -> np.ndarray:\n    \"\"\"\n    Creates a NumPy grid with the given height and width, pre-filled with the specified fill_value.\n    \"\"\"\n    return np.full((height, width), fill_value, dtype=dtype)\ndef draw_border(grid: np.ndarray, border_width: int, border_object: str) -> None:\n    \"\"\"\n    Draws a border on the given grid in-place. The border (of thickness border_width) is set to border_object.\n    \"\"\"\n    grid[:border_width, :] = border_object",
        "detail": "mettagrid.src.metta.mettagrid.room.utils",
        "documentation": {}
    },
    {
        "label": "draw_border",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.room.utils",
        "description": "mettagrid.src.metta.mettagrid.room.utils",
        "peekOfCode": "def draw_border(grid: np.ndarray, border_width: int, border_object: str) -> None:\n    \"\"\"\n    Draws a border on the given grid in-place. The border (of thickness border_width) is set to border_object.\n    \"\"\"\n    grid[:border_width, :] = border_object\n    grid[-border_width:, :] = border_object\n    grid[:, :border_width] = border_object\n    grid[:, -border_width:] = border_object\ndef bresenham_line(x0: int, y0: int, x1: int, y1: int) -> List[Tuple[int, int]]:\n    \"\"\"",
        "detail": "mettagrid.src.metta.mettagrid.room.utils",
        "documentation": {}
    },
    {
        "label": "bresenham_line",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.room.utils",
        "description": "mettagrid.src.metta.mettagrid.room.utils",
        "peekOfCode": "def bresenham_line(x0: int, y0: int, x1: int, y1: int) -> List[Tuple[int, int]]:\n    \"\"\"\n    Generate points on a line from (x0, y0) to (x1, y1) using Bresenham's algorithm.\n    Returns a list of (x, y) tuples along the line.\n    \"\"\"\n    points = []\n    dx = abs(x1 - x0)\n    dy = abs(y1 - y0)\n    sx = 1 if x0 < x1 else -1\n    sy = 1 if y0 < y1 else -1",
        "detail": "mettagrid.src.metta.mettagrid.room.utils",
        "documentation": {}
    },
    {
        "label": "compute_positions",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.room.utils",
        "description": "mettagrid.src.metta.mettagrid.room.utils",
        "peekOfCode": "def compute_positions(start: int, end: int, blocks: List[Tuple[str, int]]) -> Dict[str, int]:\n    \"\"\"\n    Given a starting and ending coordinate along an axis and a list of blocks (name, width),\n    compute and return a dictionary mapping each block name to its starting coordinate.\n    This is useful for laying out consecutive blocks with evenly distributed gaps.\n    \"\"\"\n    total_blocks = sum(width for _, width in blocks)\n    total_gap = (end - start) - total_blocks\n    num_gaps = len(blocks) - 1\n    base_gap = total_gap // num_gaps if num_gaps > 0 else 0",
        "detail": "mettagrid.src.metta.mettagrid.room.utils",
        "documentation": {}
    },
    {
        "label": "sample_position",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.room.utils",
        "description": "mettagrid.src.metta.mettagrid.room.utils",
        "peekOfCode": "def sample_position(\n    x_min: int,\n    x_max: int,\n    y_min: int,\n    y_max: int,\n    min_distance: int,\n    existing: List[Tuple[int, int]],\n    forbidden: Optional[Set[Tuple[int, int]]] = None,\n    rng: Optional[np.random.Generator] = None,\n    attempts: int = 100,",
        "detail": "mettagrid.src.metta.mettagrid.room.utils",
        "documentation": {}
    },
    {
        "label": "make_odd",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.room.utils",
        "description": "mettagrid.src.metta.mettagrid.room.utils",
        "peekOfCode": "def make_odd(x):\n    return x if x % 2 == 1 else x + 1\ndef set_position(x, upper_bound):\n    x = make_odd(x)\n    if x < 0:\n        return 1\n    if x >= upper_bound:\n        return upper_bound - 1 if x % 2 == 0 else upper_bound - 2\n    return x",
        "detail": "mettagrid.src.metta.mettagrid.room.utils",
        "documentation": {}
    },
    {
        "label": "set_position",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.room.utils",
        "description": "mettagrid.src.metta.mettagrid.room.utils",
        "peekOfCode": "def set_position(x, upper_bound):\n    x = make_odd(x)\n    if x < 0:\n        return 1\n    if x >= upper_bound:\n        return upper_bound - 1 if x % 2 == 0 else upper_bound - 2\n    return x",
        "detail": "mettagrid.src.metta.mettagrid.room.utils",
        "documentation": {}
    },
    {
        "label": "Orientation",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.util.actions",
        "description": "mettagrid.src.metta.mettagrid.util.actions",
        "peekOfCode": "class Orientation(Enum):\n    UP = 0\n    DOWN = 1\n    LEFT = 2\n    RIGHT = 3\n    def __new__(cls, value):\n        \"\"\"Create new Orientation instance.\"\"\"\n        if isinstance(value, str):\n            # Handle string initialization like Orientation(\"up\")\n            value = value.upper()",
        "detail": "mettagrid.src.metta.mettagrid.util.actions",
        "documentation": {}
    },
    {
        "label": "generate_valid_random_actions",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.actions",
        "description": "mettagrid.src.metta.mettagrid.util.actions",
        "peekOfCode": "def generate_valid_random_actions(\n    env: MettaGridEnv,\n    num_agents: int,\n    force_action_type: Optional[int] = None,\n    force_action_arg: Optional[int] = None,\n    seed: Optional[int] = None,\n) -> np.ndarray:\n    \"\"\"\n    Generate valid actions for all agents, respecting maximum argument values.\n    Args:",
        "detail": "mettagrid.src.metta.mettagrid.util.actions",
        "documentation": {}
    },
    {
        "label": "move",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.actions",
        "description": "mettagrid.src.metta.mettagrid.util.actions",
        "peekOfCode": "def move(env: MettaGrid, orientation: Orientation, agent_idx: int = 0) -> Dict[str, Any]:\n    \"\"\"\n    Move agent in specified direction with full validation.\n    Args:\n        env: MettaGrid environment\n        orientation: Orientation enum, string (\"up\", \"down\", \"left\", \"right\"), or int (0=Up, 1=Down, 2=Left, 3=Right)\n        agent_idx: Agent index (default 0)\n    Returns:\n        Dict with movement results and validation\n    \"\"\"",
        "detail": "mettagrid.src.metta.mettagrid.util.actions",
        "documentation": {}
    },
    {
        "label": "rotate",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.actions",
        "description": "mettagrid.src.metta.mettagrid.util.actions",
        "peekOfCode": "def rotate(env: MettaGrid, orientation: Orientation, agent_idx: int = 0) -> Dict[str, Any]:\n    \"\"\"\n    Rotate agent to face specified direction.\n    Args:\n        env: MettaGrid environment\n        orientation: Orientation enum, string (\"up\", \"down\", \"left\", \"right\"), or int (0=Up, 1=Down, 2=Left, 3=Right)\n        agent_idx: Agent index (default 0)\n    Returns:\n        Dict with rotation results and validation\n    \"\"\"",
        "detail": "mettagrid.src.metta.mettagrid.util.actions",
        "documentation": {}
    },
    {
        "label": "get_current_observation",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.actions",
        "description": "mettagrid.src.metta.mettagrid.util.actions",
        "peekOfCode": "def get_current_observation(env: MettaGrid, agent_idx: int):\n    \"\"\"Get current observation using noop action.\"\"\"\n    try:\n        action_names = env.action_names()\n        if \"noop\" in action_names:\n            noop_idx = action_names.index(\"noop\")\n            noop_action = np.zeros((env.num_agents, 2), dtype=dtype_actions)\n            noop_action[agent_idx] = [noop_idx, 0]\n            obs, _, _, _, _ = env.step(noop_action)\n            return obs.copy()",
        "detail": "mettagrid.src.metta.mettagrid.util.actions",
        "documentation": {}
    },
    {
        "label": "get_agent_position",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.actions",
        "description": "mettagrid.src.metta.mettagrid.util.actions",
        "peekOfCode": "def get_agent_position(env: MettaGrid, agent_idx: int = 0) -> Optional[tuple]:\n    \"\"\"Get agent's current position (r, c).\"\"\"\n    try:\n        grid_objects = env.grid_objects()\n        for _obj_id, obj_data in grid_objects.items():\n            if \"agent_id\" in obj_data and obj_data.get(\"agent_id\") == agent_idx:\n                return (obj_data[\"r\"], obj_data[\"c\"])\n        return None\n    except Exception:\n        return None",
        "detail": "mettagrid.src.metta.mettagrid.util.actions",
        "documentation": {}
    },
    {
        "label": "get_agent_orientation",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.actions",
        "description": "mettagrid.src.metta.mettagrid.util.actions",
        "peekOfCode": "def get_agent_orientation(env: MettaGrid, agent_idx: int = 0) -> Optional[int]:\n    \"\"\"Get agent's current orientation.\"\"\"\n    try:\n        grid_objects = env.grid_objects()\n        for _obj_id, obj_data in grid_objects.items():\n            if \"agent_id\" in obj_data and obj_data.get(\"agent_id\") == agent_idx:\n                return obj_data.get(\"agent:orientation\", None)\n        return None\n    except Exception:\n        return None",
        "detail": "mettagrid.src.metta.mettagrid.util.actions",
        "documentation": {}
    },
    {
        "label": "CustomEncoder",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.util.debug",
        "description": "mettagrid.src.metta.mettagrid.util.debug",
        "peekOfCode": "class CustomEncoder(json.JSONEncoder):\n    \"\"\"Custom JSON encoder for handling non-serializable objects.\"\"\"\n    def default(self, obj):\n        try:\n            # Handle OmegaConf objects explicitly\n            if isinstance(obj, DictConfig):\n                return filter_test_data(OmegaConf.to_container(obj, resolve=True))\n            # Try to convert to a dictionary\n            elif hasattr(obj, \"to_dict\") and callable(obj.to_dict):\n                return obj.to_dict()",
        "detail": "mettagrid.src.metta.mettagrid.util.debug",
        "documentation": {}
    },
    {
        "label": "save_array_slice",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.debug",
        "description": "mettagrid.src.metta.mettagrid.util.debug",
        "peekOfCode": "def save_array_slice(\n    array: np.ndarray, indices: tuple, file_path: Path, max_preview_elements: int = 60, append: bool = False\n) -> None:\n    \"\"\"\n    Save a slice of an array to a file, with a preview of values.\n    Args:\n        array: The NumPy array to slice\n        indices: Tuple of indices to select the slice (use None for ':' in that dimension)\n                 e.g., (0, None, 5) would represent array[0, :, 5]\n        file_path: Path to the file to save the slice information",
        "detail": "mettagrid.src.metta.mettagrid.util.debug",
        "documentation": {}
    },
    {
        "label": "save_args_for_c",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.debug",
        "description": "mettagrid.src.metta.mettagrid.util.debug",
        "peekOfCode": "def save_args_for_c(\n    args: Dict[str, Any], base_filename: str = \"c_test_args\", output_dir: Optional[str] = None\n) -> Dict[str, str]:\n    \"\"\"\n    Save Python arguments in formats suitable for C testing.\n    Args:\n        args: Dictionary of arguments to save. Each key-value pair will be saved.\n        base_filename: Base name for the output files (without extension).\n        output_dir: Directory to save files. If None, uses current directory.\n    Returns:",
        "detail": "mettagrid.src.metta.mettagrid.util.debug",
        "documentation": {}
    },
    {
        "label": "save_mettagrid_args",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.debug",
        "description": "mettagrid.src.metta.mettagrid.util.debug",
        "peekOfCode": "def save_mettagrid_args(\n    env_cfg: DictConfig,\n    env_map: np.ndarray,\n    base_filename: str = \"mettagrid_test_args\",\n    output_dir: Optional[str] = \"./test_data\",\n) -> Dict[str, str]:\n    \"\"\"\n    Specialized function to save MettaGrid constructor arguments for C testing.\n    Args:\n        env_cfg: Environment configuration",
        "detail": "mettagrid.src.metta.mettagrid.util.debug",
        "documentation": {}
    },
    {
        "label": "filter_test_data",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.debug",
        "description": "mettagrid.src.metta.mettagrid.util.debug",
        "peekOfCode": "def filter_test_data(data: Any) -> Any:\n    \"\"\"\n    Filter out unnecessary fields from test data to make it more compact.\n    Args:\n        data: Dictionary or other data structure to filter\n    Returns:\n        Filtered data with unnecessary fields removed\n    \"\"\"\n    if isinstance(data, dict):\n        # Remove metadata that's not needed for C tests",
        "detail": "mettagrid.src.metta.mettagrid.util.debug",
        "documentation": {}
    },
    {
        "label": "save_step_results",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.debug",
        "description": "mettagrid.src.metta.mettagrid.util.debug",
        "peekOfCode": "def save_step_results(\n    observations: np.ndarray,\n    rewards: np.ndarray,\n    terminals: np.ndarray,\n    truncations: np.ndarray,\n    infos: Dict[str, Any],\n    base_filename: str = \"step_results\",\n    output_dir: Optional[str] = \"./test_data\",\n    step_count: Optional[int] = None,\n) -> Dict[str, str]:",
        "detail": "mettagrid.src.metta.mettagrid.util.debug",
        "documentation": {}
    },
    {
        "label": "_max_recursion_depth",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.util.debug",
        "description": "mettagrid.src.metta.mettagrid.util.debug",
        "peekOfCode": "_max_recursion_depth = 10  # Limit recursion depth\ndef save_array_slice(\n    array: np.ndarray, indices: tuple, file_path: Path, max_preview_elements: int = 60, append: bool = False\n) -> None:\n    \"\"\"\n    Save a slice of an array to a file, with a preview of values.\n    Args:\n        array: The NumPy array to slice\n        indices: Tuple of indices to select the slice (use None for ':' in that dimension)\n                 e.g., (0, None, 5) would represent array[0, :, 5]",
        "detail": "mettagrid.src.metta.mettagrid.util.debug",
        "documentation": {}
    },
    {
        "label": "unroll_nested_dict",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.dict_utils",
        "description": "mettagrid.src.metta.mettagrid.util.dict_utils",
        "peekOfCode": "def unroll_nested_dict(d: dict[str, Any]) -> Generator[tuple[str, Any], None, None]:\n    for k, v in d.items():\n        if isinstance(v, dict):\n            for k2, v2 in unroll_nested_dict(v):\n                yield f\"{k}/{k2}\", v2\n        else:\n            yield k, v",
        "detail": "mettagrid.src.metta.mettagrid.util.dict_utils",
        "documentation": {}
    },
    {
        "label": "calculate_diversity_bonus",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.diversity",
        "description": "mettagrid.src.metta.mettagrid.util.diversity",
        "peekOfCode": "def calculate_diversity_bonus(\n    episode_rewards: np.ndarray,\n    agent_groups: np.ndarray,\n    similarity_coef: float,\n    diversity_coef: float,\n) -> np.ndarray:\n    \"\"\"Calculate diversity scaling factor for each agent based on their rewards and group.\n    The scaling factor encourages agents to be similar to their own group but different from other groups.\n    For each agent:\n    1. Calculate normalized distance to own group mean",
        "detail": "mettagrid.src.metta.mettagrid.util.diversity",
        "documentation": {}
    },
    {
        "label": "WandbURI",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.util.file",
        "description": "mettagrid.src.metta.mettagrid.util.file",
        "peekOfCode": "class WandbURI:\n    \"\"\"Parsed representation of a W&B artifact URI.\"\"\"\n    project: str\n    artifact_path: str\n    version: str = \"latest\"\n    # ---------- factory ---------- #\n    @classmethod\n    def parse(cls, uri: str) -> \"WandbURI\":\n        if not uri.startswith(\"wandb://\"):\n            raise ValueError(\"W&B URI must start with wandb://\")",
        "detail": "mettagrid.src.metta.mettagrid.util.file",
        "documentation": {}
    },
    {
        "label": "exists",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.file",
        "description": "mettagrid.src.metta.mettagrid.util.file",
        "peekOfCode": "def exists(path: str) -> bool:\n    \"\"\"\n    Return *True* if *path* points to an existing local file, S3 object,\n    or W&B artifact **version** (latest if omitted).  Network errors are\n    propagated so callers can decide how to handle them.\n    \"\"\"\n    # ---------- S3 ---------- #\n    if path.startswith(\"s3://\"):\n        bucket, key = path[5:].split(\"/\", 1)\n        try:",
        "detail": "mettagrid.src.metta.mettagrid.util.file",
        "documentation": {}
    },
    {
        "label": "write_data",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.file",
        "description": "mettagrid.src.metta.mettagrid.util.file",
        "peekOfCode": "def write_data(path: str, data: Union[str, bytes], *, content_type: str = \"application/octet-stream\") -> None:\n    \"\"\"\n    Write in-memory bytes/str to *local*, *s3://* or *wandb://* destinations.\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    if isinstance(data, str):\n        data = data.encode()\n    # ---------- S3 ---------- #\n    if path.startswith(\"s3://\"):\n        bucket, key = path[5:].split(\"/\", 1)",
        "detail": "mettagrid.src.metta.mettagrid.util.file",
        "documentation": {}
    },
    {
        "label": "write_file",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.file",
        "description": "mettagrid.src.metta.mettagrid.util.file",
        "peekOfCode": "def write_file(path: str, local_file: str, *, content_type: str = \"application/octet-stream\") -> None:\n    \"\"\"\n    Upload a file from disk to *s3://* or *wandb://* (or copy locally).\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    # ---------- S3 ---------- #\n    if path.startswith(\"s3://\"):\n        bucket, key = path[5:].split(\"/\", 1)\n        boto3.client(\"s3\").upload_file(local_file, bucket, key, ExtraArgs={\"ContentType\": content_type})\n        logger.info(\"Uploaded %s  %s (size %d B)\", local_file, path, os.path.getsize(local_file))",
        "detail": "mettagrid.src.metta.mettagrid.util.file",
        "documentation": {}
    },
    {
        "label": "read",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.file",
        "description": "mettagrid.src.metta.mettagrid.util.file",
        "peekOfCode": "def read(path: str) -> bytes:\n    \"\"\"\n    Read bytes from local path, S3 object, or W&B artifact.\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    # ---------- S3 ---------- #\n    if path.startswith(\"s3://\"):\n        bucket, key = path[5:].split(\"/\", 1)\n        try:\n            body = boto3.client(\"s3\").get_object(Bucket=bucket, Key=key)[\"Body\"].read()",
        "detail": "mettagrid.src.metta.mettagrid.util.file",
        "documentation": {}
    },
    {
        "label": "local_copy",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.file",
        "description": "mettagrid.src.metta.mettagrid.util.file",
        "peekOfCode": "def local_copy(path: str):\n    \"\"\"\n    Yield a local *Path* for *path* (supports local / s3:// / wandb://).\n     Local paths are yielded as-is.\n     Remote URIs are streamed into a NamedTemporaryFile that is removed\n      when the context exits, so callers never worry about cleanup.\n    Usage:\n        with local_copy(uri) as p:\n            do_something_with(Path(p))\n    \"\"\"",
        "detail": "mettagrid.src.metta.mettagrid.util.file",
        "documentation": {}
    },
    {
        "label": "http_url",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.file",
        "description": "mettagrid.src.metta.mettagrid.util.file",
        "peekOfCode": "def http_url(path: str) -> str:\n    \"\"\"\n    Convert *s3://* or *wandb://* URI to a public browser URL.\n    No-op for local paths.\n    \"\"\"\n    if path.startswith(\"s3://\"):\n        bucket, key = path[5:].split(\"/\", 1)\n        return f\"https://{bucket}.s3.amazonaws.com/{key}\"\n    if path.startswith(\"wandb://\"):\n        return WandbURI.parse(path).http_url()",
        "detail": "mettagrid.src.metta.mettagrid.util.file",
        "documentation": {}
    },
    {
        "label": "upload_bytes_to_wandb",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.file",
        "description": "mettagrid.src.metta.mettagrid.util.file",
        "peekOfCode": "def upload_bytes_to_wandb(uri: WandbURI, blob: bytes, name: str) -> None:\n    with tempfile.NamedTemporaryFile(delete=False) as fh:\n        fh.write(blob)\n        tmpname = fh.name\n    try:\n        upload_file_to_wandb(uri, tmpname, name=name)\n    finally:\n        os.unlink(tmpname)\n@contextmanager\ndef wandb_export_context(project: str, entity: str = WANDB_ENTITY) -> wandb.Run:",
        "detail": "mettagrid.src.metta.mettagrid.util.file",
        "documentation": {}
    },
    {
        "label": "wandb_export_context",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.file",
        "description": "mettagrid.src.metta.mettagrid.util.file",
        "peekOfCode": "def wandb_export_context(project: str, entity: str = WANDB_ENTITY) -> wandb.Run:\n    \"\"\"\n    Context manager that ensures a wandb run exists for artifact exports.\n    TODO: Refactor to use WandbContext without requiring passing a deep hydra config\n    TODO: Remove this after switching to using wandb_context\n    Args:\n        project: wandb project name\n        entity: wandb entity name\n    Yields:\n        The active wandb run object",
        "detail": "mettagrid.src.metta.mettagrid.util.file",
        "documentation": {}
    },
    {
        "label": "upload_file_to_wandb",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.file",
        "description": "mettagrid.src.metta.mettagrid.util.file",
        "peekOfCode": "def upload_file_to_wandb(uri, local_file: str, name: str) -> None:\n    \"\"\"\n    Upload *local_file* to W&B as the next version of\n        wandb://{uri.project}/{uri.artifact_path}:latest    (type=\"file\")\n     Re-uses the caller's active run if present.\n     Otherwise creates a temporary run just for this upload and finishes it\n    Args:\n        uri: A WandbURI object containing project, artifact_path, and version\n        local_file: Path to the file to upload\n    Returns:",
        "detail": "mettagrid.src.metta.mettagrid.util.file",
        "documentation": {}
    },
    {
        "label": "config_from_path",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.hydra",
        "description": "mettagrid.src.metta.mettagrid.util.hydra",
        "peekOfCode": "def config_from_path(\n    config_path: str, overrides: Optional[DictConfig | ListConfig | dict] = None\n) -> DictConfig | ListConfig:\n    \"\"\"\n    Load configuration from a path, with better error handling\n    Args:\n        config_path: Path to the configuration\n        overrides: Optional overrides to apply to the configuration\n    Returns:\n        The loaded configuration",
        "detail": "mettagrid.src.metta.mettagrid.util.hydra",
        "documentation": {}
    },
    {
        "label": "get_test_basic_cfg",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.hydra",
        "description": "mettagrid.src.metta.mettagrid.util.hydra",
        "peekOfCode": "def get_test_basic_cfg() -> DictConfig:\n    return get_cfg(\"test_basic\")\ndef get_cfg(config_name: str) -> DictConfig:\n    # Save current directory to restore later if needed\n    original_cwd = Path.cwd()\n    try:\n        # Change to repository root\n        cd_repo_root()\n        # Now we can use a consistent path from repo root\n        mettagrid_configs_root = Path(\"mettagrid/configs\")",
        "detail": "mettagrid.src.metta.mettagrid.util.hydra",
        "documentation": {}
    },
    {
        "label": "get_cfg",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.util.hydra",
        "description": "mettagrid.src.metta.mettagrid.util.hydra",
        "peekOfCode": "def get_cfg(config_name: str) -> DictConfig:\n    # Save current directory to restore later if needed\n    original_cwd = Path.cwd()\n    try:\n        # Change to repository root\n        cd_repo_root()\n        # Now we can use a consistent path from repo root\n        mettagrid_configs_root = Path(\"mettagrid/configs\")\n        config_path = mettagrid_configs_root / f\"{config_name}.yaml\"\n        if not config_path.exists():",
        "detail": "mettagrid.src.metta.mettagrid.util.hydra",
        "documentation": {}
    },
    {
        "label": "grid_object_to_char",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.char_encoder",
        "description": "mettagrid.src.metta.mettagrid.char_encoder",
        "peekOfCode": "def grid_object_to_char(name: str) -> str:\n    if name in NAME_TO_CHAR:\n        return NAME_TO_CHAR[name][0]\n    raise ValueError(f\"Unknown object type: {name}\")\ndef char_to_grid_object(char: str) -> str:\n    if char in CHAR_TO_NAME:\n        return CHAR_TO_NAME[char]\n    raise ValueError(f\"Unknown character: {char}\")\ndef normalize_grid_char(char: str) -> str:\n    return grid_object_to_char(char_to_grid_object(char))",
        "detail": "mettagrid.src.metta.mettagrid.char_encoder",
        "documentation": {}
    },
    {
        "label": "char_to_grid_object",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.char_encoder",
        "description": "mettagrid.src.metta.mettagrid.char_encoder",
        "peekOfCode": "def char_to_grid_object(char: str) -> str:\n    if char in CHAR_TO_NAME:\n        return CHAR_TO_NAME[char]\n    raise ValueError(f\"Unknown character: {char}\")\ndef normalize_grid_char(char: str) -> str:\n    return grid_object_to_char(char_to_grid_object(char))",
        "detail": "mettagrid.src.metta.mettagrid.char_encoder",
        "documentation": {}
    },
    {
        "label": "normalize_grid_char",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.char_encoder",
        "description": "mettagrid.src.metta.mettagrid.char_encoder",
        "peekOfCode": "def normalize_grid_char(char: str) -> str:\n    return grid_object_to_char(char_to_grid_object(char))",
        "detail": "mettagrid.src.metta.mettagrid.char_encoder",
        "documentation": {}
    },
    {
        "label": "EpisodeStatsDB",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.episode_stats_db",
        "description": "mettagrid.src.metta.mettagrid.episode_stats_db",
        "peekOfCode": "class EpisodeStatsDB:\n    \"\"\"\n    DuckDB database for recording the outcomes of episodes.\n    Includes per-agent and per-group statistics along with episode metadata.\n    Can be extended (e.g. see SimulationStatsDb) with additional context on top of this data.\n    \"\"\"\n    def __init__(self, path: Path) -> None:\n        self.path = path\n        os.makedirs(path.parent, exist_ok=True)\n        self.con = duckdb.connect(path)",
        "detail": "mettagrid.src.metta.mettagrid.episode_stats_db",
        "documentation": {}
    },
    {
        "label": "EPISODE_DB_TABLES",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.episode_stats_db",
        "description": "mettagrid.src.metta.mettagrid.episode_stats_db",
        "peekOfCode": "EPISODE_DB_TABLES = {\n    \"episodes\": \"\"\"\n    CREATE TABLE IF NOT EXISTS episodes (\n        id TEXT PRIMARY KEY,\n        step_count INTEGER,\n        created_at TIMESTAMP,\n        completed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n        simulation_id TEXT,\n        replay_url TEXT\n    );",
        "detail": "mettagrid.src.metta.mettagrid.episode_stats_db",
        "documentation": {}
    },
    {
        "label": "SingleAgentWrapper",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.gym_wrapper",
        "description": "mettagrid.src.metta.mettagrid.gym_wrapper",
        "peekOfCode": "class SingleAgentWrapper(gym.Wrapper):\n    def __init__(self, env):\n        super(SingleAgentWrapper, self).__init__(env)\n    def step(self, action):\n        action = np.asarray(action, dtype=np.uint32)\n        action = action[None, ...]\n        observations, rewards, terminals, truncations, infos = self.env.step(action)\n        observations = observations.squeeze(0)\n        rewards = rewards.squeeze(0)\n        terminals = terminals.squeeze(0)",
        "detail": "mettagrid.src.metta.mettagrid.gym_wrapper",
        "documentation": {}
    },
    {
        "label": "MultiToDiscreteWrapper",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.gym_wrapper",
        "description": "mettagrid.src.metta.mettagrid.gym_wrapper",
        "peekOfCode": "class MultiToDiscreteWrapper(gym.ActionWrapper):\n    def __init__(self, env):\n        super(MultiToDiscreteWrapper, self).__init__(env)\n        max_action_args = env.unwrapped.max_action_args\n        arg_counts = [a + 1 for a in max_action_args]\n        self.n_actions = np.sum(arg_counts)\n        self.action_map = np.zeros((self.n_actions, 2), dtype=np.int32)\n        i = 0\n        for action, max_arg in enumerate(arg_counts):\n            for arg in range(max_arg):",
        "detail": "mettagrid.src.metta.mettagrid.gym_wrapper",
        "documentation": {}
    },
    {
        "label": "Level",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.level_builder",
        "description": "mettagrid.src.metta.mettagrid.level_builder",
        "peekOfCode": "class Level:\n    \"\"\"\n    Represents a level in the MettaGrid game.\n    Note: this is intentionally called \"Level\" instead of \"Map\" because `map` is a reserved word in Python.\n    \"\"\"\n    # Two-dimensional grid of strings.\n    # Possible values: \"wall\", \"empty\", \"agent\", etc.\n    # For the full list, see `mettagrid_c.cpp`.\n    grid: npt.NDArray[np.str_]\n    # List of labels. These will be used for `rewards/map:...` episode stats.",
        "detail": "mettagrid.src.metta.mettagrid.level_builder",
        "documentation": {}
    },
    {
        "label": "LevelBuilder",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.level_builder",
        "description": "mettagrid.src.metta.mettagrid.level_builder",
        "peekOfCode": "class LevelBuilder(ABC):\n    \"\"\"\n    A base class for building MettaGridEnv levels.\n    Right now we have two implementations:\n    1. `mettagrid.room.room.Room` and its subclasses\n    2. `metta.map.mapgen.MapGen`\n    MapGen system is more flexible and the current plan is to refactor away the Room class hierarchy.\n    \"\"\"\n    @abstractmethod\n    def build(self) -> Level: ...",
        "detail": "mettagrid.src.metta.mettagrid.level_builder",
        "documentation": {}
    },
    {
        "label": "ActionConfig_cpp",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "peekOfCode": "class ActionConfig_cpp(BaseModelWithForbidExtra):\n    \"\"\"Action configuration.\"\"\"\n    # Required resources should be a superset of consumed resources.\n    # E.g., maybe you need a laser and a battery to attack, but only consume the laser.\n    required_resources: Dict[FeatureId, int]\n    consumed_resources: Dict[FeatureId, int]\n    enabled: bool\nclass AttackActionConfig_cpp(ActionConfig_cpp):\n    \"\"\"Attack action configuration.\"\"\"\n    # If there are no defense resources, the attack will always succeed.",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "documentation": {}
    },
    {
        "label": "AttackActionConfig_cpp",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "peekOfCode": "class AttackActionConfig_cpp(ActionConfig_cpp):\n    \"\"\"Attack action configuration.\"\"\"\n    # If there are no defense resources, the attack will always succeed.\n    # Otherwise, you need to have enough defense resources to block the attack.\n    defense_resources: Dict[FeatureId, int]\nclass ActionsConfig_cpp(BaseModelWithForbidExtra):\n    \"\"\"Actions configuration.\"\"\"\n    noop: ActionConfig_cpp\n    move: ActionConfig_cpp\n    rotate: ActionConfig_cpp",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "documentation": {}
    },
    {
        "label": "ActionsConfig_cpp",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "peekOfCode": "class ActionsConfig_cpp(BaseModelWithForbidExtra):\n    \"\"\"Actions configuration.\"\"\"\n    noop: ActionConfig_cpp\n    move: ActionConfig_cpp\n    rotate: ActionConfig_cpp\n    put_items: ActionConfig_cpp\n    get_items: ActionConfig_cpp\n    attack: AttackActionConfig_cpp\n    swap: ActionConfig_cpp\n    change_color: ActionConfig_cpp",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "documentation": {}
    },
    {
        "label": "ObjectConfig_cpp",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "peekOfCode": "class ObjectConfig_cpp(BaseModelWithForbidExtra):\n    \"\"\"Object configuration.\"\"\"\n    object_type: Literal[\"agent\", \"converter\", \"wall\"]\n    # type_id is meant for consumption by the agents, and it should show up in features.\n    type_id: int\n    # type_name is meant for consumption by humans, and will be used in stats and the viewer.\n    type_name: str\nclass AgentGroupConfig_cpp(ObjectConfig_cpp):\n    \"\"\"Agent group configuration.\"\"\"\n    object_type: Literal[\"agent\"] = \"agent\"",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "documentation": {}
    },
    {
        "label": "AgentGroupConfig_cpp",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "peekOfCode": "class AgentGroupConfig_cpp(ObjectConfig_cpp):\n    \"\"\"Agent group configuration.\"\"\"\n    object_type: Literal[\"agent\"] = \"agent\"\n    freeze_duration: int = Field(ge=-1)\n    action_failure_penalty: float = Field(default=0, ge=0)\n    max_items_per_type: Dict[FeatureId, int] = Field(default_factory=dict)\n    resource_rewards: Dict[FeatureId, float] = Field(default_factory=dict)\n    resource_reward_max: Dict[FeatureId, float] = Field(default_factory=dict)\n    group_name: str\n    group_id: int",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "documentation": {}
    },
    {
        "label": "WallConfig_cpp",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "peekOfCode": "class WallConfig_cpp(ObjectConfig_cpp):\n    \"\"\"Wall/Block configuration.\"\"\"\n    object_type: Literal[\"wall\"] = \"wall\"\n    swappable: Optional[bool] = None\n    type_id: Byte\nclass ConverterConfig_cpp(ObjectConfig_cpp):\n    \"\"\"Converter configuration for objects that convert items.\"\"\"\n    object_type: Literal[\"converter\"] = \"converter\"\n    recipe_input: Dict[FeatureId, int] = Field(default_factory=dict)\n    recipe_output: Dict[FeatureId, int] = Field(default_factory=dict)",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "documentation": {}
    },
    {
        "label": "ConverterConfig_cpp",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "peekOfCode": "class ConverterConfig_cpp(ObjectConfig_cpp):\n    \"\"\"Converter configuration for objects that convert items.\"\"\"\n    object_type: Literal[\"converter\"] = \"converter\"\n    recipe_input: Dict[FeatureId, int] = Field(default_factory=dict)\n    recipe_output: Dict[FeatureId, int] = Field(default_factory=dict)\n    max_output: int = Field(ge=-1)\n    conversion_ticks: int = Field(ge=0)\n    cooldown: int = Field(ge=0)\n    initial_items: int = Field(ge=0)\n    color: Byte = Field(default=0)",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "documentation": {}
    },
    {
        "label": "RewardSharingGroup_cpp",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "peekOfCode": "class RewardSharingGroup_cpp(RootModel[Dict[str, float]]):\n    \"\"\"Reward sharing configuration for a group.\"\"\"\n    pass\nclass RewardSharingConfig_cpp(BaseModelWithForbidExtra):\n    \"\"\"Reward sharing configuration.\"\"\"\n    groups: Optional[Dict[str, RewardSharingGroup_cpp]] = None\nclass GameConfig_cpp(BaseModelWithForbidExtra):\n    \"\"\"Game configuration.\"\"\"\n    inventory_item_names: List[str]\n    num_agents: int = Field(ge=1)",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "documentation": {}
    },
    {
        "label": "RewardSharingConfig_cpp",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "peekOfCode": "class RewardSharingConfig_cpp(BaseModelWithForbidExtra):\n    \"\"\"Reward sharing configuration.\"\"\"\n    groups: Optional[Dict[str, RewardSharingGroup_cpp]] = None\nclass GameConfig_cpp(BaseModelWithForbidExtra):\n    \"\"\"Game configuration.\"\"\"\n    inventory_item_names: List[str]\n    num_agents: int = Field(ge=1)\n    max_steps: int = Field(ge=0)\n    obs_width: int = Field(ge=1)\n    obs_height: int = Field(ge=1)",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "documentation": {}
    },
    {
        "label": "GameConfig_cpp",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "peekOfCode": "class GameConfig_cpp(BaseModelWithForbidExtra):\n    \"\"\"Game configuration.\"\"\"\n    inventory_item_names: List[str]\n    num_agents: int = Field(ge=1)\n    max_steps: int = Field(ge=0)\n    obs_width: int = Field(ge=1)\n    obs_height: int = Field(ge=1)\n    num_observation_tokens: int = Field(ge=1)\n    actions: ActionsConfig_cpp\n    objects: Dict[str, AgentGroupConfig_cpp | ConverterConfig_cpp | WallConfig_cpp]",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "documentation": {}
    },
    {
        "label": "from_mettagrid_config",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "peekOfCode": "def from_mettagrid_config(mettagrid_config: GameConfig_py) -> GameConfig_cpp:\n    \"\"\"Convert a mettagrid_config.GameConfig to a mettagrid_c_config.GameConfig.\"\"\"\n    inventory_item_names = list(mettagrid_config.inventory_item_names)\n    inventory_item_ids = dict((name, i) for i, name in enumerate(inventory_item_names))\n    object_configs = {}\n    # these are the baseline settings for all agents\n    agent_default_config_dict = mettagrid_config.agent.model_dump(by_alias=True, exclude_unset=True)\n    # Group information is more specific than the defaults, so it should override\n    for group_name, group_config in mettagrid_config.groups.items():\n        group_config_dict = group_config.model_dump(by_alias=True, exclude_unset=True)",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "documentation": {}
    },
    {
        "label": "cpp_config_dict",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "peekOfCode": "def cpp_config_dict(game_config_dict: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Validates a config dict and returns a config_c dict.\n    In particular, this function converts from the style of config we have in yaml to the style of config we expect\n    in cpp; and validates along the way.\n    \"\"\"\n    game_config = GameConfig_py(**game_config_dict)\n    return from_mettagrid_config(game_config).model_dump(by_alias=True, exclude_none=True)",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "documentation": {}
    },
    {
        "label": "Byte",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "peekOfCode": "Byte = conint(ge=0, le=255)\nFeatureId = Byte\nclass ActionConfig_cpp(BaseModelWithForbidExtra):\n    \"\"\"Action configuration.\"\"\"\n    # Required resources should be a superset of consumed resources.\n    # E.g., maybe you need a laser and a battery to attack, but only consume the laser.\n    required_resources: Dict[FeatureId, int]\n    consumed_resources: Dict[FeatureId, int]\n    enabled: bool\nclass AttackActionConfig_cpp(ActionConfig_cpp):",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "documentation": {}
    },
    {
        "label": "FeatureId",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "peekOfCode": "FeatureId = Byte\nclass ActionConfig_cpp(BaseModelWithForbidExtra):\n    \"\"\"Action configuration.\"\"\"\n    # Required resources should be a superset of consumed resources.\n    # E.g., maybe you need a laser and a battery to attack, but only consume the laser.\n    required_resources: Dict[FeatureId, int]\n    consumed_resources: Dict[FeatureId, int]\n    enabled: bool\nclass AttackActionConfig_cpp(ActionConfig_cpp):\n    \"\"\"Attack action configuration.\"\"\"",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_c_config",
        "documentation": {}
    },
    {
        "label": "AgentRewards",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "peekOfCode": "class AgentRewards(BaseModelWithForbidExtra):\n    \"\"\"Agent reward configuration.\"\"\"\n    action_failure_penalty: Optional[float] = Field(default=None, ge=0)\n    ore_red: Optional[float] = Field(default=None)\n    ore_blue: Optional[float] = Field(default=None)\n    ore_green: Optional[float] = Field(default=None)\n    ore_red_max: Optional[float] = Field(default=None)\n    ore_blue_max: Optional[float] = Field(default=None)\n    ore_green_max: Optional[float] = Field(default=None)\n    battery_red: Optional[float] = Field(default=None)",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "documentation": {}
    },
    {
        "label": "AgentConfig",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "peekOfCode": "class AgentConfig(BaseModelWithForbidExtra):\n    \"\"\"Agent configuration.\"\"\"\n    default_item_max: Optional[int] = Field(default=None, ge=0)\n    freeze_duration: Optional[int] = Field(default=None, ge=-1)\n    rewards: Optional[AgentRewards] = None\n    ore_red_max: Optional[int] = Field(default=None)\n    ore_blue_max: Optional[int] = Field(default=None)\n    ore_green_max: Optional[int] = Field(default=None)\n    battery_red_max: Optional[int] = Field(default=None)\n    battery_blue_max: Optional[int] = Field(default=None)",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "documentation": {}
    },
    {
        "label": "GroupProps",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "peekOfCode": "class GroupProps(RootModel[Dict[str, Any]]):\n    \"\"\"Group properties configuration.\"\"\"\n    pass\nclass GroupConfig(BaseModelWithForbidExtra):\n    \"\"\"Group configuration.\"\"\"\n    id: int\n    sprite: Optional[int] = Field(default=None)\n    # Values outside of 0 and 1 are probably mistakes, and are probably\n    # unstable. If you want to use values outside this range, please update this comment!\n    group_reward_pct: Optional[float] = Field(default=None, ge=0, le=1)",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "documentation": {}
    },
    {
        "label": "GroupConfig",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "peekOfCode": "class GroupConfig(BaseModelWithForbidExtra):\n    \"\"\"Group configuration.\"\"\"\n    id: int\n    sprite: Optional[int] = Field(default=None)\n    # Values outside of 0 and 1 are probably mistakes, and are probably\n    # unstable. If you want to use values outside this range, please update this comment!\n    group_reward_pct: Optional[float] = Field(default=None, ge=0, le=1)\n    props: Optional[GroupProps] = None\nclass ActionConfig(BaseModelWithForbidExtra):\n    \"\"\"Action configuration.\"\"\"",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "documentation": {}
    },
    {
        "label": "ActionConfig",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "peekOfCode": "class ActionConfig(BaseModelWithForbidExtra):\n    \"\"\"Action configuration.\"\"\"\n    enabled: bool\n    # defaults to consumed_resources. Otherwise, should be a superset of consumed_resources.\n    required_resources: Optional[Dict[str, int]] = None\n    consumed_resources: Optional[Dict[str, int]] = Field(default_factory=dict)\nclass AttackActionConfig(ActionConfig):\n    \"\"\"Attack action configuration.\"\"\"\n    defense_resources: Optional[Dict[str, int]] = Field(default_factory=dict)\nclass ActionsConfig(BaseModelWithForbidExtra):",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "documentation": {}
    },
    {
        "label": "AttackActionConfig",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "peekOfCode": "class AttackActionConfig(ActionConfig):\n    \"\"\"Attack action configuration.\"\"\"\n    defense_resources: Optional[Dict[str, int]] = Field(default_factory=dict)\nclass ActionsConfig(BaseModelWithForbidExtra):\n    \"\"\"Actions configuration.\"\"\"\n    noop: ActionConfig\n    move: ActionConfig\n    rotate: ActionConfig\n    put_items: ActionConfig\n    get_items: ActionConfig",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "documentation": {}
    },
    {
        "label": "ActionsConfig",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "peekOfCode": "class ActionsConfig(BaseModelWithForbidExtra):\n    \"\"\"Actions configuration.\"\"\"\n    noop: ActionConfig\n    move: ActionConfig\n    rotate: ActionConfig\n    put_items: ActionConfig\n    get_items: ActionConfig\n    attack: AttackActionConfig\n    swap: ActionConfig\n    change_color: ActionConfig",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "documentation": {}
    },
    {
        "label": "WallConfig",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "peekOfCode": "class WallConfig(BaseModelWithForbidExtra):\n    \"\"\"Wall/Block configuration.\"\"\"\n    type_id: int\n    swappable: Optional[bool] = None\nclass ConverterConfig(BaseModelWithForbidExtra):\n    \"\"\"Converter configuration for objects that convert items.\"\"\"\n    # Input items (e.g., \"input_ore_red\": 3)\n    input_ore_red: Optional[int] = Field(default=None, ge=0, le=255)\n    input_ore_blue: Optional[int] = Field(default=None, ge=0, le=255)\n    input_ore_green: Optional[int] = Field(default=None, ge=0, le=255)",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "documentation": {}
    },
    {
        "label": "ConverterConfig",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "peekOfCode": "class ConverterConfig(BaseModelWithForbidExtra):\n    \"\"\"Converter configuration for objects that convert items.\"\"\"\n    # Input items (e.g., \"input_ore_red\": 3)\n    input_ore_red: Optional[int] = Field(default=None, ge=0, le=255)\n    input_ore_blue: Optional[int] = Field(default=None, ge=0, le=255)\n    input_ore_green: Optional[int] = Field(default=None, ge=0, le=255)\n    input_battery_red: Optional[int] = Field(default=None, ge=0, le=255)\n    input_battery_blue: Optional[int] = Field(default=None, ge=0, le=255)\n    input_battery_green: Optional[int] = Field(default=None, ge=0, le=255)\n    input_heart: Optional[int] = Field(default=None, ge=0, le=255)",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "documentation": {}
    },
    {
        "label": "RewardSharingGroup",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "peekOfCode": "class RewardSharingGroup(RootModel[Dict[str, float]]):\n    \"\"\"Reward sharing configuration for a group.\"\"\"\n    pass\nclass RewardSharingConfig(BaseModelWithForbidExtra):\n    \"\"\"Reward sharing configuration.\"\"\"\n    groups: Optional[Dict[str, RewardSharingGroup]] = None\nclass GameConfig(BaseModelWithForbidExtra):\n    \"\"\"Game configuration.\"\"\"\n    inventory_item_names: List[str]\n    num_agents: int = Field(ge=1)",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "documentation": {}
    },
    {
        "label": "RewardSharingConfig",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "peekOfCode": "class RewardSharingConfig(BaseModelWithForbidExtra):\n    \"\"\"Reward sharing configuration.\"\"\"\n    groups: Optional[Dict[str, RewardSharingGroup]] = None\nclass GameConfig(BaseModelWithForbidExtra):\n    \"\"\"Game configuration.\"\"\"\n    inventory_item_names: List[str]\n    num_agents: int = Field(ge=1)\n    # zero means \"no limit\"\n    max_steps: int = Field(ge=0)\n    obs_width: int = Field(ge=1)",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "documentation": {}
    },
    {
        "label": "GameConfig",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "peekOfCode": "class GameConfig(BaseModelWithForbidExtra):\n    \"\"\"Game configuration.\"\"\"\n    inventory_item_names: List[str]\n    num_agents: int = Field(ge=1)\n    # zero means \"no limit\"\n    max_steps: int = Field(ge=0)\n    obs_width: int = Field(ge=1)\n    obs_height: int = Field(ge=1)\n    num_observation_tokens: int = Field(ge=1)\n    agent: AgentConfig",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_config",
        "documentation": {}
    },
    {
        "label": "MettaGridEnv",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "peekOfCode": "class MettaGridEnv(PufferEnv, GymEnv):\n    # Type hints for attributes defined in the C++ extension to help Pylance\n    observations: np.ndarray\n    terminals: np.ndarray\n    truncations: np.ndarray\n    rewards: np.ndarray\n    actions: np.ndarray\n    @validate_call(config={\"arbitrary_types_allowed\": True})\n    def __init__(\n        self,",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "required",
        "kind": 2,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "peekOfCode": "def required(func):\n    \"\"\"Marks methods that PufferEnv requires but does not implement for override.\"\"\"\n    return func\nclass MettaGridEnv(PufferEnv, GymEnv):\n    # Type hints for attributes defined in the C++ extension to help Pylance\n    observations: np.ndarray\n    terminals: np.ndarray\n    truncations: np.ndarray\n    rewards: np.ndarray\n    actions: np.ndarray",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_observations",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "peekOfCode": "dtype_observations = np.dtype(np.uint8)\ndtype_terminals = np.dtype(bool)\ndtype_truncations = np.dtype(bool)\ndtype_rewards = np.dtype(np.float32)\ndtype_actions = np.dtype(np.int32)  # must be int32!\ndtype_masks = np.dtype(bool)\ndtype_success = np.dtype(bool)\nlogger = logging.getLogger(\"MettaGridEnv\")\ndef required(func):\n    \"\"\"Marks methods that PufferEnv requires but does not implement for override.\"\"\"",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_terminals",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "peekOfCode": "dtype_terminals = np.dtype(bool)\ndtype_truncations = np.dtype(bool)\ndtype_rewards = np.dtype(np.float32)\ndtype_actions = np.dtype(np.int32)  # must be int32!\ndtype_masks = np.dtype(bool)\ndtype_success = np.dtype(bool)\nlogger = logging.getLogger(\"MettaGridEnv\")\ndef required(func):\n    \"\"\"Marks methods that PufferEnv requires but does not implement for override.\"\"\"\n    return func",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_truncations",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "peekOfCode": "dtype_truncations = np.dtype(bool)\ndtype_rewards = np.dtype(np.float32)\ndtype_actions = np.dtype(np.int32)  # must be int32!\ndtype_masks = np.dtype(bool)\ndtype_success = np.dtype(bool)\nlogger = logging.getLogger(\"MettaGridEnv\")\ndef required(func):\n    \"\"\"Marks methods that PufferEnv requires but does not implement for override.\"\"\"\n    return func\nclass MettaGridEnv(PufferEnv, GymEnv):",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_rewards",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "peekOfCode": "dtype_rewards = np.dtype(np.float32)\ndtype_actions = np.dtype(np.int32)  # must be int32!\ndtype_masks = np.dtype(bool)\ndtype_success = np.dtype(bool)\nlogger = logging.getLogger(\"MettaGridEnv\")\ndef required(func):\n    \"\"\"Marks methods that PufferEnv requires but does not implement for override.\"\"\"\n    return func\nclass MettaGridEnv(PufferEnv, GymEnv):\n    # Type hints for attributes defined in the C++ extension to help Pylance",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_actions",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "peekOfCode": "dtype_actions = np.dtype(np.int32)  # must be int32!\ndtype_masks = np.dtype(bool)\ndtype_success = np.dtype(bool)\nlogger = logging.getLogger(\"MettaGridEnv\")\ndef required(func):\n    \"\"\"Marks methods that PufferEnv requires but does not implement for override.\"\"\"\n    return func\nclass MettaGridEnv(PufferEnv, GymEnv):\n    # Type hints for attributes defined in the C++ extension to help Pylance\n    observations: np.ndarray",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_masks",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "peekOfCode": "dtype_masks = np.dtype(bool)\ndtype_success = np.dtype(bool)\nlogger = logging.getLogger(\"MettaGridEnv\")\ndef required(func):\n    \"\"\"Marks methods that PufferEnv requires but does not implement for override.\"\"\"\n    return func\nclass MettaGridEnv(PufferEnv, GymEnv):\n    # Type hints for attributes defined in the C++ extension to help Pylance\n    observations: np.ndarray\n    terminals: np.ndarray",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "dtype_success",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "peekOfCode": "dtype_success = np.dtype(bool)\nlogger = logging.getLogger(\"MettaGridEnv\")\ndef required(func):\n    \"\"\"Marks methods that PufferEnv requires but does not implement for override.\"\"\"\n    return func\nclass MettaGridEnv(PufferEnv, GymEnv):\n    # Type hints for attributes defined in the C++ extension to help Pylance\n    observations: np.ndarray\n    terminals: np.ndarray\n    truncations: np.ndarray",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "description": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "peekOfCode": "logger = logging.getLogger(\"MettaGridEnv\")\ndef required(func):\n    \"\"\"Marks methods that PufferEnv requires but does not implement for override.\"\"\"\n    return func\nclass MettaGridEnv(PufferEnv, GymEnv):\n    # Type hints for attributes defined in the C++ extension to help Pylance\n    observations: np.ndarray\n    terminals: np.ndarray\n    truncations: np.ndarray\n    rewards: np.ndarray",
        "detail": "mettagrid.src.metta.mettagrid.mettagrid_env",
        "documentation": {}
    },
    {
        "label": "ReplayWriter",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.replay_writer",
        "description": "mettagrid.src.metta.mettagrid.replay_writer",
        "peekOfCode": "class ReplayWriter:\n    \"\"\"Helper class for generating and uploading replays.\"\"\"\n    def __init__(self, replay_dir: str | None = None):\n        self.replay_dir = replay_dir\n        self.episodes = {}\n    def start_episode(self, episode_id: str, env: MettaGridEnv):\n        self.episodes[episode_id] = EpisodeReplay(env)\n    def log_step(self, episode_id: str, actions: np.ndarray, rewards: np.ndarray):\n        self.episodes[episode_id].log_step(actions, rewards)\n    def write_replay(self, episode_id: str) -> str | None:",
        "detail": "mettagrid.src.metta.mettagrid.replay_writer",
        "documentation": {}
    },
    {
        "label": "EpisodeReplay",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.replay_writer",
        "description": "mettagrid.src.metta.mettagrid.replay_writer",
        "peekOfCode": "class EpisodeReplay:\n    def __init__(self, env: MettaGridEnv):\n        self.env = env\n        self.step = 0\n        self.grid_objects = []\n        self.total_rewards = np.zeros(env.num_agents)\n        self.replay_data = {\n            \"version\": 1,\n            \"action_names\": env.action_names,\n            \"inventory_items\": env.inventory_item_names,",
        "detail": "mettagrid.src.metta.mettagrid.replay_writer",
        "documentation": {}
    },
    {
        "label": "StatsWriter",
        "kind": 6,
        "importPath": "mettagrid.src.metta.mettagrid.stats_writer",
        "description": "mettagrid.src.metta.mettagrid.stats_writer",
        "peekOfCode": "class StatsWriter:\n    \"\"\"\n    Writer class for tracking statistics in MettaGrid; can be used by multiple environments simultaneously.\n    Safe to serialize/deserialize with multiprocessing as long as we have not yet created a connection to a duckdb file.\n    \"\"\"\n    def __init__(self, dir: Path) -> None:\n        self.dir = dir\n        # We do not pick a specific path or open a connection here,\n        # because for simplicity we pass a single StatsWriter as an\n        # argument to make_vecenv. These objects are pickled/unpickled",
        "detail": "mettagrid.src.metta.mettagrid.stats_writer",
        "documentation": {}
    },
    {
        "label": "TestMiniscopeRenderer",
        "kind": 6,
        "importPath": "mettagrid.tests.renderer.test_miniscope",
        "description": "mettagrid.tests.renderer.test_miniscope",
        "peekOfCode": "class TestMiniscopeRenderer:\n    \"\"\"Test suite for MiniscopeRenderer functionality.\"\"\"\n    @pytest.fixture\n    def object_type_names(self):\n        \"\"\"Provide standard object type names for testing.\"\"\"\n        return [\"agent\", \"wall\", \"altar\", \"mine_red\", \"generator_red\", \"lasery\", \"marker\", \"block\"]\n    @pytest.fixture\n    def renderer(self, object_type_names):\n        return MiniscopeRenderer(object_type_names)\n    def test_initialization(self, renderer):",
        "detail": "mettagrid.tests.renderer.test_miniscope",
        "documentation": {}
    },
    {
        "label": "suppress_stdout",
        "kind": 2,
        "importPath": "mettagrid.tests.renderer.test_miniscope",
        "description": "mettagrid.tests.renderer.test_miniscope",
        "peekOfCode": "def suppress_stdout():\n    \"\"\"Context manager to suppress stdout during tests.\"\"\"\n    old_stdout = sys.stdout\n    sys.stdout = io.StringIO()\n    try:\n        yield\n    finally:\n        sys.stdout = old_stdout\nclass TestMiniscopeRenderer:\n    \"\"\"Test suite for MiniscopeRenderer functionality.\"\"\"",
        "detail": "mettagrid.tests.renderer.test_miniscope",
        "documentation": {}
    },
    {
        "label": "TestNethackRenderer",
        "kind": 6,
        "importPath": "mettagrid.tests.renderer.test_nethack",
        "description": "mettagrid.tests.renderer.test_nethack",
        "peekOfCode": "class TestNethackRenderer:\n    \"\"\"Test suite for NethackRenderer functionality.\"\"\"\n    @pytest.fixture\n    def basic_renderer(self):\n        \"\"\"Create a basic renderer for testing.\"\"\"\n        object_type_names = [\"agent\", \"wall\", \"empty\", \"mine_red\", \"generator_red\", \"altar\", \"factory\", \"lab\", \"temple\"]\n        return NethackRenderer(object_type_names)\n    @pytest.fixture\n    def sample_grid_objects(self):\n        \"\"\"Create sample grid objects for testing.\"\"\"",
        "detail": "mettagrid.tests.renderer.test_nethack",
        "documentation": {}
    },
    {
        "label": "TestRendererIntegration",
        "kind": 6,
        "importPath": "mettagrid.tests.renderer.test_nethack",
        "description": "mettagrid.tests.renderer.test_nethack",
        "peekOfCode": "class TestRendererIntegration:\n    \"\"\"Test renderer integration with MettaGridEnv and tools.sim style setup.\"\"\"\n    @patch(\"builtins.print\")\n    def test_environment_rendering_workflow(self, mock_print):\n        \"\"\"Test complete rendering workflow with environment.\"\"\"\n        # Use the working approach from our demo scripts\n        cfg = get_cfg(\"benchmark\")\n        cfg.game.num_agents = 1\n        cfg.game.max_steps = 5\n        cfg.game.map_builder = OmegaConf.create(",
        "detail": "mettagrid.tests.renderer.test_nethack",
        "documentation": {}
    },
    {
        "label": "TestSymbolAnalysis",
        "kind": 6,
        "importPath": "mettagrid.tests.renderer.test_nethack",
        "description": "mettagrid.tests.renderer.test_nethack",
        "peekOfCode": "class TestSymbolAnalysis:\n    \"\"\"Test symbol analysis and double-width character detection.\"\"\"\n    def test_current_symbols_mapping(self):\n        \"\"\"Test analysis of current SYMBOLS mapping.\"\"\"\n        emoji_symbols = []\n        ascii_symbols = []\n        for char, obj_type in CHAR_TO_NAME.items():\n            if ord(char[0]) > 127:\n                emoji_symbols.append((char, obj_type))\n            else:",
        "detail": "mettagrid.tests.renderer.test_nethack",
        "documentation": {}
    },
    {
        "label": "TestNetHackStyleSolution",
        "kind": 6,
        "importPath": "mettagrid.tests.renderer.test_nethack",
        "description": "mettagrid.tests.renderer.test_nethack",
        "peekOfCode": "class TestNetHackStyleSolution:\n    \"\"\"Test NetHack-style solution for perfect alignment.\"\"\"\n    def test_nethack_symbol_mapping(self):\n        \"\"\"Test proposed NetHack-style symbol mapping.\"\"\"\n        nethack_mapping = {\n            \"wall\": \"#\",\n            \"agent\": \"@\",\n            \"empty\": \".\",\n            \"generator_red\": \"G\",\n            \"altar\": \"_\",",
        "detail": "mettagrid.tests.renderer.test_nethack",
        "documentation": {}
    },
    {
        "label": "base_config",
        "kind": 2,
        "importPath": "mettagrid.tests.test_actions",
        "description": "mettagrid.tests.test_actions",
        "peekOfCode": "def base_config():\n    \"\"\"Base configuration for MettaGrid tests.\"\"\"\n    return {\n        \"max_steps\": 50,\n        \"num_agents\": 1,\n        \"obs_width\": OBS_WIDTH,\n        \"obs_height\": OBS_HEIGHT,\n        \"num_observation_tokens\": NUM_OBS_TOKENS,\n        \"inventory_item_names\": [\"laser\", \"armor\"],\n        \"actions\": {",
        "detail": "mettagrid.tests.test_actions",
        "documentation": {}
    },
    {
        "label": "movement_game_map",
        "kind": 2,
        "importPath": "mettagrid.tests.test_actions",
        "description": "mettagrid.tests.test_actions",
        "peekOfCode": "def movement_game_map():\n    \"\"\"Game map with agent in center and room to move.\"\"\"\n    return [\n        [\"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\"],\n        [\"wall\", \"empty\", \"empty\", \"empty\", \"empty\", \"empty\", \"wall\"],\n        [\"wall\", \"empty\", \"empty\", \"agent.red\", \"empty\", \"empty\", \"wall\"],  # Agent in center\n        [\"wall\", \"empty\", \"empty\", \"empty\", \"empty\", \"empty\", \"wall\"],\n        [\"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\"],\n    ]\n@pytest.fixture",
        "detail": "mettagrid.tests.test_actions",
        "documentation": {}
    },
    {
        "label": "small_movement_game_map",
        "kind": 2,
        "importPath": "mettagrid.tests.test_actions",
        "description": "mettagrid.tests.test_actions",
        "peekOfCode": "def small_movement_game_map():\n    \"\"\"Smaller game map for focused movement tests.\"\"\"\n    return [\n        [\"wall\", \"wall\", \"wall\", \"wall\", \"wall\"],\n        [\"wall\", \"empty\", \"empty\", \"empty\", \"wall\"],\n        [\"wall\", \"empty\", \"agent.red\", \"empty\", \"wall\"],\n        [\"wall\", \"empty\", \"empty\", \"empty\", \"wall\"],\n        [\"wall\", \"wall\", \"wall\", \"wall\", \"wall\"],\n    ]\n@pytest.fixture",
        "detail": "mettagrid.tests.test_actions",
        "documentation": {}
    },
    {
        "label": "blocked_game_map",
        "kind": 2,
        "importPath": "mettagrid.tests.test_actions",
        "description": "mettagrid.tests.test_actions",
        "peekOfCode": "def blocked_game_map():\n    \"\"\"Game map where agent is completely surrounded by walls.\"\"\"\n    return [\n        [\"wall\", \"wall\", \"wall\"],\n        [\"wall\", \"agent.red\", \"wall\"],\n        [\"wall\", \"wall\", \"wall\"],\n    ]\n@pytest.fixture\ndef configured_env(base_config):\n    \"\"\"Factory fixture that creates a configured MettaGrid environment.\"\"\"",
        "detail": "mettagrid.tests.test_actions",
        "documentation": {}
    },
    {
        "label": "configured_env",
        "kind": 2,
        "importPath": "mettagrid.tests.test_actions",
        "description": "mettagrid.tests.test_actions",
        "peekOfCode": "def configured_env(base_config):\n    \"\"\"Factory fixture that creates a configured MettaGrid environment.\"\"\"\n    def _create_env(game_map, config_overrides=None):\n        game_config = base_config.copy()\n        if config_overrides:\n            game_config.update(config_overrides)\n        print(cpp_config_dict(game_config))\n        env = MettaGrid(cpp_config_dict(game_config), game_map, 42)\n        # Set up buffers\n        observations = np.zeros((1, NUM_OBS_TOKENS, OBS_TOKEN_SIZE), dtype=dtype_observations)",
        "detail": "mettagrid.tests.test_actions",
        "documentation": {}
    },
    {
        "label": "test_move_all_directions",
        "kind": 2,
        "importPath": "mettagrid.tests.test_actions",
        "description": "mettagrid.tests.test_actions",
        "peekOfCode": "def test_move_all_directions(configured_env, movement_game_map):\n    \"\"\"Test the move function in all four directions.\"\"\"\n    env = configured_env(movement_game_map)\n    initial_pos = get_agent_position(env)\n    assert initial_pos is not None, \"Agent should have a valid initial position\"\n    directions = [\n        Orientation.UP,\n        Orientation.RIGHT,\n        Orientation.DOWN,\n        Orientation.LEFT,",
        "detail": "mettagrid.tests.test_actions",
        "documentation": {}
    },
    {
        "label": "test_move_up",
        "kind": 2,
        "importPath": "mettagrid.tests.test_actions",
        "description": "mettagrid.tests.test_actions",
        "peekOfCode": "def test_move_up(configured_env, small_movement_game_map):\n    \"\"\"Test moving up specifically.\"\"\"\n    env = configured_env(small_movement_game_map, {\"max_steps\": 10})\n    result = move(env, Orientation.UP)  # Use Orientation enum\n    assert result[\"success\"], f\"Move up should succeed. Error: {result.get('error')}\"\n    assert result[\"moved_correctly\"], \"Agent should move up correctly\"\n    assert result[\"position_before\"][0] - result[\"position_after\"][0] == 1, \"Should move up by 1 row\"\ndef test_move_blocked_by_wall(configured_env, blocked_game_map):\n    \"\"\"Test that movement is properly blocked by walls.\"\"\"\n    env = configured_env(blocked_game_map, {\"max_steps\": 10})",
        "detail": "mettagrid.tests.test_actions",
        "documentation": {}
    },
    {
        "label": "test_move_blocked_by_wall",
        "kind": 2,
        "importPath": "mettagrid.tests.test_actions",
        "description": "mettagrid.tests.test_actions",
        "peekOfCode": "def test_move_blocked_by_wall(configured_env, blocked_game_map):\n    \"\"\"Test that movement is properly blocked by walls.\"\"\"\n    env = configured_env(blocked_game_map, {\"max_steps\": 10})\n    directions = [\n        Orientation.UP,\n        Orientation.RIGHT,\n        Orientation.DOWN,\n        Orientation.LEFT,\n    ]\n    for orientation in directions:",
        "detail": "mettagrid.tests.test_actions",
        "documentation": {}
    },
    {
        "label": "test_move_returns_to_center",
        "kind": 2,
        "importPath": "mettagrid.tests.test_actions",
        "description": "mettagrid.tests.test_actions",
        "peekOfCode": "def test_move_returns_to_center(configured_env, movement_game_map):\n    \"\"\"Test that we can move in a circle and return to center.\"\"\"\n    env = configured_env(movement_game_map)\n    initial_pos = get_agent_position(env)\n    assert initial_pos is not None, \"Agent should have a valid initial position\"\n    # Move in a circle: up, right, down, left\n    moves = [\n        Orientation.UP,\n        Orientation.RIGHT,\n        Orientation.DOWN,",
        "detail": "mettagrid.tests.test_actions",
        "documentation": {}
    },
    {
        "label": "corridor_game_map",
        "kind": 2,
        "importPath": "mettagrid.tests.test_actions",
        "description": "mettagrid.tests.test_actions",
        "peekOfCode": "def corridor_game_map():\n    \"\"\"Game map with a corridor for walking tests.\"\"\"\n    return [\n        [\"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\"],\n        [\"wall\", \"agent.red\", \"empty\", \"empty\", \"empty\", \"empty\", \"wall\"],\n        [\"wall\", \"empty\", \"empty\", \"altar\", \"empty\", \"empty\", \"wall\"],\n        [\"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\"],\n    ]\ndef test_agent_walks_across_room(configured_env, corridor_game_map):\n    \"\"\"",
        "detail": "mettagrid.tests.test_actions",
        "documentation": {}
    },
    {
        "label": "test_agent_walks_across_room",
        "kind": 2,
        "importPath": "mettagrid.tests.test_actions",
        "description": "mettagrid.tests.test_actions",
        "peekOfCode": "def test_agent_walks_across_room(configured_env, corridor_game_map):\n    \"\"\"\n    Test where a single agent walks across a room.\n    Creates a simple corridor and attempts to walk the agent from one end to the other.\n    The move() function already handles observation validation.\n    \"\"\"\n    print(\"Testing agent walking across room...\")\n    # Create environment with walking-specific config\n    env = configured_env(\n        corridor_game_map,",
        "detail": "mettagrid.tests.test_actions",
        "documentation": {}
    },
    {
        "label": "test_agent_walks_in_all_possible_directions",
        "kind": 2,
        "importPath": "mettagrid.tests.test_actions",
        "description": "mettagrid.tests.test_actions",
        "peekOfCode": "def test_agent_walks_in_all_possible_directions(configured_env, corridor_game_map):\n    \"\"\"Test that agent can move in all non-blocked directions.\"\"\"\n    print(\"Testing agent movement in all possible directions...\")\n    env = configured_env(corridor_game_map, {\"max_steps\": 20})\n    successful_directions = []\n    failed_directions = []\n    # Test all orientations using enum\n    directions = [\n        Orientation.UP,\n        Orientation.RIGHT,",
        "detail": "mettagrid.tests.test_actions",
        "documentation": {}
    },
    {
        "label": "test_orientation_enum_functionality",
        "kind": 2,
        "importPath": "mettagrid.tests.test_actions",
        "description": "mettagrid.tests.test_actions",
        "peekOfCode": "def test_orientation_enum_functionality():\n    \"\"\"Test that the Orientation enum works as expected.\"\"\"\n    assert Orientation.UP.movement_delta == (-1, 0)\n    assert Orientation.DOWN.movement_delta == (1, 0)\n    assert Orientation.LEFT.movement_delta == (0, -1)\n    assert Orientation.RIGHT.movement_delta == (0, 1)\n    assert str(Orientation.UP) == \"up\"\n    assert str(Orientation.DOWN) == \"down\"\n    assert str(Orientation.LEFT) == \"left\"\n    assert str(Orientation.RIGHT) == \"right\"",
        "detail": "mettagrid.tests.test_actions",
        "documentation": {}
    },
    {
        "label": "test_move_with_string_orientation",
        "kind": 2,
        "importPath": "mettagrid.tests.test_actions",
        "description": "mettagrid.tests.test_actions",
        "peekOfCode": "def test_move_with_string_orientation(configured_env, small_movement_game_map):\n    \"\"\"Test that move function accepts string orientations.\"\"\"\n    env = configured_env(small_movement_game_map, {\"max_steps\": 10})\n    # Test with string\n    result = move(env, Orientation.UP)\n    # Should work the same as using the enum directly\n    assert result[\"success\"], f\"Move with string orientation should succeed. Error: {result.get('error')}\"\n    assert result[\"moved_correctly\"], \"Agent should move up correctly\"",
        "detail": "mettagrid.tests.test_actions",
        "documentation": {}
    },
    {
        "label": "OBS_WIDTH",
        "kind": 5,
        "importPath": "mettagrid.tests.test_actions",
        "description": "mettagrid.tests.test_actions",
        "peekOfCode": "OBS_WIDTH = 3  # should be odd\nOBS_HEIGHT = 3  # should be odd\nNUM_OBS_TOKENS = 100\nOBS_TOKEN_SIZE = 3\n@pytest.fixture\ndef base_config():\n    \"\"\"Base configuration for MettaGrid tests.\"\"\"\n    return {\n        \"max_steps\": 50,\n        \"num_agents\": 1,",
        "detail": "mettagrid.tests.test_actions",
        "documentation": {}
    },
    {
        "label": "OBS_HEIGHT",
        "kind": 5,
        "importPath": "mettagrid.tests.test_actions",
        "description": "mettagrid.tests.test_actions",
        "peekOfCode": "OBS_HEIGHT = 3  # should be odd\nNUM_OBS_TOKENS = 100\nOBS_TOKEN_SIZE = 3\n@pytest.fixture\ndef base_config():\n    \"\"\"Base configuration for MettaGrid tests.\"\"\"\n    return {\n        \"max_steps\": 50,\n        \"num_agents\": 1,\n        \"obs_width\": OBS_WIDTH,",
        "detail": "mettagrid.tests.test_actions",
        "documentation": {}
    },
    {
        "label": "NUM_OBS_TOKENS",
        "kind": 5,
        "importPath": "mettagrid.tests.test_actions",
        "description": "mettagrid.tests.test_actions",
        "peekOfCode": "NUM_OBS_TOKENS = 100\nOBS_TOKEN_SIZE = 3\n@pytest.fixture\ndef base_config():\n    \"\"\"Base configuration for MettaGrid tests.\"\"\"\n    return {\n        \"max_steps\": 50,\n        \"num_agents\": 1,\n        \"obs_width\": OBS_WIDTH,\n        \"obs_height\": OBS_HEIGHT,",
        "detail": "mettagrid.tests.test_actions",
        "documentation": {}
    },
    {
        "label": "OBS_TOKEN_SIZE",
        "kind": 5,
        "importPath": "mettagrid.tests.test_actions",
        "description": "mettagrid.tests.test_actions",
        "peekOfCode": "OBS_TOKEN_SIZE = 3\n@pytest.fixture\ndef base_config():\n    \"\"\"Base configuration for MettaGrid tests.\"\"\"\n    return {\n        \"max_steps\": 50,\n        \"num_agents\": 1,\n        \"obs_width\": OBS_WIDTH,\n        \"obs_height\": OBS_HEIGHT,\n        \"num_observation_tokens\": NUM_OBS_TOKENS,",
        "detail": "mettagrid.tests.test_actions",
        "documentation": {}
    },
    {
        "label": "TestBuffers",
        "kind": 6,
        "importPath": "mettagrid.tests.test_buffers",
        "description": "mettagrid.tests.test_buffers",
        "peekOfCode": "class TestBuffers:\n    \"\"\"Comprehensive tests for MettaGrid buffer functionality.\"\"\"\n    def test_default_buffers_in_gym_mode(self):\n        \"\"\"Test that buffers work correctly in gym mode (without explicit set_buffers call).\"\"\"\n        c_env = create_minimal_mettagrid_c_env()\n        c_env.reset()\n        noop_action_idx = c_env.action_names().index(\"noop\")\n        actions = np.full((NUM_AGENTS, 2), [noop_action_idx, 0], dtype=dtype_actions)\n        obs, rewards, terminals, truncations, info = c_env.step(actions)\n        episode_rewards = c_env.get_episode_rewards()",
        "detail": "mettagrid.tests.test_buffers",
        "documentation": {}
    },
    {
        "label": "create_minimal_mettagrid_c_env",
        "kind": 2,
        "importPath": "mettagrid.tests.test_buffers",
        "description": "mettagrid.tests.test_buffers",
        "peekOfCode": "def create_minimal_mettagrid_c_env(max_steps=10, width=5, height=5, config_override=None):\n    \"\"\"Helper function to create a MettaGrid environment with minimal config.\n    Args:\n        max_steps: Maximum steps before truncation\n        width: Map width\n        height: Map height\n        config_override: Dictionary to override/merge with default config\n    \"\"\"\n    # Define a simple map: empty with walls around perimeter\n    game_map = np.full((height, width), \"empty\", dtype=\"<U50\")",
        "detail": "mettagrid.tests.test_buffers",
        "documentation": {}
    },
    {
        "label": "NUM_AGENTS",
        "kind": 5,
        "importPath": "mettagrid.tests.test_buffers",
        "description": "mettagrid.tests.test_buffers",
        "peekOfCode": "NUM_AGENTS = 2\nOBS_HEIGHT = 3\nOBS_WIDTH = 3\nNUM_OBS_TOKENS = 100\nOBS_TOKEN_SIZE = 3\ndef create_minimal_mettagrid_c_env(max_steps=10, width=5, height=5, config_override=None):\n    \"\"\"Helper function to create a MettaGrid environment with minimal config.\n    Args:\n        max_steps: Maximum steps before truncation\n        width: Map width",
        "detail": "mettagrid.tests.test_buffers",
        "documentation": {}
    },
    {
        "label": "OBS_HEIGHT",
        "kind": 5,
        "importPath": "mettagrid.tests.test_buffers",
        "description": "mettagrid.tests.test_buffers",
        "peekOfCode": "OBS_HEIGHT = 3\nOBS_WIDTH = 3\nNUM_OBS_TOKENS = 100\nOBS_TOKEN_SIZE = 3\ndef create_minimal_mettagrid_c_env(max_steps=10, width=5, height=5, config_override=None):\n    \"\"\"Helper function to create a MettaGrid environment with minimal config.\n    Args:\n        max_steps: Maximum steps before truncation\n        width: Map width\n        height: Map height",
        "detail": "mettagrid.tests.test_buffers",
        "documentation": {}
    },
    {
        "label": "OBS_WIDTH",
        "kind": 5,
        "importPath": "mettagrid.tests.test_buffers",
        "description": "mettagrid.tests.test_buffers",
        "peekOfCode": "OBS_WIDTH = 3\nNUM_OBS_TOKENS = 100\nOBS_TOKEN_SIZE = 3\ndef create_minimal_mettagrid_c_env(max_steps=10, width=5, height=5, config_override=None):\n    \"\"\"Helper function to create a MettaGrid environment with minimal config.\n    Args:\n        max_steps: Maximum steps before truncation\n        width: Map width\n        height: Map height\n        config_override: Dictionary to override/merge with default config",
        "detail": "mettagrid.tests.test_buffers",
        "documentation": {}
    },
    {
        "label": "NUM_OBS_TOKENS",
        "kind": 5,
        "importPath": "mettagrid.tests.test_buffers",
        "description": "mettagrid.tests.test_buffers",
        "peekOfCode": "NUM_OBS_TOKENS = 100\nOBS_TOKEN_SIZE = 3\ndef create_minimal_mettagrid_c_env(max_steps=10, width=5, height=5, config_override=None):\n    \"\"\"Helper function to create a MettaGrid environment with minimal config.\n    Args:\n        max_steps: Maximum steps before truncation\n        width: Map width\n        height: Map height\n        config_override: Dictionary to override/merge with default config\n    \"\"\"",
        "detail": "mettagrid.tests.test_buffers",
        "documentation": {}
    },
    {
        "label": "OBS_TOKEN_SIZE",
        "kind": 5,
        "importPath": "mettagrid.tests.test_buffers",
        "description": "mettagrid.tests.test_buffers",
        "peekOfCode": "OBS_TOKEN_SIZE = 3\ndef create_minimal_mettagrid_c_env(max_steps=10, width=5, height=5, config_override=None):\n    \"\"\"Helper function to create a MettaGrid environment with minimal config.\n    Args:\n        max_steps: Maximum steps before truncation\n        width: Map width\n        height: Map height\n        config_override: Dictionary to override/merge with default config\n    \"\"\"\n    # Define a simple map: empty with walls around perimeter",
        "detail": "mettagrid.tests.test_buffers",
        "documentation": {}
    },
    {
        "label": "env_cfg",
        "kind": 2,
        "importPath": "mettagrid.tests.test_curriculum",
        "description": "mettagrid.tests.test_curriculum",
        "peekOfCode": "def env_cfg():\n    return OmegaConf.create({\"sampling\": 0, \"game\": {\"num_agents\": 1, \"map\": {\"width\": 10, \"height\": 10}}})\ndef fake_curriculum_from_config_path(path, env_overrides=None):\n    base_config = OmegaConf.create({\"game\": {\"num_agents\": 5, \"map\": {\"width\": 10, \"height\": 10}}})\n    task_cfg = OmegaConf.merge(base_config, env_overrides or {})\n    assert isinstance(task_cfg, DictConfig)\n    return SingleTaskCurriculum(path, task_cfg=task_cfg)\ndef test_single_task_curriculum(env_cfg):\n    curr = SingleTaskCurriculum(\"task\", env_cfg)\n    task = curr.get_task()",
        "detail": "mettagrid.tests.test_curriculum",
        "documentation": {}
    },
    {
        "label": "fake_curriculum_from_config_path",
        "kind": 2,
        "importPath": "mettagrid.tests.test_curriculum",
        "description": "mettagrid.tests.test_curriculum",
        "peekOfCode": "def fake_curriculum_from_config_path(path, env_overrides=None):\n    base_config = OmegaConf.create({\"game\": {\"num_agents\": 5, \"map\": {\"width\": 10, \"height\": 10}}})\n    task_cfg = OmegaConf.merge(base_config, env_overrides or {})\n    assert isinstance(task_cfg, DictConfig)\n    return SingleTaskCurriculum(path, task_cfg=task_cfg)\ndef test_single_task_curriculum(env_cfg):\n    curr = SingleTaskCurriculum(\"task\", env_cfg)\n    task = curr.get_task()\n    assert task.id() == \"task\"\n    assert task.env_cfg() == env_cfg",
        "detail": "mettagrid.tests.test_curriculum",
        "documentation": {}
    },
    {
        "label": "test_single_task_curriculum",
        "kind": 2,
        "importPath": "mettagrid.tests.test_curriculum",
        "description": "mettagrid.tests.test_curriculum",
        "peekOfCode": "def test_single_task_curriculum(env_cfg):\n    curr = SingleTaskCurriculum(\"task\", env_cfg)\n    task = curr.get_task()\n    assert task.id() == \"task\"\n    assert task.env_cfg() == env_cfg\n    assert not task.is_complete()\n    task.complete(0.5)\n    assert task.is_complete()\n    with pytest.raises(AssertionError):\n        task.complete(0.1)",
        "detail": "mettagrid.tests.test_curriculum",
        "documentation": {}
    },
    {
        "label": "test_random_curriculum_selects_task",
        "kind": 2,
        "importPath": "mettagrid.tests.test_curriculum",
        "description": "mettagrid.tests.test_curriculum",
        "peekOfCode": "def test_random_curriculum_selects_task(monkeypatch, env_cfg):\n    monkeypatch.setattr(random, \"choices\", lambda population, weights: [\"b\"])\n    monkeypatch.setattr(\n        \"metta.mettagrid.curriculum.random.curriculum_from_config_path\", fake_curriculum_from_config_path\n    )\n    curr = RandomCurriculum({\"a\": 1.0, \"b\": 1.0}, OmegaConf.create({}))\n    task = curr.get_task()\n    assert task.id() == \"b\"\n    assert task.name() == \"b:b\"\ndef test_low_reward_curriculum_updates(monkeypatch, env_cfg):",
        "detail": "mettagrid.tests.test_curriculum",
        "documentation": {}
    },
    {
        "label": "test_low_reward_curriculum_updates",
        "kind": 2,
        "importPath": "mettagrid.tests.test_curriculum",
        "description": "mettagrid.tests.test_curriculum",
        "peekOfCode": "def test_low_reward_curriculum_updates(monkeypatch, env_cfg):\n    monkeypatch.setattr(\n        \"metta.mettagrid.curriculum.random.curriculum_from_config_path\", fake_curriculum_from_config_path\n    )\n    curr = LowRewardCurriculum({\"a\": 1.0, \"b\": 1.0}, OmegaConf.create({}))\n    curr.complete_task(\"a\", 0.1)\n    weight_after_a = curr._task_weights[\"a\"]\n    assert weight_after_a > curr._task_weights[\"b\"]\n    prev_b = curr._task_weights[\"b\"]\n    curr.complete_task(\"b\", 1.0)",
        "detail": "mettagrid.tests.test_curriculum",
        "documentation": {}
    },
    {
        "label": "test_sampling_curriculum",
        "kind": 2,
        "importPath": "mettagrid.tests.test_curriculum",
        "description": "mettagrid.tests.test_curriculum",
        "peekOfCode": "def test_sampling_curriculum(monkeypatch, env_cfg):\n    monkeypatch.setattr(\n        \"metta.mettagrid.curriculum.sampling.config_from_path\", lambda path, env_overrides=None: env_cfg\n    )\n    curr = SamplingCurriculum(\"dummy\")\n    t1 = curr.get_task()\n    t2 = curr.get_task()\n    assert t1.id() == \"sample(0)\"\n    assert t1.env_cfg().game.map.width == 10\n    assert t1.id() == t2.id()",
        "detail": "mettagrid.tests.test_curriculum",
        "documentation": {}
    },
    {
        "label": "test_progressive_curriculum",
        "kind": 2,
        "importPath": "mettagrid.tests.test_curriculum",
        "description": "mettagrid.tests.test_curriculum",
        "peekOfCode": "def test_progressive_curriculum(monkeypatch, env_cfg):\n    monkeypatch.setattr(\n        \"metta.mettagrid.curriculum.sampling.config_from_path\", lambda path, env_overrides=None: env_cfg\n    )\n    curr = ProgressiveCurriculum(\"dummy\")\n    t1 = curr.get_task()\n    assert t1.env_cfg().game.map.width == 10\n    curr.complete_task(t1.id(), 0.6)\n    t2 = curr.get_task()\n    assert t2.env_cfg().game.map.width == 20",
        "detail": "mettagrid.tests.test_curriculum",
        "documentation": {}
    },
    {
        "label": "test_bucketed_curriculum",
        "kind": 2,
        "importPath": "mettagrid.tests.test_curriculum",
        "description": "mettagrid.tests.test_curriculum",
        "peekOfCode": "def test_bucketed_curriculum(monkeypatch, env_cfg):\n    monkeypatch.setattr(\n        \"metta.mettagrid.curriculum.bucketed.config_from_path\", lambda path, env_overrides=None: env_cfg\n    )\n    buckets = {\n        \"game.map.width\": {\"values\": [5, 10]},\n        \"game.map.height\": {\"values\": [5, 10]},\n    }\n    curr = BucketedCurriculum(\"dummy\", buckets=buckets)\n    # There should be 4 tasks (2x2 grid)",
        "detail": "mettagrid.tests.test_curriculum",
        "documentation": {}
    },
    {
        "label": "test_expand_buckets_values_and_range",
        "kind": 2,
        "importPath": "mettagrid.tests.test_curriculum",
        "description": "mettagrid.tests.test_curriculum",
        "peekOfCode": "def test_expand_buckets_values_and_range():\n    buckets = {\n        \"param1\": {\"values\": [1, 2, 3]},\n        \"param2\": {\"range\": (0, 10), \"bins\": 2},\n    }\n    expanded = _expand_buckets(buckets)\n    # param1 should be a direct list\n    assert expanded[\"param1\"] == [1, 2, 3]\n    # param2 should be a list of 2 bins, each a dict with 'range' and 'want_int'\n    assert len(expanded[\"param2\"]) == 2",
        "detail": "mettagrid.tests.test_curriculum",
        "documentation": {}
    },
    {
        "label": "test_sampled_task_curriculum",
        "kind": 2,
        "importPath": "mettagrid.tests.test_curriculum",
        "description": "mettagrid.tests.test_curriculum",
        "peekOfCode": "def test_sampled_task_curriculum():\n    # Setup: one value bucket, one range bucket (int), one range bucket (float)\n    task_id = \"test_task\"\n    task_cfg_template = OmegaConf.create({\"param1\": None, \"param2\": None, \"param3\": None})\n    bucket_parameters = [\"param1\", \"param2\", \"param3\"]\n    bucket_values = [42, {\"range\": (0, 10), \"want_int\": True}, {\"range\": (0.0, 1.0)}]\n    curr = SampledTaskCurriculum(task_id, task_cfg_template, bucket_parameters, bucket_values)\n    task = curr.get_task()\n    assert task.id() == task_id\n    cfg = task.env_cfg()",
        "detail": "mettagrid.tests.test_curriculum",
        "documentation": {}
    },
    {
        "label": "test_multi_task_curriculum_completion_rates",
        "kind": 2,
        "importPath": "mettagrid.tests.test_curriculum",
        "description": "mettagrid.tests.test_curriculum",
        "peekOfCode": "def test_multi_task_curriculum_completion_rates(env_cfg):\n    # Dummy curriculum that returns a task with env_cfg\n    class DummyCurriculum:\n        def get_task(self):\n            class DummyTask:\n                def env_cfg(self):\n                    return env_cfg\n            return DummyTask()\n        def complete_task(self, id, score):\n            pass",
        "detail": "mettagrid.tests.test_curriculum",
        "documentation": {}
    },
    {
        "label": "test_calculate_diversity_bonus_simple_case",
        "kind": 2,
        "importPath": "mettagrid.tests.test_diversity",
        "description": "mettagrid.tests.test_diversity",
        "peekOfCode": "def test_calculate_diversity_bonus_simple_case():\n    episode_rewards = np.array([10.0, 12.0, 20.0, 22.0])\n    agent_groups = np.array([0, 0, 1, 1])\n    similarity_coef = 0.1\n    diversity_coef = 0.2\n    actual_factors = calculate_diversity_bonus(episode_rewards, agent_groups, similarity_coef, diversity_coef)\n    # Group 0: rewards [10, 12], mean = 11, std = 1\n    # Group 1: rewards [20, 22], mean = 21, std = 1\n    exp_m_1 = np.exp(-1)\n    exp_m_9 = np.exp(-9)",
        "detail": "mettagrid.tests.test_diversity",
        "documentation": {}
    },
    {
        "label": "test_calculate_diversity_bonus_single_group",
        "kind": 2,
        "importPath": "mettagrid.tests.test_diversity",
        "description": "mettagrid.tests.test_diversity",
        "peekOfCode": "def test_calculate_diversity_bonus_single_group():\n    episode_rewards = np.array([10.0, 12.0, 11.0])\n    agent_groups = np.array([0, 0, 0])\n    similarity_coef = 0.1\n    diversity_coef = 0.2\n    # Group 0: rewards [10, 12, 11], mean = 11, std = sqrt(2/3)\n    std_g0 = np.sqrt(2 / 3)\n    sim_score_agent0 = np.exp(-1 / std_g0)\n    sim_score_agent1 = np.exp(-1 / std_g0)\n    sim_score_agent2 = 1.0",
        "detail": "mettagrid.tests.test_diversity",
        "documentation": {}
    },
    {
        "label": "test_calculate_diversity_bonus_zero_coefficients",
        "kind": 2,
        "importPath": "mettagrid.tests.test_diversity",
        "description": "mettagrid.tests.test_diversity",
        "peekOfCode": "def test_calculate_diversity_bonus_zero_coefficients():\n    episode_rewards = np.array([10.0, 12.0, 20.0, 22.0])\n    agent_groups = np.array([0, 0, 1, 1])\n    similarity_coef = 0.0\n    diversity_coef = 0.0\n    # If both coeffs are 0, the factor should be 1 for all agents\n    expected_factors = np.array([1.0, 1.0, 1.0, 1.0])\n    actual_factors = calculate_diversity_bonus(episode_rewards, agent_groups, similarity_coef, diversity_coef)\n    np.testing.assert_allclose(actual_factors, expected_factors, rtol=1e-6)\ndef test_calculate_diversity_bonus_identical_rewards_in_group():",
        "detail": "mettagrid.tests.test_diversity",
        "documentation": {}
    },
    {
        "label": "test_calculate_diversity_bonus_identical_rewards_in_group",
        "kind": 2,
        "importPath": "mettagrid.tests.test_diversity",
        "description": "mettagrid.tests.test_diversity",
        "peekOfCode": "def test_calculate_diversity_bonus_identical_rewards_in_group():\n    episode_rewards = np.array([10.0, 10.0, 20.0, 20.0])\n    agent_groups = np.array([0, 0, 1, 1])\n    similarity_coef = 0.1\n    diversity_coef = 0.2\n    # Group 0: rewards [10, 10], mean = 10, std = 1e-6 (due to epsilon)\n    # Group 1: rewards [20, 20], mean = 20, std = 1e-6\n    # Similarity score for all agents is 1 (exp(0)).\n    # Diversity value for group 0 agents (to group 1) is 1 - exp(-10/1e-6) -> approx 1.\n    # Diversity value for group 1 agents (to group 0) is 1 - exp(-10/1e-6) -> approx 1.",
        "detail": "mettagrid.tests.test_diversity",
        "documentation": {}
    },
    {
        "label": "test_calculate_diversity_bonus_three_groups",
        "kind": 2,
        "importPath": "mettagrid.tests.test_diversity",
        "description": "mettagrid.tests.test_diversity",
        "peekOfCode": "def test_calculate_diversity_bonus_three_groups():\n    episode_rewards = np.array(\n        [\n            10.0,\n            15.0,  # Group 0\n            20.0,\n            25.0,  # Group 1\n            30.0,\n            35.0,\n        ]",
        "detail": "mettagrid.tests.test_diversity",
        "documentation": {}
    },
    {
        "label": "test_zero_total_diversity_score_when_agent_reward_equals_all_other_group_means",
        "kind": 2,
        "importPath": "mettagrid.tests.test_diversity",
        "description": "mettagrid.tests.test_diversity",
        "peekOfCode": "def test_zero_total_diversity_score_when_agent_reward_equals_all_other_group_means():\n    \"\"\"Agent's diversity score is 0 if its reward matches all other group means.\"\"\"\n    episode_rewards = np.array(\n        [\n            25.0,\n            15.0,  # Group 0: Agent 0 (reward 25), Agent 1 (reward 15). Mean G0 = 20. Std G0 = 5.\n            20.0,\n            30.0,  # Group 1: Agents 2,3. Mean G1 = 25. Std G1 = 5.\n            22.0,\n            28.0,  # Group 2: Agents 4,5. Mean G2 = 25. Std G2 = 3.",
        "detail": "mettagrid.tests.test_diversity",
        "documentation": {}
    },
    {
        "label": "test_env_map",
        "kind": 2,
        "importPath": "mettagrid.tests.test_env_map",
        "description": "mettagrid.tests.test_env_map",
        "peekOfCode": "def test_env_map():\n    cfg = get_cfg(\"benchmark\")\n    del cfg.game.map_builder\n    cfg.game.num_agents = 1\n    # Create a level with one agent\n    level_builder = Random(width=3, height=4, objects=OmegaConf.create({}), agents=1, border_width=1)\n    level = level_builder.build()\n    curriculum = SingleTaskCurriculum(\"benchmark\", cfg)\n    env = MettaGridEnv(curriculum, render_mode=\"human\", level=level)\n    assert env.map_width == 3 + 2 * 1",
        "detail": "mettagrid.tests.test_env_map",
        "documentation": {}
    },
    {
        "label": "cfg",
        "kind": 2,
        "importPath": "mettagrid.tests.test_leaks",
        "description": "mettagrid.tests.test_leaks",
        "peekOfCode": "def cfg():\n    # Initialize Hydra with the correct relative path\n    with initialize(version_base=None, config_path=\"../configs\"):\n        # Load the default config\n        cfg = compose(config_name=\"test_basic\")\n        yield cfg\ndef test_mettagrid_env_init(cfg):\n    \"\"\"Test that the MettaGridEnv can be initialized properly.\"\"\"\n    curriculum = SingleTaskCurriculum(\"test\", cfg)\n    env = MettaGridEnv(curriculum, render_mode=None)",
        "detail": "mettagrid.tests.test_leaks",
        "documentation": {}
    },
    {
        "label": "test_mettagrid_env_init",
        "kind": 2,
        "importPath": "mettagrid.tests.test_leaks",
        "description": "mettagrid.tests.test_leaks",
        "peekOfCode": "def test_mettagrid_env_init(cfg):\n    \"\"\"Test that the MettaGridEnv can be initialized properly.\"\"\"\n    curriculum = SingleTaskCurriculum(\"test\", cfg)\n    env = MettaGridEnv(curriculum, render_mode=None)\n    assert env is not None, \"Failed to initialize MettaGridEnv\"\ndef test_mettagrid_env_reset(cfg):\n    \"\"\"Test that the MettaGridEnv can be reset multiple times without memory leaks.\"\"\"\n    curriculum = SingleTaskCurriculum(\"test\", cfg)\n    env = MettaGridEnv(curriculum, render_mode=None)\n    # Reset the environment multiple times",
        "detail": "mettagrid.tests.test_leaks",
        "documentation": {}
    },
    {
        "label": "test_mettagrid_env_reset",
        "kind": 2,
        "importPath": "mettagrid.tests.test_leaks",
        "description": "mettagrid.tests.test_leaks",
        "peekOfCode": "def test_mettagrid_env_reset(cfg):\n    \"\"\"Test that the MettaGridEnv can be reset multiple times without memory leaks.\"\"\"\n    curriculum = SingleTaskCurriculum(\"test\", cfg)\n    env = MettaGridEnv(curriculum, render_mode=None)\n    # Reset the environment multiple times\n    for _ in range(10):\n        observation = env.reset()\n        assert observation is not None, \"Reset should return a valid observation\"\ndef get_memory_usage():\n    \"\"\"Get the current memory usage of the Python process in MB.\"\"\"",
        "detail": "mettagrid.tests.test_leaks",
        "documentation": {}
    },
    {
        "label": "get_memory_usage",
        "kind": 2,
        "importPath": "mettagrid.tests.test_leaks",
        "description": "mettagrid.tests.test_leaks",
        "peekOfCode": "def get_memory_usage():\n    \"\"\"Get the current memory usage of the Python process in MB.\"\"\"\n    process = psutil.Process(os.getpid())\n    return process.memory_info().rss / (1024 * 1024)  # Convert to MB\ndef test_mettagrid_env_no_memory_leaks(cfg):\n    \"\"\"\n    Test that the MettaGridEnv can be reset multiple times without memory leaks.\n    This test creates and destroys an environment object after multiple resets\n    to verify that no memory leaks occur during this process.\n    \"\"\"",
        "detail": "mettagrid.tests.test_leaks",
        "documentation": {}
    },
    {
        "label": "test_mettagrid_env_no_memory_leaks",
        "kind": 2,
        "importPath": "mettagrid.tests.test_leaks",
        "description": "mettagrid.tests.test_leaks",
        "peekOfCode": "def test_mettagrid_env_no_memory_leaks(cfg):\n    \"\"\"\n    Test that the MettaGridEnv can be reset multiple times without memory leaks.\n    This test creates and destroys an environment object after multiple resets\n    to verify that no memory leaks occur during this process.\n    \"\"\"\n    # Force garbage collection before starting\n    gc.collect()\n    # Get initial memory usage\n    initial_memory = get_memory_usage()",
        "detail": "mettagrid.tests.test_leaks",
        "documentation": {}
    },
    {
        "label": "TestObservations",
        "kind": 6,
        "importPath": "mettagrid.tests.test_mettagrid",
        "description": "mettagrid.tests.test_mettagrid",
        "peekOfCode": "class TestObservations:\n    \"\"\"Test observation functionality and formats.\"\"\"\n    def test_observation_tokens(self):\n        \"\"\"Test observation token format and content.\"\"\"\n        c_env = create_minimal_mettagrid_c_env()\n        # These come from constants in the C++ code, and are fragile.\n        TYPE_ID_FEATURE = 0\n        WALL_TYPE_ID = 1\n        obs, _info = c_env.reset()\n        # Agent 0 starts at (1,1) and should see walls above and to the left",
        "detail": "mettagrid.tests.test_mettagrid",
        "documentation": {}
    },
    {
        "label": "TestGlobalTokens",
        "kind": 6,
        "importPath": "mettagrid.tests.test_mettagrid",
        "description": "mettagrid.tests.test_mettagrid",
        "peekOfCode": "class TestGlobalTokens:\n    \"\"\"Test global token functionality and formats.\"\"\"\n    def test_global_tokens(self):\n        \"\"\"Test global token format and content.\"\"\"\n        max_steps = 10\n        c_env = create_minimal_mettagrid_c_env(max_steps=max_steps)\n        obs, _info = c_env.reset()\n        # These come from constants in the C++ code\n        EPISODE_COMPLETION_PCT = 8\n        LAST_ACTION = 9",
        "detail": "mettagrid.tests.test_mettagrid",
        "documentation": {}
    },
    {
        "label": "create_minimal_mettagrid_c_env",
        "kind": 2,
        "importPath": "mettagrid.tests.test_mettagrid",
        "description": "mettagrid.tests.test_mettagrid",
        "peekOfCode": "def create_minimal_mettagrid_c_env(max_steps=10, width=5, height=5):\n    \"\"\"Helper function to create a MettaGrid environment with minimal config.\"\"\"\n    # Define a simple map: empty with walls around perimeter\n    game_map = np.full((height, width), \"empty\", dtype=\"<U50\")\n    game_map[0, :] = \"wall\"\n    game_map[-1, :] = \"wall\"\n    game_map[:, 0] = \"wall\"\n    game_map[:, -1] = \"wall\"\n    # Place first agent in upper left\n    game_map[1, 1] = \"agent.red\"",
        "detail": "mettagrid.tests.test_mettagrid",
        "documentation": {}
    },
    {
        "label": "test_grid_hash",
        "kind": 2,
        "importPath": "mettagrid.tests.test_mettagrid",
        "description": "mettagrid.tests.test_mettagrid",
        "peekOfCode": "def test_grid_hash():\n    \"\"\"Test grid object representation and properties.\"\"\"\n    c_env = create_minimal_mettagrid_c_env()\n    assert c_env.initial_grid_hash == 8082132383455666218\ndef test_truncation_at_max_steps():\n    \"\"\"Test that environments properly truncate at max_steps.\"\"\"\n    max_steps = 5\n    c_env = create_minimal_mettagrid_c_env(max_steps=max_steps)\n    _obs, _info = c_env.reset()\n    # Noop until time runs out",
        "detail": "mettagrid.tests.test_mettagrid",
        "documentation": {}
    },
    {
        "label": "test_truncation_at_max_steps",
        "kind": 2,
        "importPath": "mettagrid.tests.test_mettagrid",
        "description": "mettagrid.tests.test_mettagrid",
        "peekOfCode": "def test_truncation_at_max_steps():\n    \"\"\"Test that environments properly truncate at max_steps.\"\"\"\n    max_steps = 5\n    c_env = create_minimal_mettagrid_c_env(max_steps=max_steps)\n    _obs, _info = c_env.reset()\n    # Noop until time runs out\n    noop_action_idx = c_env.action_names().index(\"noop\")\n    actions = np.full((NUM_AGENTS, 2), [noop_action_idx, 0], dtype=dtype_actions)\n    for step_num in range(1, max_steps + 1):\n        _obs, _rewards, terminals, truncations, _info = c_env.step(actions)",
        "detail": "mettagrid.tests.test_mettagrid",
        "documentation": {}
    },
    {
        "label": "test_grid_objects",
        "kind": 2,
        "importPath": "mettagrid.tests.test_mettagrid",
        "description": "mettagrid.tests.test_mettagrid",
        "peekOfCode": "def test_grid_objects():\n    \"\"\"Test grid object representation and properties.\"\"\"\n    c_env = create_minimal_mettagrid_c_env()\n    objects = c_env.grid_objects()\n    # Test that we have the expected number of objects\n    # 4 walls on each side (minus corners) + 2 agents\n    expected_walls = 2 * (c_env.map_width + c_env.map_height - 2)\n    expected_agents = 2\n    assert len(objects) == expected_walls + expected_agents, \"Wrong number of objects\"\n    common_properties = {\"r\", \"c\", \"layer\", \"type\", \"id\"}",
        "detail": "mettagrid.tests.test_mettagrid",
        "documentation": {}
    },
    {
        "label": "test_environment_initialization",
        "kind": 2,
        "importPath": "mettagrid.tests.test_mettagrid",
        "description": "mettagrid.tests.test_mettagrid",
        "peekOfCode": "def test_environment_initialization():\n    \"\"\"Test basic environment initialization and configuration.\"\"\"\n    c_env = create_minimal_mettagrid_c_env()\n    # Test basic properties\n    assert c_env.map_width == 5, \"Map width should be 5\"\n    assert c_env.map_height == 5, \"Map height should be 5\"\n    assert len(c_env.action_names()) > 0, \"Should have available actions\"\n    assert len(c_env.feature_normalizations()) > 0, \"Should have feature normalizations\"\n    # Test reset functionality\n    obs, info = c_env.reset()",
        "detail": "mettagrid.tests.test_mettagrid",
        "documentation": {}
    },
    {
        "label": "test_action_interface",
        "kind": 2,
        "importPath": "mettagrid.tests.test_mettagrid",
        "description": "mettagrid.tests.test_mettagrid",
        "peekOfCode": "def test_action_interface():\n    \"\"\"Test action interface and basic action execution.\"\"\"\n    c_env = create_minimal_mettagrid_c_env()\n    c_env.reset()\n    # Test action names\n    action_names = c_env.action_names()\n    assert \"noop\" in action_names, \"Noop action should be available\"\n    assert \"move\" in action_names, \"Move action should be available\"\n    assert \"rotate\" in action_names, \"Rotate action should be available\"\n    # Test basic action execution",
        "detail": "mettagrid.tests.test_mettagrid",
        "documentation": {}
    },
    {
        "label": "test_environment_state_consistency",
        "kind": 2,
        "importPath": "mettagrid.tests.test_mettagrid",
        "description": "mettagrid.tests.test_mettagrid",
        "peekOfCode": "def test_environment_state_consistency():\n    \"\"\"Test that environment state remains consistent across operations.\"\"\"\n    c_env = create_minimal_mettagrid_c_env()\n    # Initial state\n    _obs1, _info1 = c_env.reset()\n    initial_objects = c_env.grid_objects()\n    # Take a noop action (should not change world state significantly)\n    noop_action_idx = c_env.action_names().index(\"noop\")\n    actions = np.full((NUM_AGENTS, 2), [noop_action_idx, 0], dtype=dtype_actions)\n    _obs2, _rewards, _terminals, _truncations, _info2 = c_env.step(actions)",
        "detail": "mettagrid.tests.test_mettagrid",
        "documentation": {}
    },
    {
        "label": "NUM_AGENTS",
        "kind": 5,
        "importPath": "mettagrid.tests.test_mettagrid",
        "description": "mettagrid.tests.test_mettagrid",
        "peekOfCode": "NUM_AGENTS = 2\nOBS_HEIGHT = 3\nOBS_WIDTH = 3\nNUM_OBS_TOKENS = 100\nOBS_TOKEN_SIZE = 3\ndef create_minimal_mettagrid_c_env(max_steps=10, width=5, height=5):\n    \"\"\"Helper function to create a MettaGrid environment with minimal config.\"\"\"\n    # Define a simple map: empty with walls around perimeter\n    game_map = np.full((height, width), \"empty\", dtype=\"<U50\")\n    game_map[0, :] = \"wall\"",
        "detail": "mettagrid.tests.test_mettagrid",
        "documentation": {}
    },
    {
        "label": "OBS_HEIGHT",
        "kind": 5,
        "importPath": "mettagrid.tests.test_mettagrid",
        "description": "mettagrid.tests.test_mettagrid",
        "peekOfCode": "OBS_HEIGHT = 3\nOBS_WIDTH = 3\nNUM_OBS_TOKENS = 100\nOBS_TOKEN_SIZE = 3\ndef create_minimal_mettagrid_c_env(max_steps=10, width=5, height=5):\n    \"\"\"Helper function to create a MettaGrid environment with minimal config.\"\"\"\n    # Define a simple map: empty with walls around perimeter\n    game_map = np.full((height, width), \"empty\", dtype=\"<U50\")\n    game_map[0, :] = \"wall\"\n    game_map[-1, :] = \"wall\"",
        "detail": "mettagrid.tests.test_mettagrid",
        "documentation": {}
    },
    {
        "label": "OBS_WIDTH",
        "kind": 5,
        "importPath": "mettagrid.tests.test_mettagrid",
        "description": "mettagrid.tests.test_mettagrid",
        "peekOfCode": "OBS_WIDTH = 3\nNUM_OBS_TOKENS = 100\nOBS_TOKEN_SIZE = 3\ndef create_minimal_mettagrid_c_env(max_steps=10, width=5, height=5):\n    \"\"\"Helper function to create a MettaGrid environment with minimal config.\"\"\"\n    # Define a simple map: empty with walls around perimeter\n    game_map = np.full((height, width), \"empty\", dtype=\"<U50\")\n    game_map[0, :] = \"wall\"\n    game_map[-1, :] = \"wall\"\n    game_map[:, 0] = \"wall\"",
        "detail": "mettagrid.tests.test_mettagrid",
        "documentation": {}
    },
    {
        "label": "NUM_OBS_TOKENS",
        "kind": 5,
        "importPath": "mettagrid.tests.test_mettagrid",
        "description": "mettagrid.tests.test_mettagrid",
        "peekOfCode": "NUM_OBS_TOKENS = 100\nOBS_TOKEN_SIZE = 3\ndef create_minimal_mettagrid_c_env(max_steps=10, width=5, height=5):\n    \"\"\"Helper function to create a MettaGrid environment with minimal config.\"\"\"\n    # Define a simple map: empty with walls around perimeter\n    game_map = np.full((height, width), \"empty\", dtype=\"<U50\")\n    game_map[0, :] = \"wall\"\n    game_map[-1, :] = \"wall\"\n    game_map[:, 0] = \"wall\"\n    game_map[:, -1] = \"wall\"",
        "detail": "mettagrid.tests.test_mettagrid",
        "documentation": {}
    },
    {
        "label": "OBS_TOKEN_SIZE",
        "kind": 5,
        "importPath": "mettagrid.tests.test_mettagrid",
        "description": "mettagrid.tests.test_mettagrid",
        "peekOfCode": "OBS_TOKEN_SIZE = 3\ndef create_minimal_mettagrid_c_env(max_steps=10, width=5, height=5):\n    \"\"\"Helper function to create a MettaGrid environment with minimal config.\"\"\"\n    # Define a simple map: empty with walls around perimeter\n    game_map = np.full((height, width), \"empty\", dtype=\"<U50\")\n    game_map[0, :] = \"wall\"\n    game_map[-1, :] = \"wall\"\n    game_map[:, 0] = \"wall\"\n    game_map[:, -1] = \"wall\"\n    # Place first agent in upper left",
        "detail": "mettagrid.tests.test_mettagrid",
        "documentation": {}
    },
    {
        "label": "test_invalid_env_map_type_raises",
        "kind": 2,
        "importPath": "mettagrid.tests.test_mettagrid_env",
        "description": "mettagrid.tests.test_mettagrid_env",
        "peekOfCode": "def test_invalid_env_map_type_raises():\n    cfg = OmegaConf.create({})\n    curriculum = SingleTaskCurriculum(\"test\", cfg)\n    with pytest.raises(ConfigAttributeError):\n        MettaGridEnv(curriculum, render_mode=None, env_map={})\ndef test_invalid_env_cfg_type_raises():\n    with pytest.raises(ValidationError):\n        MettaGridEnv({}, render_mode=None)",
        "detail": "mettagrid.tests.test_mettagrid_env",
        "documentation": {}
    },
    {
        "label": "test_invalid_env_cfg_type_raises",
        "kind": 2,
        "importPath": "mettagrid.tests.test_mettagrid_env",
        "description": "mettagrid.tests.test_mettagrid_env",
        "peekOfCode": "def test_invalid_env_cfg_type_raises():\n    with pytest.raises(ValidationError):\n        MettaGridEnv({}, render_mode=None)",
        "detail": "mettagrid.tests.test_mettagrid_env",
        "documentation": {}
    },
    {
        "label": "TestRewards",
        "kind": 6,
        "importPath": "mettagrid.tests.test_rewards",
        "description": "mettagrid.tests.test_rewards",
        "peekOfCode": "class TestRewards:\n    def test_step_rewards_initialization(self):\n        \"\"\"Test that step rewards are properly initialized to zero.\"\"\"\n        env = create_reward_test_env()\n        # Create buffers\n        observations = np.zeros((NUM_AGENTS, NUM_OBS_TOKENS, OBS_TOKEN_SIZE), dtype=dtype_observations)\n        terminals = np.zeros(NUM_AGENTS, dtype=dtype_terminals)\n        truncations = np.zeros(NUM_AGENTS, dtype=dtype_truncations)\n        rewards = np.zeros(NUM_AGENTS, dtype=dtype_rewards)\n        env.set_buffers(observations, terminals, truncations, rewards)",
        "detail": "mettagrid.tests.test_rewards",
        "documentation": {}
    },
    {
        "label": "create_heart_reward_test_env",
        "kind": 2,
        "importPath": "mettagrid.tests.test_rewards",
        "description": "mettagrid.tests.test_rewards",
        "peekOfCode": "def create_heart_reward_test_env(max_steps=50, num_agents=NUM_AGENTS):\n    \"\"\"Helper function to create a MettaGrid environment with heart collection for reward testing.\"\"\"\n    # Create a simple map with agent, altar, and walls\n    game_map = [\n        [\"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\"],\n        [\"wall\", \"agent.red\", \"empty\", \"altar\", \"empty\", \"wall\"],\n        [\"wall\", \"empty\", \"empty\", \"empty\", \"empty\", \"wall\"],\n        [\"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\"],\n    ]\n    game_config = {",
        "detail": "mettagrid.tests.test_rewards",
        "documentation": {}
    },
    {
        "label": "create_reward_test_env",
        "kind": 2,
        "importPath": "mettagrid.tests.test_rewards",
        "description": "mettagrid.tests.test_rewards",
        "peekOfCode": "def create_reward_test_env(max_steps=10, width=5, height=5, num_agents=NUM_AGENTS):\n    \"\"\"Helper function to create a basic MettaGrid environment for reward testing.\"\"\"\n    # Define a simple map with walls and agents\n    game_map = np.full((height, width), \"empty\", dtype=\"<U50\")\n    game_map[0, :] = \"wall\"\n    game_map[-1, :] = \"wall\"\n    game_map[:, 0] = \"wall\"\n    game_map[:, -1] = \"wall\"\n    # Place agents\n    for i in range(num_agents):",
        "detail": "mettagrid.tests.test_rewards",
        "documentation": {}
    },
    {
        "label": "perform_action",
        "kind": 2,
        "importPath": "mettagrid.tests.test_rewards",
        "description": "mettagrid.tests.test_rewards",
        "peekOfCode": "def perform_action(env, action_name, arg=0):\n    \"\"\"Perform a single action and return results.\"\"\"\n    available_actions = env.action_names()\n    if action_name not in available_actions:\n        raise ValueError(f\"Unknown action '{action_name}'. Available actions: {available_actions}\")\n    action_idx = available_actions.index(action_name)\n    action = np.zeros((NUM_AGENTS, 2), dtype=dtype_actions)\n    action[0] = [action_idx, arg]\n    obs, rewards, terminals, truncations, info = env.step(action)\n    return obs, float(rewards[0]), env.action_success()[0]",
        "detail": "mettagrid.tests.test_rewards",
        "documentation": {}
    },
    {
        "label": "wait_for_heart_production",
        "kind": 2,
        "importPath": "mettagrid.tests.test_rewards",
        "description": "mettagrid.tests.test_rewards",
        "peekOfCode": "def wait_for_heart_production(env, steps=5):\n    \"\"\"Wait for altar to produce hearts by performing noop actions.\"\"\"\n    for _ in range(steps):\n        perform_action(env, \"noop\")\ndef collect_heart_from_altar(env):\n    \"\"\"Move agent to altar (if needed) and collect a heart. Returns (success, reward).\"\"\"\n    agent_pos = get_agent_position(env, 0)\n    _altar_pos = (1, 3)  # Known altar position\n    target_pos = (1, 2)  # Adjacent position to altar\n    # Only move if not already in the correct position",
        "detail": "mettagrid.tests.test_rewards",
        "documentation": {}
    },
    {
        "label": "collect_heart_from_altar",
        "kind": 2,
        "importPath": "mettagrid.tests.test_rewards",
        "description": "mettagrid.tests.test_rewards",
        "peekOfCode": "def collect_heart_from_altar(env):\n    \"\"\"Move agent to altar (if needed) and collect a heart. Returns (success, reward).\"\"\"\n    agent_pos = get_agent_position(env, 0)\n    _altar_pos = (1, 3)  # Known altar position\n    target_pos = (1, 2)  # Adjacent position to altar\n    # Only move if not already in the correct position\n    if agent_pos != target_pos:\n        move_result = move(env, Orientation.RIGHT, agent_idx=0)\n        if not move_result[\"success\"]:\n            return False, 0.0",
        "detail": "mettagrid.tests.test_rewards",
        "documentation": {}
    },
    {
        "label": "NUM_AGENTS",
        "kind": 5,
        "importPath": "mettagrid.tests.test_rewards",
        "description": "mettagrid.tests.test_rewards",
        "peekOfCode": "NUM_AGENTS = 1\nOBS_HEIGHT = 3\nOBS_WIDTH = 3\nNUM_OBS_TOKENS = 100\nOBS_TOKEN_SIZE = 3\ndef create_heart_reward_test_env(max_steps=50, num_agents=NUM_AGENTS):\n    \"\"\"Helper function to create a MettaGrid environment with heart collection for reward testing.\"\"\"\n    # Create a simple map with agent, altar, and walls\n    game_map = [\n        [\"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\"],",
        "detail": "mettagrid.tests.test_rewards",
        "documentation": {}
    },
    {
        "label": "OBS_HEIGHT",
        "kind": 5,
        "importPath": "mettagrid.tests.test_rewards",
        "description": "mettagrid.tests.test_rewards",
        "peekOfCode": "OBS_HEIGHT = 3\nOBS_WIDTH = 3\nNUM_OBS_TOKENS = 100\nOBS_TOKEN_SIZE = 3\ndef create_heart_reward_test_env(max_steps=50, num_agents=NUM_AGENTS):\n    \"\"\"Helper function to create a MettaGrid environment with heart collection for reward testing.\"\"\"\n    # Create a simple map with agent, altar, and walls\n    game_map = [\n        [\"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\"],\n        [\"wall\", \"agent.red\", \"empty\", \"altar\", \"empty\", \"wall\"],",
        "detail": "mettagrid.tests.test_rewards",
        "documentation": {}
    },
    {
        "label": "OBS_WIDTH",
        "kind": 5,
        "importPath": "mettagrid.tests.test_rewards",
        "description": "mettagrid.tests.test_rewards",
        "peekOfCode": "OBS_WIDTH = 3\nNUM_OBS_TOKENS = 100\nOBS_TOKEN_SIZE = 3\ndef create_heart_reward_test_env(max_steps=50, num_agents=NUM_AGENTS):\n    \"\"\"Helper function to create a MettaGrid environment with heart collection for reward testing.\"\"\"\n    # Create a simple map with agent, altar, and walls\n    game_map = [\n        [\"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\"],\n        [\"wall\", \"agent.red\", \"empty\", \"altar\", \"empty\", \"wall\"],\n        [\"wall\", \"empty\", \"empty\", \"empty\", \"empty\", \"wall\"],",
        "detail": "mettagrid.tests.test_rewards",
        "documentation": {}
    },
    {
        "label": "NUM_OBS_TOKENS",
        "kind": 5,
        "importPath": "mettagrid.tests.test_rewards",
        "description": "mettagrid.tests.test_rewards",
        "peekOfCode": "NUM_OBS_TOKENS = 100\nOBS_TOKEN_SIZE = 3\ndef create_heart_reward_test_env(max_steps=50, num_agents=NUM_AGENTS):\n    \"\"\"Helper function to create a MettaGrid environment with heart collection for reward testing.\"\"\"\n    # Create a simple map with agent, altar, and walls\n    game_map = [\n        [\"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\"],\n        [\"wall\", \"agent.red\", \"empty\", \"altar\", \"empty\", \"wall\"],\n        [\"wall\", \"empty\", \"empty\", \"empty\", \"empty\", \"wall\"],\n        [\"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\"],",
        "detail": "mettagrid.tests.test_rewards",
        "documentation": {}
    },
    {
        "label": "OBS_TOKEN_SIZE",
        "kind": 5,
        "importPath": "mettagrid.tests.test_rewards",
        "description": "mettagrid.tests.test_rewards",
        "peekOfCode": "OBS_TOKEN_SIZE = 3\ndef create_heart_reward_test_env(max_steps=50, num_agents=NUM_AGENTS):\n    \"\"\"Helper function to create a MettaGrid environment with heart collection for reward testing.\"\"\"\n    # Create a simple map with agent, altar, and walls\n    game_map = [\n        [\"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\"],\n        [\"wall\", \"agent.red\", \"empty\", \"altar\", \"empty\", \"wall\"],\n        [\"wall\", \"empty\", \"empty\", \"empty\", \"empty\", \"wall\"],\n        [\"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\"],\n    ]",
        "detail": "mettagrid.tests.test_rewards",
        "documentation": {}
    },
    {
        "label": "temp_dir",
        "kind": 2,
        "importPath": "mettagrid.tests.test_stats_writer",
        "description": "mettagrid.tests.test_stats_writer",
        "peekOfCode": "def temp_dir():\n    \"\"\"Create a temporary directory for test files.\"\"\"\n    with tempfile.TemporaryDirectory() as tmpdirname:\n        yield Path(tmpdirname)\ndef test_stats_writer_initialization(temp_dir):\n    \"\"\"Test that StatsWriter initializes correctly.\"\"\"\n    writer = StatsWriter(temp_dir)\n    assert writer.dir == temp_dir\n    assert writer.db is None  # Database should be created on demand\ndef test_ensure_db(temp_dir):",
        "detail": "mettagrid.tests.test_stats_writer",
        "documentation": {}
    },
    {
        "label": "test_stats_writer_initialization",
        "kind": 2,
        "importPath": "mettagrid.tests.test_stats_writer",
        "description": "mettagrid.tests.test_stats_writer",
        "peekOfCode": "def test_stats_writer_initialization(temp_dir):\n    \"\"\"Test that StatsWriter initializes correctly.\"\"\"\n    writer = StatsWriter(temp_dir)\n    assert writer.dir == temp_dir\n    assert writer.db is None  # Database should be created on demand\ndef test_ensure_db(temp_dir):\n    \"\"\"Test that _ensure_db creates a database when needed.\"\"\"\n    writer = StatsWriter(temp_dir)\n    writer._ensure_db()\n    assert writer.db is not None",
        "detail": "mettagrid.tests.test_stats_writer",
        "documentation": {}
    },
    {
        "label": "test_ensure_db",
        "kind": 2,
        "importPath": "mettagrid.tests.test_stats_writer",
        "description": "mettagrid.tests.test_stats_writer",
        "peekOfCode": "def test_ensure_db(temp_dir):\n    \"\"\"Test that _ensure_db creates a database when needed.\"\"\"\n    writer = StatsWriter(temp_dir)\n    writer._ensure_db()\n    assert writer.db is not None\n    assert isinstance(writer.db, EpisodeStatsDB)\n    # Check that the database file exists\n    db_files = list(temp_dir.glob(\"*.duckdb\"))\n    assert len(db_files) == 1\n    writer.close()",
        "detail": "mettagrid.tests.test_stats_writer",
        "documentation": {}
    },
    {
        "label": "test_episode_lifecycle",
        "kind": 2,
        "importPath": "mettagrid.tests.test_stats_writer",
        "description": "mettagrid.tests.test_stats_writer",
        "peekOfCode": "def test_episode_lifecycle(temp_dir):\n    \"\"\"Test the full lifecycle of an episode.\"\"\"\n    writer = StatsWriter(temp_dir)\n    # Create episode ID\n    episode_id = str(uuid.uuid4())\n    # Episode attributes\n    attributes = {\"seed\": \"12345\", \"map_w\": \"10\", \"map_h\": \"20\", \"meta\": '{\"key\": \"value\"}'}\n    # Metrics\n    agent_metrics = {0: {\"reward\": 10.5, \"steps\": 50.0}, 1: {\"reward\": 8.2, \"steps\": 45.0}}\n    agent_groups = {0: 0, 1: 1}",
        "detail": "mettagrid.tests.test_stats_writer",
        "documentation": {}
    },
    {
        "label": "test_close_without_db",
        "kind": 2,
        "importPath": "mettagrid.tests.test_stats_writer",
        "description": "mettagrid.tests.test_stats_writer",
        "peekOfCode": "def test_close_without_db(temp_dir):\n    \"\"\"Test calling close() on a StatsWriter that hasn't created a DB yet.\"\"\"\n    writer = StatsWriter(temp_dir)\n    assert writer.db is None\n    # This should not raise an error\n    writer.close()\n    assert writer.db is None",
        "detail": "mettagrid.tests.test_stats_writer",
        "documentation": {}
    },
    {
        "label": "pytest_configure",
        "kind": 2,
        "importPath": "mettagrid.conftest",
        "description": "mettagrid.conftest",
        "peekOfCode": "def pytest_configure(config):\n    # Add multiple markers correctly\n    config.addinivalue_line(\"markers\", \"benchmark: mark a test as a benchmark test\")\n    config.addinivalue_line(\"markers\", \"verbose: mark a test to display verbose output\")\n@pytest.fixture\ndef verbose(request):\n    \"\"\"Fixture that can be used in tests to check if verbose mode is enabled.\"\"\"\n    marker = request.node.get_closest_marker(\"verbose\")\n    return marker is not None\n# Properly handle output capture for verbose tests",
        "detail": "mettagrid.conftest",
        "documentation": {}
    },
    {
        "label": "verbose",
        "kind": 2,
        "importPath": "mettagrid.conftest",
        "description": "mettagrid.conftest",
        "peekOfCode": "def verbose(request):\n    \"\"\"Fixture that can be used in tests to check if verbose mode is enabled.\"\"\"\n    marker = request.node.get_closest_marker(\"verbose\")\n    return marker is not None\n# Properly handle output capture for verbose tests\n@pytest.hookimpl(hookwrapper=True)\ndef pytest_runtest_makereport(item, call):\n    outcome = yield\n    report = outcome.get_result()\n    # Only process after the call phase (actual test execution)",
        "detail": "mettagrid.conftest",
        "documentation": {}
    },
    {
        "label": "pytest_runtest_makereport",
        "kind": 2,
        "importPath": "mettagrid.conftest",
        "description": "mettagrid.conftest",
        "peekOfCode": "def pytest_runtest_makereport(item, call):\n    outcome = yield\n    report = outcome.get_result()\n    # Only process after the call phase (actual test execution)\n    if report.when == \"call\" and item.get_closest_marker(\"verbose\"):\n        capman = item.config.pluginmanager.get_plugin(\"capturemanager\")\n        if capman and hasattr(report, \"capstdout\") and hasattr(report, \"capstderr\"):\n            # Print the captured output with formatting\n            print(f\"\\n\\n===== VERBOSE OUTPUT FOR: {item.name} =====\\n\")\n            if report.capstdout:",
        "detail": "mettagrid.conftest",
        "documentation": {}
    },
    {
        "label": "base_dir",
        "kind": 5,
        "importPath": "mettagrid.conftest",
        "description": "mettagrid.conftest",
        "peekOfCode": "base_dir = Path(__file__).resolve().parent\nprint(\"\\n===== DEBUG: Python sys.path =====\")\nfor i, path in enumerate(sys.path):\n    print(f\"{i}: {path}\")\nprint(\"===== END DEBUG: Python sys.path =====\\n\")\ndef pytest_configure(config):\n    # Add multiple markers correctly\n    config.addinivalue_line(\"markers\", \"benchmark: mark a test as a benchmark test\")\n    config.addinivalue_line(\"markers\", \"verbose: mark a test to display verbose output\")\n@pytest.fixture",
        "detail": "mettagrid.conftest",
        "documentation": {}
    },
    {
        "label": "attack_grid",
        "kind": 2,
        "importPath": "mettascope.tests.attack_grid",
        "description": "mettascope.tests.attack_grid",
        "peekOfCode": "def attack_grid(orientation, idx):\n    i = idx - 1\n    if orientation == 0:\n        dx = i % 3 - 1\n        dy = -(i // 3) - 1\n    elif orientation == 1:\n        dx = -(i % 3) + 1\n        dy = i // 3 + 1\n    elif orientation == 2:\n        dx = -(i // 3) - 1",
        "detail": "mettascope.tests.attack_grid",
        "documentation": {}
    },
    {
        "label": "file_name",
        "kind": 5,
        "importPath": "mettascope.tests.test_z",
        "description": "mettascope.tests.test_z",
        "peekOfCode": "file_name = \"replay.json.z\"\nwith open(file_name, \"rb\") as file:\n    compressed_data = file.read()\n# Decompress the data\ndecompressed_data = zlib.decompress(compressed_data)\n# Parse the JSON data\njson_data = json.loads(decompressed_data)\n# Print the JSON data\nprint(json_data)",
        "detail": "mettascope.tests.test_z",
        "documentation": {}
    },
    {
        "label": "decompressed_data",
        "kind": 5,
        "importPath": "mettascope.tests.test_z",
        "description": "mettascope.tests.test_z",
        "peekOfCode": "decompressed_data = zlib.decompress(compressed_data)\n# Parse the JSON data\njson_data = json.loads(decompressed_data)\n# Print the JSON data\nprint(json_data)",
        "detail": "mettascope.tests.test_z",
        "documentation": {}
    },
    {
        "label": "json_data",
        "kind": 5,
        "importPath": "mettascope.tests.test_z",
        "description": "mettascope.tests.test_z",
        "peekOfCode": "json_data = json.loads(decompressed_data)\n# Print the JSON data\nprint(json_data)",
        "detail": "mettascope.tests.test_z",
        "documentation": {}
    },
    {
        "label": "put_image",
        "kind": 2,
        "importPath": "mettascope.tools.gen_atlas",
        "description": "mettascope.tools.gen_atlas",
        "peekOfCode": "def put_image(img, name):\n    \"\"\"\n    Place an image in the atlas at the specified coordinates or find the best position.\n    Args:\n        img: The pixie Image to place in the atlas\n        name: The name/key to use in the images dictionary\n    Returns:\n        Tuple of (x, y, width, height) indicating the image position\n    \"\"\"\n    global heights, atlas_image, images",
        "detail": "mettascope.tools.gen_atlas",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "mettascope.tools.gen_atlas",
        "description": "mettascope.tools.gen_atlas",
        "peekOfCode": "def main():\n    \"\"\"Main entry point for atlas generation.\"\"\"\n    # Ensure output directory exists\n    os.makedirs(\"dist\", exist_ok=True)\n    # Walk the data dir:\n    atlas_dir = \"data/atlas\"\n    if not os.path.exists(atlas_dir):\n        print(f\"Error: Atlas directory '{atlas_dir}' not found\", file=sys.stderr)\n        sys.exit(1)\n    image_count = 0",
        "detail": "mettascope.tools.gen_atlas",
        "documentation": {}
    },
    {
        "label": "ATLAS_SIZE",
        "kind": 5,
        "importPath": "mettascope.tools.gen_atlas",
        "description": "mettascope.tools.gen_atlas",
        "peekOfCode": "ATLAS_SIZE = 1024 * 8\natlas_image = pixie.Image(ATLAS_SIZE, ATLAS_SIZE)\nimages = {}\nheights = [0] * atlas_image.width\npadding = 64\ndef put_image(img, name):\n    \"\"\"\n    Place an image in the atlas at the specified coordinates or find the best position.\n    Args:\n        img: The pixie Image to place in the atlas",
        "detail": "mettascope.tools.gen_atlas",
        "documentation": {}
    },
    {
        "label": "atlas_image",
        "kind": 5,
        "importPath": "mettascope.tools.gen_atlas",
        "description": "mettascope.tools.gen_atlas",
        "peekOfCode": "atlas_image = pixie.Image(ATLAS_SIZE, ATLAS_SIZE)\nimages = {}\nheights = [0] * atlas_image.width\npadding = 64\ndef put_image(img, name):\n    \"\"\"\n    Place an image in the atlas at the specified coordinates or find the best position.\n    Args:\n        img: The pixie Image to place in the atlas\n        name: The name/key to use in the images dictionary",
        "detail": "mettascope.tools.gen_atlas",
        "documentation": {}
    },
    {
        "label": "images",
        "kind": 5,
        "importPath": "mettascope.tools.gen_atlas",
        "description": "mettascope.tools.gen_atlas",
        "peekOfCode": "images = {}\nheights = [0] * atlas_image.width\npadding = 64\ndef put_image(img, name):\n    \"\"\"\n    Place an image in the atlas at the specified coordinates or find the best position.\n    Args:\n        img: The pixie Image to place in the atlas\n        name: The name/key to use in the images dictionary\n    Returns:",
        "detail": "mettascope.tools.gen_atlas",
        "documentation": {}
    },
    {
        "label": "heights",
        "kind": 5,
        "importPath": "mettascope.tools.gen_atlas",
        "description": "mettascope.tools.gen_atlas",
        "peekOfCode": "heights = [0] * atlas_image.width\npadding = 64\ndef put_image(img, name):\n    \"\"\"\n    Place an image in the atlas at the specified coordinates or find the best position.\n    Args:\n        img: The pixie Image to place in the atlas\n        name: The name/key to use in the images dictionary\n    Returns:\n        Tuple of (x, y, width, height) indicating the image position",
        "detail": "mettascope.tools.gen_atlas",
        "documentation": {}
    },
    {
        "label": "padding",
        "kind": 5,
        "importPath": "mettascope.tools.gen_atlas",
        "description": "mettascope.tools.gen_atlas",
        "peekOfCode": "padding = 64\ndef put_image(img, name):\n    \"\"\"\n    Place an image in the atlas at the specified coordinates or find the best position.\n    Args:\n        img: The pixie Image to place in the atlas\n        name: The name/key to use in the images dictionary\n    Returns:\n        Tuple of (x, y, width, height) indicating the image position\n    \"\"\"",
        "detail": "mettascope.tools.gen_atlas",
        "documentation": {}
    },
    {
        "label": "DomNode",
        "kind": 6,
        "importPath": "mettascope.tools.gen_html",
        "description": "mettascope.tools.gen_html",
        "peekOfCode": "class DomNode:\n    \"\"\"A simple DOM node implementation for HTML generation.\"\"\"\n    # List of HTML5 self-closing tags\n    SELF_CLOSING_TAGS = [\n        \"area\",\n        \"base\",\n        \"br\",\n        \"col\",\n        \"embed\",\n        \"hr\",",
        "detail": "mettascope.tools.gen_html",
        "documentation": {}
    },
    {
        "label": "HtmlGenerator",
        "kind": 6,
        "importPath": "mettascope.tools.gen_html",
        "description": "mettascope.tools.gen_html",
        "peekOfCode": "class HtmlGenerator:\n    \"\"\"Class to handle the generation of HTML and CSS from Figma data.\"\"\"\n    def __init__(self, output_dir: str, extra_css: str, extra_js: str, data_dir: str, tmp_dir: str):\n        \"\"\"\n        Initialize the HTML generator.\n        Args:\n            output_dir: Directory where generated files will be saved\n            default_image_path: Path for image references\n            default_font_family: Default font family for text elements\n        \"\"\"",
        "detail": "mettascope.tools.gen_html",
        "documentation": {}
    },
    {
        "label": "rgba",
        "kind": 2,
        "importPath": "mettascope.tools.gen_html",
        "description": "mettascope.tools.gen_html",
        "peekOfCode": "def rgba(color: Dict[str, float], opacity=1) -> str:\n    \"\"\"\n    Convert a Figma color object to CSS rgba color string.\n    Args:\n        color: A dictionary with r, g, b, a values in the range 0-1\n    Returns:\n        str: CSS rgba color string\n    \"\"\"\n    r = round(color.get(\"r\", 0) * 255)\n    g = round(color.get(\"g\", 0) * 255)",
        "detail": "mettascope.tools.gen_html",
        "documentation": {}
    },
    {
        "label": "px",
        "kind": 2,
        "importPath": "mettascope.tools.gen_html",
        "description": "mettascope.tools.gen_html",
        "peekOfCode": "def px(value: Any) -> str:\n    \"\"\"\n    Convert a value to CSS pixel string with 2 decimal places.\n    Removes trailing zeros and decimal point if the result is a whole number.\n    Args:\n        value: Numeric value\n    Returns:\n        str: Formatted CSS pixel value\n    \"\"\"\n    # If its None its 0",
        "detail": "mettascope.tools.gen_html",
        "documentation": {}
    },
    {
        "label": "parse_name",
        "kind": 2,
        "importPath": "mettascope.tools.gen_html",
        "description": "mettascope.tools.gen_html",
        "peekOfCode": "def parse_name(name: str) -> tuple[str, str, list[str], str]:\n    \"\"\"Parse figma name into tag, id or class\"\"\"\n    tags = [\"input\", \"img\", \"textarea\", \"button\", \"a\", \"canvas\", \"iframe\"]\n    tag = \"div\"\n    id = \"\"\n    clss = []\n    for part in name.split(\".\"):\n        if part in tags:\n            tag = part\n        elif part.startswith(\"#\"):",
        "detail": "mettascope.tools.gen_html",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "mettascope.tools.gen_html",
        "description": "mettascope.tools.gen_html",
        "peekOfCode": "def parse_args():\n    parser = argparse.ArgumentParser(description=\"Convert Figma file to HTML with optional extras.\")\n    parser.add_argument(\n        \"--input_url\",\n        help=\"URL of the input Figma file.\",\n        default=\"https://www.figma.com/design/WeQldl3PsqFIpDnTka5Kd3\",\n    )\n    parser.add_argument(\"--output_dir\", help=\"Directory to write output files to.\", default=\".\")\n    parser.add_argument(\"--tmp_dir\", help=\"Temporary directory for intermediate files.\", default=\"dist\")\n    parser.add_argument(\"--extra-css\", dest=\"extra_css\", help=\"Path to extra CSS file to include.\", default=\"style.css\")",
        "detail": "mettascope.tools.gen_html",
        "documentation": {}
    },
    {
        "label": "create_simulation",
        "kind": 2,
        "importPath": "mettascope.replays",
        "description": "mettascope.replays",
        "peekOfCode": "def create_simulation(cfg):\n    setup_mettagrid_environment(cfg)\n    logger = setup_mettagrid_logger(\"replay\")\n    logger.info(f\"Replaying {cfg.run}\")\n    with WandbContext(cfg.wandb, cfg) as wandb_run:\n        policy_store = PolicyStore(cfg, wandb_run)\n        if cfg.replay_job.policy_uri is not None:\n            policy_record = policy_store.policy_record(cfg.replay_job.policy_uri)\n        else:\n            # Set the policy_uri to \"\" to run play without a policy.",
        "detail": "mettascope.replays",
        "documentation": {}
    },
    {
        "label": "generate_replay",
        "kind": 2,
        "importPath": "mettascope.replays",
        "description": "mettascope.replays",
        "peekOfCode": "def generate_replay(sim: Simulation) -> dict:\n    assert len(sim._vecenv.envs) == 1, \"Replay generation requires a single environment\"\n    start = time.time()\n    sim.simulate()\n    end = time.time()\n    print(\"Simulate time\", end - start)\n    assert len(sim._replay_writer.episodes) == 1, \"Expected exactly one replay episode\"\n    for _, episode_replay in sim._replay_writer.episodes.items():\n        return episode_replay.get_replay_data()\n    return {}",
        "detail": "mettascope.replays",
        "documentation": {}
    },
    {
        "label": "CustomStaticFiles",
        "kind": 6,
        "importPath": "mettascope.server",
        "description": "mettascope.server",
        "peekOfCode": "class CustomStaticFiles(StaticFiles):\n    \"\"\"StaticFiles that disables caching for specific file extensions and sets custom content types.\"\"\"\n    def __init__(self, *args, no_cache_extensions=None, custom_content_types=None, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.no_cache_extensions = no_cache_extensions or {\".js\", \".json\"}\n        self.custom_content_types = custom_content_types or {}\n    def file_response(\n        self,\n        full_path,\n        stat_result,",
        "detail": "mettascope.server",
        "documentation": {}
    },
    {
        "label": "clear_memory",
        "kind": 2,
        "importPath": "mettascope.server",
        "description": "mettascope.server",
        "peekOfCode": "def clear_memory(sim: replays.Simulation, what: str, agent_id: int) -> None:\n    \"\"\"Clear the memory of the policy.\"\"\"\n    policy_state = sim.get_policy_state()\n    if policy_state is None or policy_state.lstm_c is None or policy_state.lstm_h is None:\n        logger.error(\"No policy state to clear\")\n        return\n    if what == \"0\":\n        policy_state.lstm_c[:, agent_id, :].zero_()\n        policy_state.lstm_h[:, agent_id, :].zero_()\n    elif what == \"1\":",
        "detail": "mettascope.server",
        "documentation": {}
    },
    {
        "label": "copy_memory",
        "kind": 2,
        "importPath": "mettascope.server",
        "description": "mettascope.server",
        "peekOfCode": "def copy_memory(sim: replays.Simulation, agent_id: int) -> tuple[list[float], list[float]]:\n    \"\"\"Copy the memory of the policy.\"\"\"\n    policy_state = sim.get_policy_state()\n    if policy_state is None or policy_state.lstm_c is None or policy_state.lstm_h is None:\n        logger.error(\"No policy state to copy\")\n        return [], []\n    # Copy the memory of the policy.\n    lstm_c = policy_state.lstm_c[:, agent_id, :].clone()\n    lstm_h = policy_state.lstm_h[:, agent_id, :].clone()\n    return lstm_c.tolist(), lstm_h.tolist()",
        "detail": "mettascope.server",
        "documentation": {}
    },
    {
        "label": "paste_memory",
        "kind": 2,
        "importPath": "mettascope.server",
        "description": "mettascope.server",
        "peekOfCode": "def paste_memory(sim: replays.Simulation, agent_id: int, memory: tuple[list[float], list[float]]):\n    \"\"\"Paste the memory of the policy.\"\"\"\n    policy_state = sim.get_policy_state()\n    if policy_state is None or policy_state.lstm_c is None or policy_state.lstm_h is None:\n        logger.error(\"No policy state to paste\")\n        return\n    [lstm_c, lstm_h] = memory\n    policy_state.lstm_c[:, agent_id, :] = th.tensor(lstm_c)\n    policy_state.lstm_h[:, agent_id, :] = th.tensor(lstm_h)\ndef make_app(cfg: DictConfig):",
        "detail": "mettascope.server",
        "documentation": {}
    },
    {
        "label": "make_app",
        "kind": 2,
        "importPath": "mettascope.server",
        "description": "mettascope.server",
        "peekOfCode": "def make_app(cfg: DictConfig):\n    app = FastAPI()\n    @app.get(\"/\", response_class=HTMLResponse)\n    async def get_client():\n        try:\n            with open(\"mettascope/index.html\", \"r\") as file:\n                html_content = file.read()\n            return HTMLResponse(content=html_content)\n        except FileNotFoundError as err:\n            raise HTTPException(status_code=404, detail=\"Client HTML file not found\") from err",
        "detail": "mettascope.server",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "mettascope.server",
        "description": "mettascope.server",
        "peekOfCode": "def run(cfg: DictConfig, open_url: str | None = None):\n    app = make_app(cfg)\n    if open_url:\n        server_url = \"http://localhost:8000\"\n        @app.on_event(\"startup\")\n        async def _open_browser():\n            webbrowser.open(f\"{server_url}{open_url}\")\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n@hydra.main(version_base=None, config_path=\"../configs\", config_name=\"replay_job\")\n@metta_script",
        "detail": "mettascope.server",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "mettascope.server",
        "description": "mettascope.server",
        "peekOfCode": "def main(cfg):\n    run(cfg)\nif __name__ == \"__main__\":\n    main()",
        "detail": "mettascope.server",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "mettascope.server",
        "description": "mettascope.server",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass CustomStaticFiles(StaticFiles):\n    \"\"\"StaticFiles that disables caching for specific file extensions and sets custom content types.\"\"\"\n    def __init__(self, *args, no_cache_extensions=None, custom_content_types=None, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.no_cache_extensions = no_cache_extensions or {\".js\", \".json\"}\n        self.custom_content_types = custom_content_types or {}\n    def file_response(\n        self,\n        full_path,",
        "detail": "mettascope.server",
        "documentation": {}
    },
    {
        "label": "download",
        "kind": 2,
        "importPath": "observatory.node_modules.plotly.js..circleci.download_google_fonts",
        "description": "observatory.node_modules.plotly.js..circleci.download_google_fonts",
        "peekOfCode": "def download(repo, family, types) :\n    for t in types :\n        name = family + t + '.ttf'\n        url = repo + name + '?raw=true'\n        print(url)\n        req = requests.get(url, allow_redirects=True)\n        open(dirOut + name, 'wb').write(req.content)\ndownload(\n    'https://github.com/googlefonts/noto-fonts/blob/main/hinted/ttf/NotoSansMono/',\n    'NotoSansMono',",
        "detail": "observatory.node_modules.plotly.js..circleci.download_google_fonts",
        "documentation": {}
    },
    {
        "label": "dirOut",
        "kind": 5,
        "importPath": "observatory.node_modules.plotly.js..circleci.download_google_fonts",
        "description": "observatory.node_modules.plotly.js..circleci.download_google_fonts",
        "peekOfCode": "dirOut = '.circleci/fonts/truetype/googleFonts/'\ndef download(repo, family, types) :\n    for t in types :\n        name = family + t + '.ttf'\n        url = repo + name + '?raw=true'\n        print(url)\n        req = requests.get(url, allow_redirects=True)\n        open(dirOut + name, 'wb').write(req.content)\ndownload(\n    'https://github.com/googlefonts/noto-fonts/blob/main/hinted/ttf/NotoSansMono/',",
        "detail": "observatory.node_modules.plotly.js..circleci.download_google_fonts",
        "documentation": {}
    },
    {
        "label": "_Known",
        "kind": 6,
        "importPath": "studio.node_modules..pnpm.flat-cache@4.0.1.node_modules.flatted.python.flatted",
        "description": "studio.node_modules..pnpm.flat-cache@4.0.1.node_modules.flatted.python.flatted",
        "peekOfCode": "class _Known:\n    def __init__(self):\n        self.key = []\n        self.value = []\nclass _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0",
        "detail": "studio.node_modules..pnpm.flat-cache@4.0.1.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "_String",
        "kind": 6,
        "importPath": "studio.node_modules..pnpm.flat-cache@4.0.1.node_modules.flatted.python.flatted",
        "description": "studio.node_modules..pnpm.flat-cache@4.0.1.node_modules.flatted.python.flatted",
        "peekOfCode": "class _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0\n    for _ in value:\n        keys.append(i)\n        i += 1\n    return keys",
        "detail": "studio.node_modules..pnpm.flat-cache@4.0.1.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "parse",
        "kind": 2,
        "importPath": "studio.node_modules..pnpm.flat-cache@4.0.1.node_modules.flatted.python.flatted",
        "description": "studio.node_modules..pnpm.flat-cache@4.0.1.node_modules.flatted.python.flatted",
        "peekOfCode": "def parse(value, *args, **kwargs):\n    json = _json.loads(value, *args, **kwargs)\n    wrapped = []\n    for value in json:\n        wrapped.append(_wrap(value))\n    input = []\n    for value in wrapped:\n        if isinstance(value, _String):\n            input.append(value.value)\n        else:",
        "detail": "studio.node_modules..pnpm.flat-cache@4.0.1.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "studio.node_modules..pnpm.flat-cache@4.0.1.node_modules.flatted.python.flatted",
        "description": "studio.node_modules..pnpm.flat-cache@4.0.1.node_modules.flatted.python.flatted",
        "peekOfCode": "def stringify(value, *args, **kwargs):\n    known = _Known()\n    input = []\n    output = []\n    i = int(_index(known, input, value))\n    while i < len(input):\n        output.append(_transform(known, input, input[i]))\n        i += 1\n    return _json.dumps(output, *args, **kwargs)",
        "detail": "studio.node_modules..pnpm.flat-cache@4.0.1.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "_Known",
        "kind": 6,
        "importPath": "studio.node_modules..pnpm.flatted@3.3.3.node_modules.flatted.python.flatted",
        "description": "studio.node_modules..pnpm.flatted@3.3.3.node_modules.flatted.python.flatted",
        "peekOfCode": "class _Known:\n    def __init__(self):\n        self.key = []\n        self.value = []\nclass _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0",
        "detail": "studio.node_modules..pnpm.flatted@3.3.3.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "_String",
        "kind": 6,
        "importPath": "studio.node_modules..pnpm.flatted@3.3.3.node_modules.flatted.python.flatted",
        "description": "studio.node_modules..pnpm.flatted@3.3.3.node_modules.flatted.python.flatted",
        "peekOfCode": "class _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0\n    for _ in value:\n        keys.append(i)\n        i += 1\n    return keys",
        "detail": "studio.node_modules..pnpm.flatted@3.3.3.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "parse",
        "kind": 2,
        "importPath": "studio.node_modules..pnpm.flatted@3.3.3.node_modules.flatted.python.flatted",
        "description": "studio.node_modules..pnpm.flatted@3.3.3.node_modules.flatted.python.flatted",
        "peekOfCode": "def parse(value, *args, **kwargs):\n    json = _json.loads(value, *args, **kwargs)\n    wrapped = []\n    for value in json:\n        wrapped.append(_wrap(value))\n    input = []\n    for value in wrapped:\n        if isinstance(value, _String):\n            input.append(value.value)\n        else:",
        "detail": "studio.node_modules..pnpm.flatted@3.3.3.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "studio.node_modules..pnpm.flatted@3.3.3.node_modules.flatted.python.flatted",
        "description": "studio.node_modules..pnpm.flatted@3.3.3.node_modules.flatted.python.flatted",
        "peekOfCode": "def stringify(value, *args, **kwargs):\n    known = _Known()\n    input = []\n    output = []\n    i = int(_index(known, input, value))\n    while i < len(input):\n        output.append(_transform(known, input, input[i]))\n        i += 1\n    return _json.dumps(output, *args, **kwargs)",
        "detail": "studio.node_modules..pnpm.flatted@3.3.3.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "_Known",
        "kind": 6,
        "importPath": "studio.node_modules..pnpm.node_modules.flatted.python.flatted",
        "description": "studio.node_modules..pnpm.node_modules.flatted.python.flatted",
        "peekOfCode": "class _Known:\n    def __init__(self):\n        self.key = []\n        self.value = []\nclass _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0",
        "detail": "studio.node_modules..pnpm.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "_String",
        "kind": 6,
        "importPath": "studio.node_modules..pnpm.node_modules.flatted.python.flatted",
        "description": "studio.node_modules..pnpm.node_modules.flatted.python.flatted",
        "peekOfCode": "class _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0\n    for _ in value:\n        keys.append(i)\n        i += 1\n    return keys",
        "detail": "studio.node_modules..pnpm.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "parse",
        "kind": 2,
        "importPath": "studio.node_modules..pnpm.node_modules.flatted.python.flatted",
        "description": "studio.node_modules..pnpm.node_modules.flatted.python.flatted",
        "peekOfCode": "def parse(value, *args, **kwargs):\n    json = _json.loads(value, *args, **kwargs)\n    wrapped = []\n    for value in json:\n        wrapped.append(_wrap(value))\n    input = []\n    for value in wrapped:\n        if isinstance(value, _String):\n            input.append(value.value)\n        else:",
        "detail": "studio.node_modules..pnpm.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "studio.node_modules..pnpm.node_modules.flatted.python.flatted",
        "description": "studio.node_modules..pnpm.node_modules.flatted.python.flatted",
        "peekOfCode": "def stringify(value, *args, **kwargs):\n    known = _Known()\n    input = []\n    output = []\n    i = int(_index(known, input, value))\n    while i < len(input):\n        output.append(_transform(known, input, input[i]))\n        i += 1\n    return _json.dumps(output, *args, **kwargs)",
        "detail": "studio.node_modules..pnpm.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "studio.start",
        "description": "studio.start",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--dev\", action=\"store_true\", help=\"Run in development mode\")\n    args = parser.parse_args()\n    cd_repo_root()\n    repo_root = Path.cwd()\n    studio_dir = repo_root / \"studio\"\n    print(f\"Starting servers from repo root: {repo_root}\")\n    print(f\"Studio frontend directory: {studio_dir}\")\n    # Ensure color output from child processes even when stdout is piped.",
        "detail": "studio.start",
        "documentation": {}
    },
    {
        "label": "test_db",
        "kind": 2,
        "importPath": "tests.eval.test_dashboard_data",
        "description": "tests.eval.test_dashboard_data",
        "peekOfCode": "def test_db():\n    with tempfile.TemporaryDirectory() as tmp:\n        p = Path(tmp) / f\"{uuid.uuid4().hex}.duckdb\"\n        db, eps, sid = _create_test_db_with_metrics(p)\n        yield db, eps, sid\n        db.close()\ndef test_get_policy_eval_metrics(test_db):\n    db, _, _ = test_db\n    policy_evals = get_policy_eval_metrics(db)\n    # Should have one policy eval since we only created one simulation",
        "detail": "tests.eval.test_dashboard_data",
        "documentation": {}
    },
    {
        "label": "test_get_policy_eval_metrics",
        "kind": 2,
        "importPath": "tests.eval.test_dashboard_data",
        "description": "tests.eval.test_dashboard_data",
        "peekOfCode": "def test_get_policy_eval_metrics(test_db):\n    db, _, _ = test_db\n    policy_evals = get_policy_eval_metrics(db)\n    # Should have one policy eval since we only created one simulation\n    assert len(policy_evals) == 1\n    policy_eval = policy_evals[0]\n    # Check policy eval fields\n    assert policy_eval.policy_key == \"test_policy\"\n    assert policy_eval.policy_version == 1\n    assert policy_eval.eval_name == \"test_sim\"",
        "detail": "tests.eval.test_dashboard_data",
        "documentation": {}
    },
    {
        "label": "test_db",
        "kind": 2,
        "importPath": "tests.eval.test_eval_stats_db",
        "description": "tests.eval.test_eval_stats_db",
        "peekOfCode": "def test_db():\n    with tempfile.TemporaryDirectory() as tmp:\n        p = Path(tmp) / f\"{uuid.uuid4().hex}.duckdb\"\n        db, eps, sid = _create_test_db_with_missing_metrics(p)\n        yield db, eps, sid\n        db.close()\n# -------- Tests ------------------------------------------------------------ #\ndef test_metrics_normalization(test_db):\n    db, _, _ = test_db\n    policy_record = MockPolicyRecord.from_key_and_version(\"test_policy\", 1)",
        "detail": "tests.eval.test_eval_stats_db",
        "documentation": {}
    },
    {
        "label": "test_metrics_normalization",
        "kind": 2,
        "importPath": "tests.eval.test_eval_stats_db",
        "description": "tests.eval.test_eval_stats_db",
        "peekOfCode": "def test_metrics_normalization(test_db):\n    db, _, _ = test_db\n    policy_record = MockPolicyRecord.from_key_and_version(\"test_policy\", 1)\n    pk, pv = db.key_and_version(policy_record)  # type: ignore\n    # hearts_collected: only 2/5 potential samples recorded (value 3 each)\n    avg_hearts = db.get_average_metric_by_filter(\"hearts_collected\", policy_record)\n    assert 1.15 <= avg_hearts <= 1.25, f\"expected 1.2 got {avg_hearts}\"\n    potential = db.potential_samples_for_metric(pk, pv)\n    assert potential == 5\n    recorded = db.count_metric_agents(pk, pv, \"hearts_collected\")",
        "detail": "tests.eval.test_eval_stats_db",
        "documentation": {}
    },
    {
        "label": "test_simulation_scores_normalization",
        "kind": 2,
        "importPath": "tests.eval.test_eval_stats_db",
        "description": "tests.eval.test_eval_stats_db",
        "peekOfCode": "def test_simulation_scores_normalization(test_db):\n    db, _, _ = test_db\n    policy_record = MockPolicyRecord.from_key_and_version(\"test_policy\", 1)\n    scores = db.simulation_scores(policy_record, \"hearts_collected\")\n    assert len(scores) == 1\n    key = next(iter(scores))\n    exp = scores[key]\n    assert key == (\"test_suite\", \"test_sim\", \"env_test\")\n    assert 1.15 <= exp <= 1.25\n    # Compare to raw (nonnormalized) mean",
        "detail": "tests.eval.test_eval_stats_db",
        "documentation": {}
    },
    {
        "label": "test_sum_metric_normalization",
        "kind": 2,
        "importPath": "tests.eval.test_eval_stats_db",
        "description": "tests.eval.test_eval_stats_db",
        "peekOfCode": "def test_sum_metric_normalization(test_db):\n    db, _, _ = test_db\n    policy_record = MockPolicyRecord.from_key_and_version(\"test_policy\", 1)\n    sum_norm = db.get_sum_metric_by_filter(\"hearts_collected\", policy_record)\n    assert 1.15 <= sum_norm <= 1.25  # (6 / 5)  1.2\ndef test_no_metrics(test_db):\n    db, _, _ = test_db\n    policy_record = MockPolicyRecord.from_key_and_version(\"test_policy\", 1)\n    assert db.get_average_metric_by_filter(\"nonexistent\", policy_record) == 0.0\n    bad_policy_record = MockPolicyRecord.from_key_and_version(\"none\", 99)",
        "detail": "tests.eval.test_eval_stats_db",
        "documentation": {}
    },
    {
        "label": "test_no_metrics",
        "kind": 2,
        "importPath": "tests.eval.test_eval_stats_db",
        "description": "tests.eval.test_eval_stats_db",
        "peekOfCode": "def test_no_metrics(test_db):\n    db, _, _ = test_db\n    policy_record = MockPolicyRecord.from_key_and_version(\"test_policy\", 1)\n    assert db.get_average_metric_by_filter(\"nonexistent\", policy_record) == 0.0\n    bad_policy_record = MockPolicyRecord.from_key_and_version(\"none\", 99)\n    assert db.get_average_metric_by_filter(\"hearts_collected\", bad_policy_record) is None\ndef test_empty_database():\n    with tempfile.TemporaryDirectory() as tmp:\n        db = EvalStatsDB(Path(tmp) / \"empty.duckdb\")\n        policy_record = MockPolicyRecord.from_key_and_version(\"test\", 1)",
        "detail": "tests.eval.test_eval_stats_db",
        "documentation": {}
    },
    {
        "label": "test_empty_database",
        "kind": 2,
        "importPath": "tests.eval.test_eval_stats_db",
        "description": "tests.eval.test_eval_stats_db",
        "peekOfCode": "def test_empty_database():\n    with tempfile.TemporaryDirectory() as tmp:\n        db = EvalStatsDB(Path(tmp) / \"empty.duckdb\")\n        policy_record = MockPolicyRecord.from_key_and_version(\"test\", 1)\n        assert db.get_average_metric_by_filter(\"reward\", cast(PolicyRecord, policy_record)) is None\n        assert db.potential_samples_for_metric(\"test\", 1) == 0\n        db.close()\ndef test_metric_by_policy_eval(test_db):\n    \"\"\"metric_by_policy_eval should return a normalized mean per policy and eval.\"\"\"\n    db, _, _ = test_db",
        "detail": "tests.eval.test_eval_stats_db",
        "documentation": {}
    },
    {
        "label": "test_metric_by_policy_eval",
        "kind": 2,
        "importPath": "tests.eval.test_eval_stats_db",
        "description": "tests.eval.test_eval_stats_db",
        "peekOfCode": "def test_metric_by_policy_eval(test_db):\n    \"\"\"metric_by_policy_eval should return a normalized mean per policy and eval.\"\"\"\n    db, _, _ = test_db\n    policy_record = MockPolicyRecord.from_key_and_version(\"test_policy\", 1)\n    pk, pv = db.key_and_version(policy_record)  # type: ignore\n    df = db.metric_by_policy_eval(\"hearts_collected\", policy_record)\n    # Expect one row (env_test) with 1.2\n    assert len(df) == 1\n    row = df.iloc[0]\n    assert row[\"policy_uri\"] == f\"{pk}:v{pv}\"",
        "detail": "tests.eval.test_eval_stats_db",
        "documentation": {}
    },
    {
        "label": "test_basic",
        "kind": 2,
        "importPath": "tests.map.scenes.test_ascii",
        "description": "tests.map.scenes.test_ascii",
        "peekOfCode": "def test_basic():\n    scene = render_scene(Ascii, {\"uri\": \"tests/map/scenes/fixtures/test.map\"}, (4, 4))\n    assert_grid(\n        scene,\n        \"\"\"\n####\n#_.#\n##.#\n####\n        \"\"\",",
        "detail": "tests.map.scenes.test_ascii",
        "documentation": {}
    },
    {
        "label": "test_basic",
        "kind": 2,
        "importPath": "tests.map.scenes.test_auto",
        "description": "tests.map.scenes.test_auto",
        "peekOfCode": "def test_basic():\n    params = {\n        \"num_agents\": 1,\n        \"objects\": {\"altar\": 2},\n        \"room_objects\": {\"altar\": [\"uniform\", 0.0005, 0.01]},\n        \"room_symmetry\": {\"horizontal\": 1, \"vertical\": 1, \"x4\": 1, \"none\": 1},\n        \"layout\": {\"grid\": 1, \"bsp\": 1},\n        \"grid\": {\"rows\": 3, \"columns\": 3},\n        \"bsp\": {\"area_count\": 3},\n        \"content\": [",
        "detail": "tests.map.scenes.test_auto",
        "documentation": {}
    },
    {
        "label": "test_basic",
        "kind": 2,
        "importPath": "tests.map.scenes.test_bsp",
        "description": "tests.map.scenes.test_bsp",
        "peekOfCode": "def test_basic():\n    for _ in range(10):\n        scene = render_scene(\n            BSP,\n            {\"rooms\": 7, \"min_room_size\": 3, \"min_room_size_ratio\": 0.5, \"max_room_size_ratio\": 0.9},\n            (20, 20),\n        )\n        assert_connected(scene.grid)",
        "detail": "tests.map.scenes.test_bsp",
        "documentation": {}
    },
    {
        "label": "test_basic",
        "kind": 2,
        "importPath": "tests.map.scenes.test_convchain",
        "description": "tests.map.scenes.test_convchain",
        "peekOfCode": "def test_basic():\n    scene = render_scene(\n        ConvChain,\n        dict(\n            pattern=\"\"\"\n##..#\n#....\n#####\n\"\"\",\n            pattern_size=3,",
        "detail": "tests.map.scenes.test_convchain",
        "documentation": {}
    },
    {
        "label": "test_basic",
        "kind": 2,
        "importPath": "tests.map.scenes.test_inline_ascii",
        "description": "tests.map.scenes.test_inline_ascii",
        "peekOfCode": "def test_basic():\n    scene = render_scene(\n        InlineAscii,\n        {\n            \"data\": \"\"\"\n#.@.#\n#...#\n\"\"\"\n        },\n        (3, 7),",
        "detail": "tests.map.scenes.test_inline_ascii",
        "documentation": {}
    },
    {
        "label": "test_row_column",
        "kind": 2,
        "importPath": "tests.map.scenes.test_inline_ascii",
        "description": "tests.map.scenes.test_inline_ascii",
        "peekOfCode": "def test_row_column():\n    scene = render_scene(\n        InlineAscii,\n        {\n            \"data\": \"#.@.#\",\n            \"row\": 1,\n            \"column\": 2,\n        },\n        (3, 7),\n    )",
        "detail": "tests.map.scenes.test_inline_ascii",
        "documentation": {}
    },
    {
        "label": "test_overflow",
        "kind": 2,
        "importPath": "tests.map.scenes.test_inline_ascii",
        "description": "tests.map.scenes.test_inline_ascii",
        "peekOfCode": "def test_overflow():\n    with pytest.raises(ValueError):\n        render_scene(\n            InlineAscii,\n            {\n                \"data\": \"####\",\n                \"row\": 1,\n                \"column\": 2,\n            },\n            (1, 3),",
        "detail": "tests.map.scenes.test_inline_ascii",
        "documentation": {}
    },
    {
        "label": "test_connect_room_grid",
        "kind": 2,
        "importPath": "tests.map.scenes.test_make_connected",
        "description": "tests.map.scenes.test_make_connected",
        "peekOfCode": "def test_connect_room_grid():\n    scene = render_scene(\n        RoomGrid,\n        params=dict(\n            rows=2,\n            columns=3,\n        ),\n        shape=(20, 20),\n        children=[ChildrenAction(scene=lambda grid: MakeConnected(grid=grid, params={}), where=\"full\")],\n    )",
        "detail": "tests.map.scenes.test_make_connected",
        "documentation": {}
    },
    {
        "label": "test_basic",
        "kind": 2,
        "importPath": "tests.map.scenes.test_maze",
        "description": "tests.map.scenes.test_maze",
        "peekOfCode": "def test_basic():\n    scene = render_scene(MazeKruskal, {}, (9, 9))\n    assert_connected(scene.grid)\n    # The number of walls is fixed for a given size.\n    # For height 9, the simplest maze has 4 continuous horizontal walls, each with length 8.\n    assert (scene.grid == \"wall\").sum() == 4 * 8",
        "detail": "tests.map.scenes.test_maze",
        "documentation": {}
    },
    {
        "label": "test_horizontal",
        "kind": 2,
        "importPath": "tests.map.scenes.test_mirror",
        "description": "tests.map.scenes.test_mirror",
        "peekOfCode": "def test_horizontal():\n    scene = render_scene(\n        Mirror,\n        {\"scene\": lambda grid: MazeKruskal(grid=grid, params={}, seed=123), \"symmetry\": \"horizontal\"},\n        shape=(9, 9),\n    )\n    assert_grid(\n        scene,\n        \"\"\"\n           .#.#.#.#.",
        "detail": "tests.map.scenes.test_mirror",
        "documentation": {}
    },
    {
        "label": "test_vertical",
        "kind": 2,
        "importPath": "tests.map.scenes.test_mirror",
        "description": "tests.map.scenes.test_mirror",
        "peekOfCode": "def test_vertical():\n    scene = render_scene(\n        Mirror,\n        {\"scene\": lambda grid: MazeKruskal(grid=grid, params={}, seed=123), \"symmetry\": \"vertical\"},\n        shape=(9, 9),\n    )\n    assert_grid(\n        scene,\n        \"\"\"\n           ...#.....",
        "detail": "tests.map.scenes.test_mirror",
        "documentation": {}
    },
    {
        "label": "test_x4",
        "kind": 2,
        "importPath": "tests.map.scenes.test_mirror",
        "description": "tests.map.scenes.test_mirror",
        "peekOfCode": "def test_x4():\n    scene = render_scene(\n        Mirror,\n        {\"scene\": lambda grid: MazeKruskal(grid=grid, params={}, seed=123), \"symmetry\": \"x4\"},\n        shape=(9, 9),\n    )\n    assert_grid(\n        scene,\n        \"\"\"\n           .#.#.#.#.",
        "detail": "tests.map.scenes.test_mirror",
        "documentation": {}
    },
    {
        "label": "test_basic",
        "kind": 2,
        "importPath": "tests.map.scenes.test_multi_left_and_right",
        "description": "tests.map.scenes.test_multi_left_and_right",
        "peekOfCode": "def test_basic():\n    scene = render_scene(\n        MultiLeftAndRight,\n        params=dict(rows=3, columns=2, altar_ratio=0.75, total_altars=4),\n        shape=(20, 20),\n    )\n    assert (scene.grid == \"wall\").sum() > 0",
        "detail": "tests.map.scenes.test_multi_left_and_right",
        "documentation": {}
    },
    {
        "label": "test_basic",
        "kind": 2,
        "importPath": "tests.map.scenes.test_nop",
        "description": "tests.map.scenes.test_nop",
        "peekOfCode": "def test_basic():\n    scene = render_scene(Nop, {}, (3, 3))\n    assert (scene.grid == \"empty\").sum() == 9",
        "detail": "tests.map.scenes.test_nop",
        "documentation": {}
    },
    {
        "label": "make_grid",
        "kind": 2,
        "importPath": "tests.map.scenes.test_random",
        "description": "tests.map.scenes.test_random",
        "peekOfCode": "def make_grid(height: int, width: int) -> np.ndarray:\n    return np.full((height, width), \"empty\", dtype=\"<U50\")\ndef test_objects():\n    scene = render_scene(Random, {\"objects\": {\"altar\": 3, \"temple\": 2}}, (3, 3))\n    assert (scene.grid == \"altar\").sum() == 3\n    assert (scene.grid == \"temple\").sum() == 2\ndef test_agents():\n    scene = render_scene(Random, {\"agents\": 2}, (3, 3))\n    assert (scene.grid == \"agent.agent\").sum() == 2\ndef test_agents_dict():",
        "detail": "tests.map.scenes.test_random",
        "documentation": {}
    },
    {
        "label": "test_objects",
        "kind": 2,
        "importPath": "tests.map.scenes.test_random",
        "description": "tests.map.scenes.test_random",
        "peekOfCode": "def test_objects():\n    scene = render_scene(Random, {\"objects\": {\"altar\": 3, \"temple\": 2}}, (3, 3))\n    assert (scene.grid == \"altar\").sum() == 3\n    assert (scene.grid == \"temple\").sum() == 2\ndef test_agents():\n    scene = render_scene(Random, {\"agents\": 2}, (3, 3))\n    assert (scene.grid == \"agent.agent\").sum() == 2\ndef test_agents_dict():\n    scene = render_scene(Random, {\"agents\": {\"prey\": 2, \"predator\": 1}}, (3, 3))\n    assert (scene.grid == \"agent.prey\").sum() == 2",
        "detail": "tests.map.scenes.test_random",
        "documentation": {}
    },
    {
        "label": "test_agents",
        "kind": 2,
        "importPath": "tests.map.scenes.test_random",
        "description": "tests.map.scenes.test_random",
        "peekOfCode": "def test_agents():\n    scene = render_scene(Random, {\"agents\": 2}, (3, 3))\n    assert (scene.grid == \"agent.agent\").sum() == 2\ndef test_agents_dict():\n    scene = render_scene(Random, {\"agents\": {\"prey\": 2, \"predator\": 1}}, (3, 3))\n    assert (scene.grid == \"agent.prey\").sum() == 2\n    assert (scene.grid == \"agent.predator\").sum() == 1",
        "detail": "tests.map.scenes.test_random",
        "documentation": {}
    },
    {
        "label": "test_agents_dict",
        "kind": 2,
        "importPath": "tests.map.scenes.test_random",
        "description": "tests.map.scenes.test_random",
        "peekOfCode": "def test_agents_dict():\n    scene = render_scene(Random, {\"agents\": {\"prey\": 2, \"predator\": 1}}, (3, 3))\n    assert (scene.grid == \"agent.prey\").sum() == 2\n    assert (scene.grid == \"agent.predator\").sum() == 1",
        "detail": "tests.map.scenes.test_random",
        "documentation": {}
    },
    {
        "label": "test_objects",
        "kind": 2,
        "importPath": "tests.map.scenes.test_random_objects",
        "description": "tests.map.scenes.test_random_objects",
        "peekOfCode": "def test_objects():\n    scene = render_scene(\n        RandomObjects,\n        dict(object_ranges={\"altar\": (\"uniform\", 0.2, 0.5)}),\n        (10, 10),\n    )\n    altar_count = (scene.grid == \"altar\").sum()\n    assert 0.2 * 100 <= altar_count <= 0.5 * 100",
        "detail": "tests.map.scenes.test_random_objects",
        "documentation": {}
    },
    {
        "label": "test_objects",
        "kind": 2,
        "importPath": "tests.map.scenes.test_random_scene",
        "description": "tests.map.scenes.test_random_scene",
        "peekOfCode": "def test_objects():\n    w_count = 0\n    a_count = 0\n    # 1 / 2^30 chance of failure\n    for _ in range(30):\n        scene = render_scene(\n            RandomScene,\n            dict(\n                candidates=[\n                    {\"scene\": lambda grid: InlineAscii(grid=grid, params={\"data\": \"#\"}), \"weight\": 1},",
        "detail": "tests.map.scenes.test_random_scene",
        "documentation": {}
    },
    {
        "label": "test_basic",
        "kind": 2,
        "importPath": "tests.map.scenes.test_random_scene_from_dir",
        "description": "tests.map.scenes.test_random_scene_from_dir",
        "peekOfCode": "def test_basic(monkeypatch):\n    scene = render_scene(\n        RandomSceneFromDir,\n        dict(dir=\"scenes/test\"),\n        (10, 10),\n    )\n    assert (scene.grid == \"wall\").sum() > 0",
        "detail": "tests.map.scenes.test_random_scene_from_dir",
        "documentation": {}
    },
    {
        "label": "test_basic",
        "kind": 2,
        "importPath": "tests.map.scenes.test_remove_agents",
        "description": "tests.map.scenes.test_remove_agents",
        "peekOfCode": "def test_basic():\n    scene = render_scene(\n        Nop,\n        {},\n        (3, 3),\n        children=[\n            ChildrenAction(\n                scene=lambda grid: InlineAscii(\n                    grid=grid,\n                    params={",
        "detail": "tests.map.scenes.test_remove_agents",
        "documentation": {}
    },
    {
        "label": "test_exact",
        "kind": 2,
        "importPath": "tests.map.scenes.test_room_grid",
        "description": "tests.map.scenes.test_room_grid",
        "peekOfCode": "def test_exact():\n    # Test creating a 2x3 grid of rooms\n    scene = render_scene(RoomGrid, {\"rows\": 2, \"columns\": 3, \"border_width\": 1, \"border_object\": \"wall\"}, (10, 10))\n    assert_grid(\n        scene,\n        \"\"\"\n..#..#..##\n..#..#..##\n..#..#..##\n..#..#..##",
        "detail": "tests.map.scenes.test_room_grid",
        "documentation": {}
    },
    {
        "label": "test_with_rows_columns",
        "kind": 2,
        "importPath": "tests.map.scenes.test_room_grid",
        "description": "tests.map.scenes.test_room_grid",
        "peekOfCode": "def test_with_rows_columns():\n    # Test creating a 2x3 grid of rooms\n    scene = render_scene(RoomGrid, {\"rows\": 2, \"columns\": 3, \"border_width\": 1, \"border_object\": \"wall\"}, (10, 10))\n    # Verify the grid structure\n    # Should have walls at inner borders\n    assert np.array_equal(scene.grid[4, :], [\"wall\"] * 10)  # Horizontal border\n    assert np.array_equal(scene.grid[:, 2], [\"wall\"] * 10)  # Vertical border\n    areas = scene.select_areas(AreaQuery())\n    # Verify room areas are created. The 4x2 shape is due to the border width.\n    assert len(areas) == 6",
        "detail": "tests.map.scenes.test_room_grid",
        "documentation": {}
    },
    {
        "label": "test_with_layout",
        "kind": 2,
        "importPath": "tests.map.scenes.test_room_grid",
        "description": "tests.map.scenes.test_room_grid",
        "peekOfCode": "def test_with_layout():\n    # Test creating rooms with a specific layout and tags\n    layout = [[\"room1\", \"room2\"], [\"room3\", \"room4\"]]\n    scene = render_scene(RoomGrid, {\"layout\": layout, \"border_width\": 1, \"border_object\": \"wall\"}, (10, 10))\n    areas = scene.select_areas(AreaQuery())\n    # Verify room areas are created with correct tags\n    assert len(areas) == 4\n    assert all(area.grid.shape == (4, 4) for area in areas)\n    # Verifying that the tagged areas are where we expect them to be is a pain,\n    # so for now just verify that the tags are what we expect.",
        "detail": "tests.map.scenes.test_room_grid",
        "documentation": {}
    },
    {
        "label": "benchmark_size",
        "kind": 2,
        "importPath": "tests.map.scenes.test_room_grid",
        "description": "tests.map.scenes.test_room_grid",
        "peekOfCode": "def benchmark_size(request):\n    return request.param\ndef test_benchmark_room_grid(benchmark, benchmark_size):\n    \"\"\"Benchmark creating a room grid.\"\"\"\n    def create_grid():\n        scene = render_scene(\n            RoomGrid,\n            {\"rows\": benchmark_size[0], \"columns\": benchmark_size[1], \"border_width\": 1, \"border_object\": \"wall\"},\n            (100, 100),\n        )",
        "detail": "tests.map.scenes.test_room_grid",
        "documentation": {}
    },
    {
        "label": "test_benchmark_room_grid",
        "kind": 2,
        "importPath": "tests.map.scenes.test_room_grid",
        "description": "tests.map.scenes.test_room_grid",
        "peekOfCode": "def test_benchmark_room_grid(benchmark, benchmark_size):\n    \"\"\"Benchmark creating a room grid.\"\"\"\n    def create_grid():\n        scene = render_scene(\n            RoomGrid,\n            {\"rows\": benchmark_size[0], \"columns\": benchmark_size[1], \"border_width\": 1, \"border_object\": \"wall\"},\n            (100, 100),\n        )\n        return scene.select_areas(AreaQuery())\n    areas = benchmark(create_grid)",
        "detail": "tests.map.scenes.test_room_grid",
        "documentation": {}
    },
    {
        "label": "test_basic",
        "kind": 2,
        "importPath": "tests.map.scenes.test_wfc",
        "description": "tests.map.scenes.test_wfc",
        "peekOfCode": "def test_basic():\n    scene = render_scene(\n        WFC,\n        dict(\n            pattern=\"\"\"\n        .#...\n        ###..\n        ###..\n            \"\"\",\n        ),",
        "detail": "tests.map.scenes.test_wfc",
        "documentation": {}
    },
    {
        "label": "render_scene",
        "kind": 2,
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "peekOfCode": "def render_scene(cls: type[Scene], params: dict, shape: tuple[int, int], children: list[ChildrenAction] | None = None):\n    grid = np.full(shape, \"empty\", dtype=\"<U50\")\n    scene = cls(grid=grid, params=params, children=children or [])\n    scene.render_with_children()\n    return scene\ndef assert_grid(scene: Scene, ascii_grid: str):\n    grid_lines = grid_to_lines(scene.grid)\n    expected_lines, _, _ = char_grid_to_lines(ascii_grid)\n    if grid_lines != expected_lines:\n        expected_grid = \"\\n\".join(add_pretty_border(expected_lines))",
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "assert_grid",
        "kind": 2,
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "peekOfCode": "def assert_grid(scene: Scene, ascii_grid: str):\n    grid_lines = grid_to_lines(scene.grid)\n    expected_lines, _, _ = char_grid_to_lines(ascii_grid)\n    if grid_lines != expected_lines:\n        expected_grid = \"\\n\".join(add_pretty_border(expected_lines))\n        actual_grid = \"\\n\".join(add_pretty_border(grid_lines))\n        pytest.fail(f\"Grid does not match expected:\\nEXPECTED:\\n{expected_grid}\\n\\nACTUAL:\\n{actual_grid}\")\ndef is_connected(grid: MapGrid):\n    \"\"\"Check if all empty cells in the grid are connected.\"\"\"\n    height, width = grid.shape",
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "is_connected",
        "kind": 2,
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "peekOfCode": "def is_connected(grid: MapGrid):\n    \"\"\"Check if all empty cells in the grid are connected.\"\"\"\n    height, width = grid.shape\n    def is_empty(cell: str) -> bool:\n        return cell == \"empty\" or cell.startswith(\"agent\")\n    # Find all empty cells\n    empty_cells = set()\n    for r in range(height):\n        for c in range(width):\n            if is_empty(grid[r, c]):",
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "assert_connected",
        "kind": 2,
        "importPath": "tests.map.scenes.utils",
        "description": "tests.map.scenes.utils",
        "peekOfCode": "def assert_connected(grid: MapGrid):\n    if not is_connected(grid):\n        pytest.fail(\"Grid is not connected:\\n\" + \"\\n\".join(grid_to_lines(grid, border=True)))",
        "detail": "tests.map.scenes.utils",
        "documentation": {}
    },
    {
        "label": "TestParseAscii",
        "kind": 6,
        "importPath": "tests.map.utils.test_pattern",
        "description": "tests.map.utils.test_pattern",
        "peekOfCode": "class TestParseAscii:\n    def test_basic_parsing(self):\n        source = \"\"\"\n            ###\n            #.#\n            ###\n        \"\"\"\n        grid = parse_ascii_into_grid(source)\n        expected = np.array(\n            [",
        "detail": "tests.map.utils.test_pattern",
        "documentation": {}
    },
    {
        "label": "TestPattern",
        "kind": 6,
        "importPath": "tests.map.utils.test_pattern",
        "description": "tests.map.utils.test_pattern",
        "peekOfCode": "class TestPattern:\n    def test_basic_creation(self):\n        source = \"\"\"\n            ###\n            #.#\n            ###\n        \"\"\"\n        grid = parse_ascii_into_grid(source)\n        # Create pattern from top-left corner\n        pattern = Pattern(grid, 0, 0, 2)",
        "detail": "tests.map.utils.test_pattern",
        "documentation": {}
    },
    {
        "label": "TestPatternsWithCounts",
        "kind": 6,
        "importPath": "tests.map.utils.test_pattern",
        "description": "tests.map.utils.test_pattern",
        "peekOfCode": "class TestPatternsWithCounts:\n    def test_nonperiodic(self):\n        # Simple 2x2 grid with only one pattern\n        source = \"\"\"\n            ##\n            ##\n        \"\"\"\n        patterns = ascii_to_patterns_with_counts(source, 2, periodic=False, symmetry=\"none\")\n        print(patterns)\n        # There should be 1 pattern (only one 2x2 pattern in a 2x2 source)",
        "detail": "tests.map.utils.test_pattern",
        "documentation": {}
    },
    {
        "label": "TestWeightsOfAllPatterns",
        "kind": 6,
        "importPath": "tests.map.utils.test_pattern",
        "description": "tests.map.utils.test_pattern",
        "peekOfCode": "class TestWeightsOfAllPatterns:\n    def test_simple_source(self):\n        # Simple source with one pattern\n        source = \"\"\"\n            ##\n            ##\n        \"\"\"\n        weights = ascii_to_weights_of_all_patterns(source, 2, periodic=False, symmetry=\"none\")\n        # For a 2x2 pattern, there are 2^4 = 16 possible patterns (0-15)\n        assert len(weights) == 16",
        "detail": "tests.map.utils.test_pattern",
        "documentation": {}
    },
    {
        "label": "simple_map",
        "kind": 2,
        "importPath": "tests.map.utils.test_storable_map_io",
        "description": "tests.map.utils.test_storable_map_io",
        "peekOfCode": "def simple_map():\n    grid = np.array([[\"empty\", \"wall\"], [\"wall\", \"empty\"]], dtype=\"<U50\")\n    return StorableMap(grid, metadata={}, config=DictConfig({}))\ndef test_save_and_load_local(tmp_path):\n    path = tmp_path / \"map.yaml\"\n    m = simple_map()\n    m.save(str(path))\n    loaded = StorableMap.from_uri(str(path))\n    assert np.array_equal(loaded.grid, m.grid)\ndef test_save_s3_uses_file_utils(monkeypatch):",
        "detail": "tests.map.utils.test_storable_map_io",
        "documentation": {}
    },
    {
        "label": "test_save_and_load_local",
        "kind": 2,
        "importPath": "tests.map.utils.test_storable_map_io",
        "description": "tests.map.utils.test_storable_map_io",
        "peekOfCode": "def test_save_and_load_local(tmp_path):\n    path = tmp_path / \"map.yaml\"\n    m = simple_map()\n    m.save(str(path))\n    loaded = StorableMap.from_uri(str(path))\n    assert np.array_equal(loaded.grid, m.grid)\ndef test_save_s3_uses_file_utils(monkeypatch):\n    calls = []\n    def fake_write_data(uri, data, content_type=\"application/octet-stream\"):\n        calls.append((uri, data, content_type))",
        "detail": "tests.map.utils.test_storable_map_io",
        "documentation": {}
    },
    {
        "label": "test_save_s3_uses_file_utils",
        "kind": 2,
        "importPath": "tests.map.utils.test_storable_map_io",
        "description": "tests.map.utils.test_storable_map_io",
        "peekOfCode": "def test_save_s3_uses_file_utils(monkeypatch):\n    calls = []\n    def fake_write_data(uri, data, content_type=\"application/octet-stream\"):\n        calls.append((uri, data, content_type))\n    monkeypatch.setattr(file_utils, \"write_data\", fake_write_data)\n    m = simple_map()\n    m.save(\"s3://bucket/key\")\n    assert calls == [(\"s3://bucket/key\", str(m), \"text/plain\")]",
        "detail": "tests.map.utils.test_storable_map_io",
        "documentation": {}
    },
    {
        "label": "MockParams",
        "kind": 6,
        "importPath": "tests.map.test_scene",
        "description": "tests.map.test_scene",
        "peekOfCode": "class MockParams(Config):\n    pass\nclass MockScene(Scene[MockParams]):\n    def render(self):\n        pass\n@pytest.fixture\ndef scene():\n    # Set NumPy seed for reproducibility\n    np.random.seed(SEED)\n    # Create a 5x5 grid with some test data",
        "detail": "tests.map.test_scene",
        "documentation": {}
    },
    {
        "label": "MockScene",
        "kind": 6,
        "importPath": "tests.map.test_scene",
        "description": "tests.map.test_scene",
        "peekOfCode": "class MockScene(Scene[MockParams]):\n    def render(self):\n        pass\n@pytest.fixture\ndef scene():\n    # Set NumPy seed for reproducibility\n    np.random.seed(SEED)\n    # Create a 5x5 grid with some test data\n    grid = np.array(\n        [",
        "detail": "tests.map.test_scene",
        "documentation": {}
    },
    {
        "label": "scene",
        "kind": 2,
        "importPath": "tests.map.test_scene",
        "description": "tests.map.test_scene",
        "peekOfCode": "def scene():\n    # Set NumPy seed for reproducibility\n    np.random.seed(SEED)\n    # Create a 5x5 grid with some test data\n    grid = np.array(\n        [\n            [\"A\", \"B\", \"C\", \"D\", \"E\"],\n            [\"F\", \"G\", \"H\", \"I\", \"J\"],\n            [\"K\", \"L\", \"M\", \"N\", \"O\"],\n            [\"P\", \"Q\", \"R\", \"S\", \"T\"],",
        "detail": "tests.map.test_scene",
        "documentation": {}
    },
    {
        "label": "test_areas_are_correctly_created",
        "kind": 2,
        "importPath": "tests.map.test_scene",
        "description": "tests.map.test_scene",
        "peekOfCode": "def test_areas_are_correctly_created(scene):\n    assert scene._areas[0].id == 0\n    assert scene._areas[0].tags == [\"tag1\", \"tag2\"]\n    assert np.array_equal(scene._areas[0].grid, np.array([[\"A\", \"B\", \"C\"], [\"F\", \"G\", \"H\"]]))\n    assert scene._areas[1].id == 1\n    assert scene._areas[1].tags == [\"tag2\", \"tag3\"]\n    assert np.array_equal(scene._areas[1].grid, np.array([[\"L\", \"M\"], [\"Q\", \"R\"]]))\n    assert scene._areas[2].id == 2\n    assert scene._areas[2].tags == [\"tag1\", \"tag3\"]\n    assert np.array_equal(scene._areas[2].grid, np.array([[\"N\", \"O\"], [\"S\", \"T\"], [\"X\", \"Y\"]]))",
        "detail": "tests.map.test_scene",
        "documentation": {}
    },
    {
        "label": "test_select_areas_with_where_tags",
        "kind": 2,
        "importPath": "tests.map.test_scene",
        "description": "tests.map.test_scene",
        "peekOfCode": "def test_select_areas_with_where_tags(scene):\n    assert np.random.get_state()[1][0] == SEED  # Verify seed is still effective\n    # Test selecting areas with specific tags\n    query = AreaQuery(where=AreaWhere(tags=[\"tag1\", \"tag2\"]))\n    selected_areas = scene.select_areas(query)\n    assert len(selected_areas) == 1\n    assert selected_areas[0].id == 0  # First area has both tags\n    # Test selecting areas with single tag\n    query = AreaQuery(where=AreaWhere(tags=[\"tag2\"]))\n    selected_areas = scene.select_areas(query)",
        "detail": "tests.map.test_scene",
        "documentation": {}
    },
    {
        "label": "test_select_areas_with_where_full",
        "kind": 2,
        "importPath": "tests.map.test_scene",
        "description": "tests.map.test_scene",
        "peekOfCode": "def test_select_areas_with_where_full(scene):\n    # Test selecting the full area\n    query = AreaQuery(where=\"full\")\n    selected_areas = scene.select_areas(query)\n    assert len(selected_areas) == 1\n    assert selected_areas[0].id == -1  # Full area has id -1\ndef test_select_areas_with_limit(scene):\n    # Test limiting number of results\n    query = AreaQuery(limit=2)\n    selected_areas = scene.select_areas(query)",
        "detail": "tests.map.test_scene",
        "documentation": {}
    },
    {
        "label": "test_select_areas_with_limit",
        "kind": 2,
        "importPath": "tests.map.test_scene",
        "description": "tests.map.test_scene",
        "peekOfCode": "def test_select_areas_with_limit(scene):\n    # Test limiting number of results\n    query = AreaQuery(limit=2)\n    selected_areas = scene.select_areas(query)\n    assert len(selected_areas) == 2\n    # Test with order_by=\"first\"\n    query = AreaQuery(limit=2, order_by=\"first\")\n    selected_areas = scene.select_areas(query)\n    assert len(selected_areas) == 2\n    assert selected_areas[0].id == 0",
        "detail": "tests.map.test_scene",
        "documentation": {}
    },
    {
        "label": "test_select_areas_with_lock",
        "kind": 2,
        "importPath": "tests.map.test_scene",
        "description": "tests.map.test_scene",
        "peekOfCode": "def test_select_areas_with_lock(scene):\n    # Test locking mechanism\n    query = AreaQuery(lock=\"test_lock\", order_by=\"first\", limit=1)\n    selected_areas = scene.select_areas(query)\n    assert len(selected_areas) == 1\n    assert selected_areas[0].id == 0\n    # When we query again, we skip the locked area\n    selected_areas2 = scene.select_areas(query)\n    assert len(selected_areas2) == 1\n    assert selected_areas2[0].id == 1",
        "detail": "tests.map.test_scene",
        "documentation": {}
    },
    {
        "label": "test_select_areas_with_offset",
        "kind": 2,
        "importPath": "tests.map.test_scene",
        "description": "tests.map.test_scene",
        "peekOfCode": "def test_select_areas_with_offset(scene):\n    # Test offset with first ordering\n    query = AreaQuery(limit=2, order_by=\"first\", offset=1)\n    selected_areas = scene.select_areas(query)\n    assert len(selected_areas) == 2\n    assert selected_areas[0].id == 1\n    assert selected_areas[1].id == 2\n    # Test offset with last ordering\n    query = AreaQuery(limit=2, order_by=\"last\", offset=1)\n    selected_areas = scene.select_areas(query)",
        "detail": "tests.map.test_scene",
        "documentation": {}
    },
    {
        "label": "test_select_areas_returns_list_type",
        "kind": 2,
        "importPath": "tests.map.test_scene",
        "description": "tests.map.test_scene",
        "peekOfCode": "def test_select_areas_returns_list_type(scene):\n    \"\"\"Test that select_areas always returns a list, not a numpy array\"\"\"\n    # Test with no query\n    selected_areas = scene.select_areas(AreaQuery())\n    assert isinstance(selected_areas, list), \"select_areas should return a list\"\n    # Test with random ordering (which uses numpy internally)\n    query = AreaQuery(limit=2, order_by=\"random\", order_by_seed=42)\n    selected_areas = scene.select_areas(query)\n    assert isinstance(selected_areas, list), \"select_areas with random ordering should return a list\"\n    # Test with first ordering",
        "detail": "tests.map.test_scene",
        "documentation": {}
    },
    {
        "label": "SEED",
        "kind": 5,
        "importPath": "tests.map.test_scene",
        "description": "tests.map.test_scene",
        "peekOfCode": "SEED = 42\nclass MockParams(Config):\n    pass\nclass MockScene(Scene[MockParams]):\n    def render(self):\n        pass\n@pytest.fixture\ndef scene():\n    # Set NumPy seed for reproducibility\n    np.random.seed(SEED)",
        "detail": "tests.map.test_scene",
        "documentation": {}
    },
    {
        "label": "TestAsciiMap",
        "kind": 6,
        "importPath": "tests.map.test_validate_all_ascii_maps",
        "description": "tests.map.test_validate_all_ascii_maps",
        "peekOfCode": "class TestAsciiMap:\n    \"\"\"Test suite for ASCII map validation.\"\"\"\n    @pytest.fixture\n    def content(self, map_file):\n        with open(map_file, \"r\", encoding=\"utf-8\") as f:\n            return f.read()\n    def test_uses_known_symbols(self, content, map_file):\n        \"\"\"Verify that the map only use symbols defined in SYMBOLS mapping.\"\"\"\n        all_chars = set(content)\n        unknown_chars = all_chars - set(CHAR_TO_NAME.keys()) - {\"\\t\", \"\\r\", \"\\n\"}",
        "detail": "tests.map.test_validate_all_ascii_maps",
        "documentation": {}
    },
    {
        "label": "find_map_files",
        "kind": 2,
        "importPath": "tests.map.test_validate_all_ascii_maps",
        "description": "tests.map.test_validate_all_ascii_maps",
        "peekOfCode": "def find_map_files(root_dir=\"configs\") -> list[str]:\n    \"\"\"\n    Find all .map files.\n    Args:\n        root_dir: Root directory to search from\n    Returns:\n        Sorted list of relative paths for .map files\n    \"\"\"\n    root_path = Path(root_dir).resolve()\n    map_files = list(root_path.rglob(\"*.map\"))",
        "detail": "tests.map.test_validate_all_ascii_maps",
        "documentation": {}
    },
    {
        "label": "map_files",
        "kind": 2,
        "importPath": "tests.map.test_validate_all_ascii_maps",
        "description": "tests.map.test_validate_all_ascii_maps",
        "peekOfCode": "def map_files():\n    return find_map_files()\ndef test_map_files_discovered(map_files):\n    \"\"\"Verify that map files are found in the repository.\"\"\"\n    assert len(map_files) > 0, \"Should discover at least one .map file\"\n@pytest.mark.parametrize(\"map_file\", find_map_files(), ids=[str(path) for path in find_map_files()])\nclass TestAsciiMap:\n    \"\"\"Test suite for ASCII map validation.\"\"\"\n    @pytest.fixture\n    def content(self, map_file):",
        "detail": "tests.map.test_validate_all_ascii_maps",
        "documentation": {}
    },
    {
        "label": "test_map_files_discovered",
        "kind": 2,
        "importPath": "tests.map.test_validate_all_ascii_maps",
        "description": "tests.map.test_validate_all_ascii_maps",
        "peekOfCode": "def test_map_files_discovered(map_files):\n    \"\"\"Verify that map files are found in the repository.\"\"\"\n    assert len(map_files) > 0, \"Should discover at least one .map file\"\n@pytest.mark.parametrize(\"map_file\", find_map_files(), ids=[str(path) for path in find_map_files()])\nclass TestAsciiMap:\n    \"\"\"Test suite for ASCII map validation.\"\"\"\n    @pytest.fixture\n    def content(self, map_file):\n        with open(map_file, \"r\", encoding=\"utf-8\") as f:\n            return f.read()",
        "detail": "tests.map.test_validate_all_ascii_maps",
        "documentation": {}
    },
    {
        "label": "map_or_env_configs",
        "kind": 2,
        "importPath": "tests.map.test_validate_all_env_maps",
        "description": "tests.map.test_validate_all_env_maps",
        "peekOfCode": "def map_or_env_configs() -> list[MettagridCfgFileMetadata]:\n    metadata_by_kind = MettagridCfgFileMetadata.get_all()\n    result = metadata_by_kind[\"map\"] + metadata_by_kind[\"env\"]\n    # If this test is failing and you have configs that are too hard to fix\n    # properly, you can add them to this list.\n    exclude_patterns = [\n        \"multiagent/experiments\",\n        \"multiagent/multiagent\",\n        # \"memory/evals\",\n        \"mettagrid.yaml\",",
        "detail": "tests.map.test_validate_all_env_maps",
        "documentation": {}
    },
    {
        "label": "test_validate_cfg",
        "kind": 2,
        "importPath": "tests.map.test_validate_all_env_maps",
        "description": "tests.map.test_validate_all_env_maps",
        "peekOfCode": "def test_validate_cfg(cfg_metadata):\n    try:\n        map_cfg = cfg_metadata.get_cfg().get_map_cfg()\n        map_builder_cfg_to_storable_map(map_cfg)\n    except (NoCredentialsError, ProfileNotFound) as e:\n        pytest.skip(f\"Skipping {cfg_metadata.path} because it requires AWS credentials: {e}\")\n    except Exception as e:\n        pytest.fail(f\"Failed to validate map config {cfg_metadata.path}: {e}\")",
        "detail": "tests.map.test_validate_all_env_maps",
        "documentation": {}
    },
    {
        "label": "TestComputeGAE",
        "kind": 6,
        "importPath": "tests.rl.fast_gae.test_fast_gae",
        "description": "tests.rl.fast_gae.test_fast_gae",
        "peekOfCode": "class TestComputeGAE:\n    \"\"\"Test suite for the compute_gae function.\"\"\"\n    def test_basic_functionality(self, simple_trajectory, gae_params):\n        \"\"\"Test basic GAE calculation on a simple trajectory.\"\"\"\n        data = simple_trajectory\n        gamma = gae_params[\"gamma\"]\n        gae_lambda = gae_params[\"gae_lambda\"]\n        # Compute with both implementations\n        expected = numpy_compute_gae(data[\"dones\"], data[\"values\"], data[\"rewards\"], gamma, gae_lambda)\n        advantages = compute_gae(data[\"dones\"], data[\"values\"], data[\"rewards\"], gamma, gae_lambda)",
        "detail": "tests.rl.fast_gae.test_fast_gae",
        "documentation": {}
    },
    {
        "label": "numpy_compute_gae",
        "kind": 2,
        "importPath": "tests.rl.fast_gae.test_fast_gae",
        "description": "tests.rl.fast_gae.test_fast_gae",
        "peekOfCode": "def numpy_compute_gae(dones, values, rewards, gamma, gae_lambda):\n    \"\"\"Pure NumPy implementation of GAE for testing purposes.\n    Args:\n        dones: Binary flags indicating episode termination (1.0 for done, 0.0 for not done)\n        values: Value function estimates at each timestep\n        rewards: Rewards at each timestep\n        gamma: Discount factor\n        gae_lambda: GAE lambda parameter for advantage estimation\n    Returns:\n        advantages: Calculated advantage values",
        "detail": "tests.rl.fast_gae.test_fast_gae",
        "documentation": {}
    },
    {
        "label": "gae_params",
        "kind": 2,
        "importPath": "tests.rl.fast_gae.test_fast_gae",
        "description": "tests.rl.fast_gae.test_fast_gae",
        "peekOfCode": "def gae_params():\n    \"\"\"Provides standard GAE hyperparameters.\"\"\"\n    return {\"gamma\": 0.99, \"gae_lambda\": 0.95}\n# Fixtures for test data\n@pytest.fixture(scope=\"function\")\ndef simple_trajectory():\n    \"\"\"Basic trajectory for testing GAE calculation.\"\"\"\n    return {\n        \"dones\": np.array([0.0, 0.0, 0.0, 1.0], dtype=np.float32),\n        \"values\": np.array([1.0, 2.0, 3.0, 4.0], dtype=np.float32),",
        "detail": "tests.rl.fast_gae.test_fast_gae",
        "documentation": {}
    },
    {
        "label": "simple_trajectory",
        "kind": 2,
        "importPath": "tests.rl.fast_gae.test_fast_gae",
        "description": "tests.rl.fast_gae.test_fast_gae",
        "peekOfCode": "def simple_trajectory():\n    \"\"\"Basic trajectory for testing GAE calculation.\"\"\"\n    return {\n        \"dones\": np.array([0.0, 0.0, 0.0, 1.0], dtype=np.float32),\n        \"values\": np.array([1.0, 2.0, 3.0, 4.0], dtype=np.float32),\n        \"rewards\": np.array([0.5, 0.5, 0.5, 10.0], dtype=np.float32),\n        \"expected_with_gamma_0_99\": np.array([-2.005, -2.5, 0.0, 0.0], dtype=np.float32),\n    }\n@pytest.fixture(scope=\"function\")\ndef multi_episode_trajectory():",
        "detail": "tests.rl.fast_gae.test_fast_gae",
        "documentation": {}
    },
    {
        "label": "multi_episode_trajectory",
        "kind": 2,
        "importPath": "tests.rl.fast_gae.test_fast_gae",
        "description": "tests.rl.fast_gae.test_fast_gae",
        "peekOfCode": "def multi_episode_trajectory():\n    \"\"\"Trajectory with multiple episodes to test episode boundary handling.\"\"\"\n    return {\n        \"dones\": np.array([0.0, 1.0, 0.0, 1.0], dtype=np.float32),\n        \"values\": np.array([1.0, 2.0, 1.0, 2.0], dtype=np.float32),\n        \"rewards\": np.array([0.5, 1.0, 0.5, 1.0], dtype=np.float32),\n    }\n@pytest.fixture(scope=\"function\")\ndef zeros_trajectory():\n    \"\"\"Edge case with all zeros to test numerical stability.\"\"\"",
        "detail": "tests.rl.fast_gae.test_fast_gae",
        "documentation": {}
    },
    {
        "label": "zeros_trajectory",
        "kind": 2,
        "importPath": "tests.rl.fast_gae.test_fast_gae",
        "description": "tests.rl.fast_gae.test_fast_gae",
        "peekOfCode": "def zeros_trajectory():\n    \"\"\"Edge case with all zeros to test numerical stability.\"\"\"\n    return {\n        \"dones\": np.zeros(5, dtype=np.float32),\n        \"values\": np.zeros(5, dtype=np.float32),\n        \"rewards\": np.zeros(5, dtype=np.float32),\n    }\n@pytest.fixture(scope=\"function\")\ndef constant_trajectory():\n    \"\"\"Trajectory with constant values for testing different gamma/lambda effects.\"\"\"",
        "detail": "tests.rl.fast_gae.test_fast_gae",
        "documentation": {}
    },
    {
        "label": "constant_trajectory",
        "kind": 2,
        "importPath": "tests.rl.fast_gae.test_fast_gae",
        "description": "tests.rl.fast_gae.test_fast_gae",
        "peekOfCode": "def constant_trajectory():\n    \"\"\"Trajectory with constant values for testing different gamma/lambda effects.\"\"\"\n    return {\n        \"dones\": np.array([0.0, 0.0, 0.0, 0.0], dtype=np.float32),\n        \"values\": np.array([1.0, 1.0, 1.0, 1.0], dtype=np.float32),\n        \"rewards\": np.array([1.0, 1.0, 1.0, 1.0], dtype=np.float32),\n    }\n@pytest.fixture(scope=\"function\")\ndef mismatched_arrays():\n    \"\"\"Arrays with mismatched lengths for testing input validation.\"\"\"",
        "detail": "tests.rl.fast_gae.test_fast_gae",
        "documentation": {}
    },
    {
        "label": "mismatched_arrays",
        "kind": 2,
        "importPath": "tests.rl.fast_gae.test_fast_gae",
        "description": "tests.rl.fast_gae.test_fast_gae",
        "peekOfCode": "def mismatched_arrays():\n    \"\"\"Arrays with mismatched lengths for testing input validation.\"\"\"\n    return {\n        \"dones\": np.array([0.0, 0.0], dtype=np.float32),\n        \"values\": np.array([1.0, 1.0, 1.0], dtype=np.float32),\n        \"rewards\": np.array([0.5, 0.5, 0.5], dtype=np.float32),\n    }\n# Benchmark fixtures with different sizes\n@pytest.fixture(scope=\"module\")\ndef make_trajectory():",
        "detail": "tests.rl.fast_gae.test_fast_gae",
        "documentation": {}
    },
    {
        "label": "make_trajectory",
        "kind": 2,
        "importPath": "tests.rl.fast_gae.test_fast_gae",
        "description": "tests.rl.fast_gae.test_fast_gae",
        "peekOfCode": "def make_trajectory():\n    \"\"\"Factory fixture to create trajectories of variable size.\"\"\"\n    def _make_trajectory(size, gamma=0.99, gae_lambda=0.95, random_values=False):\n        dones = np.zeros(size, dtype=np.float32)\n        dones[-1] = 1.0\n        if random_values:\n            # Use fixed seed for reproducibility\n            rng = np.random.RandomState(42)\n            values = rng.normal(0, 1, size=size).astype(np.float32)\n            rewards = rng.normal(0, 1, size=size).astype(np.float32)",
        "detail": "tests.rl.fast_gae.test_fast_gae",
        "documentation": {}
    },
    {
        "label": "small_trajectory",
        "kind": 2,
        "importPath": "tests.rl.fast_gae.test_fast_gae",
        "description": "tests.rl.fast_gae.test_fast_gae",
        "peekOfCode": "def small_trajectory(make_trajectory):\n    \"\"\"Small trajectory (100 timesteps) for benchmarking.\"\"\"\n    return make_trajectory(100)\n@pytest.fixture(scope=\"function\")\ndef medium_trajectory(make_trajectory):\n    \"\"\"Medium trajectory (1000 timesteps) for benchmarking.\"\"\"\n    return make_trajectory(1000)\n@pytest.fixture(scope=\"function\")\ndef large_trajectory(make_trajectory):\n    \"\"\"Large trajectory (10000 timesteps) for benchmarking.\"\"\"",
        "detail": "tests.rl.fast_gae.test_fast_gae",
        "documentation": {}
    },
    {
        "label": "medium_trajectory",
        "kind": 2,
        "importPath": "tests.rl.fast_gae.test_fast_gae",
        "description": "tests.rl.fast_gae.test_fast_gae",
        "peekOfCode": "def medium_trajectory(make_trajectory):\n    \"\"\"Medium trajectory (1000 timesteps) for benchmarking.\"\"\"\n    return make_trajectory(1000)\n@pytest.fixture(scope=\"function\")\ndef large_trajectory(make_trajectory):\n    \"\"\"Large trajectory (10000 timesteps) for benchmarking.\"\"\"\n    return make_trajectory(10000)\n@pytest.fixture(scope=\"function\")\ndef realistic_rl_batch(gae_params):\n    \"\"\"Realistic batch size in RL (e.g., PPO with 8 parallel environments, 128 steps).\"\"\"",
        "detail": "tests.rl.fast_gae.test_fast_gae",
        "documentation": {}
    },
    {
        "label": "large_trajectory",
        "kind": 2,
        "importPath": "tests.rl.fast_gae.test_fast_gae",
        "description": "tests.rl.fast_gae.test_fast_gae",
        "peekOfCode": "def large_trajectory(make_trajectory):\n    \"\"\"Large trajectory (10000 timesteps) for benchmarking.\"\"\"\n    return make_trajectory(10000)\n@pytest.fixture(scope=\"function\")\ndef realistic_rl_batch(gae_params):\n    \"\"\"Realistic batch size in RL (e.g., PPO with 8 parallel environments, 128 steps).\"\"\"\n    # Use fixed seed for reproducibility\n    rng = np.random.RandomState(42)\n    batch_size = 1024  # 8 envs * 128 steps\n    dones = np.zeros(batch_size, dtype=np.float32)",
        "detail": "tests.rl.fast_gae.test_fast_gae",
        "documentation": {}
    },
    {
        "label": "realistic_rl_batch",
        "kind": 2,
        "importPath": "tests.rl.fast_gae.test_fast_gae",
        "description": "tests.rl.fast_gae.test_fast_gae",
        "peekOfCode": "def realistic_rl_batch(gae_params):\n    \"\"\"Realistic batch size in RL (e.g., PPO with 8 parallel environments, 128 steps).\"\"\"\n    # Use fixed seed for reproducibility\n    rng = np.random.RandomState(42)\n    batch_size = 1024  # 8 envs * 128 steps\n    dones = np.zeros(batch_size, dtype=np.float32)\n    # Add episode terminations at the end of each environment trajectory\n    dones[127::128] = 1.0\n    return {\n        \"dones\": dones,",
        "detail": "tests.rl.fast_gae.test_fast_gae",
        "documentation": {}
    },
    {
        "label": "TestKickstarter",
        "kind": 6,
        "importPath": "tests.rl.test_kickstarter",
        "description": "tests.rl.test_kickstarter",
        "peekOfCode": "class TestKickstarter:\n    \"\"\"Test suite for the Kickstarter class.\"\"\"\n    @pytest.fixture\n    def mock_config(self):\n        \"\"\"Create a mock configuration for testing.\"\"\"\n        cfg = MagicMock()\n        cfg.additional_teachers = None\n        cfg.anneal_ratio = 0.2\n        cfg.teacher_uri = None\n        cfg.kickstart_steps = 1000",
        "detail": "tests.rl.test_kickstarter",
        "documentation": {}
    },
    {
        "label": "TestLosses",
        "kind": 6,
        "importPath": "tests.rl.test_losses",
        "description": "tests.rl.test_losses",
        "peekOfCode": "class TestLosses:\n    \"\"\"Test suite for the Losses class.\"\"\"\n    def test_initialization(self):\n        \"\"\"Test that a new Losses instance is properly initialized with zeros.\"\"\"\n        losses = Losses()\n        # Check that all loss values are initialized to zero\n        assert losses.policy_loss_sum == 0.0\n        assert losses.value_loss_sum == 0.0\n        assert losses.entropy_sum == 0.0\n        assert losses.approx_kl_sum == 0.0",
        "detail": "tests.rl.test_losses",
        "documentation": {}
    },
    {
        "label": "TestTypedConfigs",
        "kind": 6,
        "importPath": "tests.rl.test_trainer_config",
        "description": "tests.rl.test_trainer_config",
        "peekOfCode": "class TestTypedConfigs:\n    def test_basic_typed_config_parsing(self):\n        trainer_config = parse_trainer_config(make_cfg(valid_trainer_config))\n        assert trainer_config.optimizer.type == \"adam\"\n        assert trainer_config.optimizer.learning_rate == 0.001\n        assert trainer_config.bptt_horizon == 32\n        # Test that runtime paths are set correctly\n        assert trainer_config.checkpoint.checkpoint_dir == \"/tmp/test_run/checkpoints\"\n        assert trainer_config.simulation.replay_dir == \"s3://softmax-public/replays/test_run\"\n    def test_config_field_validation(self):",
        "detail": "tests.rl.test_trainer_config",
        "documentation": {}
    },
    {
        "label": "TestRealTypedConfigs",
        "kind": 6,
        "importPath": "tests.rl.test_trainer_config",
        "description": "tests.rl.test_trainer_config",
        "peekOfCode": "class TestRealTypedConfigs:\n    def test_all_trainer_configs_comprehensive(self):\n        config_files = [f.stem for f in Path(configs_dir).glob(\"*.yaml\")]\n        for config_name in config_files:\n            try:\n                # some of the configs don't have num_workers specified because train.sh provides it\n                cfg = load_config_with_hydra(config_name, overrides=[\"trainer.num_workers=1\"])\n                validated_config = parse_trainer_config(cfg)\n                # Verify some basic fields and  constraints\n                assert validated_config.batch_size > 0",
        "detail": "tests.rl.test_trainer_config",
        "documentation": {}
    },
    {
        "label": "make_cfg",
        "kind": 2,
        "importPath": "tests.rl.test_trainer_config",
        "description": "tests.rl.test_trainer_config",
        "peekOfCode": "def make_cfg(trainer_cfg: dict) -> DictConfig:\n    return DictConfig(\n        {\n            \"run_dir\": \"/tmp/test_run\",\n            \"run\": \"test_run\",\n            \"trainer\": trainer_cfg,\n        }\n    )\nclass TestTypedConfigs:\n    def test_basic_typed_config_parsing(self):",
        "detail": "tests.rl.test_trainer_config",
        "documentation": {}
    },
    {
        "label": "load_config_with_hydra",
        "kind": 2,
        "importPath": "tests.rl.test_trainer_config",
        "description": "tests.rl.test_trainer_config",
        "peekOfCode": "def load_config_with_hydra(trainer_name: str, overrides: list[str] | None = None) -> DictConfig:\n    configs_dir = str(Path(__file__).parent.parent.parent / \"configs\")\n    default_overrides = [\n        \"run=test_run\",\n        f\"trainer={trainer_name}\",\n        \"wandb=off\",  # Disable wandb for tests\n    ]\n    with initialize_config_dir(config_dir=configs_dir, version_base=None):\n        return compose(\n            config_name=\"train_job\",",
        "detail": "tests.rl.test_trainer_config",
        "documentation": {}
    },
    {
        "label": "valid_optimizer_config",
        "kind": 5,
        "importPath": "tests.rl.test_trainer_config",
        "description": "tests.rl.test_trainer_config",
        "peekOfCode": "valid_optimizer_config = {\n    \"type\": \"adam\",\n    \"learning_rate\": 0.001,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"eps\": 1e-8,\n    \"weight_decay\": 0.0,\n}\n# Complete valid trainer config with all required fields\nvalid_trainer_config = {",
        "detail": "tests.rl.test_trainer_config",
        "documentation": {}
    },
    {
        "label": "valid_trainer_config",
        "kind": 5,
        "importPath": "tests.rl.test_trainer_config",
        "description": "tests.rl.test_trainer_config",
        "peekOfCode": "valid_trainer_config = {\n    \"_target_\": \"metta.rl.trainer.MettaTrainer\",\n    \"total_timesteps\": 1000000,\n    \"batch_size\": 1024,\n    \"minibatch_size\": 256,\n    \"bptt_horizon\": 32,\n    \"update_epochs\": 1,\n    \"forward_pass_minibatch_target_size\": 512,\n    \"async_factor\": 2,\n    \"zero_copy\": True,",
        "detail": "tests.rl.test_trainer_config",
        "documentation": {}
    },
    {
        "label": "configs_dir",
        "kind": 5,
        "importPath": "tests.rl.test_trainer_config",
        "description": "tests.rl.test_trainer_config",
        "peekOfCode": "configs_dir = str(Path(__file__).parent.parent.parent / \"configs\" / \"trainer\")\ndef load_config_with_hydra(trainer_name: str, overrides: list[str] | None = None) -> DictConfig:\n    configs_dir = str(Path(__file__).parent.parent.parent / \"configs\")\n    default_overrides = [\n        \"run=test_run\",\n        f\"trainer={trainer_name}\",\n        \"wandb=off\",  # Disable wandb for tests\n    ]\n    with initialize_config_dir(config_dir=configs_dir, version_base=None):\n        return compose(",
        "detail": "tests.rl.test_trainer_config",
        "documentation": {}
    },
    {
        "label": "build_simulation_suite_config",
        "kind": 2,
        "importPath": "tests.sim.test_simulation_config",
        "description": "tests.sim.test_simulation_config",
        "peekOfCode": "def build_simulation_suite_config():\n    def _build(cfg: Dict):\n        # First create the OmegaConf object\n        dict_config = OmegaConf.create(cfg)\n        # Convert to a Python dictionary\n        regular_dict = OmegaConf.to_container(dict_config, resolve=True)\n        # Now create the SimulationSuiteConfig using the model_validate method\n        return SimulationSuiteConfig.model_validate(regular_dict)\n    return _build\n# ---------------------------------------------------------------------------",
        "detail": "tests.sim.test_simulation_config",
        "documentation": {}
    },
    {
        "label": "test_propagate_defaults_and_overrides",
        "kind": 2,
        "importPath": "tests.sim.test_simulation_config",
        "description": "tests.sim.test_simulation_config",
        "peekOfCode": "def test_propagate_defaults_and_overrides(build_simulation_suite_config):\n    cfg = {\n        \"name\": \"test\",\n        \"num_episodes\": 4,\n        \"simulations\": {\n            \"a\": {\"env\": CHILD_A},  # inherits device, num_envs is default (50)\n            \"b\": {\"env\": CHILD_B, \"num_episodes\": 8},  # overrides num_envs\n        },\n    }\n    suite = build_simulation_suite_config(cfg)",
        "detail": "tests.sim.test_simulation_config",
        "documentation": {}
    },
    {
        "label": "test_allow_extra_child_keys",
        "kind": 2,
        "importPath": "tests.sim.test_simulation_config",
        "description": "tests.sim.test_simulation_config",
        "peekOfCode": "def test_allow_extra_child_keys(build_simulation_suite_config, has_extra, should_pass):\n    child_node = {\"env\": CHILD_A}\n    if has_extra:\n        child_node[\"foo\"] = \"bar\"  # <- unknown key\n    cfg = {\n        \"name\": \"test\",\n        \"num_episodes\": 4,\n        \"simulations\": {\"sim\": child_node},\n    }\n    if should_pass:",
        "detail": "tests.sim.test_simulation_config",
        "documentation": {}
    },
    {
        "label": "test_missing_device_always_errors",
        "kind": 2,
        "importPath": "tests.sim.test_simulation_config",
        "description": "tests.sim.test_simulation_config",
        "peekOfCode": "def test_missing_device_always_errors(build_simulation_suite_config):\n    cfg = {\n        \"num_episodes\": 4,\n        \"simulations\": {\"sim\": {}},\n    }\n    with pytest.raises(ValidationError):\n        build_simulation_suite_config(cfg)\ndef test_missing_suite_env_is_allowed(build_simulation_suite_config):\n    cfg = {\n        \"name\": \"test\",",
        "detail": "tests.sim.test_simulation_config",
        "documentation": {}
    },
    {
        "label": "test_missing_suite_env_is_allowed",
        "kind": 2,
        "importPath": "tests.sim.test_simulation_config",
        "description": "tests.sim.test_simulation_config",
        "peekOfCode": "def test_missing_suite_env_is_allowed(build_simulation_suite_config):\n    cfg = {\n        \"name\": \"test\",\n        \"num_episodes\": 4,\n        \"simulations\": {\n            \"sim\": {\n                \"env\": CHILD_A,\n            }\n        },\n    }",
        "detail": "tests.sim.test_simulation_config",
        "documentation": {}
    },
    {
        "label": "DEVICE",
        "kind": 5,
        "importPath": "tests.sim.test_simulation_config",
        "description": "tests.sim.test_simulation_config",
        "peekOfCode": "DEVICE = \"cpu\"\n@pytest.fixture\ndef build_simulation_suite_config():\n    def _build(cfg: Dict):\n        # First create the OmegaConf object\n        dict_config = OmegaConf.create(cfg)\n        # Convert to a Python dictionary\n        regular_dict = OmegaConf.to_container(dict_config, resolve=True)\n        # Now create the SimulationSuiteConfig using the model_validate method\n        return SimulationSuiteConfig.model_validate(regular_dict)",
        "detail": "tests.sim.test_simulation_config",
        "documentation": {}
    },
    {
        "label": "get_count",
        "kind": 2,
        "importPath": "tests.sim.test_simulation_stats_db",
        "description": "tests.sim.test_simulation_stats_db",
        "peekOfCode": "def get_count(con: DuckDBPyConnection, query: str) -> int:\n    result = con.execute(query).fetchone()\n    assert result is not None\n    return result[0]\ndef _create_worker_db(path: Path, sim_steps: int = 0) -> str:\n    path.parent.mkdir(parents=True, exist_ok=True)\n    db = SimulationStatsDB(path)\n    episode_id = str(uuid.uuid4())\n    attributes = {\"seed\": \"0\", \"map_w\": \"1\", \"map_h\": \"1\"}\n    agent_metrics = {0: {\"reward\": 1.0}}",
        "detail": "tests.sim.test_simulation_stats_db",
        "documentation": {}
    },
    {
        "label": "test_from_uri_context_manager",
        "kind": 2,
        "importPath": "tests.sim.test_simulation_stats_db",
        "description": "tests.sim.test_simulation_stats_db",
        "peekOfCode": "def test_from_uri_context_manager(tmp_path: Path):\n    db_path = tmp_path / \"test_db.duckdb\"\n    ep_id = _create_worker_db(db_path)\n    with SimulationStatsDB.from_uri(str(db_path)) as db:\n        episode_ids = [row[0] for row in db.con.execute(\"SELECT id FROM episodes\").fetchall()]\n        assert ep_id in episode_ids\ndef test_insert_agent_policies(tmp_path: Path):\n    db_path = tmp_path / \"policies.duckdb\"\n    db = SimulationStatsDB(db_path)\n    for _, sql in db.tables().items():",
        "detail": "tests.sim.test_simulation_stats_db",
        "documentation": {}
    },
    {
        "label": "test_insert_agent_policies",
        "kind": 2,
        "importPath": "tests.sim.test_simulation_stats_db",
        "description": "tests.sim.test_simulation_stats_db",
        "peekOfCode": "def test_insert_agent_policies(tmp_path: Path):\n    db_path = tmp_path / \"policies.duckdb\"\n    db = SimulationStatsDB(db_path)\n    for _, sql in db.tables().items():\n        db.con.execute(sql)\n    episode_id = str(uuid.uuid4())\n    db.con.execute(\"INSERT INTO episodes (id) VALUES (?)\", (episode_id,))\n    agent_map = {0: (\"policy_a\", 1), 1: (\"policy_b\", 0)}\n    db._insert_agent_policies([episode_id], agent_map)\n    rows = db.con.execute(\"SELECT * FROM agent_policies\").fetchall()",
        "detail": "tests.sim.test_simulation_stats_db",
        "documentation": {}
    },
    {
        "label": "test_insert_agent_policies_empty_inputs",
        "kind": 2,
        "importPath": "tests.sim.test_simulation_stats_db",
        "description": "tests.sim.test_simulation_stats_db",
        "peekOfCode": "def test_insert_agent_policies_empty_inputs(tmp_path: Path):\n    db_path = tmp_path / \"empty_policies.duckdb\"\n    db = SimulationStatsDB(db_path)\n    for _, sql in db.tables().items():\n        db.con.execute(sql)\n    db._insert_agent_policies([], _DUMMY_AGENT_MAP)\n    db._insert_agent_policies([str(uuid.uuid4())], {})\n    count = get_count(db.con, \"SELECT COUNT(*) FROM agent_policies\")\n    assert count == 0\n    db.close()",
        "detail": "tests.sim.test_simulation_stats_db",
        "documentation": {}
    },
    {
        "label": "test_merge_in",
        "kind": 2,
        "importPath": "tests.sim.test_simulation_stats_db",
        "description": "tests.sim.test_simulation_stats_db",
        "peekOfCode": "def test_merge_in(tmp_path: Path):\n    db1_path = tmp_path / \"db1.duckdb\"\n    db2_path = tmp_path / \"db2.duckdb\"\n    ep1 = _create_worker_db(db1_path)\n    ep2 = _create_worker_db(db2_path)\n    db1 = SimulationStatsDB(db1_path)\n    db2 = SimulationStatsDB(db2_path)\n    db1.merge_in(db2)\n    episodes = db1.con.execute(\"SELECT id FROM episodes\").fetchall()\n    episode_ids = [row[0] for row in episodes]",
        "detail": "tests.sim.test_simulation_stats_db",
        "documentation": {}
    },
    {
        "label": "test_tables",
        "kind": 2,
        "importPath": "tests.sim.test_simulation_stats_db",
        "description": "tests.sim.test_simulation_stats_db",
        "peekOfCode": "def test_tables(tmp_path: Path):\n    db_path = tmp_path / \"tables.duckdb\"\n    db = SimulationStatsDB(db_path)\n    tables = db.tables()\n    assert \"episodes\" in tables\n    assert \"agent_metrics\" in tables\n    assert \"simulations\" in tables\n    assert \"agent_policies\" in tables\n    db.close()\ndef test_insert_simulation(tmp_path: Path):",
        "detail": "tests.sim.test_simulation_stats_db",
        "documentation": {}
    },
    {
        "label": "test_insert_simulation",
        "kind": 2,
        "importPath": "tests.sim.test_simulation_stats_db",
        "description": "tests.sim.test_simulation_stats_db",
        "peekOfCode": "def test_insert_simulation(tmp_path: Path):\n    db_path = tmp_path / \"sim_table.duckdb\"\n    db = SimulationStatsDB(db_path)\n    for _, sql in db.tables().items():\n        db.con.execute(sql)\n    sim_id = str(uuid.uuid4())\n    policy_key = \"test_policy\"\n    policy_version = 1\n    db._insert_simulation(sim_id, \"test_sim\", \"test_suite\", \"test_env\", policy_key, policy_version)\n    rows = db.con.execute(\"SELECT id, name, suite, env, policy_key, policy_version FROM simulations\").fetchall()",
        "detail": "tests.sim.test_simulation_stats_db",
        "documentation": {}
    },
    {
        "label": "test_get_replay_urls",
        "kind": 2,
        "importPath": "tests.sim.test_simulation_stats_db",
        "description": "tests.sim.test_simulation_stats_db",
        "peekOfCode": "def test_get_replay_urls(tmp_path: Path):\n    \"\"\"Test retrieving replay URLs with various filters.\"\"\"\n    db_path = tmp_path / \"replay_urls.duckdb\"\n    db = SimulationStatsDB(db_path)\n    # Create tables\n    for _, sql in db.tables().items():\n        db.con.execute(sql)\n    # Add the simulation_id column to episodes if it doesn't exist\n    db.con.execute(\"ALTER TABLE episodes ADD COLUMN IF NOT EXISTS simulation_id TEXT\")\n    # Create a few episodes with replay URLs",
        "detail": "tests.sim.test_simulation_stats_db",
        "documentation": {}
    },
    {
        "label": "test_from_shards_and_context",
        "kind": 2,
        "importPath": "tests.sim.test_simulation_stats_db",
        "description": "tests.sim.test_simulation_stats_db",
        "peekOfCode": "def test_from_shards_and_context(tmp_path: Path):\n    \"\"\"Test creating a SimulationStatsDB from shards and context.\n    This test creates a shard database with a test episode, then uses the\n    from_shards_and_context method to merge it into a new database.\n    \"\"\"\n    # Create a shard with some data\n    shard_dir = tmp_path / \"shards\"\n    shard_dir.mkdir(parents=True, exist_ok=True)\n    shard_path = shard_dir / \"shard.duckdb\"\n    ep_id = _create_worker_db(shard_path)",
        "detail": "tests.sim.test_simulation_stats_db",
        "documentation": {}
    },
    {
        "label": "test_sequential_policy_merges",
        "kind": 2,
        "importPath": "tests.sim.test_simulation_stats_db",
        "description": "tests.sim.test_simulation_stats_db",
        "peekOfCode": "def test_sequential_policy_merges(tmp_path: Path):\n    \"\"\"Test that policies are preserved during sequential merges.\n    This test simulates the workflow in the actual code where:\n    1. We create a database with Policy A\n    2. Export it to a destination\n    3. Create a new database with Policy B\n    4. Have the new database merge with the exported one\n    5. Export the result\n    6. Verify both policies exist in the final database\n    \"\"\"",
        "detail": "tests.sim.test_simulation_stats_db",
        "documentation": {}
    },
    {
        "label": "test_export_preserves_all_policies",
        "kind": 2,
        "importPath": "tests.sim.test_simulation_stats_db",
        "description": "tests.sim.test_simulation_stats_db",
        "peekOfCode": "def test_export_preserves_all_policies(tmp_path: Path):\n    \"\"\"Test that export correctly preserves all policies when merging.\"\"\"\n    # Create a database with two policies\n    db_path = tmp_path / \"source.duckdb\"\n    db = SimulationStatsDB(db_path)\n    for _, sql in db.tables().items():\n        db.con.execute(sql)\n    # Add two different policies\n    db._insert_simulation(\"sim1\", \"test_sim\", \"test_suite\", \"env_test\", \"policy_X\", 1)\n    db._insert_simulation(\"sim2\", \"test_sim\", \"test_suite\", \"env_test\", \"policy_Y\", 1)",
        "detail": "tests.sim.test_simulation_stats_db",
        "documentation": {}
    },
    {
        "label": "_DUMMY_AGENT_MAP",
        "kind": 5,
        "importPath": "tests.sim.test_simulation_stats_db",
        "description": "tests.sim.test_simulation_stats_db",
        "peekOfCode": "_DUMMY_AGENT_MAP = {0: (\"dummy_policy\", 0)}\ndef test_from_uri_context_manager(tmp_path: Path):\n    db_path = tmp_path / \"test_db.duckdb\"\n    ep_id = _create_worker_db(db_path)\n    with SimulationStatsDB.from_uri(str(db_path)) as db:\n        episode_ids = [row[0] for row in db.con.execute(\"SELECT id FROM episodes\").fetchall()]\n        assert ep_id in episode_ids\ndef test_insert_agent_policies(tmp_path: Path):\n    db_path = tmp_path / \"policies.duckdb\"\n    db = SimulationStatsDB(db_path)",
        "detail": "tests.sim.test_simulation_stats_db",
        "documentation": {}
    },
    {
        "label": "TestMettaProtein",
        "kind": 6,
        "importPath": "tests.sweep.test_protein_metta",
        "description": "tests.sweep.test_protein_metta",
        "peekOfCode": "class TestMettaProtein:\n    \"\"\"Test cases for MettaProtein class.\"\"\"\n    def test_metta_protein_init_with_full_config(self):\n        \"\"\"Test MettaProtein initialization with complete config.\"\"\"\n        config = OmegaConf.create(\n            {\n                \"protein\": {\n                    \"max_suggestion_cost\": 7200,\n                    \"resample_frequency\": 0,\n                    \"num_random_samples\": 100,",
        "detail": "tests.sweep.test_protein_metta",
        "documentation": {}
    },
    {
        "label": "TestWandbProtein",
        "kind": 6,
        "importPath": "tests.sweep.test_protein_wandb",
        "description": "tests.sweep.test_protein_wandb",
        "peekOfCode": "class TestWandbProtein:\n    \"\"\"Test cases for WandbProtein class with real wandb integration.\"\"\"\n    @pytest.fixture(autouse=True)\n    def setup_wandb(self):\n        \"\"\"Setup wandb for testing with offline mode.\"\"\"\n        # Use a temporary directory for wandb\n        self.temp_dir = tempfile.mkdtemp()\n        os.environ[\"WANDB_DIR\"] = self.temp_dir\n        os.environ[\"WANDB_MODE\"] = \"offline\"  # Prevent actual API calls\n        os.environ[\"WANDB_SILENT\"] = \"true\"  # Reduce logging noise",
        "detail": "tests.sweep.test_protein_wandb",
        "documentation": {}
    },
    {
        "label": "test_gen_basic",
        "kind": 2,
        "importPath": "tests.tools.map.test_gen",
        "description": "tests.tools.map.test_gen",
        "peekOfCode": "def test_gen_basic():\n    subprocess.check_call(\n        [\n            \"python\",\n            \"-m\",\n            f\"{MAP_MODULE}.gen\",\n            \"--show-mode\",\n            \"ascii\",\n            MAZE_CONFIG,\n        ]",
        "detail": "tests.tools.map.test_gen",
        "documentation": {}
    },
    {
        "label": "test_hydra",
        "kind": 2,
        "importPath": "tests.tools.map.test_gen",
        "description": "tests.tools.map.test_gen",
        "peekOfCode": "def test_hydra():\n    subprocess.check_call(\n        [\n            \"python\",\n            \"-m\",\n            f\"{MAP_MODULE}.gen\",\n            \"--show-mode\",\n            \"ascii\",\n            \"./configs/env/mettagrid/puffer.yaml\",\n        ]",
        "detail": "tests.tools.map.test_gen",
        "documentation": {}
    },
    {
        "label": "test_gen_missing_config",
        "kind": 2,
        "importPath": "tests.tools.map.test_gen",
        "description": "tests.tools.map.test_gen",
        "peekOfCode": "def test_gen_missing_config():\n    exit_status = subprocess.call(\n        [\n            \"python\",\n            \"-m\",\n            f\"{MAP_MODULE}.gen\",\n            \"--show-mode\",\n            \"ascii\",\n            \"./NON_EXISTENT_CONFIG.yaml\",\n        ]",
        "detail": "tests.tools.map.test_gen",
        "documentation": {}
    },
    {
        "label": "test_save",
        "kind": 2,
        "importPath": "tests.tools.map.test_gen",
        "description": "tests.tools.map.test_gen",
        "peekOfCode": "def test_save(tmpdir):\n    subprocess.check_call(\n        [\n            \"python\",\n            \"-m\",\n            f\"{MAP_MODULE}.gen\",\n            \"--output-uri\",\n            tmpdir,\n            \"--show-mode\",\n            \"ascii\",",
        "detail": "tests.tools.map.test_gen",
        "documentation": {}
    },
    {
        "label": "test_save_exact_file",
        "kind": 2,
        "importPath": "tests.tools.map.test_gen",
        "description": "tests.tools.map.test_gen",
        "peekOfCode": "def test_save_exact_file(tmpdir):\n    subprocess.check_call(\n        [\n            \"python\",\n            \"-m\",\n            f\"{MAP_MODULE}.gen\",\n            \"--output-uri\",\n            tmpdir + \"/map.yaml\",\n            \"--show-mode\",\n            \"ascii\",",
        "detail": "tests.tools.map.test_gen",
        "documentation": {}
    },
    {
        "label": "test_save_multiple",
        "kind": 2,
        "importPath": "tests.tools.map.test_gen",
        "description": "tests.tools.map.test_gen",
        "peekOfCode": "def test_save_multiple(tmpdir):\n    count = 3\n    subprocess.check_call(\n        [\n            \"python\",\n            \"-m\",\n            f\"{MAP_MODULE}.gen\",\n            \"--output-uri\",\n            tmpdir,\n            \"--show-mode\",",
        "detail": "tests.tools.map.test_gen",
        "documentation": {}
    },
    {
        "label": "test_view",
        "kind": 2,
        "importPath": "tests.tools.map.test_gen",
        "description": "tests.tools.map.test_gen",
        "peekOfCode": "def test_view(tmpdir):\n    subprocess.check_call(\n        [\n            \"python\",\n            \"-m\",\n            f\"{MAP_MODULE}.gen\",\n            \"--output-uri\",\n            tmpdir + \"/map.yaml\",\n            \"--show-mode\",\n            \"none\",",
        "detail": "tests.tools.map.test_gen",
        "documentation": {}
    },
    {
        "label": "test_view_random",
        "kind": 2,
        "importPath": "tests.tools.map.test_gen",
        "description": "tests.tools.map.test_gen",
        "peekOfCode": "def test_view_random(tmpdir):\n    subprocess.check_call(\n        [\n            \"python\",\n            \"-m\",\n            f\"{MAP_MODULE}.gen\",\n            \"--output-uri\",\n            tmpdir,\n            \"--show-mode\",\n            \"none\",",
        "detail": "tests.tools.map.test_gen",
        "documentation": {}
    },
    {
        "label": "MAZE_CONFIG",
        "kind": 5,
        "importPath": "tests.tools.map.test_gen",
        "description": "tests.tools.map.test_gen",
        "peekOfCode": "MAZE_CONFIG = Path(__file__).parent / \"maze.yaml\"\nMAP_MODULE = \"tools.map\"\ndef test_gen_basic():\n    subprocess.check_call(\n        [\n            \"python\",\n            \"-m\",\n            f\"{MAP_MODULE}.gen\",\n            \"--show-mode\",\n            \"ascii\",",
        "detail": "tests.tools.map.test_gen",
        "documentation": {}
    },
    {
        "label": "MAP_MODULE",
        "kind": 5,
        "importPath": "tests.tools.map.test_gen",
        "description": "tests.tools.map.test_gen",
        "peekOfCode": "MAP_MODULE = \"tools.map\"\ndef test_gen_basic():\n    subprocess.check_call(\n        [\n            \"python\",\n            \"-m\",\n            f\"{MAP_MODULE}.gen\",\n            \"--show-mode\",\n            \"ascii\",\n            MAZE_CONFIG,",
        "detail": "tests.tools.map.test_gen",
        "documentation": {}
    },
    {
        "label": "TestRendererJob",
        "kind": 6,
        "importPath": "tests.tools.test_renderer_job",
        "description": "tests.tools.test_renderer_job",
        "peekOfCode": "class TestRendererJob:\n    \"\"\"Test renderer job works with debug environments.\"\"\"\n    # Map of environment names to their map file paths\n    DEBUG_ENVIRONMENTS = {\n        \"tiny_two_altars\": \"configs/env/mettagrid/maps/debug/tiny_two_altars.map\",\n        \"simple_obstacles\": \"configs/env/mettagrid/maps/debug/simple_obstacles.map\",\n        \"resource_collection\": \"configs/env/mettagrid/maps/debug/resource_collection.map\",\n        \"mixed_objects\": \"configs/env/mettagrid/maps/debug/mixed_objects.map\",\n    }\n    def test_map_files_exist(self):",
        "detail": "tests.tools.test_renderer_job",
        "documentation": {}
    },
    {
        "label": "hydra_init_once",
        "kind": 2,
        "importPath": "tests.tools.test_replay_job",
        "description": "tests.tools.test_replay_job",
        "peekOfCode": "def hydra_init_once():\n    GlobalHydra.instance().clear()\n    hydra.initialize(config_path=\"../../configs\", version_base=None)\n@pytest.fixture\ndef build_config():\n    def _build(overrides: List[str]):\n        hydra_cfg = hydra.compose(config_name=\"replay_job\", overrides=overrides)\n        return ReplayJob(hydra_cfg.replay_job)\n    return _build\ndef test_config_defaults(build_config):",
        "detail": "tests.tools.test_replay_job",
        "documentation": {}
    },
    {
        "label": "build_config",
        "kind": 2,
        "importPath": "tests.tools.test_replay_job",
        "description": "tests.tools.test_replay_job",
        "peekOfCode": "def build_config():\n    def _build(overrides: List[str]):\n        hydra_cfg = hydra.compose(config_name=\"replay_job\", overrides=overrides)\n        return ReplayJob(hydra_cfg.replay_job)\n    return _build\ndef test_config_defaults(build_config):\n    cfg = build_config([\"run=test\"])\n    assert cfg.selector_type == \"top\"\n    assert cfg.policy_uri.endswith(\"test/checkpoints\")\n    assert cfg.sim.env == \"/env/mettagrid/simple\"",
        "detail": "tests.tools.test_replay_job",
        "documentation": {}
    },
    {
        "label": "test_config_defaults",
        "kind": 2,
        "importPath": "tests.tools.test_replay_job",
        "description": "tests.tools.test_replay_job",
        "peekOfCode": "def test_config_defaults(build_config):\n    cfg = build_config([\"run=test\"])\n    assert cfg.selector_type == \"top\"\n    assert cfg.policy_uri.endswith(\"test/checkpoints\")\n    assert cfg.sim.env == \"/env/mettagrid/simple\"\ndef test_config_overrides(build_config):\n    cfg = build_config(\n        [\n            \"run=test\",\n            \"sim.env=/env/mettagrid/teams\",",
        "detail": "tests.tools.test_replay_job",
        "documentation": {}
    },
    {
        "label": "test_config_overrides",
        "kind": 2,
        "importPath": "tests.tools.test_replay_job",
        "description": "tests.tools.test_replay_job",
        "peekOfCode": "def test_config_overrides(build_config):\n    cfg = build_config(\n        [\n            \"run=test\",\n            \"sim.env=/env/mettagrid/teams\",\n            \"+sim.env_overrides.game.num_agents=36\",\n            \"policy_uri=test_policy\",\n            \"sim.num_episodes=10\",\n        ]\n    )",
        "detail": "tests.tools.test_replay_job",
        "documentation": {}
    },
    {
        "label": "hydra_init_once",
        "kind": 2,
        "importPath": "tests.tools.test_sim_job",
        "description": "tests.tools.test_sim_job",
        "peekOfCode": "def hydra_init_once():\n    GlobalHydra.instance().clear()\n    hydra.initialize(config_path=\"../../configs\", version_base=None)\n@pytest.fixture\ndef build_config():\n    def _build(overrides: List[str]):\n        hydra_cfg = hydra.compose(config_name=\"sim_job\", overrides=overrides)\n        return SimJob(hydra_cfg.sim_job)\n    return _build\ndef test_config_defaults(build_config):",
        "detail": "tests.tools.test_sim_job",
        "documentation": {}
    },
    {
        "label": "build_config",
        "kind": 2,
        "importPath": "tests.tools.test_sim_job",
        "description": "tests.tools.test_sim_job",
        "peekOfCode": "def build_config():\n    def _build(overrides: List[str]):\n        hydra_cfg = hydra.compose(config_name=\"sim_job\", overrides=overrides)\n        return SimJob(hydra_cfg.sim_job)\n    return _build\ndef test_config_defaults(build_config):\n    cfg = build_config([\"run=test\"])\n    assert cfg.selector_type == \"top\"\n    assert len(cfg.policy_uris) == 1\n    assert cfg.policy_uris[0].endswith(\"test/checkpoints\")",
        "detail": "tests.tools.test_sim_job",
        "documentation": {}
    },
    {
        "label": "test_config_defaults",
        "kind": 2,
        "importPath": "tests.tools.test_sim_job",
        "description": "tests.tools.test_sim_job",
        "peekOfCode": "def test_config_defaults(build_config):\n    cfg = build_config([\"run=test\"])\n    assert cfg.selector_type == \"top\"\n    assert len(cfg.policy_uris) == 1\n    assert cfg.policy_uris[0].endswith(\"test/checkpoints\")\n    assert cfg.simulation_suite.name == \"all\"\ndef test_config_overrides(build_config):\n    cfg = build_config(\n        [\n            \"run=test\",",
        "detail": "tests.tools.test_sim_job",
        "documentation": {}
    },
    {
        "label": "test_config_overrides",
        "kind": 2,
        "importPath": "tests.tools.test_sim_job",
        "description": "tests.tools.test_sim_job",
        "peekOfCode": "def test_config_overrides(build_config):\n    cfg = build_config(\n        [\n            \"run=test\",\n            \"sim=smoke_test\",\n            \"policy_uri=test_policy\",\n            \"sim.num_episodes=10\",\n        ]\n    )\n    print(cfg)",
        "detail": "tests.tools.test_sim_job",
        "documentation": {}
    },
    {
        "label": "TestValidateConfig",
        "kind": 6,
        "importPath": "tests.tools.test_validate_config",
        "description": "tests.tools.test_validate_config",
        "peekOfCode": "class TestValidateConfig(unittest.TestCase):\n    \"\"\"Test the validate_config script functionality.\"\"\"\n    def setUp(self):\n        \"\"\"Clear Hydra state before each test.\"\"\"\n        GlobalHydra.instance().clear()\n    def tearDown(self):\n        \"\"\"Clear Hydra state after each test.\"\"\"\n        GlobalHydra.instance().clear()\n    def test_load_and_print_config_simple(self):\n        \"\"\"Test loading env/mettagrid/simple.yaml config.\"\"\"",
        "detail": "tests.tools.test_validate_config",
        "documentation": {}
    },
    {
        "label": "collect_py_files",
        "kind": 2,
        "importPath": "tests.test_no_xcxc",
        "description": "tests.test_no_xcxc",
        "peekOfCode": "def collect_py_files(root: Path, exclude_dirs: set[str]) -> list[Path]:\n    files = []\n    for path in root.rglob(\"*.py\"):\n        if any(part in exclude_dirs for part in path.parts):\n            continue\n        files.append(path)\n    return files\ndef test_no_xcxc():\n    root = Path(__file__).resolve().parents[1]\n    exclude_dirs = {\".venv\", \"build\", \"metta.egg-info\", \".git\"}",
        "detail": "tests.test_no_xcxc",
        "documentation": {}
    },
    {
        "label": "test_no_xcxc",
        "kind": 2,
        "importPath": "tests.test_no_xcxc",
        "description": "tests.test_no_xcxc",
        "peekOfCode": "def test_no_xcxc():\n    root = Path(__file__).resolve().parents[1]\n    exclude_dirs = {\".venv\", \"build\", \"metta.egg-info\", \".git\"}\n    py_files = collect_py_files(root, exclude_dirs)\n    this_file = Path(__file__).resolve()\n    offenders = []\n    for file in py_files:\n        if file == this_file:\n            continue\n        content = file.read_text(encoding=\"utf-8\", errors=\"ignore\")",
        "detail": "tests.test_no_xcxc",
        "documentation": {}
    },
    {
        "label": "test_load_train_job_config_with_overrides",
        "kind": 2,
        "importPath": "tests.test_sweep_config_utils",
        "description": "tests.test_sweep_config_utils",
        "peekOfCode": "def test_load_train_job_config_with_overrides():\n    \"\"\"Test loading train job config with overrides from file.\"\"\"\n    # Import here to avoid circular imports\n    from tools.sweep_config_utils import load_train_job_config_with_overrides\n    with tempfile.TemporaryDirectory() as tmpdir:\n        # Create a base config without trainer to avoid validation\n        base_cfg = OmegaConf.create(\n            {\n                \"run_dir\": tmpdir,\n                \"device\": \"cpu\",",
        "detail": "tests.test_sweep_config_utils",
        "documentation": {}
    },
    {
        "label": "test_load_train_job_config_with_overrides_no_file",
        "kind": 2,
        "importPath": "tests.test_sweep_config_utils",
        "description": "tests.test_sweep_config_utils",
        "peekOfCode": "def test_load_train_job_config_with_overrides_no_file():\n    \"\"\"Test that config is unchanged when no override file exists.\"\"\"\n    from tools.sweep_config_utils import load_train_job_config_with_overrides\n    with tempfile.TemporaryDirectory() as tmpdir:\n        base_cfg = OmegaConf.create(\n            {\n                \"run_dir\": tmpdir,\n                \"device\": \"cpu\",\n                \"some_value\": 99,\n            }",
        "detail": "tests.test_sweep_config_utils",
        "documentation": {}
    },
    {
        "label": "test_save_train_job_override_config",
        "kind": 2,
        "importPath": "tests.test_sweep_config_utils",
        "description": "tests.test_sweep_config_utils",
        "peekOfCode": "def test_save_train_job_override_config():\n    \"\"\"Test saving train job override config.\"\"\"\n    from tools.sweep_config_utils import save_train_job_override_config\n    with tempfile.TemporaryDirectory() as tmpdir:\n        # Create configs\n        cfg = OmegaConf.create(\n            {\n                \"run_dir\": tmpdir,\n            }\n        )",
        "detail": "tests.test_sweep_config_utils",
        "documentation": {}
    },
    {
        "label": "test_apply_carbs_suggestion",
        "kind": 2,
        "importPath": "tests.test_sweep_config_utils",
        "description": "tests.test_sweep_config_utils",
        "peekOfCode": "def test_apply_carbs_suggestion():\n    \"\"\"Test applying CARBS suggestions to a config.\"\"\"\n    from tools.sweep_config_utils import apply_carbs_suggestion\n    # Create a base config\n    config = OmegaConf.create({\"trainer\": {\"gamma\": 0.99, \"batch_size\": 512, \"optimizer\": {\"learning_rate\": 0.001}}})\n    # Create a CARBS suggestion\n    suggestion = OmegaConf.create(\n        {\n            \"trainer.gamma\": 0.95,\n            \"trainer.batch_size\": 256,",
        "detail": "tests.test_sweep_config_utils",
        "documentation": {}
    },
    {
        "label": "TensorDtypeChecker",
        "kind": 6,
        "importPath": "tests.test_tensors_have_dtype",
        "description": "tests.test_tensors_have_dtype",
        "peekOfCode": "class TensorDtypeChecker(ast.NodeVisitor):\n    \"\"\"AST visitor to find torch.tensor() calls without dtype parameter.\"\"\"\n    def __init__(self, filename: str):\n        self.filename = filename\n        self.issues: List[Tuple[int, str]] = []\n    def visit_Call(self, node: ast.Call):\n        \"\"\"Visit function call nodes and check for torch.tensor() calls.\"\"\"\n        # Check if this is a torch.tensor() call\n        if self._is_torch_tensor_call(node):\n            has_dtype = self._has_dtype_argument(node)",
        "detail": "tests.test_tensors_have_dtype",
        "documentation": {}
    },
    {
        "label": "collect_py_files",
        "kind": 2,
        "importPath": "tests.test_tensors_have_dtype",
        "description": "tests.test_tensors_have_dtype",
        "peekOfCode": "def collect_py_files(root: Path, exclude_dirs: set[str]) -> list[Path]:\n    \"\"\"Collect all Python files from the root directory, excluding specified directories.\"\"\"\n    files = []\n    for path in root.rglob(\"*.py\"):\n        if any(part in exclude_dirs for part in path.parts):\n            continue\n        files.append(path)\n    return files\ndef check_file_for_tensor_dtypes(filepath: Path) -> List[Tuple[int, str]]:\n    \"\"\"Check a single Python file for torch.tensor() calls without dtype.\"\"\"",
        "detail": "tests.test_tensors_have_dtype",
        "documentation": {}
    },
    {
        "label": "check_file_for_tensor_dtypes",
        "kind": 2,
        "importPath": "tests.test_tensors_have_dtype",
        "description": "tests.test_tensors_have_dtype",
        "peekOfCode": "def check_file_for_tensor_dtypes(filepath: Path) -> List[Tuple[int, str]]:\n    \"\"\"Check a single Python file for torch.tensor() calls without dtype.\"\"\"\n    try:\n        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n            content = f.read()\n        tree = ast.parse(content, filename=str(filepath))\n        checker = TensorDtypeChecker(str(filepath))\n        checker.visit(tree)\n        return checker.issues\n    except (SyntaxError, UnicodeDecodeError):",
        "detail": "tests.test_tensors_have_dtype",
        "documentation": {}
    },
    {
        "label": "test_tensors_have_dtype",
        "kind": 2,
        "importPath": "tests.test_tensors_have_dtype",
        "description": "tests.test_tensors_have_dtype",
        "peekOfCode": "def test_tensors_have_dtype():\n    \"\"\"Test that all torch.tensor() calls in the codebase have explicit dtype parameters.\"\"\"\n    root = Path(__file__).resolve().parents[1]\n    exclude_dirs = {\n        \".venv\",\n        \"build\",\n        \"build-debug\",\n        \"metta.egg-info\",\n        \".git\",\n        \"__pycache__\",",
        "detail": "tests.test_tensors_have_dtype",
        "documentation": {}
    },
    {
        "label": "make_map",
        "kind": 2,
        "importPath": "tools.map.gen",
        "description": "tools.map.gen",
        "peekOfCode": "def make_map(cfg_path: str, overrides: DictConfig | None = None):\n    # since we are not using hydra here we can't rely on the callback that normally sets up our custom resolvers\n    register_resolvers()\n    with hydra.initialize(config_path=\"../../configs\", version_base=None):\n        hydra_cfg_path = os.path.relpath(cfg_path, \"./configs\")\n        if \"../\" in hydra_cfg_path:\n            logger.info(\"Config is not in the configs directory, loading with OmegaConf\")\n            cfg = OmegaConf.load(cfg_path)\n        else:\n            logger.info(f\"Loading hydra config from {hydra_cfg_path}\")",
        "detail": "tools.map.gen",
        "documentation": {}
    },
    {
        "label": "uri_is_file",
        "kind": 2,
        "importPath": "tools.map.gen",
        "description": "tools.map.gen",
        "peekOfCode": "def uri_is_file(uri: str) -> bool:\n    last_part = uri.split(\"/\")[-1]\n    return \".\" in last_part and len(last_part.split(\".\")[-1]) <= 4\ndef main():\n    register_resolvers()\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--output-uri\", type=str, help=\"Output URI\")\n    parser.add_argument(\"--show-mode\", choices=get_args(ShowMode), help=\"Show the map in the specified mode\")\n    parser.add_argument(\"--count\", type=int, default=1, help=\"Number of maps to generate\")\n    parser.add_argument(\"--overrides\", type=str, default=\"\", help=\"OmegaConf overrides for the map config\")",
        "detail": "tools.map.gen",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.map.gen",
        "description": "tools.map.gen",
        "peekOfCode": "def main():\n    register_resolvers()\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--output-uri\", type=str, help=\"Output URI\")\n    parser.add_argument(\"--show-mode\", choices=get_args(ShowMode), help=\"Show the map in the specified mode\")\n    parser.add_argument(\"--count\", type=int, default=1, help=\"Number of maps to generate\")\n    parser.add_argument(\"--overrides\", type=str, default=\"\", help=\"OmegaConf overrides for the map config\")\n    parser.add_argument(\"cfg_path\", type=str, help=\"Path to the map config file\")\n    args = parser.parse_args()\n    show_mode = args.show_mode",
        "detail": "tools.map.gen",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "tools.map.gen",
        "description": "tools.map.gen",
        "peekOfCode": "logger = logging.getLogger(__name__)\nlogging.basicConfig(level=logging.INFO)\ndef make_map(cfg_path: str, overrides: DictConfig | None = None):\n    # since we are not using hydra here we can't rely on the callback that normally sets up our custom resolvers\n    register_resolvers()\n    with hydra.initialize(config_path=\"../../configs\", version_base=None):\n        hydra_cfg_path = os.path.relpath(cfg_path, \"./configs\")\n        if \"../\" in hydra_cfg_path:\n            logger.info(\"Config is not in the configs directory, loading with OmegaConf\")\n            cfg = OmegaConf.load(cfg_path)",
        "detail": "tools.map.gen",
        "documentation": {}
    },
    {
        "label": "make_map",
        "kind": 2,
        "importPath": "tools.map.gen_scene",
        "description": "tools.map.gen_scene",
        "peekOfCode": "def make_map(cfg_path: str, width: int, height: int, overrides: DictConfig | None = None):\n    register_resolvers()\n    cfg: DictConfig = cast(DictConfig, OmegaConf.merge(OmegaConf.load(cfg_path), overrides))\n    if not OmegaConf.is_dict(cfg):\n        raise ValueError(f\"Invalid config type: {type(cfg)}\")\n    cfg = cast(DictConfig, cfg)\n    mapgen_cfg = OmegaConf.create(\n        {\n            \"_target_\": \"metta.map.mapgen.MapGen\",\n            \"width\": width,",
        "detail": "tools.map.gen_scene",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.map.gen_scene",
        "description": "tools.map.gen_scene",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--show-mode\", choices=get_args(ShowMode), default=\"mettascope\", help=\"Show the map in the specified mode\"\n    )\n    parser.add_argument(\"--overrides\", type=str, default=\"\", help=\"OmegaConf overrides for the scene config\")\n    parser.add_argument(\"cfg_path\", type=str, help=\"Path to the scene config file\")\n    parser.add_argument(\"width\", type=int, help=\"Width of the map\")\n    parser.add_argument(\"height\", type=int, help=\"Height of the map\")\n    args = parser.parse_args()",
        "detail": "tools.map.gen_scene",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "tools.map.gen_scene",
        "description": "tools.map.gen_scene",
        "peekOfCode": "logger = logging.getLogger(__name__)\nlogging.basicConfig(level=logging.INFO)\ndef make_map(cfg_path: str, width: int, height: int, overrides: DictConfig | None = None):\n    register_resolvers()\n    cfg: DictConfig = cast(DictConfig, OmegaConf.merge(OmegaConf.load(cfg_path), overrides))\n    if not OmegaConf.is_dict(cfg):\n        raise ValueError(f\"Invalid config type: {type(cfg)}\")\n    cfg = cast(DictConfig, cfg)\n    mapgen_cfg = OmegaConf.create(\n        {",
        "detail": "tools.map.gen_scene",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.map.normalize_ascii_map",
        "description": "tools.map.normalize_ascii_map",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--in-place\", action=\"store_true\", help=\"Overwrite the map file with the normalized version\")\n    parser.add_argument(\"map_file\", type=Path)\n    args = parser.parse_args()\n    with open(args.map_file, \"r\", encoding=\"utf-8\") as f:\n        content = f.read()\n    normalized_lines = []\n    lines = content.splitlines()\n    for line in lines:",
        "detail": "tools.map.normalize_ascii_map",
        "documentation": {}
    },
    {
        "label": "str_presenter",
        "kind": 2,
        "importPath": "tools.map.normalize_scene_patterns",
        "description": "tools.map.normalize_scene_patterns",
        "peekOfCode": "def str_presenter(dumper, data):\n    # if the string contains any newline, dump it as a literal block\n    if \"\\n\" in data:\n        return dumper.represent_scalar(\n            \"tag:yaml.org,2002:str\",\n            data,\n            style=\"|\",  # force literal style\n        )\n    # otherwise use default (plain) style\n    return dumper.represent_scalar(\"tag:yaml.org,2002:str\", data)",
        "detail": "tools.map.normalize_scene_patterns",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.map.normalize_scene_patterns",
        "description": "tools.map.normalize_scene_patterns",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--in-place\", action=\"store_true\", help=\"Overwrite the yaml file with the normalized version\")\n    parser.add_argument(\"file\", type=Path)\n    args = parser.parse_args()\n    cfg = OmegaConf.load(args.file)\n    # both WFC and ConvChain have a pattern under `params.pattern`\n    pattern = cfg.params.pattern\n    lines, _, _ = char_grid_to_lines(pattern)\n    updated_lines = []",
        "detail": "tools.map.normalize_scene_patterns",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.map.view",
        "description": "tools.map.view",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--show-mode\", choices=get_args(ShowMode), help=\"Show the map in the specified mode\", default=\"mettascope\"\n    )\n    parser.add_argument(\"uri\", type=str, help=\"URI of the map to view\")\n    args = parser.parse_args()\n    register_resolvers()\n    uri = args.uri\n    if not uri_is_file(uri):",
        "detail": "tools.map.view",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "tools.map.view",
        "description": "tools.map.view",
        "peekOfCode": "logger = logging.getLogger(__name__)\nlogging.basicConfig(level=logging.INFO)\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--show-mode\", choices=get_args(ShowMode), help=\"Show the map in the specified mode\", default=\"mettascope\"\n    )\n    parser.add_argument(\"uri\", type=str, help=\"URI of the map to view\")\n    args = parser.parse_args()\n    register_resolvers()",
        "detail": "tools.map.view",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.analyze",
        "description": "tools.analyze",
        "peekOfCode": "def main(cfg: DictConfig) -> None:\n    setup_mettagrid_environment(cfg)\n    logger = setup_mettagrid_logger(\"analyze\")\n    logger.info(f\"Analyze job config:\\n{OmegaConf.to_yaml(cfg, resolve=True)}\")\n    config = AnalysisConfig(cfg.analysis)\n    policy_store = PolicyStore(cfg, None)\n    policy_pr = policy_store.policy_record(\n        config.policy_uri, config.policy_selector.type, metric=config.policy_selector.metric\n    )\n    analyze(policy_pr, config)",
        "detail": "tools.analyze",
        "documentation": {}
    },
    {
        "label": "make_env",
        "kind": 2,
        "importPath": "tools.autotune",
        "description": "tools.autotune",
        "peekOfCode": "def make_env():\n    global env_config\n    env = hydra.utils.instantiate(env_config.env, render_mode=\"human\")\n    env.emulated = None\n    env.single_observation_space = env.observation_space\n    env.single_action_space = env.action_space\n    env.num_agents = env.player_count\n    env.done = False\n    return env\n@hydra.main(version_base=None, config_path=\"../configs\", config_name=\"config\")",
        "detail": "tools.autotune",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.autotune",
        "description": "tools.autotune",
        "peekOfCode": "def main(cfg):\n    global env_config\n    env_config = cfg\n    pufferlib.vector.autotune(make_env, batch_size=16320 // 20, max_envs=1024, max_env_ram_gb=64)\n    # pufferlib.vector.autotune(make_env, batch_size=16384//20)\nif __name__ == \"__main__\":\n    main()",
        "detail": "tools.autotune",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.dashboard",
        "description": "tools.dashboard",
        "peekOfCode": "def main(cfg: DictConfig) -> None:\n    setup_mettagrid_environment(cfg)\n    logger = setup_mettagrid_logger(\"dashboard\")\n    logger.info(f\"Dashboard job config:\\n{OmegaConf.to_yaml(cfg, resolve=True)}\")\n    logger.info(\"Generating dashboard\")\n    config = DashboardConfig(cfg.dashboard)\n    write_dashboard_data(config)\n    if config.output_path.startswith(\"s3://\"):\n        logger.info(\n            \"Wrote dashboard data to S3. View dashboard at \" + DASHBOARD_URL + \"?data=\" + http_url(config.output_path)",
        "detail": "tools.dashboard",
        "documentation": {}
    },
    {
        "label": "DASHBOARD_URL",
        "kind": 5,
        "importPath": "tools.dashboard",
        "description": "tools.dashboard",
        "peekOfCode": "DASHBOARD_URL = \"https://metta-ai.github.io/metta/observatory/\"\n@hydra.main(version_base=None, config_path=\"../configs\", config_name=\"dashboard_job\")\ndef main(cfg: DictConfig) -> None:\n    setup_mettagrid_environment(cfg)\n    logger = setup_mettagrid_logger(\"dashboard\")\n    logger.info(f\"Dashboard job config:\\n{OmegaConf.to_yaml(cfg, resolve=True)}\")\n    logger.info(\"Generating dashboard\")\n    config = DashboardConfig(cfg.dashboard)\n    write_dashboard_data(config)\n    if config.output_path.startswith(\"s3://\"):",
        "detail": "tools.dashboard",
        "documentation": {}
    },
    {
        "label": "dump_files",
        "kind": 2,
        "importPath": "tools.dump_src",
        "description": "tools.dump_src",
        "peekOfCode": "def dump_files(paths, extensions):\n    for path in paths:\n        for root, _, files in os.walk(path):\n            for file in files:\n                if extensions is None or len(extensions) == 0 or any(file.endswith(ext) for ext in extensions):\n                    file_path = os.path.join(root, file)\n                    with open(file_path, \"r\") as infile:\n                        print(f\"<file: {file_path}>\")\n                        print(infile.read())\n                        print(\"</file>\")",
        "detail": "tools.dump_src",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.play",
        "description": "tools.play",
        "peekOfCode": "def main(cfg):\n    server.run(cfg, open_url=\"?wsUrl=%2Fws\")\nif __name__ == \"__main__\":\n    main()",
        "detail": "tools.play",
        "documentation": {}
    },
    {
        "label": "Policy",
        "kind": 6,
        "importPath": "tools.renderer",
        "description": "tools.renderer",
        "peekOfCode": "class Policy(Protocol):\n    \"\"\"Protocol for policy classes.\"\"\"\n    def predict(self, obs: np.ndarray) -> np.ndarray:\n        \"\"\"Predict actions given observations.\"\"\"\n        ...\nclass BasePolicy(ABC):\n    \"\"\"Base class for all policies.\"\"\"\n    def __init__(self, env: MettaGridEnv) -> None:\n        self.env = env\n        self.num_agents = env.num_agents",
        "detail": "tools.renderer",
        "documentation": {}
    },
    {
        "label": "BasePolicy",
        "kind": 6,
        "importPath": "tools.renderer",
        "description": "tools.renderer",
        "peekOfCode": "class BasePolicy(ABC):\n    \"\"\"Base class for all policies.\"\"\"\n    def __init__(self, env: MettaGridEnv) -> None:\n        self.env = env\n        self.num_agents = env.num_agents\n        self.action_space = env.action_space\n        self.single_action_space = env.single_action_space\n    @abstractmethod\n    def predict(self, obs: np.ndarray) -> np.ndarray:\n        \"\"\"Predict actions given observations.\"\"\"",
        "detail": "tools.renderer",
        "documentation": {}
    },
    {
        "label": "RandomPolicy",
        "kind": 6,
        "importPath": "tools.renderer",
        "description": "tools.renderer",
        "peekOfCode": "class RandomPolicy(BasePolicy):\n    \"\"\"Simple random policy using valid action generation.\"\"\"\n    def predict(self, obs: np.ndarray) -> np.ndarray:\n        \"\"\"Return valid random actions for all agents.\"\"\"\n        assert obs.dtype == dtype_observations\n        return generate_valid_random_actions(self.env, self.num_agents)\nclass SimplePolicy(BasePolicy):\n    \"\"\"A simple policy that tries to move towards objectives with valid actions.\"\"\"\n    def __init__(self, env: MettaGridEnv) -> None:\n        super().__init__(env)",
        "detail": "tools.renderer",
        "documentation": {}
    },
    {
        "label": "SimplePolicy",
        "kind": 6,
        "importPath": "tools.renderer",
        "description": "tools.renderer",
        "peekOfCode": "class SimplePolicy(BasePolicy):\n    \"\"\"A simple policy that tries to move towards objectives with valid actions.\"\"\"\n    def __init__(self, env: MettaGridEnv) -> None:\n        super().__init__(env)\n        # Movement options\n        self.cardinal_directions: List[int] = [1, 3, 5, 7]  # up, left, right, down\n        self.move_directions: List[int] = [1, 2, 3, 5, 7, 8]  # Cardinal + diagonal\n        self.rotation_orientations: List[int] = [0, 1, 2, 3]  # up, down, left, right\n        # Get action indices\n        self._initialize_action_indices()",
        "detail": "tools.renderer",
        "documentation": {}
    },
    {
        "label": "TrainedPolicyWrapper",
        "kind": 6,
        "importPath": "tools.renderer",
        "description": "tools.renderer",
        "peekOfCode": "class TrainedPolicyWrapper(BasePolicy):\n    \"\"\"Wrapper for trained policies with action validation.\"\"\"\n    def __init__(self, policy: Any, env: MettaGridEnv) -> None:\n        super().__init__(env)\n        self.policy = policy\n        self._max_args: List[int] = env._c_env.max_action_args()\n        self._num_action_types: int = env.single_action_space.nvec[0]\n    def predict(self, obs: np.ndarray) -> np.ndarray:\n        \"\"\"Predict actions using trained policy with validation.\"\"\"\n        assert obs.dtype == dtype_observations",
        "detail": "tools.renderer",
        "documentation": {}
    },
    {
        "label": "get_policy",
        "kind": 2,
        "importPath": "tools.renderer",
        "description": "tools.renderer",
        "peekOfCode": "def get_policy(policy_type: str, env: MettaGridEnv, cfg: DictConfig) -> Policy:\n    \"\"\"\n    Get a policy based on the specified type.\n    Args:\n        policy_type: Type of policy (\"random\", \"simple\", or \"trained\")\n        env: MettaGrid environment\n        cfg: Hydra configuration\n    Returns:\n        Policy instance\n    \"\"\"",
        "detail": "tools.renderer",
        "documentation": {}
    },
    {
        "label": "setup_environment",
        "kind": 2,
        "importPath": "tools.renderer",
        "description": "tools.renderer",
        "peekOfCode": "def setup_environment(cfg: DictConfig) -> Tuple[MettaGridEnv, str]:\n    \"\"\"\n    Set up the MettaGrid environment based on configuration.\n    Args:\n        cfg: Hydra configuration\n    Returns:\n        Tuple of (environment, render_mode)\n    \"\"\"\n    # Determine render mode\n    render_mode: str = cfg.renderer_job.get(\"renderer_type\", \"human\")",
        "detail": "tools.renderer",
        "documentation": {}
    },
    {
        "label": "run_renderer",
        "kind": 2,
        "importPath": "tools.renderer",
        "description": "tools.renderer",
        "peekOfCode": "def run_renderer(cfg: DictConfig) -> None:\n    \"\"\"\n    Run policy visualization with ASCII or Miniscope rendering.\n    Args:\n        cfg: Hydra configuration\n    \"\"\"\n    # Set up environment\n    env, render_mode = setup_environment(cfg)\n    # Get policy\n    policy: Policy = get_policy(cfg.renderer_job.policy_type, env, cfg)",
        "detail": "tools.renderer",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.renderer",
        "description": "tools.renderer",
        "peekOfCode": "def main(cfg: DictConfig) -> None:\n    run_renderer(cfg)\nif __name__ == \"__main__\":\n    main()",
        "detail": "tools.renderer",
        "documentation": {}
    },
    {
        "label": "ReplayJob",
        "kind": 6,
        "importPath": "tools.replay",
        "description": "tools.replay",
        "peekOfCode": "class ReplayJob(Config):\n    __init__ = Config.__init__\n    sim: SingleEnvSimulationConfig\n    policy_uri: str\n    selector_type: str\n    replay_dir: str\n    stats_dir: str\n@hydra.main(version_base=None, config_path=\"../configs\", config_name=\"replay_job\")\n@metta_script\ndef main(cfg):",
        "detail": "tools.replay",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.replay",
        "description": "tools.replay",
        "peekOfCode": "def main(cfg):\n    setup_mettagrid_environment(cfg)\n    logger = setup_mettagrid_logger(\"metta.tools.replay\")\n    logger.info(f\"Replay job config:\\n{OmegaConf.to_yaml(cfg, resolve=True)}\")\n    with WandbContext(cfg.wandb, cfg) as wandb_run:\n        policy_store = PolicyStore(cfg, wandb_run)\n        replay_job = ReplayJob(cfg.replay_job)\n        policy_record = policy_store.policy_record(replay_job.policy_uri)\n        sim_config = SingleEnvSimulationConfig(cfg.replay_job.sim)\n        sim_name = sim_config.env.split(\"/\")[-1]",
        "detail": "tools.replay",
        "documentation": {}
    },
    {
        "label": "SimJob",
        "kind": 6,
        "importPath": "tools.sim",
        "description": "tools.sim",
        "peekOfCode": "class SimJob(Config):\n    __init__ = Config.__init__\n    simulation_suite: SimulationSuiteConfig\n    policy_uris: List[str]\n    selector_type: str = \"top\"\n    stats_db_uri: str\n    stats_dir: str  # The (local) directory where stats should be stored\n    replay_dir: str  # where to store replays\n# --------------------------------------------------------------------------- #\n# Helpers                                                                     #",
        "detail": "tools.sim",
        "documentation": {}
    },
    {
        "label": "simulate_policy",
        "kind": 2,
        "importPath": "tools.sim",
        "description": "tools.sim",
        "peekOfCode": "def simulate_policy(\n    sim_job: SimJob,\n    policy_uri: str,\n    cfg: DictConfig,\n    logger: logging.Logger,\n) -> Dict[str, Any]:\n    \"\"\"\n    Evaluate **one** policy URI (may expand to several checkpoints).\n    All simulations belonging to a single checkpoint are merged into one\n    *StatsDB* which is optionally exported.",
        "detail": "tools.sim",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.sim",
        "description": "tools.sim",
        "peekOfCode": "def main(cfg: DictConfig) -> None:\n    setup_mettagrid_environment(cfg)\n    logger = setup_mettagrid_logger(\"metta.tools.sim\")\n    logger.info(f\"Sim job config:\\n{OmegaConf.to_yaml(cfg, resolve=True)}\")\n    sim_job = SimJob(cfg.sim_job)\n    all_results = {\"simulation_suite\": sim_job.simulation_suite.name, \"policies\": []}\n    for policy_uri in sim_job.policy_uris:\n        policy_results = simulate_policy(sim_job, policy_uri, cfg, logger)\n        all_results[\"policies\"].append(policy_results)\n    # Always output JSON results to stdout",
        "detail": "tools.sim",
        "documentation": {}
    },
    {
        "label": "launch_duckdb_cli",
        "kind": 2,
        "importPath": "tools.stats_duckdb_cli",
        "description": "tools.stats_duckdb_cli",
        "peekOfCode": "def launch_duckdb_cli(file_path):\n    \"\"\"\n    Launch duckdb CLI against the specified file.\n    Args:\n        file_path: Path to the file to open in duckdb\n    \"\"\"\n    # Check if duckdb is installed\n    try:\n        subprocess.run([\"duckdb\", \"--version\"], capture_output=True, check=True)\n    except (subprocess.CalledProcessError, FileNotFoundError):",
        "detail": "tools.stats_duckdb_cli",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.stats_duckdb_cli",
        "description": "tools.stats_duckdb_cli",
        "peekOfCode": "def main(cfg: DictConfig) -> int:\n    \"\"\"\n    Main function to download a stats file and launch duckdb against it.\n    \"\"\"\n    setup_mettagrid_environment(cfg)\n    logger = setup_mettagrid_logger(\"stats_duckdb_cli\")\n    # Check if eval_db_uri is configured\n    if not hasattr(cfg, \"eval_db_uri\") or not cfg.eval_db_uri:\n        logger.error(\"Error: eval_db_uri is not configured\")\n        print(\"Please set eval_db_uri in your configuration or use the command line override.\")",
        "detail": "tools.stats_duckdb_cli",
        "documentation": {}
    },
    {
        "label": "validate_merged_config",
        "kind": 2,
        "importPath": "tools.sweep_config_utils",
        "description": "tools.sweep_config_utils",
        "peekOfCode": "def validate_merged_config(\n    base_cfg: DictConfig | ListConfig, overrides: DictConfig | ListConfig | dict[str, Any]\n) -> DictConfig | ListConfig:\n    \"\"\"Validates that an input train_job config is valid after applying overrides.\"\"\"\n    cfg_copy = copy_omegaconf_config(base_cfg)\n    OmegaConf.set_struct(cfg_copy, False)\n    merged_cfg: DictConfig | ListConfig = OmegaConf.merge(cfg_copy, overrides)\n    OmegaConf.set_struct(merged_cfg, True)\n    if \"trainer\" in merged_cfg:\n        try:",
        "detail": "tools.sweep_config_utils",
        "documentation": {}
    },
    {
        "label": "save_train_job_override_config",
        "kind": 2,
        "importPath": "tools.sweep_config_utils",
        "description": "tools.sweep_config_utils",
        "peekOfCode": "def save_train_job_override_config(\n    cfg: DictConfig | ListConfig, overrides: DictConfig | ListConfig | dict[str, Any]\n) -> str:\n    save_path = os.path.join(cfg.run_dir, \"train_config_overrides.yaml\")\n    OmegaConf.save(overrides, save_path)\n    return save_path\ndef apply_carbs_suggestion(config: DictConfig | ListConfig, suggestion: DictConfig) -> None:\n    \"\"\"Apply suggestions to a configuration object using dotted path notation.\n    Args:\n        config: The configuration object to modify",
        "detail": "tools.sweep_config_utils",
        "documentation": {}
    },
    {
        "label": "apply_carbs_suggestion",
        "kind": 2,
        "importPath": "tools.sweep_config_utils",
        "description": "tools.sweep_config_utils",
        "peekOfCode": "def apply_carbs_suggestion(config: DictConfig | ListConfig, suggestion: DictConfig) -> None:\n    \"\"\"Apply suggestions to a configuration object using dotted path notation.\n    Args:\n        config: The configuration object to modify\n        suggestion: The suggestions to apply\n    \"\"\"\n    for key, value in suggestion.items():\n        if key == \"suggestion_uuid\":\n            continue\n        # Convert key to string if it's not already",
        "detail": "tools.sweep_config_utils",
        "documentation": {}
    },
    {
        "label": "load_train_job_config_with_overrides",
        "kind": 2,
        "importPath": "tools.sweep_config_utils",
        "description": "tools.sweep_config_utils",
        "peekOfCode": "def load_train_job_config_with_overrides(cfg: DictConfig | ListConfig) -> DictConfig | ListConfig:\n    overrides_path = os.path.join(cfg.run_dir, \"train_config_overrides.yaml\")\n    if os.path.exists(overrides_path):\n        override_cfg = OmegaConf.load(overrides_path)\n        cfg = validate_merged_config(cfg, override_cfg)\n    return cfg",
        "detail": "tools.sweep_config_utils",
        "documentation": {}
    },
    {
        "label": "log_file",
        "kind": 2,
        "importPath": "tools.sweep_eval",
        "description": "tools.sweep_eval",
        "peekOfCode": "def log_file(run_dir, name, data, wandb_run):\n    path = os.path.join(run_dir, name)\n    with open(path, \"w\") as f:\n        if isinstance(data, DictConfig):\n            data = OmegaConf.to_container(data, resolve=True)\n        json.dump(data, f, indent=4)\n    wandb_run.save(path, base_path=run_dir)\ndef load_file(run_dir, name):\n    path = os.path.join(run_dir, name)\n    with open(path, \"r\") as f:",
        "detail": "tools.sweep_eval",
        "documentation": {}
    },
    {
        "label": "load_file",
        "kind": 2,
        "importPath": "tools.sweep_eval",
        "description": "tools.sweep_eval",
        "peekOfCode": "def load_file(run_dir, name):\n    path = os.path.join(run_dir, name)\n    with open(path, \"r\") as f:\n        return OmegaConf.load(f)\n@hydra.main(config_path=\"../configs\", config_name=\"sweep_job\", version_base=None)\n@metta_script\ndef main(cfg: DictConfig | ListConfig) -> int:\n    setup_mettagrid_environment(cfg)\n    logger = setup_mettagrid_logger(\"sweep_eval\")\n    logger.info(\"Sweep configuration:\")",
        "detail": "tools.sweep_eval",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.sweep_eval",
        "description": "tools.sweep_eval",
        "peekOfCode": "def main(cfg: DictConfig | ListConfig) -> int:\n    setup_mettagrid_environment(cfg)\n    logger = setup_mettagrid_logger(\"sweep_eval\")\n    logger.info(\"Sweep configuration:\")\n    logger.info(yaml.dump(OmegaConf.to_container(cfg, resolve=True), default_flow_style=False))\n    simulation_suite_cfg = SimulationSuiteConfig(**cfg.sweep_job.evals)\n    results_path = os.path.join(cfg.run_dir, \"sweep_eval_results.yaml\")\n    start_time = time.time()\n    if os.environ.get(\"NODE_INDEX\", \"0\") != \"0\":\n        logger.info(\"Waiting for master to evaluate policy\")",
        "detail": "tools.sweep_eval",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.sweep_init",
        "description": "tools.sweep_init",
        "peekOfCode": "def main(cfg: DictConfig | ListConfig) -> int:\n    logger = setup_mettagrid_logger(\"sweep_eval\")\n    logger.info(\"Sweep configuration:\")\n    logger.info(yaml.dump(OmegaConf.to_container(cfg, resolve=True), default_flow_style=False))\n    cfg.wandb.name = cfg.sweep_name\n    OmegaConf.register_new_resolver(\"ss\", sweep_space, replace=True)\n    cfg.sweep = config_from_path(cfg.sweep_params, cfg.sweep_params_override)\n    is_master = os.environ.get(\"NODE_INDEX\", \"0\") == \"0\"\n    run_once(lambda: create_sweep(cfg.sweep_name, cfg, logger))\n    if is_master:",
        "detail": "tools.sweep_init",
        "documentation": {}
    },
    {
        "label": "create_sweep",
        "kind": 2,
        "importPath": "tools.sweep_init",
        "description": "tools.sweep_init",
        "peekOfCode": "def create_sweep(sweep_name: str, cfg: DictConfig | ListConfig, logger: Logger) -> None:\n    \"\"\"\n    Create a new sweep with the given name.\n    \"\"\"\n    sweep_id = sweep_id_from_name(cfg.wandb.project, cfg.wandb.entity, sweep_name)\n    if sweep_id is not None:\n        logger.info(f\"Sweep already exists, skipping creation for: {sweep_name}\")\n        return\n    logger.info(f\"Creating new sweep: {cfg.sweep_dir}\")\n    os.makedirs(cfg.runs_dir, exist_ok=True)",
        "detail": "tools.sweep_init",
        "documentation": {}
    },
    {
        "label": "create_run",
        "kind": 2,
        "importPath": "tools.sweep_init",
        "description": "tools.sweep_init",
        "peekOfCode": "def create_run(sweep_name: str, cfg: DictConfig | ListConfig, logger: Logger) -> str:\n    \"\"\"\n    Create a new run for an existing sweep.\n    Returns the run ID.\n    \"\"\"\n    sweep_cfg = OmegaConf.load(os.path.join(cfg.sweep_dir, \"config.yaml\"))\n    # Create the simulation suite config to make sure it's valid\n    SimulationSuiteConfig(**cfg.sweep_job.evals)\n    logger.info(f\"Creating new run for sweep: {sweep_name} ({sweep_cfg.wandb_path})\")\n    run_name = generate_run_id_for_sweep(sweep_cfg.wandb_path, cfg.runs_dir)",
        "detail": "tools.sweep_init",
        "documentation": {}
    },
    {
        "label": "wait_for_run",
        "kind": 2,
        "importPath": "tools.sweep_init",
        "description": "tools.sweep_init",
        "peekOfCode": "def wait_for_run(sweep_name: str, cfg: DictConfig | ListConfig, path: str, logger: Logger) -> None:\n    \"\"\"\n    Wait for a run to exist.\n    \"\"\"\n    for _ in range(10):\n        if os.path.exists(path):\n            break\n        logger.info(f\"Waiting for run for sweep: {sweep_name}\")\n        time.sleep(5)\n    run = OmegaConf.load(path).run",
        "detail": "tools.sweep_init",
        "documentation": {}
    },
    {
        "label": "apply_protein_suggestion",
        "kind": 2,
        "importPath": "tools.sweep_init",
        "description": "tools.sweep_init",
        "peekOfCode": "def apply_protein_suggestion(config: DictConfig | ListConfig, suggestion: DictConfig):\n    \"\"\"Apply suggestions to a configuration object using dotted path notation.\n    Args:\n        config: The configuration object to modify\n        suggestion: The suggestions to apply\n    \"\"\"\n    for key, value in suggestion.items():\n        if key == \"suggestion_uuid\":\n            continue\n        # Convert key to string if it's not already",
        "detail": "tools.sweep_init",
        "documentation": {}
    },
    {
        "label": "sweep_space",
        "kind": 2,
        "importPath": "tools.sweep_init",
        "description": "tools.sweep_init",
        "peekOfCode": "def sweep_space(space, min_val, max_val, center=None, *, _root_):\n    result = {\n        \"space\": space,\n        \"min\": min_val,\n        \"max\": max_val,\n        \"search_center\": center,\n    }\n    if space == \"int\":\n        result[\"is_int\"] = True\n        result[\"space\"] = \"linear\"",
        "detail": "tools.sweep_init",
        "documentation": {}
    },
    {
        "label": "TrainJob",
        "kind": 6,
        "importPath": "tools.train",
        "description": "tools.train",
        "peekOfCode": "class TrainJob(Config):\n    __init__ = Config.__init__\n    evals: SimulationSuiteConfig\n    map_preview_uri: str | None = None\ndef train(cfg: ListConfig | DictConfig, wandb_run: WandbRun | None, logger: Logger):\n    cfg = load_train_job_config_with_overrides(cfg)\n    if os.environ.get(\"RANK\", \"0\") == \"0\":\n        with open(os.path.join(cfg.run_dir, \"config.yaml\"), \"w\") as f:\n            OmegaConf.save(cfg, f)\n    train_job = TrainJob(cfg.train_job)",
        "detail": "tools.train",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "tools.train",
        "description": "tools.train",
        "peekOfCode": "def train(cfg: ListConfig | DictConfig, wandb_run: WandbRun | None, logger: Logger):\n    cfg = load_train_job_config_with_overrides(cfg)\n    if os.environ.get(\"RANK\", \"0\") == \"0\":\n        with open(os.path.join(cfg.run_dir, \"config.yaml\"), \"w\") as f:\n            OmegaConf.save(cfg, f)\n    train_job = TrainJob(cfg.train_job)\n    if torch.distributed.is_initialized():\n        world_size = torch.distributed.get_world_size()\n        if cfg.trainer.scale_batches_by_world_size:\n            cfg.trainer.forward_pass_minibatch_target_size = (",
        "detail": "tools.train",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.train",
        "description": "tools.train",
        "peekOfCode": "def main(cfg: ListConfig | DictConfig) -> int:\n    setup_mettagrid_environment(cfg)\n    record_heartbeat()\n    logger = setup_mettagrid_logger(\"train\")\n    logger.info(f\"Train job config: {OmegaConf.to_yaml(cfg, resolve=True)}\")\n    logger.info(\n        f\"Training {cfg.run} on \"\n        + f\"{os.environ.get('NODE_INDEX', '0')}: \"\n        + f\"{os.environ.get('LOCAL_RANK', '0')} ({cfg.device})\"\n    )",
        "detail": "tools.train",
        "documentation": {}
    },
    {
        "label": "is_image_file",
        "kind": 2,
        "importPath": "tools.upload_map_imgs",
        "description": "tools.upload_map_imgs",
        "peekOfCode": "def is_image_file(filename):\n    \"\"\"Check if a file is an image based on its mimetype.\"\"\"\n    mimetype, _ = mimetypes.guess_type(filename)\n    return mimetype and mimetype.startswith(\"image/\")\ndef get_proper_filename(filepath):\n    \"\"\"Ensure the file has an appropriate image extension.\"\"\"\n    path = Path(filepath)\n    # If file already has an extension, use it\n    if path.suffix:\n        return path.name",
        "detail": "tools.upload_map_imgs",
        "documentation": {}
    },
    {
        "label": "get_proper_filename",
        "kind": 2,
        "importPath": "tools.upload_map_imgs",
        "description": "tools.upload_map_imgs",
        "peekOfCode": "def get_proper_filename(filepath):\n    \"\"\"Ensure the file has an appropriate image extension.\"\"\"\n    path = Path(filepath)\n    # If file already has an extension, use it\n    if path.suffix:\n        return path.name\n    # Otherwise, try to determine extension from mimetype\n    mimetype, _ = mimetypes.guess_type(filepath)\n    if mimetype:\n        ext = mimetypes.guess_extension(mimetype)",
        "detail": "tools.upload_map_imgs",
        "documentation": {}
    },
    {
        "label": "upload_to_s3",
        "kind": 2,
        "importPath": "tools.upload_map_imgs",
        "description": "tools.upload_map_imgs",
        "peekOfCode": "def upload_to_s3(file_path, s3_bucket, s3_prefix):\n    \"\"\"Upload a file to S3.\"\"\"\n    s3_client = boto3.client(\"s3\")\n    dest_filename = get_proper_filename(file_path)\n    s3_key = f\"{s3_prefix.rstrip('/')}/{dest_filename}\"\n    try:\n        print(f\"Uploading {file_path} to s3://{s3_bucket}/{s3_key}\")\n        s3_client.upload_file(file_path, s3_bucket, s3_key)\n        return True\n    except ClientError as e:",
        "detail": "tools.upload_map_imgs",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.upload_map_imgs",
        "description": "tools.upload_map_imgs",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(description=\"Upload images to S3\")\n    parser.add_argument(\"--dry-run\", action=\"store_true\", help=\"Perform a dry run without uploading files\")\n    args = parser.parse_args()\n    # S3 destination details\n    s3_bucket = \"softmax-public\"\n    s3_prefix = \"policydash/evals/img\"\n    uploaded_count = 0\n    skipped_count = 0\n    for filename in os.listdir(\".\"):",
        "detail": "tools.upload_map_imgs",
        "documentation": {}
    },
    {
        "label": "load_and_print_config",
        "kind": 2,
        "importPath": "tools.validate_config",
        "description": "tools.validate_config",
        "peekOfCode": "def load_and_print_config(config_path: str) -> None:\n    \"\"\"\n    Load a Hydra configuration and print it as YAML.\n    Args:\n        config_path: Path to the configuration file (relative to configs/ directory)\n    \"\"\"\n    # Strip \"configs/\" prefix if present\n    if config_path.startswith(\"configs/\"):\n        config_path = config_path[len(\"configs/\") :]\n    # Clear any existing Hydra instance",
        "detail": "tools.validate_config",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.validate_config",
        "description": "tools.validate_config",
        "peekOfCode": "def main():\n    \"\"\"Main entry point for the script.\"\"\"\n    parser = argparse.ArgumentParser(description=\"Load and print Hydra configurations\")\n    parser.add_argument(\"config_path\", help=\"Path to the configuration file (relative to configs/ directory)\")\n    args = parser.parse_args()\n    load_and_print_config(args.config_path)\nif __name__ == \"__main__\":\n    main()",
        "detail": "tools.validate_config",
        "documentation": {}
    },
    {
        "label": "ReplayJob",
        "kind": 6,
        "importPath": "wandb.run-20250627_130440-daveey.local.1.3.files.code.tools.replay",
        "description": "wandb.run-20250627_130440-daveey.local.1.3.files.code.tools.replay",
        "peekOfCode": "class ReplayJob(Config):\n    __init__ = Config.__init__\n    sim: SingleEnvSimulationConfig\n    policy_uri: str\n    selector_type: str\n    replay_dir: str\n    stats_dir: str\n@hydra.main(version_base=None, config_path=\"../configs\", config_name=\"replay_job\")\ndef main(cfg):\n    setup_mettagrid_environment(cfg)",
        "detail": "wandb.run-20250627_130440-daveey.local.1.3.files.code.tools.replay",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "wandb.run-20250627_130440-daveey.local.1.3.files.code.tools.replay",
        "description": "wandb.run-20250627_130440-daveey.local.1.3.files.code.tools.replay",
        "peekOfCode": "def main(cfg):\n    setup_mettagrid_environment(cfg)\n    logger = setup_mettagrid_logger(\"metta.tools.replay\")\n    logger.info(f\"Replay job config:\\n{OmegaConf.to_yaml(cfg, resolve=True)}\")\n    with WandbContext(cfg.wandb, cfg) as wandb_run:\n        policy_store = PolicyStore(cfg, wandb_run)\n        replay_job = ReplayJob(cfg.replay_job)\n        policy_record = policy_store.policy(replay_job.policy_uri)\n        sim_config = SingleEnvSimulationConfig(cfg.replay_job.sim)\n        sim_name = sim_config.env.split(\"/\")[-1]",
        "detail": "wandb.run-20250627_130440-daveey.local.1.3.files.code.tools.replay",
        "documentation": {}
    },
    {
        "label": "ReplayJob",
        "kind": 6,
        "importPath": "wandb.run-20250627_130452-daveey.local.1.3.files.code.tools.replay",
        "description": "wandb.run-20250627_130452-daveey.local.1.3.files.code.tools.replay",
        "peekOfCode": "class ReplayJob(Config):\n    __init__ = Config.__init__\n    sim: SingleEnvSimulationConfig\n    policy_uri: str\n    selector_type: str\n    replay_dir: str\n    stats_dir: str\n@hydra.main(version_base=None, config_path=\"../configs\", config_name=\"replay_job\")\ndef main(cfg):\n    setup_mettagrid_environment(cfg)",
        "detail": "wandb.run-20250627_130452-daveey.local.1.3.files.code.tools.replay",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "wandb.run-20250627_130452-daveey.local.1.3.files.code.tools.replay",
        "description": "wandb.run-20250627_130452-daveey.local.1.3.files.code.tools.replay",
        "peekOfCode": "def main(cfg):\n    setup_mettagrid_environment(cfg)\n    logger = setup_mettagrid_logger(\"metta.tools.replay\")\n    logger.info(f\"Replay job config:\\n{OmegaConf.to_yaml(cfg, resolve=True)}\")\n    with WandbContext(cfg.wandb, cfg) as wandb_run:\n        policy_store = PolicyStore(cfg, wandb_run)\n        replay_job = ReplayJob(cfg.replay_job)\n        policy_record = policy_store.policy(replay_job.policy_uri)\n        sim_config = SingleEnvSimulationConfig(cfg.replay_job.sim)\n        sim_name = sim_config.env.split(\"/\")[-1]",
        "detail": "wandb.run-20250627_130452-daveey.local.1.3.files.code.tools.replay",
        "documentation": {}
    },
    {
        "label": "ReplayJob",
        "kind": 6,
        "importPath": "wandb.run-20250627_130529-daveey.local.1.3.files.code.tools.replay",
        "description": "wandb.run-20250627_130529-daveey.local.1.3.files.code.tools.replay",
        "peekOfCode": "class ReplayJob(Config):\n    __init__ = Config.__init__\n    sim: SingleEnvSimulationConfig\n    policy_uri: str\n    selector_type: str\n    replay_dir: str\n    stats_dir: str\n@hydra.main(version_base=None, config_path=\"../configs\", config_name=\"replay_job\")\ndef main(cfg):\n    setup_mettagrid_environment(cfg)",
        "detail": "wandb.run-20250627_130529-daveey.local.1.3.files.code.tools.replay",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "wandb.run-20250627_130529-daveey.local.1.3.files.code.tools.replay",
        "description": "wandb.run-20250627_130529-daveey.local.1.3.files.code.tools.replay",
        "peekOfCode": "def main(cfg):\n    setup_mettagrid_environment(cfg)\n    logger = setup_mettagrid_logger(\"metta.tools.replay\")\n    logger.info(f\"Replay job config:\\n{OmegaConf.to_yaml(cfg, resolve=True)}\")\n    with WandbContext(cfg.wandb, cfg) as wandb_run:\n        policy_store = PolicyStore(cfg, wandb_run)\n        replay_job = ReplayJob(cfg.replay_job)\n        policy_record = policy_store.policy(replay_job.policy_uri)\n        sim_config = SingleEnvSimulationConfig(cfg.replay_job.sim)\n        sim_name = sim_config.env.split(\"/\")[-1]",
        "detail": "wandb.run-20250627_130529-daveey.local.1.3.files.code.tools.replay",
        "documentation": {}
    },
    {
        "label": "ReplayJob",
        "kind": 6,
        "importPath": "wandb.run-20250627_130609-daveey.local.1.3.files.code.tools.replay",
        "description": "wandb.run-20250627_130609-daveey.local.1.3.files.code.tools.replay",
        "peekOfCode": "class ReplayJob(Config):\n    __init__ = Config.__init__\n    sim: SingleEnvSimulationConfig\n    policy_uri: str\n    selector_type: str\n    replay_dir: str\n    stats_dir: str\n@hydra.main(version_base=None, config_path=\"../configs\", config_name=\"replay_job\")\ndef main(cfg):\n    setup_mettagrid_environment(cfg)",
        "detail": "wandb.run-20250627_130609-daveey.local.1.3.files.code.tools.replay",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "wandb.run-20250627_130609-daveey.local.1.3.files.code.tools.replay",
        "description": "wandb.run-20250627_130609-daveey.local.1.3.files.code.tools.replay",
        "peekOfCode": "def main(cfg):\n    setup_mettagrid_environment(cfg)\n    logger = setup_mettagrid_logger(\"metta.tools.replay\")\n    logger.info(f\"Replay job config:\\n{OmegaConf.to_yaml(cfg, resolve=True)}\")\n    with WandbContext(cfg.wandb, cfg) as wandb_run:\n        policy_store = PolicyStore(cfg, wandb_run)\n        replay_job = ReplayJob(cfg.replay_job)\n        policy_record = policy_store.policy(replay_job.policy_uri)\n        sim_config = SingleEnvSimulationConfig(cfg.replay_job.sim)\n        sim_name = sim_config.env.split(\"/\")[-1]",
        "detail": "wandb.run-20250627_130609-daveey.local.1.3.files.code.tools.replay",
        "documentation": {}
    },
    {
        "label": "ReplayJob",
        "kind": 6,
        "importPath": "wandb.run-20250627_130639-daveey.local.1.3.files.code.tools.replay",
        "description": "wandb.run-20250627_130639-daveey.local.1.3.files.code.tools.replay",
        "peekOfCode": "class ReplayJob(Config):\n    __init__ = Config.__init__\n    sim: SingleEnvSimulationConfig\n    policy_uri: str\n    selector_type: str\n    replay_dir: str\n    stats_dir: str\n@hydra.main(version_base=None, config_path=\"../configs\", config_name=\"replay_job\")\ndef main(cfg):\n    setup_mettagrid_environment(cfg)",
        "detail": "wandb.run-20250627_130639-daveey.local.1.3.files.code.tools.replay",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "wandb.run-20250627_130639-daveey.local.1.3.files.code.tools.replay",
        "description": "wandb.run-20250627_130639-daveey.local.1.3.files.code.tools.replay",
        "peekOfCode": "def main(cfg):\n    setup_mettagrid_environment(cfg)\n    logger = setup_mettagrid_logger(\"metta.tools.replay\")\n    logger.info(f\"Replay job config:\\n{OmegaConf.to_yaml(cfg, resolve=True)}\")\n    with WandbContext(cfg.wandb, cfg) as wandb_run:\n        policy_store = PolicyStore(cfg, wandb_run)\n        replay_job = ReplayJob(cfg.replay_job)\n        policy_record = policy_store.policy(replay_job.policy_uri)\n        sim_config = SingleEnvSimulationConfig(cfg.replay_job.sim)\n        sim_name = sim_config.env.split(\"/\")[-1]",
        "detail": "wandb.run-20250627_130639-daveey.local.1.3.files.code.tools.replay",
        "documentation": {}
    },
    {
        "label": "ReplayJob",
        "kind": 6,
        "importPath": "wandb.run-20250627_130716-daveey.local.1.3.files.code.tools.replay",
        "description": "wandb.run-20250627_130716-daveey.local.1.3.files.code.tools.replay",
        "peekOfCode": "class ReplayJob(Config):\n    __init__ = Config.__init__\n    sim: SingleEnvSimulationConfig\n    policy_uri: str\n    selector_type: str\n    replay_dir: str\n    stats_dir: str\n@hydra.main(version_base=None, config_path=\"../configs\", config_name=\"replay_job\")\ndef main(cfg):\n    setup_mettagrid_environment(cfg)",
        "detail": "wandb.run-20250627_130716-daveey.local.1.3.files.code.tools.replay",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "wandb.run-20250627_130716-daveey.local.1.3.files.code.tools.replay",
        "description": "wandb.run-20250627_130716-daveey.local.1.3.files.code.tools.replay",
        "peekOfCode": "def main(cfg):\n    setup_mettagrid_environment(cfg)\n    logger = setup_mettagrid_logger(\"metta.tools.replay\")\n    logger.info(f\"Replay job config:\\n{OmegaConf.to_yaml(cfg, resolve=True)}\")\n    with WandbContext(cfg.wandb, cfg) as wandb_run:\n        policy_store = PolicyStore(cfg, wandb_run)\n        replay_job = ReplayJob(cfg.replay_job)\n        policy_record = policy_store.policy(replay_job.policy_uri)\n        sim_config = SingleEnvSimulationConfig(cfg.replay_job.sim)\n        sim_name = sim_config.env.split(\"/\")[-1]",
        "detail": "wandb.run-20250627_130716-daveey.local.1.3.files.code.tools.replay",
        "documentation": {}
    },
    {
        "label": "WandbCarbs",
        "kind": 6,
        "importPath": "wandb_carbs.build.lib.wandb_carbs",
        "description": "wandb_carbs.build.lib.wandb_carbs",
        "peekOfCode": "class WandbCarbs:\n    def __init__(self, carbs: CARBS, wandb_run=None, sweep_id: str = None):\n        \"\"\"\n        Initialize WandbCarbs with a CARBS instance and optionally a wandb run.\n        Args:\n            carbs (CARBS): The CARBS instance to use for suggestions.\n            wandb_run (wandb.Run, optional): The wandb run to use. If None, uses the current run.\n        \"\"\"\n        self._wandb_run = wandb_run or wandb.run\n        self._sweep_id = self._wandb_run.sweep_id",
        "detail": "wandb_carbs.build.lib.wandb_carbs",
        "documentation": {}
    },
    {
        "label": "Pow2WandbCarbs",
        "kind": 6,
        "importPath": "wandb_carbs.build.lib.wandb_carbs",
        "description": "wandb_carbs.build.lib.wandb_carbs",
        "peekOfCode": "class Pow2WandbCarbs(WandbCarbs):\n    \"\"\"\n    A subclass of WandbCarbs that handles parameters that should be treated as powers of 2.\n    This class extends WandbCarbs to support parameters that are internally represented as\n    exponents but should be presented as powers of 2 externally.\n    Attributes:\n        pow2_params (Set[str]): A set of parameter names that should be treated as powers of 2.\n    \"\"\"\n    def __init__(self, carbs: CARBS, pow2_params: Set[str], wandb_run=None):\n        \"\"\"",
        "detail": "wandb_carbs.build.lib.wandb_carbs",
        "documentation": {}
    },
    {
        "label": "create_sweep",
        "kind": 2,
        "importPath": "wandb_carbs.build.lib.wandb_carbs",
        "description": "wandb_carbs.build.lib.wandb_carbs",
        "peekOfCode": "def create_sweep(sweep_name: str, wandb_entity: str, wandb_project: str, carb_params: List[Param]):\n    \"\"\"\n    Create a new wandb sweep based on CARBS parameters.\n    Args:\n        sweep_name (str): The name of the sweep.\n        wandb_entity (str): The wandb entity (username or team name).\n        wandb_project (str): The wandb project name.\n        carb_params (List[Param]): The CARBS parameter spaces.\n    Returns:\n        str: The ID of the created sweep.",
        "detail": "wandb_carbs.build.lib.wandb_carbs",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "wandb_carbs.build.lib.wandb_carbs",
        "description": "wandb_carbs.build.lib.wandb_carbs",
        "peekOfCode": "logger = logging.getLogger(\"wandb_carbs\")\n# logger.setLevel(logging.DEBUG)\nclass WandbCarbs:\n    def __init__(self, carbs: CARBS, wandb_run=None, sweep_id: str = None):\n        \"\"\"\n        Initialize WandbCarbs with a CARBS instance and optionally a wandb run.\n        Args:\n            carbs (CARBS): The CARBS instance to use for suggestions.\n            wandb_run (wandb.Run, optional): The wandb run to use. If None, uses the current run.\n        \"\"\"",
        "detail": "wandb_carbs.build.lib.wandb_carbs",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "wandb_carbs.build.lib.wandb_carbs",
        "description": "wandb_carbs.build.lib.wandb_carbs",
        "peekOfCode": "__all__ = [\n    \"WandbCarbs\",\n    \"Pow2WandbCarbs\",\n    \"create_sweep\",\n]",
        "detail": "wandb_carbs.build.lib.wandb_carbs",
        "documentation": {}
    },
    {
        "label": "pytest_configure",
        "kind": 2,
        "importPath": "conftest",
        "description": "conftest",
        "peekOfCode": "def pytest_configure(config):\n    # Add multiple markers correctly\n    config.addinivalue_line(\"markers\", \"benchmark: mark a test as a benchmark test\")\n    config.addinivalue_line(\"markers\", \"verbose: mark a test to display verbose output\")\n@pytest.fixture\ndef verbose(request):\n    \"\"\"Fixture that can be used in tests to check if verbose mode is enabled.\"\"\"\n    marker = request.node.get_closest_marker(\"verbose\")\n    return marker is not None\n# Properly handle output capture for verbose tests",
        "detail": "conftest",
        "documentation": {}
    },
    {
        "label": "verbose",
        "kind": 2,
        "importPath": "conftest",
        "description": "conftest",
        "peekOfCode": "def verbose(request):\n    \"\"\"Fixture that can be used in tests to check if verbose mode is enabled.\"\"\"\n    marker = request.node.get_closest_marker(\"verbose\")\n    return marker is not None\n# Properly handle output capture for verbose tests\n@pytest.hookimpl(hookwrapper=True)\ndef pytest_runtest_makereport(item, call):\n    outcome = yield\n    report = outcome.get_result()\n    # Only process after the call phase (actual test execution)",
        "detail": "conftest",
        "documentation": {}
    },
    {
        "label": "pytest_runtest_makereport",
        "kind": 2,
        "importPath": "conftest",
        "description": "conftest",
        "peekOfCode": "def pytest_runtest_makereport(item, call):\n    outcome = yield\n    report = outcome.get_result()\n    # Only process after the call phase (actual test execution)\n    if report.when == \"call\" and item.get_closest_marker(\"verbose\"):\n        capman = item.config.pluginmanager.get_plugin(\"capturemanager\")\n        if capman and hasattr(report, \"capstdout\") and hasattr(report, \"capstderr\"):\n            # Print the captured output with formatting\n            print(f\"\\n\\n===== VERBOSE OUTPUT FOR: {item.name} =====\\n\")\n            if report.capstdout:",
        "detail": "conftest",
        "documentation": {}
    },
    {
        "label": "base_dir",
        "kind": 5,
        "importPath": "conftest",
        "description": "conftest",
        "peekOfCode": "base_dir = Path(__file__).resolve().parent\nprint(\"\\n===== DEBUG: Python sys.path =====\")\nfor i, path in enumerate(sys.path):\n    print(f\"{i}: {path}\")\nprint(\"===== END DEBUG: Python sys.path =====\\n\")\ndef pytest_configure(config):\n    # Add multiple markers correctly\n    config.addinivalue_line(\"markers\", \"benchmark: mark a test as a benchmark test\")\n    config.addinivalue_line(\"markers\", \"verbose: mark a test to display verbose output\")\n@pytest.fixture",
        "detail": "conftest",
        "documentation": {}
    }
]