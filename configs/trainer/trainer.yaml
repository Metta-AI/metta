num_workers: ???

curriculum: /env/mettagrid/curriculum/simple
env_overrides: {}

initial_policy:
  uri: null
  type: top
  range: 1
  metric: epoch
  filters: {}

checkpoint_dir: ${run_dir}/checkpoints

evaluate_interval: 300
checkpoint_interval: 60
wandb_checkpoint_interval: 300
replay_interval: ${trainer.evaluate_interval}
replay_dir: s3://softmax-public/replays/${run}

rewards:
  # Average reward settings
  average_reward: false # Set to true to use average reward optimization
  average_reward_alpha: 0.01 # Smoothing factor for 100k step average (ln(2)/100000)

  entropy_coef: 0.0002 # assuming agents get 0.5 reward per 1,000 steps
