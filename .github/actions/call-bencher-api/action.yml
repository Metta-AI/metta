name: "Run Unified Bencher Analysis"
description: "Run Bencher analysis with 3 core measures: latency + 2 KPIs"
inputs:
  bencher_token:
    description: "Bencher API token"
    required: true
  github_token:
    description: "GitHub token"
    required: true
  benchmark_file:
    description: "Unified benchmark results file (BMF format)"
    required: true
  project_id:
    description: "Bencher project ID"
    default: "metta"

runs:
  using: "composite"
  steps:
    - name: Install Bencher CLI
      uses: bencherdev/bencher@main

    - name: Install jq
      shell: bash
      run: sudo apt-get install -y jq

    - name: Check main branch status
      id: check-main
      shell: bash
      env:
        BENCHER_API_TOKEN: ${{ inputs.bencher_token }}
      run: |
        if bencher branch view ${{ inputs.project_id }} main --token "$BENCHER_API_TOKEN" > /tmp/branch_output.json 2>/dev/null; then
          if jq -e '.head' /tmp/branch_output.json > /dev/null; then
            echo "main_exists=true" >> $GITHUB_OUTPUT
          else
            echo "main_exists=false" >> $GITHUB_OUTPUT
          fi
        else
          echo "main_exists=false" >> $GITHUB_OUTPUT
        fi

    # Main branch: Upload baseline with ultra-simple thresholds
    - name: Upload baseline with 3-measure thresholds (main branch)
      if: github.ref == 'refs/heads/main'
      shell: bash
      env:
        BENCHER_API_TOKEN: ${{ inputs.bencher_token }}
        GITHUB_TOKEN: ${{ inputs.github_token }}
      run: |
        if [ -f "${{ inputs.benchmark_file }}" ] && [ -s "${{ inputs.benchmark_file }}" ]; then

          # Built-in latency measure (lower is better - alert on increases)
          echo "Setting upper threshold for latency (built-in timing measure)"
          bencher run \
            --project ${{ inputs.project_id }} \
            --token "$BENCHER_API_TOKEN" \
            --branch main \
            --threshold-measure latency \
            --threshold-test percentage \
            --threshold-max-sample-size 2 \
            --threshold-upper-boundary 0.20 \
            --testbed ubuntu-latest \
            --adapter json \
            --github-actions "$GITHUB_TOKEN" \
            --file "${{ inputs.benchmark_file }}" || echo "‚ö†Ô∏è Could not set latency threshold"
          
          # Core throughput KPIs (higher is better - alert on ANY 20% change)
          declare -A THROUGHPUT_METRICS=(
            ["agent_steps_per_second"]="Main agent performance KPI"
            ["env_steps_per_second"]="Main environment performance KPI"
          )
          
          for metric in "${!THROUGHPUT_METRICS[@]}"; do
            echo "Setting bidirectional threshold for ${THROUGHPUT_METRICS[$metric]}: $metric"
            bencher run \
              --project ${{ inputs.project_id }} \
              --token "$BENCHER_API_TOKEN" \
              --branch main \
              --threshold-measure "$metric" \
              --threshold-test percentage \
              --threshold-max-sample-size 2 \
              --threshold-lower-boundary 0.20 \
              --threshold-upper-boundary 0.20 \
              --testbed ubuntu-latest \
              --adapter json \
              --github-actions "$GITHUB_TOKEN" \
              --file "${{ inputs.benchmark_file }}" || echo "‚ö†Ô∏è  Could not set threshold for $metric"
          done
          
          echo "‚úÖ Thresholds configured"
        else
          echo "‚ö†Ô∏è No benchmark file found: ${{ inputs.benchmark_file }}"
        fi

    # PR: Check for significant changes in the 3 core measures
    - name: Check for significant changes in core measures
      if: |
        github.event_name == 'pull_request' &&
        !github.event.pull_request.head.repo.fork &&
        steps.check-main.outputs.main_exists == 'true'
      shell: bash
      env:
        BENCHER_API_TOKEN: ${{ inputs.bencher_token }}
        GITHUB_TOKEN: ${{ inputs.github_token }}
      run: |
        echo "üö® Checking for significant changes..."
        echo "- latency: ¬±20% timing changes"
        echo "- agent_steps_per_second: ¬±20% throughput changes" 
        echo "- env_steps_per_second: ¬±20% throughput changes"

        if [ -f "${{ inputs.benchmark_file }}" ]; then

          bencher run \
            --project ${{ inputs.project_id }} \
            --token "$BENCHER_API_TOKEN" \
            --branch "$GITHUB_HEAD_REF" \
            --start-point main \
            --start-point-reset \
            --start-point-clone-thresholds \
            --err \
            --testbed ubuntu-latest \
            --adapter json \
            --github-actions "$GITHUB_TOKEN" \
            --file "${{ inputs.benchmark_file }}"
            
          echo "‚úÖ No significant changes detected in core measures"
        else
          echo "‚ö†Ô∏è  No benchmark file found: ${{ inputs.benchmark_file }}"
          exit 1
        fi
