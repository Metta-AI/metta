
--- a/protein.py
+++ b/protein.py
@@
 def pareto_points(observations, eps=1e-6):
-    scores = np.array([e["output"] for e in observations])
-    costs = np.array([e["cost"] for e in observations])
-    pareto = []
-    idxs = []
-    for idx, obs in enumerate(observations):
-        try:
-            higher_score = scores + eps > scores[idx]
-        except Exception as e:
-            raise RuntimeError(f"Failed to compare protein scores: {e}") from e
-        lower_cost = costs - eps < costs[idx]
-        better = higher_score & lower_cost
-        better[idx] = False
-        if not better.any():
-            pareto.append(obs)
-            idxs.append(idx)
-    return pareto, idxs
+    # Backwards-compatible wrapper defaults to maximize
+    return pareto_points_oriented(observations, direction=1, eps=eps)
+
+
+def pareto_points_oriented(observations, direction=1, eps=1e-6):
+    """
+    Compute Pareto front on (score, cost) with goal encoded by `direction`.
+    direction = +1 for maximize, -1 for minimize.
+    """
+    scores = np.array([direction * e["output"] for e in observations])
+    costs = np.array([e["cost"] for e in observations])
+    pareto, idxs = [], []
+    for idx in range(len(observations)):
+        higher_score = scores + eps > scores[idx]
+        lower_cost = costs - eps < costs[idx]
+        better = higher_score & lower_cost
+        better[idx] = False
+        if not better.any():
+            pareto.append(observations[idx])
+            idxs.append(idx)
+    return pareto, idxs
@@
 def create_gp(x_dim, scale_length=1.0):
-    X = scale_length * torch.ones((1, x_dim))
+    X = torch.zeros((1, x_dim))
     y = torch.zeros((1,))
-    matern_kernel = gp.kernels.Matern32(input_dim=x_dim, lengthscale=X)
-    linear_kernel = gp.kernels.Polynomial(x_dim, degree=1)
+    matern_kernel = gp.kernels.Matern32(input_dim=x_dim, lengthscale=scale_length * torch.ones(x_dim))
+    linear_kernel = gp.kernels.Polynomial(input_dim=x_dim, degree=1)
     kernel = gp.kernels.Sum(linear_kernel, matern_kernel)
     model = gp.models.GPRegression(X, y, kernel=kernel, jitter=1.0e-4)
-    model.noise = pyro.nn.PyroSample(pyro.distributions.LogNormal(math.log(1e-2), 0.5))
-    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)
+    # Keep noise as a positive tensor (simpler & numerically stable)
+    model.noise = torch.tensor(1e-2)
+    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)
     return model, optimizer
@@ class ParetoGenetic:
     def suggest(self, fill=None):
         if len(self.success_observations) == 0:
             suggestion = self.hyperparameters.search_centers
             return self.hyperparameters.to_dict(suggestion, fill), {}
-        candidates, _ = pareto_points(self.success_observations)
+        candidates, _ = pareto_points_oriented(self.success_observations, self.hyperparameters.optimize_direction)
         pareto_costs = np.array([e["cost"] for e in candidates])
         if self.bias_cost:
             if self.log_bias:
                 cost_dists = np.abs(np.log(pareto_costs[:, None]) - np.log(pareto_costs[None, :]))
             else:
                 cost_dists = np.abs(pareto_costs[:, None] - pareto_costs[None, :])
             cost_dists += (np.max(pareto_costs) + 1) * np.eye(len(pareto_costs))  # mask self-distance
             idx = np.argmax(np.min(cost_dists, axis=1))
             search_centers = candidates[idx]["input"]
         else:
             search_centers = np.stack([e["input"] for e in candidates])
-        suggestions = self.hyperparameters.sample(len(candidates) * self.suggestions_per_pareto, mu=search_centers)
+        suggestions = self.hyperparameters.sample(
+            len(candidates) * self.suggestions_per_pareto, mu=search_centers, scale=self.global_search_scale
+        )
         suggestion = suggestions[np.random.randint(0, len(suggestions))]
         return self.hyperparameters.to_dict(suggestion, fill), {}
@@ class Protein:
-    def suggest(self, fill):
+    def suggest(self, fill=None):
         info = {}
         self.suggestion_idx += 1
@@
-        elif len(self.success_observations) < self.num_random_samples:
-            suggestions = self.hyperparameters.sample(self.random_suggestions)
+        elif len(self.success_observations) < self.num_random_samples:
+            suggestions = self.hyperparameters.sample(self.random_suggestions, scale=self.global_search_scale)
             self.suggestion = random.choice(suggestions)
             return self.hyperparameters.to_dict(self.suggestion, fill), info
         elif self.resample_frequency and self.suggestion_idx % self.resample_frequency == 0:
-            candidates, _ = pareto_points(self.success_observations)
+            candidates, _ = pareto_points_oriented(self.success_observations, self.hyperparameters.optimize_direction)
             suggestions = np.stack([e["input"] for e in candidates])
             best_idx = np.random.randint(0, len(candidates))
             best = suggestions[best_idx]
             return self.hyperparameters.to_dict(best, fill), info
-        params = np.array([e["input"] for e in self.success_observations])
-        params = torch.from_numpy(params).float()  # Convert to float32
-        y = np.array([e["output"] for e in self.success_observations])
-        min_score = np.min(y)
-        max_score = np.max(y)
-        y_norm = (y - min_score) / (np.abs(max_score - min_score) + 1e-6)
-        self.gp_score.set_data(params, torch.from_numpy(y_norm).float())  # Convert to float32
-        self.gp_score.train()
-        gp.util.train(self.gp_score, self.score_opt)
-        self.gp_score.eval()
-        c = np.array([e["cost"] for e in self.success_observations])
-        log_c = np.log(c)
-        log_c_min = np.min(log_c)
-        log_c_max = np.max(log_c)
-        log_c_norm = (log_c - log_c_min) / (log_c_max - log_c_min + 1e-6)
-        self.gp_cost.mean_function = lambda x: 1
-        self.gp_cost.set_data(params, torch.from_numpy(log_c_norm).float())  # Convert to float32
-        self.gp_cost.train()
-        gp.util.train(self.gp_cost, self.cost_opt)
-        self.gp_cost.eval()
-        candidates, pareto_idxs = pareto_points(self.success_observations)
-        search_centers = np.stack([e["input"] for e in candidates])
-        suggestions = self.hyperparameters.sample(len(candidates) * self.suggestions_per_pareto, mu=search_centers)
-        suggestions = torch.from_numpy(suggestions).float()  # Convert to float32
-        with torch.no_grad():
-            gp_y_norm, gp_y_norm_var = self.gp_score(suggestions)
-            gp_log_c_norm, _ = self.gp_cost(suggestions)
-        gp_y_norm = gp_y_norm.numpy()
-        gp_y_norm_std = np.sqrt(gp_y_norm_var.numpy())
-        gp_log_c_norm = gp_log_c_norm.numpy()
-        gp_y = gp_y_norm * (max_score - min_score) + min_score
-        gp_y_std = gp_y_norm_std * (max_score - min_score)
-        gp_log_c = gp_log_c_norm * (log_c_max - log_c_min) + log_c_min
-        gp_c = np.exp(gp_log_c)
-
-        max_c_mask = gp_c < self.max_suggestion_cost
+        # === Train score GP on standardized outputs ===
+        params = np.array([e["input"] for e in self.success_observations])
+        params_t = torch.from_numpy(params).float()
+        y = np.array([e["output"] for e in self.success_observations])
+        y_mean = float(np.mean(y))
+        y_std = float(np.std(y) + 1e-12)
+        y_z = (y - y_mean) / y_std
+
+        self.gp_score.set_data(params_t, torch.from_numpy(y_z).float())
+        self.gp_score.train(); gp.util.train(self.gp_score, self.score_opt)
+        self.gp_score.eval()
+
+        # === Build candidate suggestions from oriented Pareto centers ===
+        candidates, pareto_idxs = pareto_points_oriented(self.success_observations, self.hyperparameters.optimize_direction)
+        search_centers = np.stack([e["input"] for e in candidates])
+        suggestions = self.hyperparameters.sample(
+            len(candidates) * self.suggestions_per_pareto, mu=search_centers, scale=self.global_search_scale
+        )
+        suggestions_t = torch.from_numpy(suggestions).float()
+
+        # Predict standardized mean/var
+        with torch.no_grad():
+            mu_t, var_t = self.gp_score(suggestions_t, full_cov=False)
+        mu = mu_t.numpy()
+        sd = np.sqrt(np.maximum(var_t.numpy(), 1e-12))
+
+        # For 'naive' normalization path (info/weighting)
+        min_y, max_y = np.min(y), np.max(y)
+        mu_raw = mu * y_std + y_mean
+        gp_y_norm = (mu_raw - min_y) / (np.abs(max_y - min_y) + 1e-12)
+
+        # === Cost handling: skip GP if constant cost ===
+        c = np.array([e["cost"] for e in self.success_observations])
+        if np.max(c) - np.min(c) < 1e-12:
+            gp_log_c_norm = np.full(len(suggestions), 0.5)
+            gp_c = np.full(len(suggestions), c[0])
+        else:
+            EPS = 1e-12
+            log_c = np.log(np.maximum(c, EPS))
+            lc_min, lc_max = np.min(log_c), np.max(log_c)
+            lc_norm = (log_c - lc_min) / (lc_max - lc_min + 1e-12)
+
+            self.gp_cost.set_data(params_t, torch.from_numpy(lc_norm).float())
+            self.gp_cost.train(); gp.util.train(self.gp_cost, self.cost_opt)
+            self.gp_cost.eval()
+            with torch.no_grad():
+                gp_log_c_norm_t, _ = self.gp_cost(suggestions_t, full_cov=False)
+            gp_log_c_norm = gp_log_c_norm_t.numpy()
+            gp_log_c = gp_log_c_norm * (lc_max - lc_min) + lc_min
+            gp_c = np.exp(gp_log_c)
+
+        max_c_mask = gp_c < self.max_suggestion_cost
+        if not max_c_mask.any():
+            max_c_mask = np.ones_like(max_c_mask, dtype=bool)
+            info["cost_threshold_relaxed"] = True
@@
-        if self.acquisition_fn == "ei":
-            # Find best observed value (with safety check)
-            if len(y) > 0:
-                best_observed = np.max(y) if self.hyperparameters.optimize_direction == 1 else np.min(y)
-            else:
-                # Default when no observations (shouldn't happen but defensive)
-                best_observed = float("-inf") if self.hyperparameters.optimize_direction == 1 else float("inf")
-
-            # Add randomization to EI by jittering the best observed value
-            if self.randomize_acquisition:
-                # Sample jitter from exponential distribution with mean = 5% of score range
-                score_range = max_score - min_score if max_score != min_score else 1.0
-                jitter_scale = 0.05 * score_range
-                jitter = np.random.exponential(scale=jitter_scale)
-                # Apply jitter in the direction that makes exploration more likely
-                if self.hyperparameters.optimize_direction == 1:  # maximizing
-                    best_observed += jitter  # Higher threshold = more exploration
-                else:  # minimizing
-                    best_observed -= jitter  # Lower threshold = more exploration
-
-            ei_scores = self._compute_ei(gp_y, gp_y_std, best_observed)
-            suggestion_scores = max_c_mask * ei_scores
-        elif self.acquisition_fn == "ucb":
-            # Randomize beta parameter for UCB
-            if self.randomize_acquisition:
-                # Sample beta from exponential distribution with mean = self.ucb_beta
-                beta = np.random.exponential(scale=self.ucb_beta)
-                ucb_scores = self._compute_ucb(gp_y, gp_y_std, beta=beta)
-            else:
-                ucb_scores = self._compute_ucb(gp_y, gp_y_std)
-            suggestion_scores = max_c_mask * self.hyperparameters.optimize_direction * ucb_scores
-        else:  # naive
-            suggestion_scores = self._compute_naive_acquisition(gp_y_norm, gp_log_c_norm, max_c_mask)
+        if self.acquisition_fn == "ei":
+            # EI in standardized units
+            direction = self.hyperparameters.optimize_direction
+            best_obs = np.max(y) if direction == 1 else np.min(y)
+            best_std = (best_obs - y_mean) / y_std
+            impr = (mu - best_std) if direction == 1 else (best_std - mu)
+            z = impr / sd
+            from torch.distributions import Normal
+            N01 = Normal(0., 1.)
+            z_t = torch.from_numpy(z)
+            cdf = N01.cdf(z_t).numpy()
+            pdf = torch.exp(N01.log_prob(z_t)).numpy()
+            ei_scores = impr * cdf + sd * pdf
+            suggestion_scores = max_c_mask * ei_scores
+        elif self.acquisition_fn == "ucb":
+            # UCB: maximize direction*mu + beta*sd  (mu, sd standardized)
+            beta = np.random.exponential(self.ucb_beta) if self.randomize_acquisition else self.ucb_beta
+            ucb_scores = self._compute_ucb(mu, sd, beta=beta)
+            suggestion_scores = max_c_mask * ucb_scores
+        else:  # naive
+            # Clamp weight to nonnegative
+            target = (1 + self.expansion_rate) * np.random.rand()
+            weight = np.maximum(1 - np.abs(target - gp_log_c_norm), 0.0)
+            suggestion_scores = self.hyperparameters.optimize_direction * max_c_mask * (gp_y_norm * weight)
@@
-        info = dict(
-            cost=gp_c[best_idx].item(),
-            score=gp_y[best_idx].item(),
-            rating=suggestion_scores[best_idx].item(),
-            acquisition_fn=self.acquisition_fn,
-            randomize_acquisition=self.randomize_acquisition,
-        )
+        # Map standardized mu/sd back to raw for info (not used in selection)
+        info = dict(
+            cost=float(gp_c[best_idx]),
+            score=float(mu_raw[best_idx]),
+            rating=float(suggestion_scores[best_idx]),
+            acquisition_fn=self.acquisition_fn,
+            randomize_acquisition=self.randomize_acquisition,
+        )
@@
     def _compute_ucb(self, mean, std, beta=None):
-        """
-        Compute Upper Confidence Bound acquisition function.
-
-        Args:
-            mean: Predicted mean from GP
-            std: Predicted standard deviation from GP
-            beta: Exploration parameter (higher = more exploration)
-
-        Returns:
-            UCB values
-        """
-        if beta is None:
-            beta = self.ucb_beta
-
-        # UCB = mean + beta * std for maximization
-        # UCB = mean - beta * std for minimization
-        ucb = mean + self.hyperparameters.optimize_direction * beta * std
-
-        return ucb
+        """UCB in standardized space: maximize direction*mu + beta*sd"""
+        if beta is None:
+            beta = self.ucb_beta
+        return self.hyperparameters.optimize_direction * mean + beta * std
@@
     def _compute_naive_acquisition(self, gp_y_norm, gp_log_c_norm, max_c_mask):
@@
-        weight = 1 - abs(target - gp_log_c_norm)
+        weight = np.maximum(1 - abs(target - gp_log_c_norm), 0.0)
         suggestion_scores = self.hyperparameters.optimize_direction * max_c_mask * (gp_y_norm * weight)
         return suggestion_scores
