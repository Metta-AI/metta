{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Interactive Heatmap Widget Example\n",
    "\n",
    "This notebook demonstrates how to use the `HeatmapWidget` - an anywidget-based implementation of the observatory heatmap component for Jupyter notebooks.\n",
    "\n",
    "The widget provides interactive policy evaluation heatmaps with:\n",
    "- Hover effects showing detailed information\n",
    "- Double-click to open replay URLs\n",
    "- Dynamic control over number of policies displayed\n",
    "- Automatic organization by evaluation categories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Installation\n",
    "\n",
    "First, make sure you have the required dependencies:\n",
    "`pip install anywidget traitlets`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Import and Basic Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from experiments.notebooks.utils.metrics import fetch_metrics\n",
    "from experiments.notebooks.utils.monitoring import monitor_training_statuses\n",
    "from experiments.notebooks.utils.replays import show_replay\n",
    "from experiments.notebooks.utils.training import launch_training\n",
    "from experiments.notebooks.utils.metrics import find_training_jobs\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"default\")\n",
    "\n",
    "# Add utils directory to path\n",
    "sys.path.append(os.path.join(os.getcwd(), 'utils'))\n",
    "\n",
    "%load_ext anywidget\n",
    "\n",
    "print(\"Setup complete! Auto-reload enabled.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Example 1: Demo Heatmap with Sample Data\n",
    "\n",
    "Let's start with a simple demo that includes sample data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.notebooks.utils.heatmap_widget import HeatmapWidget, create_demo_heatmap, create_heatmap_widget\n",
    "\n",
    "# Create a demo heatmap with sample data\n",
    "demo_widget = create_demo_heatmap()\n",
    "\n",
    "# Display the widget\n",
    "demo_widget\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Real Data from Metta Database\n",
    "\n",
    "Now let's create a function that fetches real evaluation data from metta's databases:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Real data fetching functions loaded!\n",
      "📋 Available functions:\n",
      "   - fetch_real_heatmap_data(policy_names, metrics, eval_db_uri)\n",
      "   - get_available_policy_names(eval_db_uri)\n",
      "   - get_available_metrics(eval_db_uri)\n",
      "   - get_available_evaluations(eval_db_uri)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Set\n",
    "import logging\n",
    "\n",
    "# Add metta paths\n",
    "import sys\n",
    "sys.path.append('/Users/zfogg/src/github.com/metta-ai/metta')\n",
    "\n",
    "from metta.eval.eval_stats_db import EvalStatsDB\n",
    "from metta.agent.policy_record import PolicyRecord\n",
    "from experiments.notebooks.utils.heatmap_widget import HeatmapWidget, create_heatmap_widget\n",
    "\n",
    "def fetch_real_heatmap_data(\n",
    "    policy_names: List[str], \n",
    "    metrics: List[str],\n",
    "    eval_db_uri: str = \"wandb://stats/navigation_db\",\n",
    "    eval_filter: Optional[str] = None,\n",
    "    max_policies: int = 20\n",
    ") -> HeatmapWidget:\n",
    "    \"\"\"\n",
    "    Fetch real evaluation data from metta's database and create a heatmap widget.\n",
    "    \n",
    "    Args:\n",
    "        policy_names: List of policy names/URIs to include (e.g., [\"my_policy:v123\", \"other_policy:v456\"])\n",
    "        metrics: List of metrics to fetch (e.g., [\"reward\", \"heart.get\", \"action.move.success\"])\n",
    "        eval_db_uri: URI to the evaluation database (default: navigation_db)\n",
    "        eval_filter: Optional SQL filter for evaluations (e.g., \"sim_name LIKE '%maze%'\")\n",
    "        max_policies: Maximum number of policies to display\n",
    "        \n",
    "    Returns:\n",
    "        HeatmapWidget with real data from the database\n",
    "    \"\"\"\n",
    "    print(f\"🔍 Fetching real evaluation data from: {eval_db_uri}\")\n",
    "    print(f\"📋 Policy names: {policy_names}\")\n",
    "    print(f\"📊 Metrics: {metrics}\")\n",
    "    \n",
    "    # Connect to the evaluation database\n",
    "    with EvalStatsDB.from_uri(eval_db_uri) as stats_db:\n",
    "        # Store all data for all metrics\n",
    "        all_metric_data = {}\n",
    "        all_eval_names = set()\n",
    "        valid_policy_names = set()\n",
    "        \n",
    "        # Fetch data for each metric\n",
    "        for metric in metrics:\n",
    "            print(f\"📈 Fetching metric: {metric}\")\n",
    "            \n",
    "            # Get all policy-eval combinations for this metric\n",
    "            df = stats_db.metric_by_policy_eval(metric, policy_record=None)\n",
    "            \n",
    "            if df.empty:\n",
    "                print(f\"⚠️  No data found for metric: {metric}\")\n",
    "                continue\n",
    "                \n",
    "            # Filter to requested policies if specified\n",
    "            if policy_names:\n",
    "                df = df[df['policy_uri'].isin(policy_names)]\n",
    "                \n",
    "            if df.empty:\n",
    "                print(f\"⚠️  No data found for requested policies in metric: {metric}\")\n",
    "                continue\n",
    "                \n",
    "            # Apply evaluation filter if specified\n",
    "            if eval_filter:\n",
    "                # We need to query the database again with the filter\n",
    "                policy_clause = \"1=1\"\n",
    "                if policy_names:\n",
    "                    policy_uris_str = \"', '\".join(policy_names)\n",
    "                    policy_clause = f\"(policy_key || ':v' || policy_version) IN ('{policy_uris_str}')\"\n",
    "                    \n",
    "                sql = f\"\"\"\n",
    "                WITH potential AS (\n",
    "                    SELECT policy_key, policy_version, sim_env, COUNT(*) AS potential_cnt\n",
    "                      FROM policy_simulation_agent_samples\n",
    "                     WHERE {policy_clause} AND ({eval_filter})\n",
    "                     GROUP BY policy_key, policy_version, sim_env\n",
    "                ),\n",
    "                recorded AS (\n",
    "                    SELECT policy_key,\n",
    "                           policy_version,\n",
    "                           sim_env,\n",
    "                           SUM(value) AS recorded_sum\n",
    "                      FROM policy_simulation_agent_metrics\n",
    "                     WHERE metric = '{metric}' AND {policy_clause}\n",
    "                     GROUP BY policy_key, policy_version, sim_env\n",
    "                )\n",
    "                SELECT\n",
    "                    potential.policy_key || ':v' || potential.policy_version AS policy_uri,\n",
    "                    potential.sim_env AS eval_name,\n",
    "                    COALESCE(recorded.recorded_sum, 0) * 1.0 / potential.potential_cnt AS value\n",
    "                FROM potential\n",
    "                LEFT JOIN recorded USING (policy_key, policy_version, sim_env)\n",
    "                ORDER BY policy_uri, eval_name\n",
    "                \"\"\"\n",
    "                df = stats_db.query(sql)\n",
    "                \n",
    "            # Store the data for this metric\n",
    "            all_metric_data[metric] = df\n",
    "            all_eval_names.update(pd.Series(df['eval_name']).unique())\n",
    "            valid_policy_names.update(pd.Series(df['policy_uri']).unique())\n",
    "            \n",
    "            print(f\"   Found {len(df)} policy-eval combinations\")\n",
    "        \n",
    "        if not all_metric_data:\n",
    "            print(\"❌ No data found for any metrics!\")\n",
    "            return create_heatmap_widget()\n",
    "            \n",
    "        # Convert to lists and sort\n",
    "        eval_names = sorted(list(all_eval_names))\n",
    "        policy_names_list = sorted(list(valid_policy_names))\n",
    "        \n",
    "        # Limit number of policies if requested\n",
    "        if len(policy_names_list) > max_policies:\n",
    "            print(f\"🔢 Limiting to {max_policies} policies (found {len(policy_names_list)})\")\n",
    "            # Calculate average scores to pick the best policies\n",
    "            first_metric = next(iter(all_metric_data.keys()))\n",
    "            avg_scores = all_metric_data[first_metric].groupby('policy_uri')['value'].mean().sort_values(ascending=False)\n",
    "            policy_names_list = avg_scores.head(max_policies).index.tolist()\n",
    "        \n",
    "        print(f\"📊 Final dataset: {len(policy_names_list)} policies × {len(eval_names)} evaluations\")\n",
    "        \n",
    "        # Build the cells data structure for the widget\n",
    "        cells = {}\n",
    "        \n",
    "        for policy_name in policy_names_list:\n",
    "            cells[policy_name] = {}\n",
    "            \n",
    "            for eval_name in eval_names:\n",
    "                # Create the metrics dict for this cell\n",
    "                cell_metrics = {}\n",
    "                \n",
    "                for metric in metrics:\n",
    "                    if metric in all_metric_data:\n",
    "                        df = all_metric_data[metric]\n",
    "                        # Find the value for this policy-eval combination\n",
    "                        match = df[(df['policy_uri'] == policy_name) & (df['eval_name'] == eval_name)]\n",
    "                        if not match.empty:\n",
    "                            cell_metrics[metric] = float(match['value'].iloc[0])\n",
    "                        else:\n",
    "                            cell_metrics[metric] = 0.0\n",
    "                    else:\n",
    "                        cell_metrics[metric] = 0.0\n",
    "                \n",
    "                # Create the cell with metrics and metadata\n",
    "                cells[policy_name][eval_name] = {\n",
    "                    'metrics': cell_metrics,\n",
    "                    'replayUrl': f\"https://example.com/replay/{policy_name}/{eval_name}.json\",  # Placeholder\n",
    "                    'evalName': eval_name\n",
    "                }\n",
    "        \n",
    "        # Create and configure the widget\n",
    "        widget = create_heatmap_widget()\n",
    "        \n",
    "        widget.set_multi_metric_data(\n",
    "            cells=cells,\n",
    "            eval_names=eval_names,\n",
    "            policy_names=policy_names_list,\n",
    "            metrics=metrics,\n",
    "            selected_metric=metrics[0] if metrics else \"reward\"\n",
    "        )\n",
    "        \n",
    "        print(\"✅ Successfully created heatmap widget with real data!\")\n",
    "        return widget\n",
    "\n",
    "\n",
    "def get_available_policy_names(eval_db_uri: str = \"wandb://stats/navigation_db\", limit: int = 50) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get a list of available policy names from the database.\n",
    "    \n",
    "    Args:\n",
    "        eval_db_uri: URI to the evaluation database\n",
    "        limit: Maximum number of policy names to return\n",
    "        \n",
    "    Returns:\n",
    "        List of policy URI strings\n",
    "    \"\"\"\n",
    "    print(f\"🔍 Fetching available policy names from: {eval_db_uri}\")\n",
    "    \n",
    "    with EvalStatsDB.from_uri(eval_db_uri) as stats_db:\n",
    "        sql = \"\"\"\n",
    "        SELECT DISTINCT policy_key || ':v' || policy_version AS policy_uri\n",
    "        FROM policy_simulation_agent_samples\n",
    "        ORDER BY policy_uri\n",
    "        LIMIT ?\n",
    "        \"\"\"\n",
    "        df = stats_db.con.execute(sql, [limit]).fetchdf()\n",
    "        policy_names = df['policy_uri'].tolist()\n",
    "        \n",
    "    print(f\"📋 Found {len(policy_names)} policies\")\n",
    "    return policy_names\n",
    "\n",
    "\n",
    "def get_available_metrics(eval_db_uri: str = \"wandb://stats/navigation_db\", limit: int = 50) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get a list of available metrics from the database.\n",
    "    \n",
    "    Args:\n",
    "        eval_db_uri: URI to the evaluation database\n",
    "        limit: Maximum number of metrics to return\n",
    "        \n",
    "    Returns:\n",
    "        List of metric names\n",
    "    \"\"\"\n",
    "    print(f\"🔍 Fetching available metrics from: {eval_db_uri}\")\n",
    "    \n",
    "    with EvalStatsDB.from_uri(eval_db_uri) as stats_db:\n",
    "        sql = \"\"\"\n",
    "        SELECT DISTINCT metric\n",
    "        FROM policy_simulation_agent_metrics\n",
    "        ORDER BY metric\n",
    "        LIMIT ?\n",
    "        \"\"\"\n",
    "        df = stats_db.con.execute(sql, [limit]).fetchdf()\n",
    "        metric_names = df['metric'].tolist()\n",
    "        \n",
    "    print(f\"📊 Found {len(metric_names)} metrics\")\n",
    "    return metric_names\n",
    "\n",
    "\n",
    "def get_available_evaluations(eval_db_uri: str = \"wandb://stats/navigation_db\", limit: int = 100) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get a list of available evaluation names from the database.\n",
    "    \n",
    "    Args:\n",
    "        eval_db_uri: URI to the evaluation database\n",
    "        limit: Maximum number of evaluation names to return\n",
    "        \n",
    "    Returns:\n",
    "        List of evaluation names\n",
    "    \"\"\"\n",
    "    print(f\"🔍 Fetching available evaluation names from: {eval_db_uri}\")\n",
    "    \n",
    "    with EvalStatsDB.from_uri(eval_db_uri) as stats_db:\n",
    "        sql = \"\"\"\n",
    "        SELECT DISTINCT sim_env AS eval_name\n",
    "        FROM policy_simulation_agent_samples\n",
    "        ORDER BY eval_name\n",
    "        LIMIT ?\n",
    "        \"\"\"\n",
    "        df = stats_db.con.execute(sql, [limit]).fetchdf()\n",
    "        eval_names = df['eval_name'].tolist()\n",
    "        \n",
    "    print(f\"🏃 Found {len(eval_names)} evaluations\")\n",
    "    return eval_names\n",
    "\n",
    "\n",
    "print(\"🚀 Real data fetching functions loaded!\")\n",
    "print(\"📋 Available functions:\")\n",
    "print(\"   - fetch_real_heatmap_data(policy_names, metrics, eval_db_uri)\")\n",
    "print(\"   - get_available_policy_names(eval_db_uri)\")  \n",
    "print(\"   - get_available_metrics(eval_db_uri)\")\n",
    "print(\"   - get_available_evaluations(eval_db_uri)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Example: Using Real Data\n",
    "\n",
    "Now let's explore what's available in the database and create a heatmap with real data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Fetching available policy names from: wandb://stats/navigation_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact navigation_db:latest, 124.26MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4 (325.8MB/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Found 50 policies\n",
      "all_runs 40 ['alex_obs_cat_02', 'alex_obs_latent_attn_add_tokens_01', 'alex_obs_latent_fourier_01', 'alex_obs_robust_cross_01', 'alexv_lfourier8_01', 'alexv_resMLP_enc_256x64_01', 'alexv_resMLP_enc_512x32_01', 'alexv_resMLP_enc_value_512x32_01', 'alexv_resMLP_value_256x64_01', 'alexv_resMLP_value_512x32_01']\n",
      "🎯 Selecting best policies from training runs...\n",
      "🔍 Selecting best policies from 40 training runs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact navigation_db:latest, 124.26MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.3 (359.8MB/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Fetching available policy names from: wandb://stats/navigation_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact navigation_db:latest, 124.26MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4 (326.4MB/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Found 271 policies\n",
      "all_policies 271 ['alex_obs_cat_02:v18', 'alex_obs_latent_attn_add_tokens_01:v30', 'alex_obs_latent_attn_add_tokens_01:v4', 'alex_obs_latent_fourier_01:v19', 'alex_obs_robust_cross_01:v28', 'alexv_lfourier8_01:v29', 'alexv_resMLP_enc_256x64_01:v1', 'alexv_resMLP_enc_512x32_01:v12', 'alexv_resMLP_enc_value_512x32_01:v1', 'alexv_resMLP_value_256x64_01:v12']\n",
      "🏆 Best for alex_obs_cat_02: alex_obs_cat_02:v18 (score: 0.799)\n",
      "🏆 Best for alex_obs_latent_attn_add_tokens_01: alex_obs_latent_attn_add_tokens_01:v4 (score: 0.813)\n",
      "🏆 Best for alex_obs_latent_fourier_01: alex_obs_latent_fourier_01:v19 (score: 0.866)\n",
      "🏆 Best for alex_obs_robust_cross_01: alex_obs_robust_cross_01:v28 (score: 0.799)\n",
      "🏆 Best for alexv_lfourier8_01: alexv_lfourier8_01:v29 (score: 0.919)\n",
      "🏆 Best for alexv_resMLP_enc_256x64_01: alexv_resMLP_enc_256x64_01:v1 (score: 0.200)\n",
      "🏆 Best for alexv_resMLP_enc_512x32_01: alexv_resMLP_enc_512x32_01:v12 (score: 0.067)\n",
      "🏆 Best for alexv_resMLP_enc_value_512x32_01: alexv_resMLP_enc_value_512x32_01:v1 (score: 0.020)\n",
      "🏆 Best for alexv_resMLP_value_256x64_01: alexv_resMLP_value_256x64_01:v12 (score: 0.346)\n",
      "🏆 Best for alexv_resMLP_value_512x32_01: alexv_resMLP_value_512x32_01:v13 (score: 0.333)\n",
      "🏆 Best for b.daphne.test_nav_bucketedcurriculum: b.daphne.test_nav_bucketedcurriculum:v15 (score: 0.759)\n",
      "🏆 Best for b.daphne.test_nav_curriculum: b.daphne.test_nav_curriculum_full:v12 (score: 0.746)\n",
      "🏆 Best for b.daphne.test_nav_curriculum_full: b.daphne.test_nav_curriculum_full:v12 (score: 0.746)\n",
      "🏆 Best for daphne.lighter_nav: daphne.lighter_nav:v10 (score: 0.813)\n",
      "🏆 Best for daphne.navbucketedopt_devbox: daphne.navbucketedopt_devbox:v47 (score: 0.799)\n",
      "🏆 Best for daphne.navnoterrain: daphne.navnoterrain:v6 (score: 0.599)\n",
      "🏆 Best for daphne.navopt_devbox: daphne.navopt_devbox:v12 (score: 0.666)\n",
      "🏆 Best for daphne.optimize_nav: daphne.optimize_nav:v164 (score: 0.855)\n",
      "🏆 Best for daphne.optimize_nav_aws: daphne.optimize_nav_aws:v46 (score: 0.808)\n",
      "🏆 Best for daphne.optimize_nav_tokenized: daphne.optimize_nav_tokenized:v42 (score: 0.733)\n",
      "🏆 Best for daphne_nav_bucketed: daphne_nav_bucketed:v19 (score: 0.822)\n",
      "🏆 Best for daphne_navigation_bucketed: daphne_navigation_bucketed:v18 (score: 0.851)\n",
      "🏆 Best for dd.nav_optimized: dd.nav_optimized_bucket:v11 (score: 0.793)\n",
      "🏆 Best for dd.nav_optimized_bucket: dd.nav_optimized_bucket:v11 (score: 0.793)\n",
      "🏆 Best for dd.navbucketed_2: dd.navbucketed_2:v1 (score: 0.866)\n",
      "🏆 Best for dd.navbucketed_sparser: dd.navbucketed_sparser:v7 (score: 0.653)\n",
      "🏆 Best for dd_curriculum_navigation_tokenized: dd_curriculum_navigation_tokenized:v23 (score: 0.013)\n",
      "🏆 Best for dd_navigation_curriculum: dd_navigation_curriculum:v54 (score: 0.908)\n",
      "🏆 Best for m_alexv_lam_03: m_alexv_lam_03:v40 (score: 0.919)\n",
      "🏆 Best for mrazo_memory-traces_navigation_v01: mrazo_memory-traces_navigation_v01:v11 (score: 0.846)\n",
      "🏆 Best for mrazo_memory-traces_objectuse_v03: mrazo_memory-traces_objectuse_v03:v56 (score: 0.826)\n",
      "🏆 Best for relh.aws.nav.1: relh.aws.nav.1:v3 (score: 0.613)\n",
      "🏆 Best for relh.nav.dist_steps: relh.nav.dist_steps:v14 (score: 0.519)\n",
      "🏆 Best for relh.nav.main.620: relh.nav.main.620:v16 (score: 0.639)\n",
      "🏆 Best for relh.nav.new.42: relh.nav.new.42:v26 (score: 0.932)\n",
      "🏆 Best for relh.nav.new.54: relh.nav.new.54:v35 (score: 0.839)\n",
      "🏆 Best for relh.nav.new.55: relh.nav.new.55:v14 (score: 0.759)\n",
      "🏆 Best for relh.nav.new.62: relh.nav.new.62:v16 (score: 0.879)\n",
      "🏆 Best for relh.nav.new.71: relh.nav.new.71:v15 (score: 0.848)\n",
      "🏆 Best for relh.nav.new.91: relh.nav.new.91:v8 (score: 0.786)\n",
      "✅ Selected 40 policies\n",
      "🎯 Creating heatmap with real data...\n",
      "🔍 Fetching real evaluation data from: wandb://stats/navigation_db\n",
      "📋 Policy names: ['alex_obs_cat_02:v18', 'alex_obs_latent_attn_add_tokens_01:v4', 'alex_obs_latent_fourier_01:v19', 'alex_obs_robust_cross_01:v28', 'alexv_lfourier8_01:v29', 'alexv_resMLP_enc_256x64_01:v1', 'alexv_resMLP_enc_512x32_01:v12', 'alexv_resMLP_enc_value_512x32_01:v1', 'alexv_resMLP_value_256x64_01:v12', 'alexv_resMLP_value_512x32_01:v13', 'b.daphne.test_nav_bucketedcurriculum:v15', 'b.daphne.test_nav_curriculum_full:v12', 'b.daphne.test_nav_curriculum_full:v12', 'daphne.lighter_nav:v10', 'daphne.navbucketedopt_devbox:v47', 'daphne.navnoterrain:v6', 'daphne.navopt_devbox:v12', 'daphne.optimize_nav:v164', 'daphne.optimize_nav_aws:v46', 'daphne.optimize_nav_tokenized:v42', 'daphne_nav_bucketed:v19', 'daphne_navigation_bucketed:v18', 'dd.nav_optimized_bucket:v11', 'dd.nav_optimized_bucket:v11', 'dd.navbucketed_2:v1', 'dd.navbucketed_sparser:v7', 'dd_curriculum_navigation_tokenized:v23', 'dd_navigation_curriculum:v54', 'm_alexv_lam_03:v40', 'mrazo_memory-traces_navigation_v01:v11', 'mrazo_memory-traces_objectuse_v03:v56', 'relh.aws.nav.1:v3', 'relh.nav.dist_steps:v14', 'relh.nav.main.620:v16', 'relh.nav.new.42:v26', 'relh.nav.new.54:v35', 'relh.nav.new.55:v14', 'relh.nav.new.62:v16', 'relh.nav.new.71:v15', 'relh.nav.new.91:v8']\n",
      "📊 Metrics: ['reward', 'heart.get', 'ore_red.get', 'action.move.success']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact navigation_db:latest, 124.26MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4 (321.5MB/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Fetching metric: reward\n",
      "   Found 950 policy-eval combinations\n",
      "📈 Fetching metric: heart.get\n",
      "   Found 950 policy-eval combinations\n",
      "📈 Fetching metric: ore_red.get\n",
      "   Found 950 policy-eval combinations\n",
      "📈 Fetching metric: action.move.success\n",
      "   Found 950 policy-eval combinations\n",
      "🔢 Limiting to 15 policies (found 38)\n",
      "📊 Final dataset: 15 policies × 25 evaluations\n",
      "🚀 HeatmapWidget initialized successfully!\n",
      "📊 Multi-metric data set with 15 policies and 25 evaluations\n",
      "📈 Available metrics: reward, heart.get, ore_red.get, action.move.success\n",
      "📈 Selected metric: reward\n",
      "✅ Successfully created heatmap widget with real data!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6d4751705a48eb8c81112de92c38cb",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "HeatmapWidget(heatmap_data={'cells': {'relh.nav.new.42:v26': {'env/mettagrid/navigation/evals/corridors': {'me…"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's first explore what's available in the database\n",
    "# Note: This will download the database file from wandb, which may take a moment\n",
    "\n",
    "# Uncomment these lines to explore available data:\n",
    "# available_policies = get_available_policy_names(limit=10)\n",
    "# print(\"Sample policies:\", available_policies[:5])\n",
    "\n",
    "# available_metrics = get_available_metrics(limit=20) \n",
    "# print(\"Sample metrics:\", available_metrics[:10])\n",
    "\n",
    "# available_evals = get_available_evaluations(limit=20)\n",
    "# print(\"Sample evaluations:\", available_evals[:10])\n",
    "\n",
    "\n",
    "def select_best_policies_from_runs(\n",
    "    training_runs: List[str], \n",
    "    eval_db_uri: str = \"wandb://stats/navigation_db\",\n",
    "    metric: str = \"reward\",\n",
    "    selector: str = \"best\"  # \"best\" or \"latest\"\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Select the best or latest policy from each training run using the same logic as heatmap_routes.py\n",
    "    \n",
    "    Args:\n",
    "        training_runs: List of training run prefixes (e.g., [\"run1\", \"run2\"])\n",
    "        eval_db_uri: URI to the evaluation database\n",
    "        metric: Metric to use for \"best\" selection (only used if selector=\"best\")\n",
    "        selector: \"best\" (highest average score) or \"latest\" (highest epoch/version)\n",
    "        \n",
    "    Returns:\n",
    "        List of selected policy URIs\n",
    "    \"\"\"\n",
    "    print(f\"🔍 Selecting {selector} policies from {len(training_runs)} training runs...\")\n",
    "    \n",
    "    with EvalStatsDB.from_uri(eval_db_uri) as stats_db:\n",
    "        # Get all available policies\n",
    "        all_policies = get_available_policy_names(eval_db_uri, limit=1000)\n",
    "        print(\"all_policies\", len(all_policies), all_policies[:10])\n",
    "        \n",
    "        # Group policies by training run\n",
    "        run_policies = {}\n",
    "        for run in training_runs:\n",
    "            run_policies[run] = [p for p in all_policies if p.startswith(run)]\n",
    "            \n",
    "        selected_policies = []\n",
    "        \n",
    "        for run, policies in run_policies.items():\n",
    "            if not policies:\n",
    "                print(f\"⚠️  No policies found for run: {run}\")\n",
    "                continue\n",
    "                \n",
    "            if selector == \"latest\":\n",
    "                # Select latest by version/epoch number\n",
    "                def extract_version(policy_uri):\n",
    "                    if \":\" in policy_uri:\n",
    "                        try:\n",
    "                            return int(policy_uri.split(\":\")[-1].replace(\"v\", \"\"))\n",
    "                        except:\n",
    "                            return 0\n",
    "                    return 0\n",
    "                \n",
    "                best_policy = max(policies, key=extract_version)\n",
    "                selected_policies.append(best_policy)\n",
    "                print(f\"📈 Latest for {run}: {best_policy}\")\n",
    "                \n",
    "            elif selector == \"best\":\n",
    "                # Select best by average performance - same logic as heatmap_routes.py\n",
    "                policy_scores = {}\n",
    "                policy_versions = {}\n",
    "                \n",
    "                # Get evaluation data for all policies in this run\n",
    "                for policy_uri in policies:\n",
    "                    df = stats_db.metric_by_policy_eval(metric, policy_record=None)\n",
    "                    policy_data = df[df['policy_uri'] == policy_uri]\n",
    "                    \n",
    "                    if not policy_data.empty:\n",
    "                        # Calculate average score across all evaluations\n",
    "                        avg_score = policy_data['value'].mean()\n",
    "                        policy_scores[policy_uri] = avg_score\n",
    "                        \n",
    "                        # Extract version for tie-breaking\n",
    "                        try:\n",
    "                            version = int(policy_uri.split(\":\")[-1].replace(\"v\", \"\")) if \":\" in policy_uri else 0\n",
    "                        except:\n",
    "                            version = 0\n",
    "                        policy_versions[policy_uri] = version\n",
    "                \n",
    "                if policy_scores:\n",
    "                    # Find best policy (highest score, ties broken by latest version)\n",
    "                    best_policy = max(policy_scores.keys(), \n",
    "                                    key=lambda p: (policy_scores[p], policy_versions[p]))\n",
    "                    selected_policies.append(best_policy)\n",
    "                    print(f\"🏆 Best for {run}: {best_policy} (score: {policy_scores[best_policy]:.3f})\")\n",
    "                else:\n",
    "                    print(f\"⚠️  No evaluation data found for policies in run: {run}\")\n",
    "        \n",
    "        print(f\"✅ Selected {len(selected_policies)} policies\")\n",
    "        return selected_policies\n",
    "\n",
    "\n",
    "# For now, let's try with some common metrics and see what we find:\n",
    "real_heatmap = None\n",
    "try:\n",
    "    # Example: Create a heatmap with some policies and common metrics\n",
    "    # You can customize these based on what you find in your database\n",
    "    \n",
    "    # If you know specific policy names, specify them:\n",
    "    specific_policies = []  # Empty list = fetch all available policies\n",
    "    # specific_runs = [\n",
    "    #     \"daveey.arena.rnd.16x4.2\",\n",
    "    #     \"relh.skypilot.fff.j20.666\",\n",
    "    #     \"bullm.navigation.low_reward.baseline\",\n",
    "    #     \"bullm.navigation.low_reward.baseline.07-17\", \n",
    "    #     \"bullm.navigation.low_reward.baseline.07-23\",\n",
    "    #     \"relh.multigpu.fff.1\",\n",
    "    #     \"relh.skypilot.fff.j21.2\",\n",
    "    # ]\n",
    "    \n",
    "    all_policies = get_available_policy_names(eval_db_uri=\"wandb://stats/navigation_db\")\n",
    "    all_runs = list(dict.fromkeys([p.split(\":\")[0] for p in all_policies]))\n",
    "    print(\"all_runs\", len(all_runs), all_runs[:10])\n",
    "    # Select the best policies using the same logic as heatmap_routes.py\n",
    "    print(\"🎯 Selecting best policies from training runs...\")\n",
    "    specific_policies = select_best_policies_from_runs(\n",
    "        training_runs=all_runs,\n",
    "        eval_db_uri=\"wandb://stats/navigation_db\",\n",
    "        metric=\"reward\",  # Metric to use for \"best\" selection\n",
    "        selector=\"best\"   # \"best\" or \"latest\"\n",
    "    )\n",
    "    \n",
    "    # Common metrics that are likely to exist:\n",
    "    metrics_to_fetch = [\"reward\", \"heart.get\", \"ore_red.get\", \"action.move.success\"]\n",
    "    \n",
    "    # Optional: filter to specific evaluations  \n",
    "    eval_filter = None  # e.g., \"sim_env LIKE '%navigation%'\" to only include navigation tasks\n",
    "    \n",
    "    print(\"🎯 Creating heatmap with real data...\")\n",
    "    real_heatmap = fetch_real_heatmap_data(\n",
    "        policy_names=specific_policies,\n",
    "        metrics=metrics_to_fetch,\n",
    "        eval_db_uri=\"wandb://stats/navigation_db\",  # You may need to change this URI\n",
    "        eval_filter=eval_filter,\n",
    "        max_policies=15  # Limit display to keep it manageable\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error fetching real data: {e}\")\n",
    "    print(\"💡 This might happen if:\")\n",
    "    print(\"   - The database URI is incorrect\")\n",
    "    print(\"   - You're not authenticated with wandb\")\n",
    "    print(\"   - The specified metrics don't exist in the database\")\n",
    "    print(\"   - You don't have access to the database\")\n",
    "    print(\"\\n🔄 Falling back to demo data...\")\n",
    "    \n",
    "    # Fall back to demo data if real data fails\n",
    "    from experiments.notebooks.utils.heatmap_widget import create_demo_heatmap\n",
    "    demo_fallback = create_demo_heatmap()\n",
    "    demo_fallback\n",
    "    exit(1)\n",
    "\n",
    "real_heatmap"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Comparing Policy Selection Strategies\n",
    "\n",
    "Let's see the difference between \"best\" and \"latest\" policy selection:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Comparing 'best' vs 'latest' policy selection strategies:\n",
      "============================================================\n",
      "\\n📈 LATEST strategy (highest version/epoch):\n",
      "🔍 Selecting latest policies from 3 training runs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact navigation_db:latest, 124.26MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4 (279.8MB/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Fetching available policy names from: wandb://stats/navigation_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact navigation_db:latest, 124.26MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4 (280.1MB/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Found 271 policies\n",
      "all_policies ['alex_obs_cat_02:v18', 'alex_obs_latent_attn_add_tokens_01:v30', 'alex_obs_latent_attn_add_tokens_01:v4', 'alex_obs_latent_fourier_01:v19', 'alex_obs_robust_cross_01:v28', 'alexv_lfourier8_01:v29', 'alexv_resMLP_enc_256x64_01:v1', 'alexv_resMLP_enc_512x32_01:v12', 'alexv_resMLP_enc_value_512x32_01:v1', 'alexv_resMLP_value_256x64_01:v12', 'alexv_resMLP_value_512x32_01:v13', 'b.daphne.test_nav_bucketedcurriculum:v15', 'b.daphne.test_nav_curriculum:v9', 'b.daphne.test_nav_curriculum_full:v12', 'daphne.lighter_nav:v10', 'daphne.navbucketedopt_devbox:v47', 'daphne.navnoterrain:v6', 'daphne.navopt_devbox:v12', 'daphne.optimize_nav:v164', 'daphne.optimize_nav_aws:v46', 'daphne.optimize_nav_tokenized:v42', 'daphne_nav_bucketed:v19', 'daphne_navigation_bucketed:v18', 'dd.nav_optimized:v11', 'dd.nav_optimized:v31', 'dd.nav_optimized_bucket:v11', 'dd.navbucketed_2:v1', 'dd.navbucketed_sparser:v7', 'dd_curriculum_navigation_tokenized:v23', 'dd_navigation_curriculum:v54', 'm_alexv_lam_03:v40', 'm_alexv_lam_03:v57', 'mrazo_memory-traces_navigation_v01:v11', 'mrazo_memory-traces_objectuse_v03:v56', 'relh.aws.nav.1:v3', 'relh.nav.dist_steps:v14', 'relh.nav.main.620:v16', 'relh.nav.new.42:v26', 'relh.nav.new.54:v35', 'relh.nav.new.54:v7', 'relh.nav.new.55:v14', 'relh.nav.new.55:v9', 'relh.nav.new.62:v16', 'relh.nav.new.71:v15', 'relh.nav.new.71:v5', 'relh.nav.new.71:v6', 'relh.nav.new.71:v7', 'relh.nav.new.71:v8', 'relh.nav.new.91:v1', 'relh.nav.new.91:v25', 'relh.nav.new.91:v28', 'relh.nav.new.91:v34', 'relh.nav.new.91:v8', 'relh.nav.puff.620:v1', 'relh.nav.speedup.15:v42', 'relh.nav.tensortyping.1234:v4', 'relh.nav.vtrace.72:v4', 'relh.sp.nav.6:v3', 'relh.sp.nav.6:v98', 'relh.test.1:v12', 'wandb://metta-research/metta/jacke.nav_extended_multiroom_20250714_150559:v115:v5800', 'wandb://metta-research/metta/jacke.nav_extended_multiroom_20250715_112749:v154:v7750', 'wandb://metta-research/metta/jacke.nav_extended_multiroom_20250715_112755:v173:v8700', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_110454:v142:v7150', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_112035:v131:v6650', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_134110:v176:v8850', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v0:v50', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v100:v5050', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v101:v5100', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v102:v5150', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v103:v5200', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v104:v5250', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v105:v5300', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v106:v5350', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v107:v5400', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v108:v5450', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v109:v5500', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v10:v550', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v110:v5550', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v111:v5600', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v112:v5650', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v113:v5700', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v114:v5750', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v115:v5800', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v116:v5850', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v117:v5900', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v118:v5950', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v119:v6000', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v11:v600', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v120:v6050', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v121:v6100', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v122:v6150', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v123:v6200', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v124:v6250', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v125:v6300', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v126:v6350', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v127:v6400', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v128:v6450', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v129:v6500', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v12:v650', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v130:v6550', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v131:v6600', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v132:v6650', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v133:v6700', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v134:v6750', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v135:v6800', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v136:v6850', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v137:v6900', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v138:v6950', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v139:v7000', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v13:v700', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v140:v7050', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v141:v7100', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v142:v7150', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v143:v7200', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v144:v7250', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v145:v7300', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v146:v7350', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v147:v7400', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v148:v7450', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v14:v750', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v150:v7550', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v151:v7600', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v152:v7650', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v153:v7700', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v154:v7750', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v155:v7800', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v156:v7850', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v157:v7900', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v158:v7950', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v159:v8000', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v15:v800', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v160:v8050', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v161:v8100', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v162:v8150', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v163:v8200', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v164:v8250', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v165:v8300', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v16:v850', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v17:v900', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v18:v950', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v19:v1000', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v1:v100', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v20:v1050', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v21:v1100', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v22:v1150', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v23:v1200', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v24:v1250', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v25:v1300', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v26:v1350', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v27:v1400', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v28:v1450', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v29:v1500', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v2:v150', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v30:v1550', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v31:v1600', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v32:v1650', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v33:v1700', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v34:v1750', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v35:v1800', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v36:v1850', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v37:v1900', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v38:v1950', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v39:v2000', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v3:v200', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v40:v2050', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v41:v2100', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v42:v2150', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v43:v2200', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v44:v2250', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v45:v2300', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v46:v2350', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v47:v2400', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v48:v2450', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v49:v2500', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v4:v250', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v50:v2550', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v51:v2600', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v52:v2650', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v53:v2700', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v54:v2750', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v55:v2800', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v56:v2850', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v57:v2900', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v58:v2950', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v59:v3000', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v5:v300', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v60:v3050', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v61:v3100', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v62:v3150', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v63:v3200', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v64:v3250', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v65:v3300', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v66:v3350', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v67:v3400', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v68:v3450', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v69:v3500', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v6:v350', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v70:v3550', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v71:v3600', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v72:v3650', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v73:v3700', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v74:v3750', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v75:v3800', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v76:v3850', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v77:v3900', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v78:v3950', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v79:v4000', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v7:v400', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v80:v4050', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v81:v4100', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v82:v4150', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v83:v4200', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v84:v4250', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v85:v4300', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v86:v4350', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v87:v4400', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v88:v4450', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v89:v4500', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v8:v450', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v90:v4550', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v91:v4600', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v92:v4650', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v93:v4700', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v94:v4750', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v95:v4800', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v96:v4850', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v97:v4900', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v98:v4950', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v99:v5000', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v9:v500', 'wandb://metta-research/metta/jacke.sky_raster_nav_20250716_171723:v129:v6500', 'wandb://metta-research/metta/jacke.sky_raster_standard_20250716_110514:v139:v7000', 'wandb://metta-research/metta/jacke.sky_raster_standard_20250716_112030:v137:v6900', 'wandb://metta-research/metta/jacke.sky_raster_standard_20250716_134153:v170:v8550', 'wandb://metta-research/metta/jacke.sky_raster_standard_20250716_145423:v143:v7200', 'wandb://metta-research/metta/jacke.sky_spiral_nav_20250716_171713:v144:v7250', 'wandb://metta-research/metta/jacke.sky_spiral_raster_only_20250716_112801:v152:v7650', 'wandb://metta-research/metta/jacke.sky_spiral_raster_only_20250716_112805:v145:v7300', 'wandb://metta-research/metta/jacke.sky_spiral_raster_only_20250716_134139:v199:v10000', 'wandb://metta-research/metta/jacke.sky_spiral_raster_only_20250716_145434:v142:v7150', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_110438:v139:v7000', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_112045:v137:v6900', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v10:v550', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v11:v600', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v12:v650', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v13:v700', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v149:v7500', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v14:v750', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v15:v800', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v16:v850', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v19:v1000', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v1:v100', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v22:v1150', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v24:v1250', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v27:v1400', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v28:v1450', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v2:v150', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v31:v1600', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v32:v1650', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v34:v1750', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v36:v1850', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v38:v1950', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v43:v2200', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v4:v250', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v6:v350', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v7:v400', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v8:v450', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_145416:v155:v7800', 'wandb://metta-research/metta/relh.nav.fff.1:v381:v19074', 'wandb://metta-research/metta/relh.skypilot.fff.j21.2:v94:v4750']\n",
      "⚠️  No policies found for run: daveey.arena.rnd.16x4.2\n",
      "⚠️  No policies found for run: bullm.navigation.low_reward.baseline\n",
      "⚠️  No policies found for run: relh.skypilot.fff.j20.666\n",
      "✅ Selected 0 policies\n",
      "\\n🏆 BEST strategy (highest average reward):\n",
      "🔍 Selecting best policies from 3 training runs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact navigation_db:latest, 124.26MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4 (316.7MB/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Fetching available policy names from: wandb://stats/navigation_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact navigation_db:latest, 124.26MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.5 (240.7MB/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Found 271 policies\n",
      "all_policies ['alex_obs_cat_02:v18', 'alex_obs_latent_attn_add_tokens_01:v30', 'alex_obs_latent_attn_add_tokens_01:v4', 'alex_obs_latent_fourier_01:v19', 'alex_obs_robust_cross_01:v28', 'alexv_lfourier8_01:v29', 'alexv_resMLP_enc_256x64_01:v1', 'alexv_resMLP_enc_512x32_01:v12', 'alexv_resMLP_enc_value_512x32_01:v1', 'alexv_resMLP_value_256x64_01:v12', 'alexv_resMLP_value_512x32_01:v13', 'b.daphne.test_nav_bucketedcurriculum:v15', 'b.daphne.test_nav_curriculum:v9', 'b.daphne.test_nav_curriculum_full:v12', 'daphne.lighter_nav:v10', 'daphne.navbucketedopt_devbox:v47', 'daphne.navnoterrain:v6', 'daphne.navopt_devbox:v12', 'daphne.optimize_nav:v164', 'daphne.optimize_nav_aws:v46', 'daphne.optimize_nav_tokenized:v42', 'daphne_nav_bucketed:v19', 'daphne_navigation_bucketed:v18', 'dd.nav_optimized:v11', 'dd.nav_optimized:v31', 'dd.nav_optimized_bucket:v11', 'dd.navbucketed_2:v1', 'dd.navbucketed_sparser:v7', 'dd_curriculum_navigation_tokenized:v23', 'dd_navigation_curriculum:v54', 'm_alexv_lam_03:v40', 'm_alexv_lam_03:v57', 'mrazo_memory-traces_navigation_v01:v11', 'mrazo_memory-traces_objectuse_v03:v56', 'relh.aws.nav.1:v3', 'relh.nav.dist_steps:v14', 'relh.nav.main.620:v16', 'relh.nav.new.42:v26', 'relh.nav.new.54:v35', 'relh.nav.new.54:v7', 'relh.nav.new.55:v14', 'relh.nav.new.55:v9', 'relh.nav.new.62:v16', 'relh.nav.new.71:v15', 'relh.nav.new.71:v5', 'relh.nav.new.71:v6', 'relh.nav.new.71:v7', 'relh.nav.new.71:v8', 'relh.nav.new.91:v1', 'relh.nav.new.91:v25', 'relh.nav.new.91:v28', 'relh.nav.new.91:v34', 'relh.nav.new.91:v8', 'relh.nav.puff.620:v1', 'relh.nav.speedup.15:v42', 'relh.nav.tensortyping.1234:v4', 'relh.nav.vtrace.72:v4', 'relh.sp.nav.6:v3', 'relh.sp.nav.6:v98', 'relh.test.1:v12', 'wandb://metta-research/metta/jacke.nav_extended_multiroom_20250714_150559:v115:v5800', 'wandb://metta-research/metta/jacke.nav_extended_multiroom_20250715_112749:v154:v7750', 'wandb://metta-research/metta/jacke.nav_extended_multiroom_20250715_112755:v173:v8700', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_110454:v142:v7150', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_112035:v131:v6650', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_134110:v176:v8850', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v0:v50', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v100:v5050', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v101:v5100', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v102:v5150', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v103:v5200', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v104:v5250', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v105:v5300', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v106:v5350', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v107:v5400', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v108:v5450', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v109:v5500', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v10:v550', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v110:v5550', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v111:v5600', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v112:v5650', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v113:v5700', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v114:v5750', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v115:v5800', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v116:v5850', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v117:v5900', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v118:v5950', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v119:v6000', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v11:v600', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v120:v6050', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v121:v6100', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v122:v6150', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v123:v6200', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v124:v6250', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v125:v6300', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v126:v6350', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v127:v6400', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v128:v6450', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v129:v6500', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v12:v650', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v130:v6550', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v131:v6600', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v132:v6650', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v133:v6700', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v134:v6750', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v135:v6800', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v136:v6850', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v137:v6900', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v138:v6950', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v139:v7000', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v13:v700', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v140:v7050', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v141:v7100', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v142:v7150', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v143:v7200', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v144:v7250', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v145:v7300', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v146:v7350', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v147:v7400', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v148:v7450', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v14:v750', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v150:v7550', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v151:v7600', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v152:v7650', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v153:v7700', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v154:v7750', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v155:v7800', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v156:v7850', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v157:v7900', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v158:v7950', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v159:v8000', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v15:v800', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v160:v8050', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v161:v8100', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v162:v8150', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v163:v8200', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v164:v8250', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v165:v8300', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v16:v850', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v17:v900', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v18:v950', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v19:v1000', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v1:v100', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v20:v1050', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v21:v1100', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v22:v1150', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v23:v1200', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v24:v1250', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v25:v1300', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v26:v1350', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v27:v1400', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v28:v1450', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v29:v1500', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v2:v150', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v30:v1550', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v31:v1600', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v32:v1650', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v33:v1700', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v34:v1750', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v35:v1800', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v36:v1850', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v37:v1900', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v38:v1950', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v39:v2000', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v3:v200', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v40:v2050', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v41:v2100', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v42:v2150', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v43:v2200', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v44:v2250', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v45:v2300', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v46:v2350', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v47:v2400', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v48:v2450', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v49:v2500', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v4:v250', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v50:v2550', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v51:v2600', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v52:v2650', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v53:v2700', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v54:v2750', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v55:v2800', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v56:v2850', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v57:v2900', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v58:v2950', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v59:v3000', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v5:v300', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v60:v3050', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v61:v3100', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v62:v3150', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v63:v3200', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v64:v3250', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v65:v3300', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v66:v3350', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v67:v3400', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v68:v3450', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v69:v3500', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v6:v350', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v70:v3550', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v71:v3600', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v72:v3650', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v73:v3700', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v74:v3750', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v75:v3800', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v76:v3850', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v77:v3900', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v78:v3950', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v79:v4000', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v7:v400', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v80:v4050', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v81:v4100', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v82:v4150', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v83:v4200', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v84:v4250', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v85:v4300', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v86:v4350', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v87:v4400', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v88:v4450', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v89:v4500', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v8:v450', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v90:v4550', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v91:v4600', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v92:v4650', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v93:v4700', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v94:v4750', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v95:v4800', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v96:v4850', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v97:v4900', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v98:v4950', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v99:v5000', 'wandb://metta-research/metta/jacke.sky_comprehensive_20250716_145441:v9:v500', 'wandb://metta-research/metta/jacke.sky_raster_nav_20250716_171723:v129:v6500', 'wandb://metta-research/metta/jacke.sky_raster_standard_20250716_110514:v139:v7000', 'wandb://metta-research/metta/jacke.sky_raster_standard_20250716_112030:v137:v6900', 'wandb://metta-research/metta/jacke.sky_raster_standard_20250716_134153:v170:v8550', 'wandb://metta-research/metta/jacke.sky_raster_standard_20250716_145423:v143:v7200', 'wandb://metta-research/metta/jacke.sky_spiral_nav_20250716_171713:v144:v7250', 'wandb://metta-research/metta/jacke.sky_spiral_raster_only_20250716_112801:v152:v7650', 'wandb://metta-research/metta/jacke.sky_spiral_raster_only_20250716_112805:v145:v7300', 'wandb://metta-research/metta/jacke.sky_spiral_raster_only_20250716_134139:v199:v10000', 'wandb://metta-research/metta/jacke.sky_spiral_raster_only_20250716_145434:v142:v7150', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_110438:v139:v7000', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_112045:v137:v6900', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v10:v550', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v11:v600', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v12:v650', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v13:v700', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v149:v7500', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v14:v750', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v15:v800', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v16:v850', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v19:v1000', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v1:v100', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v22:v1150', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v24:v1250', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v27:v1400', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v28:v1450', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v2:v150', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v31:v1600', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v32:v1650', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v34:v1750', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v36:v1850', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v38:v1950', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v43:v2200', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v4:v250', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v6:v350', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v7:v400', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_134205:v8:v450', 'wandb://metta-research/metta/jacke.sky_spiral_traditional_20250716_145416:v155:v7800', 'wandb://metta-research/metta/relh.nav.fff.1:v381:v19074', 'wandb://metta-research/metta/relh.skypilot.fff.j21.2:v94:v4750']\n",
      "⚠️  No policies found for run: daveey.arena.rnd.16x4.2\n",
      "⚠️  No policies found for run: bullm.navigation.low_reward.baseline\n",
      "⚠️  No policies found for run: relh.skypilot.fff.j20.666\n",
      "✅ Selected 0 policies\n",
      "\\n📊 COMPARISON:\n",
      "Run                                 Latest                    Best                     \n",
      "-------------------------------------------------------------------------------------\n",
      "daveey.arena.rnd.16x4.2             None                      None                      ✅\n",
      "bullm.navigation.low_reward.baseline None                      None                      ✅\n",
      "relh.skypilot.fff.j20.666           None                      None                      ✅\n",
      "\\n💡 Key differences:\n",
      "   - 'Latest' picks the most recent version (highest epoch/version number)\n",
      "   - 'Best' picks the version with highest average performance across evaluations\n",
      "   - They may differ when a later version performs worse than an earlier one\n"
     ]
    }
   ],
   "source": [
    "# Compare \"best\" vs \"latest\" policy selection for the same runs\n",
    "sample_runs = [\n",
    "    \"daveey.arena.rnd.16x4.2\",\n",
    "    \"bullm.navigation.low_reward.baseline\",\n",
    "    \"relh.skypilot.fff.j20.666\"\n",
    "]\n",
    "\n",
    "print(\"🔍 Comparing 'best' vs 'latest' policy selection strategies:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Select using \"latest\" strategy\n",
    "    print(\"\\\\n📈 LATEST strategy (highest version/epoch):\")\n",
    "    latest_policies = select_best_policies_from_runs(\n",
    "        training_runs=sample_runs,\n",
    "        selector=\"latest\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\\\n🏆 BEST strategy (highest average reward):\")\n",
    "    best_policies = select_best_policies_from_runs(\n",
    "        training_runs=sample_runs, \n",
    "        metric=\"reward\",\n",
    "        selector=\"best\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\\\n📊 COMPARISON:\")\n",
    "    print(f\"{'Run':<35} {'Latest':<25} {'Best':<25}\")\n",
    "    print(\"-\" * 85)\n",
    "    \n",
    "    # Create lookup dictionaries\n",
    "    latest_lookup = {}\n",
    "    best_lookup = {}\n",
    "    \n",
    "    for policy in latest_policies:\n",
    "        for run in sample_runs:\n",
    "            if policy.startswith(run):\n",
    "                latest_lookup[run] = policy\n",
    "                break\n",
    "                \n",
    "    for policy in best_policies:\n",
    "        for run in sample_runs:\n",
    "            if policy.startswith(run):\n",
    "                best_lookup[run] = policy\n",
    "                break\n",
    "    \n",
    "    for run in sample_runs:\n",
    "        latest = latest_lookup.get(run, \"None\")\n",
    "        best = best_lookup.get(run, \"None\")\n",
    "        same = \"✅\" if latest == best else \"❌\"\n",
    "        print(f\"{run:<35} {latest:<25} {best:<25} {same}\")\n",
    "        \n",
    "    print(\"\\\\n💡 Key differences:\")\n",
    "    print(\"   - 'Latest' picks the most recent version (highest epoch/version number)\")\n",
    "    print(\"   - 'Best' picks the version with highest average performance across evaluations\")\n",
    "    print(\"   - They may differ when a later version performs worse than an earlier one\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error comparing strategies: {e}\")\n",
    "    print(\"💡 Make sure you have access to the evaluation database\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Advanced Usage: Custom Training Runs and Metrics\n",
    "\n",
    "Here's how to create a heatmap with your own training runs and metrics using the smart policy selection:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create a custom heatmap with specific training runs and metrics\n",
    "\n",
    "# Option 1: Use training run names (recommended - uses smart selection)\n",
    "my_training_runs = [\n",
    "    # Add your training run names here, for example:\n",
    "    # \"my_experiment_batch_1\",\n",
    "    # \"my_experiment_batch_2\", \n",
    "    # \"baseline_run_v1\"\n",
    "]\n",
    "\n",
    "# Option 2: Use exact policy URIs (if you know exactly which ones you want)\n",
    "my_specific_policies = [\n",
    "    # Add exact policy URIs here, for example:\n",
    "    # \"my_policy_name:v123\",\n",
    "    # \"baseline_experiment:v456\",\n",
    "    # \"new_approach:v789\"\n",
    "]\n",
    "\n",
    "# Step 2: Define metrics you want to compare\n",
    "my_metrics = [\n",
    "    \"reward\",\n",
    "    \"heart.get\",           # Example game-specific metric\n",
    "    \"action.move.success\", # Example action success rate\n",
    "    # Add more metrics as needed\n",
    "]\n",
    "\n",
    "# Step 3: Optional - filter to specific evaluations\n",
    "# eval_filter = \"sim_env LIKE '%maze%'\"  # Only maze environments\n",
    "# eval_filter = \"sim_env LIKE '%combat%'\"  # Only combat environments  \n",
    "eval_filter = None  # No filter - include all evaluations\n",
    "\n",
    "# Step 4: Create the heatmap\n",
    "if my_training_runs:  # Use smart policy selection from training runs\n",
    "    print(\"🎯 Creating custom heatmap with best policies from training runs...\")\n",
    "    \n",
    "    # Select best policies from training runs\n",
    "    selected_policies = select_best_policies_from_runs(\n",
    "        training_runs=my_training_runs,\n",
    "        eval_db_uri=\"wandb://stats/navigation_db\",\n",
    "        metric=\"reward\",  # Metric to optimize for when selecting \"best\"\n",
    "        selector=\"best\"   # or \"latest\"\n",
    "    )\n",
    "    \n",
    "    custom_heatmap = fetch_real_heatmap_data(\n",
    "        policy_names=selected_policies,\n",
    "        metrics=my_metrics,\n",
    "        eval_db_uri=\"wandb://stats/navigation_db\",\n",
    "        eval_filter=eval_filter,\n",
    "        max_policies=20\n",
    "    )\n",
    "    \n",
    "    print(\"📊 Custom heatmap created! Try:\")\n",
    "    print(\"   - Hovering over cells to see detailed values\")\n",
    "    print(\"   - Changing metrics with: custom_heatmap.update_metric('heart.get')\")\n",
    "    print(\"   - Adjusting policies shown: custom_heatmap.set_num_policies(15)\")\n",
    "    \n",
    "    custom_heatmap\n",
    "    \n",
    "elif my_specific_policies:  # Use exact policy URIs\n",
    "    print(\"🎯 Creating custom heatmap with specific policies...\")\n",
    "    custom_heatmap = fetch_real_heatmap_data(\n",
    "        policy_names=my_specific_policies,\n",
    "        metrics=my_metrics,\n",
    "        eval_db_uri=\"wandb://stats/navigation_db\",\n",
    "        eval_filter=eval_filter,\n",
    "        max_policies=20\n",
    "    )\n",
    "    \n",
    "    custom_heatmap\n",
    "    \n",
    "else:\n",
    "    print(\"📝 To use this example:\")\n",
    "    print(\"\\\\n🚀 RECOMMENDED: Use training run names (Option 1)\")\n",
    "    print(\"1. Add your training run names to 'my_training_runs' list above\")\n",
    "    print(\"2. The system will automatically select the best policy from each run\")\n",
    "    print(\"3. Customize the 'my_metrics' list with metrics you're interested in\")\n",
    "    print(\"4. Run this cell again\")\n",
    "    print(\"\\\\n💡 Example training run names:\")\n",
    "    print(\"   - 'my_experiment_batch_1'\")\n",
    "    print(\"   - 'baseline_run_v2'\")\n",
    "    print(\"   - 'new_approach_test'\")\n",
    "    print(\"\\\\n⚙️  ALTERNATIVE: Use exact policy URIs (Option 2)\")\n",
    "    print(\"1. Add exact policy URIs to 'my_specific_policies' list\")\n",
    "    print(\"2. Example: 'my_policy_name:v123', 'baseline:v456'\")\n",
    "    print(\"\\\\n🔍 TIP: Run the exploration code in previous cells to see available options\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Available Evaluation Database URIs\n",
    "\n",
    "You can choose from several different evaluation databases depending on what type of data you want to analyze:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🗃️ AVAILABLE EVALUATION DATABASES\n",
    "\n",
    "# Domain-specific databases (most commonly used)\n",
    "available_databases = {\n",
    "    \"navigation_db\": \"wandb://stats/navigation_db\",      # Navigation tasks\n",
    "    \"memory_db\": \"wandb://stats/memory_db\",              # Memory tasks  \n",
    "    \"objectuse_db\": \"wandb://stats/objectuse_db\",        # Object use tasks\n",
    "    \"nav_sequence_db\": \"wandb://stats/nav_sequence_db\",  # Navigation sequence tasks\n",
    "    # User-specific databases\n",
    "    \"jack_db\": \"wandb://stats/jack_db\",                  # Jack's personal database\n",
    "}\n",
    "\n",
    "print(\"🗄️  Available Evaluation Databases:\")\n",
    "print(\"=\" * 50)\n",
    "for name, uri in available_databases.items():\n",
    "    print(f\"📊 {name:<20} → {uri}\")\n",
    "\n",
    "print(\"\\n💡 Usage examples:\")\n",
    "print(\"   # For navigation analysis:\")\n",
    "print(\"   fetch_real_heatmap_data(..., eval_db_uri='wandb://stats/navigation_db')\")\n",
    "print(\"   # For memory analysis:\")  \n",
    "print(\"   fetch_real_heatmap_data(..., eval_db_uri='wandb://stats/memory_db')\")\n",
    "\n",
    "print(\"\\n🔍 You can also use:\")\n",
    "print(\"   • Local files: './path/to/my_stats.db'\")\n",
    "print(\"   • S3 buckets: 's3://bucket/path/stats.db'\")\n",
    "\n",
    "# Quick function to check what's in each database\n",
    "def explore_database(db_name: str, db_uri: str, limit: int = 5):\n",
    "    \"\"\"Quickly explore what's available in a database\"\"\"\n",
    "    print(f\"\\n🔍 Exploring {db_name} ({db_uri}):\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Get a small sample of data\n",
    "        policies = get_available_policy_names(eval_db_uri=db_uri, limit=limit)\n",
    "        metrics = get_available_metrics(eval_db_uri=db_uri, limit=10)\n",
    "        evals = get_available_evaluations(eval_db_uri=db_uri, limit=10)\n",
    "        \n",
    "        print(f\"📋 Sample policies ({len(policies)}): {policies[:3]}...\")\n",
    "        print(f\"📊 Sample metrics ({len(metrics)}): {metrics[:5]}...\")  \n",
    "        print(f\"🏃 Sample evaluations ({len(evals)}): {evals[:5]}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error accessing {db_name}: {e}\")\n",
    "        if \"wandb\" in str(e).lower():\n",
    "            print(\"💡 You may need to authenticate with wandb or check permissions\")\n",
    "\n",
    "# Uncomment to explore different databases:\n",
    "# explore_database(\"Navigation DB\", \"wandb://stats/navigation_db\")\n",
    "# explore_database(\"Memory DB\", \"wandb://stats/memory_db\")  \n",
    "# explore_database(\"Object Use DB\", \"wandb://stats/objectuse_db\")\n",
    "\n",
    "print(\"\\n📝 To explore a database, uncomment the explore_database() calls above!\")\n",
    "print(\"\\n🚀 Quick start: Most users will want 'wandb://stats/navigation_db'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 Example: Comparing Policies Across Different Task Categories\n",
    "\n",
    "# Here's how to create heatmaps from different evaluation databases:\n",
    "\n",
    "# Example 1: Navigation tasks\n",
    "print(\"🧭 Creating navigation heatmap...\")\n",
    "try:\n",
    "    navigation_runs = [\"daveey.arena.rnd.16x4.2\", \"bullm.navigation.low_reward.baseline\"]\n",
    "    \n",
    "    nav_policies = select_best_policies_from_runs(\n",
    "        training_runs=navigation_runs,\n",
    "        eval_db_uri=\"wandb://stats/navigation_db\",  # Navigation database\n",
    "        selector=\"best\",\n",
    "        metric=\"reward\"\n",
    "    )\n",
    "    \n",
    "    nav_heatmap = fetch_real_heatmap_data(\n",
    "        policy_names=nav_policies,\n",
    "        metrics=[\"reward\", \"heart.get\", \"action.move.success\"],\n",
    "        eval_db_uri=\"wandb://stats/navigation_db\",\n",
    "        max_policies=5\n",
    "    )\n",
    "    \n",
    "    print(\"✅ Navigation heatmap created successfully!\")\n",
    "    # nav_heatmap  # Uncomment to display\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Navigation heatmap failed: {e}\")\n",
    "\n",
    "# Example 2: Memory tasks (if available)\n",
    "print(\"\\n🧠 Memory tasks would use:\")\n",
    "print(\"   eval_db_uri='wandb://stats/memory_db'\")\n",
    "print(\"   # Likely different metrics like memory.recall, sequence.accuracy, etc.\")\n",
    "\n",
    "# Example 3: Object use tasks (if available)  \n",
    "print(\"\\n🔧 Object use tasks would use:\")\n",
    "print(\"   eval_db_uri='wandb://stats/objectuse_db'\")\n",
    "print(\"   # Likely different metrics like tool.use.success, manipulation.accuracy, etc.\")\n",
    "\n",
    "print(\"\\n💡 Pro tip: Each database specializes in different task types:\")\n",
    "print(\"   🧭 navigation_db    → spatial reasoning, pathfinding\")\n",
    "print(\"   🧠 memory_db        → recall, sequence learning\") \n",
    "print(\"   🔧 objectuse_db     → manipulation, tool use\")\n",
    "print(\"   📚 nav_sequence_db  → sequential navigation tasks\")\n",
    "\n",
    "print(\"\\n📊 To switch databases, just change the eval_db_uri parameter!\")\n",
    "print(\"   Example: eval_db_uri='wandb://stats/memory_db'\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Advanced Usage: Custom Policies and Metrics\n",
    "\n",
    "Here's how to create a heatmap with specific policies and metrics of your choice:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create a custom heatmap with specific policies and metrics\n",
    "\n",
    "# Step 1: Define your policies of interest\n",
    "my_policies = [\n",
    "    # Add your policy names here, for example:\n",
    "    # \"my_experiment_1:v100\",\n",
    "    # \"my_experiment_2:v200\", \n",
    "    # \"baseline_policy:v50\"\n",
    "]\n",
    "\n",
    "# Step 2: Define metrics you want to compare\n",
    "my_metrics = [\n",
    "    \"reward\",\n",
    "    \"heart.get\",           # Example game-specific metric\n",
    "    \"action.move.success\", # Example action success rate\n",
    "    # Add more metrics as needed\n",
    "]\n",
    "\n",
    "# Step 3: Optional - filter to specific evaluations\n",
    "# eval_filter = \"sim_env LIKE '%maze%'\"  # Only maze environments\n",
    "# eval_filter = \"sim_env LIKE '%combat%'\"  # Only combat environments  \n",
    "eval_filter = None  # No filter - include all evaluations\n",
    "\n",
    "# Step 4: Create the heatmap\n",
    "if my_policies:  # Only run if you've specified policies\n",
    "    print(\"🎯 Creating custom heatmap...\")\n",
    "    custom_heatmap = fetch_real_heatmap_data(\n",
    "        policy_names=my_policies,\n",
    "        metrics=my_metrics,\n",
    "        eval_db_uri=\"wandb://stats/navigation_db\",  # Adjust as needed\n",
    "        eval_filter=eval_filter,\n",
    "        max_policies=20\n",
    "    )\n",
    "    \n",
    "    # Step 5: Display and interact\n",
    "    print(\"📊 Custom heatmap created! Try:\")\n",
    "    print(\"   - Hovering over cells to see detailed values\")\n",
    "    print(\"   - Changing metrics with: custom_heatmap.update_metric('heart.get')\")\n",
    "    print(\"   - Adjusting policies shown: custom_heatmap.set_num_policies(15)\")\n",
    "    \n",
    "    custom_heatmap\n",
    "else:\n",
    "    print(\"📝 To use this example:\")\n",
    "    print(\"1. Uncomment the exploration code in the previous cell to see available policies\")\n",
    "    print(\"2. Add your policy names to the 'my_policies' list above\") \n",
    "    print(\"3. Customize the 'my_metrics' list with metrics you're interested in\")\n",
    "    print(\"4. Run this cell again\")\n",
    "    print(\"\\n💡 Example policy names might look like:\")\n",
    "    print(\"   - 'my_policy_name:v123'\")\n",
    "    print(\"   - 'baseline_experiment:v456'\") \n",
    "    print(\"   - 'new_approach:v789'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "from experiments.notebooks.utils.heatmap_widget import HeatmapWidget, create_demo_heatmap, create_heatmap_widget\n",
    "\n",
    "# Create a demo heatmap with sample data\n",
    "demo_widget = create_demo_heatmap()\n",
    "display(demo_widget)\n",
    "\n",
    "w = widgets.Button(description=\"Click me\", style=dict(width=\"200px\", height=\"50px\"))\n",
    "display(w)\n",
    "# Display the widget\n",
    "print(demo_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Try interacting with the heatmap above:**\n",
    "- Hover over cells to see detailed information\n",
    "- Click on a row's left policy title label to \"open\" that policy's Wandb URL in a new tab\n",
    "- Adjust the \"Policies to show\" input to change how many policies are displayed\n",
    "- Click on policy names to open WandB links (in demo, these won't work)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Example 2: Creating Your Own Heatmap Data\n",
    "\n",
    "Here's how to create a heatmap with your own data:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Example 4: Multiple Metrics with Working selectedMetric\n",
    "\n",
    "Now let's see the `selectedMetric` functionality working properly! This example shows a heatmap where changing the metric actually changes the displayed values:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multi-metric heatmap widget\n",
    "from experiments.notebooks.utils.heatmap_widget import create_multi_metric_demo\n",
    "\n",
    "multi_metric_widget = create_multi_metric_demo()\n",
    "\n",
    "# Display the widget\n",
    "multi_metric_widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try changing the metric to see the values actually change!\n",
    "print(\"🔄 Changing metric to 'episode_length'...\")\n",
    "multi_metric_widget.update_metric('episode_length')\n",
    "\n",
    "# NOTE: Notice how the values in the heatmap widget change as you switch\n",
    "# metrics?  Do not display the widget again and try to change that. That ends up\n",
    "# creating a seperate copy of the widget in a new output cell.  Instead just\n",
    "# reference the one you originally rendered, call its functions, and watch it\n",
    "# change in its Juypter notebook cell. Like we just did. Let's do it again in\n",
    "# the next cell too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One more time. Run this cell then scroll back up again to see the change.\n",
    "print(\"\\n🔄 Changing metric to 'success_rate'...\")\n",
    "multi_metric_widget.update_metric('success_rate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last one. Scroll up again to see the change.\n",
    "print(\"\\n🔄 Changing metric to 'success_rate'...\")\n",
    "multi_metric_widget.update_metric('success_rate')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom metrics\n",
    "\n",
    "We can really define our cells to have any metric data we want. This is useful because we plan to have all sorts of metrics. Let's look at an example of using any old metric we decide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new heatmap widget\n",
    "custom_widget = create_heatmap_widget()\n",
    "\n",
    "# Define your data structure\n",
    "# This should match the format expected by the observatory dashboard\n",
    "cells_data = {\n",
    "    'my_policy_v1': {\n",
    "        'task_a/level1': {\n",
    "            'metrics': {\n",
    "                'custom_score': 85.2,\n",
    "            },\n",
    "            'replayUrl': 'https://example.com/replay1.json', \n",
    "            'evalName': 'task_a/level1'\n",
    "        },\n",
    "        'task_a/level2': {\n",
    "            'metrics': {\n",
    "                'custom_score': 87.5,\n",
    "            },\n",
    "            'replayUrl': 'https://example.com/replay2.json', \n",
    "            'evalName': 'task_a/level2'\n",
    "        },\n",
    "        'task_b/challenge1': {\n",
    "            'metrics': {\n",
    "                'custom_score': 92.5,\n",
    "            },\n",
    "            'replayUrl': 'https://example.com/replay3.json', \n",
    "            'evalName': 'task_b/challenge1'\n",
    "        },\n",
    "    },\n",
    "    'my_policy_v2': {\n",
    "        'task_a/level1': {\n",
    "            'metrics': {\n",
    "                'custom_score': 22.5,\n",
    "            },\n",
    "            'replayUrl': 'https://example.com/replay4.json', \n",
    "            'evalName': 'task_a/level1'\n",
    "        },\n",
    "        'task_a/level2': {\n",
    "            'metrics': {\n",
    "                'custom_score': 42.5,\n",
    "            },\n",
    "            'replayUrl': 'https://example.com/replay5.json', \n",
    "            'evalName': 'task_a/level2'\n",
    "        },\n",
    "        'task_b/challenge1': {\n",
    "            'metrics': {\n",
    "                'custom_score': 62.5,\n",
    "            },\n",
    "            'replayUrl': 'https://example.com/replay6.json', \n",
    "            'evalName': 'task_b/challenge1'\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "eval_names = ['task_a/level1', 'task_a/level2', 'task_b/challenge1']\n",
    "policy_names = ['my_policy_v1', 'my_policy_v2']\n",
    "policy_averages = {\n",
    "    'my_policy_v1': 91.6,\n",
    "    'my_policy_v2': 89.6,\n",
    "}\n",
    "\n",
    "# Set the data\n",
    "custom_widget.set_data(\n",
    "    cells=cells_data,\n",
    "    eval_names=eval_names,\n",
    "    policy_names=policy_names,\n",
    "    policy_average_scores=policy_averages,\n",
    "    selected_metric=\"custom_score\"\n",
    ")\n",
    "\n",
    "# Display the widget\n",
    "custom_widget\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Example 3: Adding Callbacks for Interactivity\n",
    "\n",
    "You can add Python callbacks to respond to user interactions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: these callbacks do not work with print(), and that's really just how\n",
    "# Jupyter widgets work.  Once the Jupyter python cell finishes running and\n",
    "# outputs a widget, that widget won't be able to affect the output of the cell\n",
    "# anymore. The only way to to print() from a python widget callback is to write\n",
    "# to a file (or use a thread maybe). I give an example below.\n",
    "\n",
    "# Create another widget for callback demonstration\n",
    "callback_widget = create_heatmap_widget()\n",
    "\n",
    "# Set up the same data as before\n",
    "callback_widget.set_data(\n",
    "    cells=cells_data,\n",
    "    eval_names=eval_names,\n",
    "    policy_names=policy_names,\n",
    "    policy_average_scores=policy_averages,\n",
    "    selected_metric=\"Interactive Score (%)\"\n",
    ")\n",
    "\n",
    "# Define callback functions\n",
    "def handle_cell_selection(cell_info):\n",
    "    \"\"\"Called when user hovers over a cell (not 'overall' column).\"\"\"\n",
    "    with open(\"output_cell_selection.txt\", \"w\") as f:\n",
    "        f.write(f\"📍 Cell selected: {cell_info['policyUri']} on evaluation '{cell_info['evalName']}'\")\n",
    "\n",
    "def handle_replay_opened(replay_info):\n",
    "    \"\"\"Called when user clicks to open a replay.\"\"\"\n",
    "    with open(\"output_replay_opened.txt\", \"w\") as f:\n",
    "        f.write(f\"🎬 Replay opened: {replay_info['replayUrl']}\")\n",
    "        f.write(f\"   Policy: {replay_info['policyUri']}\")\n",
    "        f.write(f\"   Evaluation: {replay_info['evalName']}\")\n",
    "\n",
    "# Register the callbacks\n",
    "callback_widget.on_cell_selected(handle_cell_selection)\n",
    "callback_widget.on_replay_opened(handle_replay_opened)\n",
    "\n",
    "# Display the widget\n",
    "callback_widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the files created by the callbacks in the previous cell, if they exist\n",
    "import os\n",
    "\n",
    "for fname in [\"output_cell_selection.txt\", \"output_replay_opened.txt\"]:\n",
    "    try:\n",
    "        with open(fname, \"r\") as f:\n",
    "            print(f.read())\n",
    "        os.remove(fname)\n",
    "        print(f\"File {fname} deleted\")\n",
    "    except FileNotFoundError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Try interacting with the heatmap above to see the callback messages printed to\n",
    "*output files!**\n",
    "\n",
    "## Data Format Reference\n",
    "\n",
    "The heatmap widget expects data in a specific format that matches the\n",
    "observatory dashboard:\n",
    "\n",
    "```python\n",
    "cells = {\n",
    "    'policy_name': {\n",
    "        'eval_name': {\n",
    "            'metrics': {\n",
    "                'reward': 50,\n",
    "                'heart.get': 98,\n",
    "                'action.move.success': 5,\n",
    "                'ore_red.get': 24.2,\n",
    "                # ... more metrics\n",
    "            },\n",
    "            'replayUrl': str,         # URL to replay file\n",
    "            'evalName': str,          # Should match the key\n",
    "        },\n",
    "        # ... more evaluations\n",
    "    },\n",
    "    # ... more policies\n",
    "}\n",
    "```\n",
    "\n",
    "**Important notes:**\n",
    "- Evaluation names with \"/\" will be grouped by category (the part before \"/\")\n",
    "- The heatmap shows policies sorted by average score (worst to best, bottom to top)\n",
    "- Policy names that contain \":v\" will have WandB URLs generated automatically\n",
    "- Replay URLs should be accessible URLs or file paths\n",
    "\n",
    "This widget provides the same interactive functionality as the observatory dashboard but in a python environment, making it perfect for exploratory analysis and sharing results via Jupyter notebooks!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
