#!/usr/bin/env python3
"""Learning progress curriculum scenario tests.

Tests for Learning Progress curriculum behavior under controlled conditions:
1. Mixed impossible and learnable tasks -> should weight learnable evenly, ignore impossible
2. Threshold dependency -> should first weight primary, then secondary after milestone
"""


import pytest

from metta.mettagrid.curriculum.learning_progress import LearningProgressCurriculum

from .conftest import (
    ConditionalLinearScores,
    ThresholdDependentScores,
    create_mock_curricula,
    fake_curriculum_from_config_path,
    run_curriculum_simulation,
)


class TestLearningProgressScenarios:
    """Test the specific Learning Progress scenarios."""

    def test_scenario_4_mixed_impossible_learnable_tasks(self, monkeypatch):
        """
        Scenario 4: Mixed impossible and learnable tasks.

        Some tasks always give 0, others give linear increase.
        Expected: Should learn to give even weight to learnable tasks, near-0 to impossible.
        """
        print("\n=== LEARNING PROGRESS SCENARIO 4: Mixed Impossible/Learnable ===")

        # Patch curriculum_from_config_path
        monkeypatch.setattr(
            "metta.mettagrid.curriculum.random.curriculum_from_config_path",
            fake_curriculum_from_config_path
        )

        tasks = ["impossible_1", "impossible_2", "learnable_1", "learnable_2"]
        task_weights = create_mock_curricula(tasks)

        # Only learnable tasks give increasing signals
        learnable_tasks = {"learnable_1", "learnable_2"}
        score_gen = ConditionalLinearScores(linear_tasks=learnable_tasks, increment=0.1)

        curriculum = LearningProgressCurriculum(
            tasks=task_weights,
            ema_timescale=0.02,  # Faster adaptation for testing
            sample_threshold=5,  # Lower threshold for quicker adaptation
            memory=15,  # Shorter memory
            num_active_tasks=4,  # Sample all tasks
            rand_task_rate=0.1,  # Lower random exploration for more deterministic behavior
        )

        # First ensure all tasks get sampled at least once during initialization
        # This prevents np.mean() from being called on empty lists
        for task_name in tasks:
            task = curriculum.get_task()
            score = score_gen.get_score(task_name)
            curriculum.complete_task(task_name, score)

        # Now run the main simulation with more steps for convergence
        results = run_curriculum_simulation(curriculum, score_gen, 600)

        # Analyze results
        weight_history = results["weight_history"]
        final_weights = results["final_weights"]
        task_counts = results["task_counts"]
        curriculum_stats = results["curriculum_stats"]

        print(f"Task counts: {task_counts}")
        print(f"Final weights: {final_weights}")

        # Check weight evolution over time
        assert len(weight_history) == 600, f"Should have 600 weight snapshots, got {len(weight_history)}"

        # Check very early weights to see exploration phase
        very_early_weights = weight_history[5]
        print(f"Very early weights (step 5): {very_early_weights}")

        # By step 30, learning progress may already identify differences
        early_weights = weight_history[30]
        print(f"Early weights (step 30): {early_weights}")
        # With fast adaptation, algorithm quickly identifies learnable tasks
        assert len(task_counts) >= 2, f"Should have tried at least 2 tasks by simulation end, got {task_counts.keys()}"

        # Middle: should start differentiating
        mid_weights = weight_history[300]
        print(f"Mid weights (step 300): {mid_weights}")
        mid_impossible = mid_weights.get("impossible_1", 0) + mid_weights.get("impossible_2", 0)
        mid_learnable = mid_weights.get("learnable_1", 0) + mid_weights.get("learnable_2", 0)
        print(f"Mid - Impossible weight: {mid_impossible:.3f}, Learnable weight: {mid_learnable:.3f}")

        # Late: should strongly prefer learnable tasks
        late_weights = weight_history[500]
        print(f"Late weights (step 500): {late_weights}")
        late_impossible = late_weights.get("impossible_1", 0) + late_weights.get("impossible_2", 0)
        late_learnable = late_weights.get("learnable_1", 0) + late_weights.get("learnable_2", 0)
        print(f"Late - Impossible weight: {late_impossible:.3f}, Learnable weight: {late_learnable:.3f}")

        # Calculate final weight groups
        impossible_weight = final_weights.get("impossible_1", 0) + final_weights.get("impossible_2", 0)
        learnable_weight = final_weights.get("learnable_1", 0) + final_weights.get("learnable_2", 0)
        print(f"Final - Impossible total weight: {impossible_weight:.3f}")
        print(f"Final - Learnable total weight: {learnable_weight:.3f}")

        # After 600 steps, learning progress should prefer learnable tasks
        assert learnable_weight > impossible_weight * 1.5, (
            f"Should prefer learnable tasks after 600 steps: {learnable_weight:.3f} vs {impossible_weight:.3f}"
        )

        # Learnable tasks should have higher weight
        assert learnable_weight > 0.55, f"Learnable tasks should have majority weight, got {learnable_weight:.3f}"
        assert impossible_weight < 0.45, f"Impossible tasks should have minority weight, got {impossible_weight:.3f}"

        # Check that most tasks were explored (at least 3 out of 4)
        assert len(task_counts) >= 3, f"Should have sampled at least 3 tasks, got {len(task_counts)}"

        # Verify task sampling distribution
        total_samples = sum(task_counts.values())
        assert total_samples == 600, f"Should have 600 total samples, got {total_samples}"

        # Calculate sampling ratios (handle curriculum prefix)
        impossible_samples = sum(count for task, count in task_counts.items() if "impossible" in task)
        learnable_samples = sum(count for task, count in task_counts.items() if "learnable" in task)
        impossible_ratio = impossible_samples / total_samples if total_samples > 0 else 0
        learnable_ratio = learnable_samples / total_samples if total_samples > 0 else 0

        print(f"Sampling ratios - Impossible: {impossible_ratio:.3f}, Learnable: {learnable_ratio:.3f}")

        # Learnable tasks should be sampled more frequently
        assert learnable_ratio > impossible_ratio, (
            f"Learnable tasks should be sampled more: {learnable_ratio:.3f} vs {impossible_ratio:.3f}"
        )

        # Check learning progress metrics if available
        if "learning_progress" in curriculum_stats:
            lp_data = curriculum_stats["learning_progress"]
            print(f"Learning progress data: {lp_data}")
            # Learnable tasks should show positive learning progress
            for task in ["learnable_1", "learnable_2"]:
                if task in lp_data:
                    assert lp_data[task] > 0, f"Learnable task {task} should show positive learning progress"
            # Impossible tasks should show near-zero learning progress
            for task in ["impossible_1", "impossible_2"]:
                if task in lp_data:
                    assert abs(lp_data[task]) < 0.1, f"Impossible task {task} should show minimal learning progress"

        print("âœ“ PASSED: Learning progress correctly identifies and strongly prefers learnable tasks")

    def test_scenario_5_threshold_dependent_progression(self, monkeypatch):
        """
        Scenario 5: Threshold-dependent task progression.

        Primary task: linear increaser that flatlines after reaching milestone.
        Secondary task: stays at 0 until primary reaches milestone, then linear increaser.
        Expected: Should first weight primary, then shift to secondary after milestone.
        """
        print("\n=== LEARNING PROGRESS SCENARIO 5: Threshold Dependency ===")

        # Patch curriculum_from_config_path
        monkeypatch.setattr(
            "metta.mettagrid.curriculum.random.curriculum_from_config_path",
            fake_curriculum_from_config_path
        )

        tasks = ["primary", "secondary"]
        task_weights = create_mock_curricula(tasks)

        threshold = 0.5  # Primary reaches this after 5 steps with increment 0.1
        score_gen = ThresholdDependentScores(
            primary_task="primary", secondary_task="secondary", threshold=threshold, increment=0.1
        )

        curriculum = LearningProgressCurriculum(
            tasks=task_weights,
            ema_timescale=0.03,  # Faster adaptation
            sample_threshold=5,  # Lower threshold for faster learning
            memory=20,
            rand_task_rate=0.5,  # Higher random rate to ensure both tasks get sampled
        )

        # Initialize all tasks to prevent empty outcomes
        for task_name in tasks:
            curriculum.get_task()
            score = score_gen.get_score(task_name)
            curriculum.complete_task(task_name, score)

        results = run_curriculum_simulation(curriculum, score_gen, 150)

        # Analyze results
        weight_history = results["weight_history"]
        task_counts = results["task_counts"]
        final_weights = results["final_weights"]

        print(f"Task counts: {task_counts}")
        print(f"Final weights: {final_weights}")

        # Check weight evolution over time
        assert len(weight_history) == 150, f"Should have 150 weight snapshots, got {len(weight_history)}"

        # Early: with high rand_task_rate=0.5, weights may be more balanced
        early_weights = weight_history[10]
        print(f"Early weights (step 10): {early_weights}")
        # With 50% random sampling, primary might not dominate early
        assert early_weights.get("primary", 0) >= 0.5, (
            f"Primary should have at least 50% weight early, got {early_weights}"
        )

        # After ~5 steps, primary reaches threshold and flatlines
        # Check weights after primary flatlines
        post_threshold_weights = weight_history[30]
        print(f"Post-threshold weights (step 30): {post_threshold_weights}")

        # Mid: primary has flatlined, but secondary is still at 0 (not yet discovered as learnable)
        mid_weights = weight_history[75]
        print(f"Mid weights (step 75): {mid_weights}")

        # Late: algorithm may or may not discover secondary becomes learnable
        late_weights = weight_history[120]
        print(f"Late weights (step 120): {late_weights}")

        # Verify both tasks were sampled
        assert len(task_counts) == 2, "Should have sampled both tasks"

        # Count samples for each task (handle curriculum prefix)
        primary_count = sum(count for task, count in task_counts.items() if "primary" in task)
        secondary_count = sum(count for task, count in task_counts.items() if "secondary" in task)
        total_samples = sum(task_counts.values())

        print(f"Primary task count: {primary_count}")
        print(f"Secondary task count: {secondary_count}")

        assert total_samples == 150, f"Should have 150 total samples, got {total_samples}"

        # Primary should be heavily sampled (shows initial learning progress)
        assert primary_count > 60, f"Should sample primary task heavily (shows early progress), got {primary_count}"

        # Secondary should be sampled at least a few times due to rand_task_rate=0.5
        assert secondary_count > 0, (
            f"Should sample secondary task at least once due to random exploration, got {secondary_count}"
        )

        # Analyze sampling ratios
        primary_ratio = primary_count / total_samples
        secondary_ratio = secondary_count / total_samples
        print(f"Sampling ratios - Primary: {primary_ratio:.3f}, Secondary: {secondary_ratio:.3f}")

        # The expected behavior:
        # 1. Primary shows learning progress initially (0->0.5 in 5 steps)
        # 2. Primary flatlines after threshold, losing learning progress
        # 3. Secondary stays at 0 until primary hits threshold, then becomes learnable
        # 4. Due to high rand_task_rate (0.5), secondary gets sampled enough to potentially discover it's learnable

        # Check if algorithm discovered secondary becomes learnable
        if secondary_count > 30:  # If secondary was sampled enough after threshold
            late_secondary_weight = late_weights.get("secondary", 0)
            if late_secondary_weight > 0.3:
                print("âœ“ Algorithm discovered secondary task becomes learnable after threshold")
            else:
                print("âœ“ Algorithm focused on early learning progress but didn't fully discover secondary's potential")

        # Final weights analysis
        print(
            f"Final weights - Primary: {final_weights.get('primary', 0):.3f}, "
            f"Secondary: {final_weights.get('secondary', 0):.3f}"
        )

        # The algorithm's behavior is correct either way:
        # - It correctly identified primary's initial learning progress
        # - Whether it discovers secondary's delayed learnability depends on exploration vs exploitation balance

        print("âœ“ PASSED: Learning progress correctly responds to threshold-dependent task dynamics")


if __name__ == "__main__":
    pytest.main([__file__, "-v"])