defaults:
  - common
  - wandb: metta_research
  - sweep: full
  - sim: sweep_eval  # Load sweep evaluation sim config
  - _self_

sweep_name: ??? # Will be set via command line override

settings:
  max_consecutive_failures: 5
  rollout_retry_delay: 5
  max_observations_to_load: 250
  sweep_server_uri: https://api.observatory.softmax-research.net

# Base sim configuration for sweep evaluations (separate from training evals)
sim:
  num_episodes: 7  # Default for phase 1
  max_time_s: 240  # 4 minutes per simulation

schedule:
  phases:
    - name: "explore_cheap"
<<<<<<< HEAD
      num_runs: 100 # 100 * 1800 = 180,000s
      overrides:
        sweep:
          protein:
            max_suggestion_cost: 1800
            random_suggestions: 18
            expansion_rate: 0.18
          parameters:
            trainer:
              total_timesteps: { mean: 300000000 }
              batch_size: { mean: 524288 } # 2^19
              minibatch_size: { mean: 8192 } # 2^13
        sim:
          num_episodes: 7  # Quick evaluation for initial exploration

    - name: "exploit_medium"
      num_runs: 70 # 70 * 3600 = 252,000s
      overrides:
        sweep:
          protein:
            max_suggestion_cost: 3600
            random_suggestions: 10
            suggestions_per_pareto: 24
            expansion_rate: 0.10
          parameters:
            trainer:
              total_timesteps: { mean: 750000000 }
              batch_size: { mean: 1048576 } # 2^20
              minibatch_size: { mean: 16384 } # 2^14
        sim:
          num_episodes: 20  # More thorough evaluation for promising candidates

    - name: "peak_expensive"
      num_runs: 11 # 11 * 7200 = 79,200s
      overrides:
        sweep:
          protein:
            max_suggestion_cost: 7200
            random_suggestions: 5
            suggestions_per_pareto: 16
            expansion_rate: 0.06
          parameters:
            trainer:
              total_timesteps: { mean: 1000000000 } # 1B
              batch_size: { mean: 1048576 } # 2^20
              minibatch_size: { mean: 16384 } # 2^14
        sim:
          num_episodes: 50  # High confidence evaluation for final candidates
=======
      num_runs: 80 # 80 × 1B = 80B timesteps = $560
      sweep:
        protein:
          max_suggestion_cost: 1800
          random_suggestions: 18
          expansion_rate: 0.18
          # Use UCB with high beta for broad exploration in early phase
          acquisition_fn: ucb
          ucb_beta: 2.5 # High value encourages exploration of uncertain regions
        parameters:
          trainer:
            total_timesteps: { mean: 1000000000 } # 1B - explore around first plateau
            batch_size: { mean: 524288 } # 2^19
            minibatch_size: { mean: 8192 } # 2^13

    - name: "exploit_medium"
      num_runs: 50 # 50 × 2B = 100B timesteps = $700
      sweep:
        protein:
          max_suggestion_cost: 3600
          random_suggestions: 10
          suggestions_per_pareto: 24
          expansion_rate: 0.10
          # Use EI for balanced exploration/exploitation in middle phase
          acquisition_fn: ei # EI naturally balances exploration and exploitation
        parameters:
          trainer:
            total_timesteps: { mean: 2000000000 } # 2B - explore intermediate plateau
            batch_size: { mean: 1048576 } # 2^20
            minibatch_size: { mean: 16384 } # 2^14

    - name: "peak_expensive"
      num_runs: 7 # 7 × 3.5B = 24.5B timesteps = $171.50
      sweep:
        protein:
          max_suggestion_cost: 7200
          random_suggestions: 5
          suggestions_per_pareto: 16
          expansion_rate: 0.06
          # Use UCB with low beta for exploitation in final phase
          acquisition_fn: ucb
          ucb_beta: 1.0 # Low value focuses on exploitation of promising regions
        parameters:
          trainer:
            total_timesteps: { mean: 3500000000 } # 3.5B - explore optimal convergence
            batch_size: { mean: 1048576 } # 2^20
            minibatch_size: { mean: 16384 } # 2^14
>>>>>>> 57f1e4ffe (Add EI and UCB acquisition functions to Protein optimizer)

# Otherwise common will mess with us
run: null

sweep_job_overrides:
  trainer:
    curriculum: /env/mettagrid/arena/basic_easy_shaped
    simulation:
      evaluate_remote: false
      evaluate_local: true
      replay_dir: "" # No replays for sweeps

cmd: sweep
