{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mettabook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Enable auto-reload of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display\n",
    "from mettabook_widgets import (\n",
    "    JobLauncher,\n",
    "    MetricsFetcher,\n",
    "    ReplayViewer,\n",
    "    TrainingConfigurator,\n",
    "    WandBConnector,\n",
    ")\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"default\")\n",
    "\n",
    "print(\"Setup complete! Auto-reload enabled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Initialize Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_store import get_runstore\n",
    "\n",
    "run_store = get_runstore()\n",
    "\n",
    "# Create widgets using the new stateless methods\n",
    "config_widgets = TrainingConfigurator.create_widgets()\n",
    "launcher_widgets = JobLauncher.create_widgets(config_widgets)\n",
    "wandb_widgets = WandBConnector.create_widgets()\n",
    "fetcher_widgets = MetricsFetcher.create_widgets()\n",
    "replay_widgets = ReplayViewer.create_widgets(fetcher_widgets)  # Pass fetcher_widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training\n",
    "\n",
    "### 2.1 Configure and Launch Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(TrainingConfigurator.display(config_widgets))\n",
    "display(JobLauncher.display(launcher_widgets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 View All Runs\n",
    "\n",
    "The RunStore provides unified tracking of all your training runs across SkyPilot and W&B. It persists data locally and provides a single view of all runs.\n",
    "\n",
    "**Important**: If you've made changes to the code, restart the kernel (Kernel â†’ Restart) and re-run cells 1-5 to reload the modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display RunStore table with all your runs\n",
    "rs = get_runstore()\n",
    "rs.to_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Monitor Job Status (Optional)\n",
    "\n",
    "If you just launched a job, you can monitor its status here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze Runs\n",
    "\n",
    "You can analyze metrics from one or multiple runs. Copy run names from the RunStore table above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Fetch Metrics from W&B\n",
    "\n",
    "Enter one or more run names (one per line) to fetch their metrics. This will also automatically fetch available replay URLs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(MetricsFetcher.display(fetcher_widgets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Analyze Metrics\n",
    "\n",
    "The fetched metrics are stored in `fetcher_widgets['state']['metrics_dfs']` as a dictionary mapping run names to pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot overview metrics for all fetched runs\n",
    "metrics_dfs = fetcher_widgets[\"state\"][\"metrics_dfs\"]\n",
    "if not metrics_dfs:\n",
    "    print(\"No metrics data available. Please fetch metrics first.\")\n",
    "else:\n",
    "    print(f\"Plotting metrics for {len(metrics_dfs)} runs\")\n",
    "\n",
    "    # Find common metrics across all runs\n",
    "    all_columns = set()\n",
    "    for _, df in metrics_dfs.items():\n",
    "        all_columns.update(df.columns)\n",
    "\n",
    "    # Filter for overview metrics\n",
    "    include_prefixes = [\"overview/\"]\n",
    "    plot_cols = []\n",
    "\n",
    "    for col in all_columns:\n",
    "        if not any(col.startswith(prefix) for prefix in include_prefixes):\n",
    "            continue\n",
    "        # Check if this column exists in at least one run with numeric data\n",
    "        has_numeric_data = False\n",
    "        for df in metrics_dfs.values():\n",
    "            if col in df.columns and pd.api.types.is_numeric_dtype(df[col]) and df[col].nunique() > 1:\n",
    "                has_numeric_data = True\n",
    "                break\n",
    "        if has_numeric_data:\n",
    "            plot_cols.append(col)\n",
    "\n",
    "    if not plot_cols:\n",
    "        print(\"No plottable metrics found\")\n",
    "    else:\n",
    "        # Calculate grid dimensions\n",
    "        n_metrics = len(plot_cols)\n",
    "        n_cols = min(3, n_metrics)  # Max 3 columns\n",
    "        n_rows = (n_metrics + n_cols - 1) // n_cols\n",
    "\n",
    "        # Create subplots\n",
    "        fig = make_subplots(\n",
    "            rows=n_rows,\n",
    "            cols=n_cols,\n",
    "            subplot_titles=[col.replace(\"overview/\", \"\").replace(\"_\", \" \") for col in plot_cols],\n",
    "            vertical_spacing=0.08,\n",
    "            horizontal_spacing=0.1,\n",
    "        )\n",
    "\n",
    "        # Color palette for different runs\n",
    "        colors = [\"blue\", \"red\", \"green\", \"orange\", \"purple\", \"brown\", \"pink\", \"gray\", \"olive\", \"cyan\"]\n",
    "\n",
    "        # Add traces for each metric and each run\n",
    "        for idx, col in enumerate(plot_cols):\n",
    "            row = (idx // n_cols) + 1\n",
    "            col_idx = (idx % n_cols) + 1\n",
    "\n",
    "            # Plot each run for this metric\n",
    "            for run_idx, (run_name, df) in enumerate(metrics_dfs.items()):\n",
    "                if col in df.columns and \"_step\" in df.columns:\n",
    "                    color = colors[run_idx % len(colors)]\n",
    "\n",
    "                    # Only show legend on first subplot to avoid clutter\n",
    "                    show_legend = idx == 0\n",
    "\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=df[\"_step\"],\n",
    "                            y=df[col],\n",
    "                            mode=\"lines\",\n",
    "                            name=run_name,\n",
    "                            line=dict(color=color, width=2),\n",
    "                            showlegend=show_legend,\n",
    "                            legendgroup=run_name,  # Group all traces from same run\n",
    "                        ),\n",
    "                        row=row,\n",
    "                        col=col_idx,\n",
    "                    )\n",
    "\n",
    "        # Update layout\n",
    "        runs_text = \"run\" if len(metrics_dfs) == 1 else \"runs\"\n",
    "        fig.update_layout(\n",
    "            height=250 * n_rows,\n",
    "            title_text=f\"Overview Metrics ({len(metrics_dfs)} {runs_text})\",\n",
    "            showlegend=True,\n",
    "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
    "        )\n",
    "\n",
    "        # Update x-axes labels for bottom row\n",
    "        for col_idx in range(1, min(n_cols, n_metrics) + 1):\n",
    "            fig.update_xaxes(title_text=\"Steps\", row=n_rows, col=col_idx)\n",
    "\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ReplayViewer.display(replay_widgets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReplayViewer.display_iframe(replay_widgets, width=1000, height=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
