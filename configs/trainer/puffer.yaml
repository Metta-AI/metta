_target_: metta.rl.trainer.MettaTrainer

defaults:
  - trainer
  - _self_

resume: true
use_e3b: false

total_timesteps: 150_000_000

clip_coef: 0.4892960366937307
ent_coef: 0.0021495271282999063
gae_lambda: 0.9548445797172682
gamma: 0.9970473490110006

# optimizer:
#   type: muon
#   beta1: 0.943
#   beta2: 0.9997
#   eps: 1.82e-13
#   learning_rate: 0.000238167
#   weight_decay: 0

optimizer:
  type: adam
  beta1: 0.9564306102799757
  beta2: 0.99999
  eps: 9.783476537284348e-13
  learning_rate: 0.0034144261695800942
  weight_decay: 0

lr_scheduler:
  enabled: false
  anneal_lr: false

max_grad_norm: 4.131048552978143
vf_clip_coef: 0.7479924868175252
vf_coef: 4.596909413885139
l2_reg_loss_coef: 0
l2_init_loss_coef: 0

# Prioritized experience replay parameters
prioritized_experience_replay:
  prio_alpha: 0.09999999999999998  # Slight prioritization
  prio_beta0: 0.6414824826502135   # Initial importance sampling correction

norm_adv: true
clip_vloss: true
target_kl: null

# V-trace clipping parameters (for off-policy corrections)
vtrace:
  vtrace_rho_clip: 1.0478534705178881  # Slight off-policy correction
  vtrace_c_clip: 2.8594046341079227     # More aggressive bootstrapping clipping

zero_copy: true
require_contiguous_env_ids: false
verbose: true

batch_size: 786432
minibatch_size: 32768
max_minibatch_size: 32768
bptt_horizon: 64
update_epochs: 1

cpu_offload: false
compile: false
compile_mode: reduce-overhead
profiler_interval_epochs: 10000

forward_pass_minibatch_target_size: 2048
async_factor: 2
num_workers: 16

kickstart:
  teacher_uri: null
  action_loss_coef: 1
  value_loss_coef: 1
  kickstart_steps: 50_000_000
  additional_teachers:
    # - teacher_uri: wandb://run/mettabox_cogeval_defaults_lowent_initialized0005:v100
    #   action_loss_coef: 1
    #   value_loss_coef: 1
    #  - teacher_uri: wandb://run/mettabox_cogeval_defaults_lowent_initialized0005:v95
    #    action_loss_coef: 1
    #    value_loss_coef: 1
