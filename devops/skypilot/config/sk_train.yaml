resources:
  cloud: aws
  any_of:
    - region: us-east-1
      use_spot: true
      accelerators: "L4:1"
    - region: us-east-1
      use_spot: true
      accelerators: "A10G:1"
    - region: us-east-1
      accelerators: "L4:1"
    - region: us-east-1
      accelerators: "A10G:1"
    - region: us-west-2
      use_spot: true
      accelerators: "L4:1"
    - region: us-west-2
      use_spot: true
      accelerators: "A10G:1"
    - region: us-west-2
      accelerators: "L4:1"
    - region: us-west-2
      accelerators: "A10G:1"
  cpus: 8+
  image_id: docker:metta:latest
  job_recovery:
    strategy: EAGER_NEXT_REGION
    max_restarts_on_errors: 20

config:
  docker:
    run_options:
      - --cap-add=IPC_LOCK
      - --ulimit memlock=-1:-1
      - --shm-size=4g

file_mounts:
  /mnt/s3/softmax-public:
    source: s3://softmax-public
    mode: MOUNT_CACHED
  /mnt/s3/train_dir:
    source: s3://softmax-train-dir
    mode: MOUNT_CACHED

setup: |
  set -e
  cd /workspace/metta

  # Note that the docker image may start in a venv!

  # Activate the metta venv
  if [ -n "$VIRTUAL_ENV" ]; then
      deactivate 2>/dev/null || true
  fi
  . .venv/bin/activate

  git fetch --depth=1000 origin "$METTA_GIT_REF" || git fetch origin
  git checkout "$METTA_GIT_REF"
  echo "Checked out: $(git rev-parse HEAD)"

  # Python environment setup
  echo "Setting up Python environment..."
  uv sync

  # Create required directories
  mkdir -p "$WANDB_DIR"

  echo "METTA_CMD_ARGS = $METTA_CMD_ARGS"
  echo "METTA_RUN_ID = $METTA_RUN_ID"
  echo "METTA_CMD = $METTA_CMD"
  echo "METTA_GIT_REF = $METTA_GIT_REF"
  echo "HEARTBEAT_TIMEOUT = $HEARTBEAT_TIMEOUT"

  # Note that different sets of skypilot environment variables are available in "run" vs "setup"
  # see https://docs.skypilot.co/en/latest/running-jobs/environment-variables.html

run: |
  set -euo pipefail
  cd /workspace/metta

  # Activate the metta venv
  if [ -n "$VIRTUAL_ENV" ]; then
      deactivate 2>/dev/null || true
  fi
  . .venv/bin/activate

  bash ./devops/skypilot/config/configure_environment.sh

  echo "METTA_RUN_ID: $METTA_RUN_ID"
  echo "SKYPILOT_TASK_ID: $SKYPILOT_TASK_ID"

  if [ -f common/src/metta/common/util/skypilot_latency.py ]; then
    echo "Collecting skypilot latency..."
    LATENCY_OUTPUT=$(uv run python common/src/metta/common/util/skypilot_latency.py 2>&1) || true
    echo "$LATENCY_OUTPUT"
  else
    echo "Latency script is missing!"
  fi

  METTA_ENV_FILE="$(uv run ./common/src/metta/common/util/constants.py METTA_ENV_FILE)"

  if [ -f common/src/metta/common/util/cost_monitor.py ]; then
    echo "Collecting instance cost..."
    if uv run python common/src/metta/common/util/cost_monitor.py; then
      echo "wrote METTA_HOURLY_COST to $METTA_ENV_FILE"
    else
      echo "Cost monitor script failed to run."
    fi
  else
    echo "Cost monitor script is missing!"
  fi

  # Debug: Display environment file contents
  echo "=== DEBUG: Contents of $METTA_ENV_FILE ==="
  if [ -f "$METTA_ENV_FILE" ]; then
    cat "$METTA_ENV_FILE"
  else
    echo "ERROR: Environment file not found at $METTA_ENV_FILE"
  fi
  echo "=== END DEBUG ==="

  # load environment vars written by child scripts
  source "$METTA_ENV_FILE"

  echo "Cluster configuration:"
  echo "  NUM_GPUS=$NUM_GPUS"
  echo "  NUM_NODES=$NUM_NODES"
  echo "  MASTER_ADDR=$MASTER_ADDR"
  echo "  NODE_INDEX=$NODE_INDEX"

  # System diagnostics with cleaner output
  echo "System diagnostics:"
  echo "  ULIMIT=$(ulimit -l)"
  echo "  SHM_MOUNT=$(mount | grep /dev/shm || echo 'No /dev/shm mount found')"
  echo "  ROUTE_TO_MASTER=$(ip -o route get $MASTER_ADDR | head -1)"
  echo "  NETWORK_INTERFACE=$(ip -o addr show ${NCCL_SOCKET_IFNAME:-enp39s0} | head -1 || echo 'Interface ${NCCL_SOCKET_IFNAME:-enp39s0} not found')"

  # Run comprehensive GPU diagnostics and NCCL tests
  echo "Running GPU diagnostics and NCCL tests..."
  if [ "$NUM_NODES" -gt 1 ] || [ "$NUM_GPUS" -gt 1 ]; then
      # For distributed training
      if ! uv run torchrun \
        --nproc_per_node=$NUM_GPUS \
        --nnodes=$NUM_NODES \
        --node_rank=$NODE_INDEX \
        --master_addr=$MASTER_ADDR \
        --master_port="$MASTER_PORT" \
        ./devops/skypilot/test_nccl.py; then
          echo "NCCL pre-flight check failed!"
          exit 1
      fi
  else
      # For single GPU
      if ! uv run python ./devops/skypilot/test_nccl.py; then
          echo "GPU pre-flight check failed!"
          # exit 1
      fi
  fi

  HEARTBEAT_FILE=${HEARTBEAT_FILE:-$WANDB_DIR/heartbeat.txt}

  # Start train.sh in background
  ./devops/"$METTA_CMD".sh run="$METTA_RUN_ID" $METTA_CMD_ARGS &
  TRAIN_PID=$!

  # Start heartbeat *watching the train PID*
  if [[ "${HEARTBEAT_TIMEOUT}" != "0" ]]; then
    echo "[INFO] Starting heartbeat monitor ${HEARTBEAT_TIMEOUT}s on $HEARTBEAT_FILE (pid=$TRAIN_PID)"
    python -m metta.common.util.heartbeat monitor "$HEARTBEAT_FILE" \
      --pid "$TRAIN_PID" --timeout "$HEARTBEAT_TIMEOUT" \
      >/dev/null 2>&1 &
    HEARTBEAT_PID=$!
  fi

  # Wait for training to finish, capture exit, then kill heartbeat cleanly
  wait "$TRAIN_PID"
  CMD_EXIT=$?

  if [[ -n "${HEARTBEAT_PID:-}" ]]; then
    kill "$HEARTBEAT_PID" 2>/dev/null || true
    wait "$HEARTBEAT_PID" 2>/dev/null || true
  fi

  # if a github token is provided, report training status back to github
  COMMIT_SHA=$(git rev-parse HEAD)
  GITHUB_REPOSITORY="$(uv run ./common/src/metta/common/util/constants.py METTA_GITHUB_REPO)"

  # Just export the variables and run the script
  if [ -n "${GITHUB_TOKEN:-}" ]; then
      echo "Posting status to GitHubâ€¦"

      # The script reads CMD_EXIT, COMMIT_SHA, and SKYPILOT_TASK_ID from environment
      uv run python ./devops/skypilot/post_commit_status.py
  else
      echo "GITHUB_TOKEN not set; skipping GitHub status update"
  fi

  echo "$METTA_CMD job complete. (Exit code: $CMD_EXIT)"
  exit $CMD_EXIT

envs:
  METTA_RUN_ID: ""
  METTA_CMD: train
  METTA_CMD_ARGS: ""
  METTA_GIT_REF: main
  WANDB_DIR: ./wandb
  HEARTBEAT_TIMEOUT: 600

  # if a github token is provided, we will report training status back to the branch
  GITHUB_TOKEN: ""

  # s3 mount slows down uv, so we put DATA_DIR outside of /workspace/metta
  DATA_DIR: /mnt/s3/train_dir
  SKYPILOT_DOCKER_USERNAME: ""
  SKYPILOT_DOCKER_PASSWORD: ""
  SKYPILOT_DOCKER_SERVER: 751442549699.dkr.ecr.us-east-1.amazonaws.com

secrets:
  # configured by launch script based on local credentials
  WANDB_PASSWORD: ""
  OBSERVATORY_TOKEN: ""
