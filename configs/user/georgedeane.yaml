# @package __global__

defaults:
  # - override /agent: simple
  - _self_

trainer:
  curriculum: /env/mettagrid/walkaround
  simulation:
    evaluate_interval: 2
  checkpoint:
    checkpoint_interval: 2
    wandb_checkpoint_interval: 2

# eval_db_uri: wandb://artifacts/memory_db

# policy: wandb://run/b.daveey.train.maze.sm.dr.warm.0
# baselines: wandb://run/b.daveey.train.maze.sm.11x11.0

# policy_uri: wandb://run/b.daveey.sm.train.er.new.0
# policy_uri: wandb://run/daveey.ar.cards.1
# policy_uri: wandb://run/b.daveey.t.32.instant
#policy_uri: ${trained_policy_uri}
policy_uri: wandb://run/daphne.generalized_nav.bucketed.07-10

# daphne.generalized_nav.lp.sparse.07-10

# daphne.generalized_nav.bucketed.07-10

# sasmith.nav-bucketed.no-timing

# george.generalized_nav.bucketed.07-10
# george.generalized_nav.bucketed.07-10

# b.daphne.terrain_varied_cyl_lab_pretrained:v0
# policy_uri: wandb://run/terrain_training_multienv_april18
# policy_uri: wandb://run/b.daphne.terrain_multienv_april18

# Infinite_cooldown models:
# navigation_infinite_cooldown_sweep_2g_.r.0 - ok
# navigation_infinite_cooldown_sweep_2g.r.1 - 9 reward after 400 timesteps
# navigation_infinite_cooldown_high_ent_no_initial_heart - ~9, current best
# navigation_poisson_train_sampling5 breaks in infinite_cooldown, works great in poisson with short distance
# navigation_poisson_train_sampling5
# npc_policy_uri: ${trained_policy_uri}

dashboard:
  output_path: evalresults/memory_db.html

run_id: 2
run: ${oc.env:USER}.local.${run_id}
trained_policy_uri: ${run_dir}/checkpoints

sweep_params: "sweep/fast"
sweep_name: "${oc.env:USER}.local.sweep.${run_id}"
seed: null
