I ran a direct config comparison using the training entrypoint (recipes/experiment/cogs_v_clips.train) with variants=["heart_chorus"] and compared the eval suite
  config it builds (difficulty standard + heart_chorus) for an overlapping mission: hello_world.oxygen_bottleneck.

  Findings:

  - Compass is ON in both training and eval (global_obs.compass=True).
  - Vibe count and change‑vibe settings match (152 vibes; change_vibe.number_of_vibes=152).
  - But the mission parameters differ between training and eval for the same mission name:
      - game.objects.carbon_extractor.max_uses: train 25 vs eval 100
      - game.objects.oxygen_extractor.max_uses: train 5 vs eval 20
      - game.objects.germanium_extractor.max_uses: train 5 vs eval 20
      - game.objects.silicon_extractor.max_uses: train 120 vs eval 480

  So the mismatch isn’t compass — it’s the mission definitions used by training vs eval. Training uses base missions (cogames.cogs_vs_clips.missions), while eval uses
  integrated eval missions (cogames.cogs_vs_clips.evals.integrated_evals) that have different extractor settings.

  Also: the eval suite used by recipes/experiment/cogs_v_clips.train does not include machina_1.open_world at all (it only evaluates the 7 HELLO_WORLD integrated
  evals). So training can be creating hearts on easier missions while your eval runs on machina_1 are a different environment entirely.

  Relevant files:

  - Compass default: packages/cogames/src/cogames/cogs_vs_clips/mission.py
  - Training entrypoint + eval suite wiring: recipes/experiment/cogs_v_clips.py
  - Eval mission definitions: packages/cogames/src/cogames/cogs_vs_clips/evals/integrated_evals.py

  If you want true parity, we should align which mission templates eval uses (and/or include machina_1.open_world in the eval suite). I can patch this if you want —
  tell me whether you prefer:

  1. Eval suite uses the same mission templates as training (from missions.py), or
  2. Training uses the integrated eval mission definitions, or
  3. Add machina_1.open_world to the eval suite.
