{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Analysis Workbook\n",
    "\n",
    "This notebook provides a comprehensive meta-analysis workflow for analyzing policy performance correlations across multiple evaluation tasks using the Observatory API.\n",
    "\n",
    "## Overview\n",
    "- Query top policies from Observatory\n",
    "- Evaluate policies across all specified tasks\n",
    "- Analyze performance correlations\n",
    "- Visualize results with heatmaps and PCA\n",
    "- Generate comprehensive reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m183 packages\u001b[0m \u001b[2min 12ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m151 packages\u001b[0m \u001b[2min 997ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv add ipykernel seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Added /Users/bullm/Documents/GitHub/metta/mettabook to Python path\n",
      "‚úÖ All analysis modules imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get absolute path to analysis modules\n",
    "notebook_dir = Path(__file__).parent if '__file__' in globals() else Path.cwd()\n",
    "analysis_dir = notebook_dir.parent.parent / 'analysis'\n",
    "\n",
    "# Add to Python path if analysis directory exists\n",
    "if analysis_dir.exists():\n",
    "    sys.path.insert(0, str(analysis_dir.parent))\n",
    "    print(f\"‚úÖ Added {analysis_dir.parent} to Python path\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Analysis directory not found at {analysis_dir}\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our analysis modules\n",
    "try:\n",
    "    from analysis.observatory_client import ObservatoryClient\n",
    "    from analysis.correlation_analyzer import CorrelationAnalyzer\n",
    "    from analysis.meta_analyzer import MetaAnalyzer\n",
    "    from analysis.visualization_utils import VisualizationUtils\n",
    "    print(\"‚úÖ All analysis modules imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Observatory Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to Observatory API\n",
      "üìä Found 80 available environments\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Observatory client\n",
    "client = ObservatoryClient()\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    # Get available environments\n",
    "    envs = client.get_environments()\n",
    "    print(f\"‚úÖ Connected to Observatory API\")\n",
    "    print(f\"üìä Found {len(envs)} available environments\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Connection failed: {e}\")\n",
    "    print(\"Please check your Observatory API configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Query Top Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Querying top 20 policies...\n",
      "üîç Running diagnostic query...\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "API request failed: 408 - {\"detail\":\"Query execution timed out after 20 seconds\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Query top policies\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müîç Querying top \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTOP_N_POLICIES\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m policies...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m policies = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_top_policies\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTOP_N_POLICIES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43menvironments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mENVIRONMENTS\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(policies)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m policies\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTop 5 policies:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/metta/mettabook/analysis/observatory_client.py:92\u001b[39m, in \u001b[36mObservatoryClient.get_top_policies\u001b[39m\u001b[34m(self, n, environments)\u001b[39m\n\u001b[32m     78\u001b[39m diagnostic_query = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[33mSELECT\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[33m    COUNT(*) as total_policies,\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     88\u001b[39m \u001b[33mLEFT JOIN episodes ep ON eap.episode_id = ep.id\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müîç Running diagnostic query...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m diagnostic_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiagnostic_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m diagnostic_result[\u001b[33m\"\u001b[39m\u001b[33mrows\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m     94\u001b[39m     row = diagnostic_result[\u001b[33m\"\u001b[39m\u001b[33mrows\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/metta/mettabook/analysis/observatory_client.py:57\u001b[39m, in \u001b[36mObservatoryClient.execute_query\u001b[39m\u001b[34m(self, query)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m) -> Dict:\n\u001b[32m     56\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Execute a SQL query via the observatory API.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/sql/query\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/metta/mettabook/analysis/observatory_client.py:51\u001b[39m, in \u001b[36mObservatoryClient._make_request\u001b[39m\u001b[34m(self, method, endpoint, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m response = requests.request(method, url, headers=headers, **kwargs)\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code != \u001b[32m200\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAPI request failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response.json()\n",
      "\u001b[31mException\u001b[39m: API request failed: 408 - {\"detail\":\"Query execution timed out after 20 seconds\"}"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "TOP_N_POLICIES = 20\n",
    "ENVIRONMENTS = envs\n",
    "\n",
    "# Query top policies\n",
    "print(f\"üîç Querying top {TOP_N_POLICIES} policies...\")\n",
    "policies = client.get_top_policies(\n",
    "    n=TOP_N_POLICIES,\n",
    "    environments=ENVIRONMENTS\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Found {len(policies)} policies\")\n",
    "print(\"\\nTop 5 policies:\")\n",
    "for i, policy in enumerate(policies[:5]):\n",
    "    print(f\"  {i+1}. {policy['name']} (ID: {policy['id']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate Policies Across All Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Evaluating across 80 environments\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'policies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müìã Evaluating across \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_envs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m environments\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Extract policy IDs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m policy_ids = [p[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpolicies\u001b[49m]\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Get evaluation data\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müîÑ Fetching evaluation data...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'policies' is not defined"
     ]
    }
   ],
   "source": [
    "# Get all available environments for evaluation\n",
    "all_envs = client.get_environments()\n",
    "print(f\"üìã Evaluating across {len(all_envs)} environments\")\n",
    "\n",
    "# Extract policy IDs\n",
    "policy_ids = [p['id'] for p in policies]\n",
    "\n",
    "# Get evaluation data\n",
    "print(\"üîÑ Fetching evaluation data...\")\n",
    "eval_data = client.get_policy_evaluations(\n",
    "    policy_ids=policy_ids,\n",
    "    environments=all_envs\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Retrieved {len(eval_data)} evaluation records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Performance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(eval_data)\n",
    "\n",
    "# Pivot to create performance matrix\n",
    "performance_matrix = df.pivot_table(\n",
    "    index='policy_id',\n",
    "    columns='environment',\n",
    "    values='value',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "print(f\"üìä Performance matrix shape: {performance_matrix.shape}\")\n",
    "print(f\"\\nEnvironments: {list(performance_matrix.columns)}\")\n",
    "print(f\"\\nPolicies: {len(performance_matrix.index)}\")\n",
    "\n",
    "# Display first few rows\n",
    "performance_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize correlation analyzer\n",
    "corr_analyzer = CorrelationAnalyzer()\n",
    "\n",
    "# Calculate correlations\n",
    "correlation_matrix = corr_analyzer.calculate_correlations(performance_matrix)\n",
    "\n",
    "print(\"üîç Correlation Analysis Results:\")\n",
    "print(f\"\\nAverage correlation: {corr_analyzer.get_average_correlation():.3f}\")\n",
    "print(f\"Correlation range: {corr_analyzer.get_correlation_range()}\")\n",
    "\n",
    "# Find most/least correlated pairs\n",
    "most_corr = corr_analyzer.get_most_correlated_pairs(n=3)\n",
    "least_corr = corr_analyzer.get_least_correlated_pairs(n=3)\n",
    "\n",
    "print(f\"\\nMost correlated pairs:\")\n",
    "for pair, corr in most_corr:\n",
    "    print(f\"  {pair[0]} ‚Üî {pair[1]}: {corr:.3f}\")\n",
    "\n",
    "print(f\"\\nLeast correlated pairs:\")\n",
    "for pair, corr in least_corr:\n",
    "    print(f\"  {pair[0]} ‚Üî {pair[1]}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize visualization utils\n",
    "viz_utils = VisualizationUtils()\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Create correlation heatmap\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Correlation heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='RdBu_r', center=0,\n",
    "            square=True, fmt='.2f', ax=axes[0,0])\n",
    "axes[0,0].set_title('Task Performance Correlations', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 2. Performance distribution\n",
    "performance_matrix.boxplot(ax=axes[0,1])\n",
    "axes[0,1].set_title('Performance Distribution by Task', fontsize=14, fontweight='bold')\n",
    "axes[0,1].set_ylabel('Performance Score')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Performance heatmap\n",
    "sns.heatmap(performance_matrix, cmap='viridis', ax=axes[1,0], cbar_kws={'label': 'Performance'})\n",
    "axes[1,0].set_title('Policy Performance Heatmap', fontsize=14, fontweight='bold')\n",
    "axes[1,0].set_xlabel('Tasks')\n",
    "axes[1,0].set_ylabel('Policies')\n",
    "\n",
    "# 4. Correlation distribution\n",
    "corr_values = correlation_matrix.values[np.triu_indices_from(correlation_matrix.values, k=1)]\n",
    "axes[1,1].hist(corr_values, bins=20, alpha=0.7, edgecolor='black')\n",
    "axes[1,1].set_xlabel('Correlation Coefficient')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "axes[1,1].set_title('Correlation Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. PCA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize meta analyzer\n",
    "meta_analyzer = MetaAnalyzer()\n",
    "\n",
    "# Perform PCA\n",
    "pca_results = meta_analyzer.perform_pca(performance_matrix)\n",
    "\n",
    "print(\"üî¨ PCA Analysis Results:\")\n",
    "print(f\"Explained variance ratio: {pca_results['explained_variance_ratio']}\")\n",
    "print(f\"Cumulative explained variance: {np.cumsum(pca_results['explained_variance_ratio'])}\")\n",
    "\n",
    "# Plot PCA results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Scree plot\n",
    "n_components = len(pca_results['explained_variance_ratio'])\n",
    "axes[0].plot(range(1, n_components + 1), pca_results['explained_variance_ratio'], 'bo-')\n",
    "axes[0].set_xlabel('Principal Component')\n",
    "axes[0].set_ylabel('Explained Variance Ratio')\n",
    "axes[0].set_title('PCA Scree Plot', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True)\n",
    "\n",
    "# PCA loadings\n",
    "loadings = pca_results['components']\n",
    "im = axes[1].imshow(loadings, cmap='RdBu_r', aspect='auto')\n",
    "axes[1].set_xticks(range(loadings.shape[1]))\n",
    "axes[1].set_xticklabels([f'PC{i+1}' for i in range(loadings.shape[1])])\n",
    "axes[1].set_yticks(range(loadings.shape[0]))\n",
    "axes[1].set_yticklabels(performance_matrix.columns)\n",
    "axes[1].set_title('PCA Component Loadings', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics\n",
    "summary_stats = meta_analyzer.generate_summary_statistics(\n",
    "    performance_matrix=performance_matrix,\n",
    "    correlation_matrix=correlation_matrix,\n",
    "    pca_results=pca_results\n",
    ")\n",
    "\n",
    "print(\"üìà Summary Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in summary_stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "# Save results\n",
    "output_file = '../data/meta_analysis_results.json'\n",
    "meta_analyzer.save_results(summary_stats, output_file)\n",
    "print(f\"\\nüíæ Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save key visualizations\n",
    "viz_dir = '../visualizations/'\n",
    "os.makedirs(viz_dir, exist_ok=True)\n",
    "\n",
    "# Correlation heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='RdBu_r', center=0,\n",
    "            square=True, fmt='.2f')\n",
    "plt.title('Task Performance Correlations', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{viz_dir}correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Performance matrix\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.heatmap(performance_matrix, cmap='viridis', cbar_kws={'label': 'Performance'})\n",
    "plt.title('Policy Performance Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{viz_dir}policy_performance.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# PCA scree plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "n_components = len(pca_results['explained_variance_ratio'])\n",
    "ax.plot(range(1, n_components + 1), pca_results['explained_variance_ratio'], 'bo-')\n",
    "ax.set_xlabel('Principal Component')\n",
    "ax.set_ylabel('Explained Variance Ratio')\n",
    "ax.set_title('PCA Scree Plot', fontsize=14, fontweight='bold')\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{viz_dir}pca_scree_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"‚úÖ Visualizations saved to {viz_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
