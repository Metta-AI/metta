_target_: agent.metta_agent.MettaAgent

policy_selector:
  uri: null
  type: top
  range: 0
  metric: final.score
  generation: null
  
observations:
  obs_key: grid_obs
  track_last_action: ${env.track_last_action}
  
clip_range: 3.0 # clip weights greater or less than this value * largest weight in layer * clip_scale
effective_rank_interval: 10 # compute effective rank every N epochs and log to wandb
l2_init_weight_update_interval: 0 # update the copy of initial weights every N epochs, scaled by to alpha

# List each component of your agent below. Components can be found in the
# agent/lib or you can write your own and must be specified under _target_:
# Components must have their name as their top level attribute. input_source
# is also necessary but can be set to null. output_size is not necessary only
# if it is defined by the size of the input source. Do not enter an input_size
# as it's defined by the input_source's output_size.
# Necessary sources: _obs_, _core_ -> these interact with trainer in a special way.
# Necessary outputs: _action_param_, _value_ -> you only need to give your outputs
# these specific names and the appropriate output_size for the environment. They can
# otherwise be any class that works with MettaAgent.

# Layers are nn.Modules. Linear and Conv modules get extra weight helper 
# functions found in the ParameterizedLayer class. Note that these layers are also 
# appended a nonlinear layer unless you specify nonlinearity: null.

# There are also merge layers which allow you to merge multiple outputs into a single 
# output to feed into a layer. You can merge in various ways such as concatenating 
# (DenseNet), summing (resnet), taking the mean, etc. You can also take slices of a 
# single output to feed into a layer.

# Go through the components below to find additional examples.

components:

  _obs_: 
    _target_: agent.lib.obs_shaper.ObsShaper
    input_source: null

  obs_normalizer:
    _target_: agent.lib.observation_normalizer.ObservationNormalizer
    input_source: _obs_

  channel_selector_0-11: # a merge layer that takes a slice of the input
    _target_: agent.lib.merge_layer.ConcatMergeLayer
    sources:
      - source_name: _obs_
        slice: [0, 12]    # Use channels 0 to 11
        dim: 1            # Channel dimension
    output_size: 12

  channel_selector_12-22:
    _target_: agent.lib.merge_layer.ConcatMergeLayer
    sources:
      - source_name: _obs_
        slice: [12, 22]   # Use channels 12 to 23
        dim: 1
    output_size: 12

  cnn1_channels_0-11:
    _target_: agent.lib.nn_layer_library.Conv2d
    input_source: channel_selector_0-11
    output_size: 64
    clip_scale: 0
    nn_params:
      kernel_size: 5
      stride: 3
    # when defining nn.Modules, put your keyword argements under nn_params. 
    #Do not specify input_size or output_size.

  cnn1_channels_12-22:
    _target_: agent.lib.nn_layer_library.Conv2d
    input_source: channel_selector_12-22
    output_size: 64
    nn_params:
      kernel_size: 5
      stride: 3

  cnn2_channels_0-11:
    _target_: agent.lib.nn_layer_library.Conv2d
    input_source: cnn1_channels_0-11
    output_size: 64
    nn_params:
      kernel_size: 3
      stride: 1

  cnn2_channels_12-22:
    _target_: agent.lib.nn_layer_library.Conv2d
    input_source: cnn1_channels_12-22
    output_size: 64
    nn_params:
      kernel_size: 3
      stride: 1

  cnn_merger: # a merge layer that takes two slices of the input and concatenates them
    _target_: agent.lib.merge_layer.ConcatMergeLayer
    sources:
      - source_name: cnn2_channels_0-11
        slice: [0, 64]
        dim: 1
      - source_name: cnn2_channels_12-22
        slice: [0, 64]
        dim: 1

  obs_flattener:
    _target_: agent.lib.nn_layer_library.Flatten
    input_source: cnn_merger

  obs_dropout:
    _target_: agent.lib.nn_layer_library.Dropout
    input_source: obs_flattener
    nn_params:
      p: 0.5

  # using our first Linear layer as an example of the minimum required parameters
  encoded_obs:
    _target_: agent.lib.nn_layer_library.Linear
    input_source: obs_dropout
    output_size: 128

  _core_:
    _target_: agent.lib.nn_layer_library.LSTM
    input_source: encoded_obs
    output_size: 128
    nn_params:
      num_layers: 1
  
  # using our second Linear layer as an example of all available parameters
  critic_1:
    _target_: agent.lib.nn_layer_library.Linear
    input_source: _core_
    output_size: 512
    nonlinearity: Tanh
    effective_rank: true
    l2_norm_scale: 1.0
    l2_init_scale: 1.0
    clip_scale: 1.0
    initialization: xavier
    nn_params:
      bias: false

  critic_2:
    _target_: agent.lib.nn_layer_library.Linear
    input_source: critic_1
    output_size: 128

  critic_3:
    _target_: agent.lib.nn_layer_library.Linear
    input_source: critic_2
    output_size: 128

  _value_:
    _target_: agent.lib.nn_layer_library.Linear
    input_source: critic_3
    output_size: 1
    nonlinearity: null # we don't want a nonlinearity here

  actor_1:
    _target_: agent.lib.nn_layer_library.Linear
    input_source: _core_
    output_size: 512

  actor_2:
    _target_: agent.lib.nn_layer_library.Linear
    input_source: actor_1
    output_size: 512

  _action_param_:
    _target_: agent.lib.nn_layer_library.Linear
    input_source: actor_2
    output_size: 20
    nonlinearity: null # we don't want a nonlinearity here because we'll use a softmax on the action space

