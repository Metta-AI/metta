# @package __global__

defaults:
  - _self_

trainer:
  evaluate_interval: 200
  env_overrides:
    game:
      num_agents: 36
      max_steps: 1000

policy_uri: wandb://run/b.daveey.t.1.lra.dr.muon

npc_policy_uri: ${policy_uri}

analyzer:
  policy_uri: ${..policy_uri}
  eval_stats_uri: ${run_dir}/eval_stats
  analysis:
    metrics:
      - metric: episode_reward
      - metric: "heart.get"

replay_job:
  sim:
    env: /env/mettagrid/navigation/training/terrain_from_numpy


wandb:
  checkpoint_interval: 1

run_id: 2
run: ${oc.env:USER}.local.${run_id}
trained_policy_uri: ${run_dir}/checkpoints

sweep_params: "sweep/fast"
sweep_name: "${oc.env:USER}.local.sweep.${run_id}"
seed: null
