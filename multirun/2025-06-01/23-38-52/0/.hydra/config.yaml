run: ???
dist_cfg_path: null
data_dir: ./train_dir
run_dir: ${data_dir}/${run}
policy_uri: file://${run_dir}/checkpoints
torch_deterministic: true
vectorization: multiprocessing
seed: 1
device: cuda
agent:
  _target_: metta.agent.metta_agent.MettaAgent
  observations:
    obs_key: grid_obs
  clip_range: 0
  analyze_weights_interval: 300
  l2_init_weight_update_interval: 0
  components:
    _obs_:
      _target_: metta.agent.lib.obs_shaper.ObsShaper
      sources: null
    obs_normalizer:
      _target_: metta.agent.lib.observation_normalizer.ObservationNormalizer
      sources:
      - name: _obs_
    cnn1:
      _target_: metta.agent.lib.nn_layer_library.Conv2d
      sources:
      - name: obs_normalizer
      nn_params:
        out_channels: 64
        kernel_size: 5
        stride: 3
    cnn2:
      _target_: metta.agent.lib.nn_layer_library.Conv2d
      sources:
      - name: cnn1
      nn_params:
        out_channels: 64
        kernel_size: 3
        stride: 1
    obs_flattener:
      _target_: metta.agent.lib.nn_layer_library.Flatten
      sources:
      - name: cnn2
    fc1:
      _target_: metta.agent.lib.nn_layer_library.Linear
      sources:
      - name: obs_flattener
      nn_params:
        out_features: 128
    encoded_obs:
      _target_: metta.agent.lib.nn_layer_library.Linear
      sources:
      - name: fc1
      nn_params:
        out_features: 128
    _core_:
      _target_: metta.agent.lib.lstm.LSTM
      sources:
      - name: encoded_obs
      output_size: 128
      nn_params:
        num_layers: 2
    core_relu:
      _target_: metta.agent.lib.nn_layer_library.ReLU
      sources:
      - name: _core_
    critic_1:
      _target_: metta.agent.lib.nn_layer_library.Linear
      sources:
      - name: core_relu
      nn_params:
        out_features: 1024
      nonlinearity: nn.Tanh
      effective_rank: true
    _value_:
      _target_: metta.agent.lib.nn_layer_library.Linear
      sources:
      - name: critic_1
      nn_params:
        out_features: 1
      nonlinearity: null
    actor_1:
      _target_: metta.agent.lib.nn_layer_library.Linear
      sources:
      - name: core_relu
      nn_params:
        out_features: 512
    _action_embeds_:
      _target_: metta.agent.lib.action.ActionEmbedding
      sources: null
      nn_params:
        num_embeddings: 100
        embedding_dim: 16
    _action_:
      _target_: metta.agent.lib.actor.MettaActorSingleHead
      sources:
      - name: actor_1
      - name: _action_embeds_
trainer:
  num_workers: ???
  env: /env/mettagrid/simple
  env_overrides: {}
  initial_policy:
    uri: null
    type: top
    range: 1
    metric: epoch
    filters: {}
  checkpoint_dir: ${run_dir}/checkpoints
  evaluate_interval: 300
  checkpoint_interval: 60
  wandb_checkpoint_interval: 300
  replay_interval: ${trainer.evaluate_interval}
  replay_dir: s3://softmax-public/replays/${run}
  average_reward: false
  average_reward_alpha: 0.01
  _target_: metta.rl.pufferlib.trainer.PufferTrainer
  resume: true
  use_e3b: false
  total_timesteps: 50000000000
  clip_coef: 0.1
  ent_coef: 0.0021
  gae_lambda: 0.916
  gamma: 0.977
  optimizer:
    type: adam
    beta1: 0.9
    beta2: 0.999
    eps: 1.0e-12
    learning_rate: 0.0004573146765703167
  lr_scheduler:
    enabled: false
  max_grad_norm: 0.5
  vf_clip_coef: 0.1
  vf_coef: 0.44
  l2_reg_loss_coef: 0
  l2_init_loss_coef: 0
  norm_adv: true
  clip_vloss: true
  target_kl: null
  zero_copy: true
  require_contiguous_env_ids: false
  verbose: true
  batch_size: 262144
  minibatch_size: 16384
  bptt_horizon: 64
  update_epochs: 1
  cpu_offload: false
  compile: false
  compile_mode: reduce-overhead
  profiler_interval_epochs: 10000
  forward_pass_minibatch_target_size: 2048
  async_factor: 2
  stats:
    overview:
      episode/reward.mean: episode_reward
    step: train/agent_step
  kickstart:
    teacher_uri: null
    action_loss_coef: 1
    value_loss_coef: 1
    kickstart_steps: 50000000
    additional_teachers: null
sim:
  num_episodes: 1
  max_time_s: 60
  name: all
  simulations:
    navigation/emptyspace_withinsight:
      env: env/mettagrid/navigation/evals/emptyspace_withinsight
    navigation/emptyspace_outofsight:
      env: env/mettagrid/navigation/evals/emptyspace_outofsight
    navigation/emptyspace_sparse:
      env: env/mettagrid/navigation/evals/emptyspace_sparse
    navigation/walls_withinsight:
      env: env/mettagrid/navigation/evals/walls_withinsight
    navigation/walls_outofsight:
      env: env/mettagrid/navigation/evals/walls_outofsight
    navigation/walls_sparse:
      env: env/mettagrid/navigation/evals/walls_sparse
    navigation/cylinder:
      env: env/mettagrid/navigation/evals/cylinder
    navigation/obstacles0:
      env: env/mettagrid/navigation/evals/obstacles0
    navigation/obstacles1:
      env: env/mettagrid/navigation/evals/obstacles1
    navigation/obstacles2:
      env: env/mettagrid/navigation/evals/obstacles2
    navigation/obstacles3:
      env: env/mettagrid/navigation/evals/obstacles3
    navigation/corridors:
      env: env/mettagrid/navigation/evals/corridors
    navigation/labyrinth:
      env: env/mettagrid/navigation/evals/labyrinth
    navigation/radialmaze:
      env: env/mettagrid/navigation/evals/radialmaze
      policy_agents_pct: 1.0
    npc/simple:
      env: env/mettagrid/simple
      policy_agents_pct: 0.5
      npc_policy_uri: wandb://run/b.daphne.npc_simple
    objectuse/altar_use_free:
      env: env/mettagrid/object_use/evals/altar_use_free
      policy_agents_pct: 1.0
    objectuse/armory_use_free:
      env: env/mettagrid/object_use/evals/armory_use_free
      policy_agents_pct: 1.0
    objectuse/armory_use:
      env: env/mettagrid/object_use/evals/armory_use
      policy_agents_pct: 1.0
    objectuse/generator_use_free:
      env: env/mettagrid/object_use/evals/generator_use_free
      policy_agents_pct: 1.0
    objectuse/generator_use:
      env: env/mettagrid/object_use/evals/generator_use
      policy_agents_pct: 1.0
    objectuse/lasery_use_free:
      env: env/mettagrid/object_use/evals/lasery_use_free
      policy_agents_pct: 1.0
    objectuse/lasery_use:
      env: env/mettagrid/object_use/evals/lasery_use
      policy_agents_pct: 1.0
    objectuse/mine_use:
      env: env/mettagrid/object_use/evals/mine_use
      policy_agents_pct: 1.0
    objectuse/shoot_out:
      env: env/mettagrid/object_use/evals/shoot_out
      policy_agents_pct: 1.0
    objectuse/swap_in:
      env: env/mettagrid/object_use/evals/swap_in
      policy_agents_pct: 1.0
    objectuse/swap_out:
      env: env/mettagrid/object_use/evals/swap_out
      policy_agents_pct: 1.0
    objectuse/temple_use_free:
      env: env/mettagrid/object_use/evals/temple_use_free
      policy_agents_pct: 1.0
    objectuse/full_sequence:
      env: env/mettagrid/object_use/evals/full_sequence
    navsequence/cylinder:
      env: env/mettagrid/navigation_sequence/evals/cylinder
    navsequence/obstacles0:
      env: env/mettagrid/navigation_sequence/evals/obstacles0
    navsequence/obstacles1:
      env: env/mettagrid/navigation_sequence/evals/obstacles1
    navsequence/obstacles2:
      env: env/mettagrid/navigation_sequence/evals/obstacles2
    navsequence/obstacles3:
      env: env/mettagrid/navigation_sequence/evals/obstacles3
    navsequence/corridors:
      env: env/mettagrid/navigation_sequence/evals/corridors
    navsequence/cylinder_easy:
      env: env/mettagrid/navigation_sequence/evals/cylinder_easy
    navsequence/honeypot:
      env: env/mettagrid/navigation_sequence/evals/honeypot
    navsequence/knotty:
      env: env/mettagrid/navigation_sequence/evals/knotty
    navsequence/memory_palace:
      env: env/mettagrid/navigation_sequence/evals/memory_palace
    navsequence/radial_large:
      env: env/mettagrid/navigation_sequence/evals/radial_large
    navsequence/radial_mini:
      env: env/mettagrid/navigation_sequence/evals/radial_mini
    navsequence/radial_small:
      env: env/mettagrid/navigation_sequence/evals/radial_small
    navsequence/swirls:
      env: env/mettagrid/navigation_sequence/evals/swirls
    navsequence/thecube:
      env: env/mettagrid/navigation_sequence/evals/thecube
    navsequence/walkaround:
      env: env/mettagrid/navigation_sequence/evals/walkaround
    memory/easy:
      env: env/mettagrid/memory/evals/easy
    memory/medium:
      env: env/mettagrid/memory/evals/medium
    memory/hard:
      env: env/mettagrid/memory/evals/hard
    memory/access_cross:
      env: env/mettagrid/memory/evals/access_cross
    memory/boxout:
      env: env/mettagrid/memory/evals/boxout
    memory/choose_wisely:
      env: env/mettagrid/memory/evals/choose_wisely
    memory/corners:
      env: env/mettagrid/memory/evals/corners
    memory/easy_sequence:
      env: env/mettagrid/memory/evals/easy_sequence
    memory/hall_of_mirrors:
      env: env/mettagrid/memory/evals/hall_of_mirrors
    memory/hard_sequence:
      env: env/mettagrid/memory/evals/hard_sequence
    memory/journey_home:
      env: env/mettagrid/memory/evals/journey_home
    memory/little_landmark_easy:
      env: env/mettagrid/memory/evals/little_landmark_easy
    memory/little_landmark_hard:
      env: env/mettagrid/memory/evals/little_landmark_hard
    memory/lobster_legs_cues:
      env: env/mettagrid/memory/evals/lobster_legs_cues
    memory/lobster_legs:
      env: env/mettagrid/memory/evals/lobster_legs
    memory/medium_sequence:
      env: env/mettagrid/memory/evals/medium_sequence
    memory/memory_swirls_hard:
      env: env/mettagrid/memory/evals/memory_swirls_hard
    memory/memory_swirls:
      env: env/mettagrid/memory/evals/memory_swirls
    memory/passing_things:
      env: env/mettagrid/memory/evals/passing_things
    memory/spacey_memory:
      env: env/mettagrid/memory/evals/spacey_memory
    memory/tease:
      env: env/mettagrid/memory/evals/tease
    memory/venture_out:
      env: env/mettagrid/memory/evals/venture_out
    memory/which_way:
      env: env/mettagrid/memory/evals/which_way
    memory/tease_small:
      env: env/mettagrid/memory/evals/tease_small
    memory/you_shall_not_pass:
      env: env/mettagrid/memory/evals/you_shall_not_pass
wandb:
  enabled: true
  project: metta
  entity: metta-research
  group: ${run}
  name: ${run}
  run_id: ${run}
  data_dir: ${run_dir}
  job_type: ${cmd}
train_job:
  map_preview_uri: s3://softmax-public/training_runs/${run}/map_preview.json.z
  evals: ${sim}
cmd: train
sweep:
  run: sweep_test
  run_dir: ./train_dir/${run}
  policy_uri: file://${run_dir}/checkpoints
  trainer:
    optimizer:
      learning_rate: ${ss:log, 1e-5, 1e-3}
      beta1: ${ss:logit, 0.8, 0.99}
      beta2: ${ss:logit, 0.9, 0.9999}
      eps: ${ss:log, 1e-8, 1e-4}
    gamma: ${ss:logit, 0.9, 0.99}
    gae_lambda: ${ss:logit, 0.9, 0.99}
    ent_coef: ${ss:log, 1e-5, 1e-2}
    vf_coef: ${ss:logit, 0.3, 0.7}
    batch_size: ${ss:pow2, 8192, 32768}
    minibatch_size: ${ss:pow2, 1024, 8192}
    update_epochs: ${ss:int, 1, 4}
    bptt_horizon: ${ss:pow2, 8, 64}
