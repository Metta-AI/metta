# Metric Descriptions
# This file contains extended descriptions for specific metrics
# Format:
#   metric_path:
#     description: Extended description of the metric
#     unit: (optional) Unit of measurement
#     interpretation: (optional) How to interpret the values

overview/reward:
  description: The mean reward achieved per episode per agent, averaged over all environments and agents over the previous epoch.
  interpretation: Higher values indicate better agent performance. Monitor for consistent improvement during training.

overview/reward_vs_total_time:
  description: Reward plotted against total training time, showing learning efficiency.
  unit: reward per second
  interpretation: Steeper curves indicate faster learning. Plateaus may suggest convergence or need for hyperparameter adjustment.

overview/sps:
  description: Steps per second - the throughput of the training system.
  unit: steps/second
  interpretation: Higher is better. Drops may indicate resource contention or environment complexity changes.

# Core training metrics
metric/agent_step:
  description: Total number of agent steps taken across all environments.
  interpretation: Primary measure of training progress. Compare with wall-clock time for efficiency.

metric/epoch:
  description: Current training epoch number.
  interpretation: One epoch represents a full cycle of experience collection and training.

metric/total_time:
  description: Total wall-clock time since training started.
  unit: seconds

metric/train_time:
  description: Time spent in the training/optimization phase, excluding environment rollouts.
  unit: seconds
  interpretation: Compare with total_time to understand training vs rollout balance.

# Loss metrics
losses/policy_loss:
  description: Actor network loss measuring action prediction quality.
  interpretation: Should decrease over time but not to zero. Sudden spikes may indicate instability.

losses/value_loss:
  description: Critic network loss measuring value prediction accuracy.
  interpretation: Lower is better, but some noise is expected. High values suggest poor value estimates.

losses/entropy:
  description: Policy entropy measuring action distribution randomness.
  interpretation: Higher entropy encourages exploration. Should gradually decrease but not reach zero.

losses/approx_kl:
  description: Approximate KL divergence between old and new policies.
  interpretation: Should stay below target threshold (typically 0.01-0.02). High values trigger early stopping.

losses/clipfrac:
  description: Fraction of samples clipped by PPO's objective function.
  interpretation: Typically 0.1-0.3. Very high values suggest too large policy updates.

# Environment timing
env_timing_per_epoch/msec/step:
  description: Average milliseconds per environment step in the epoch.
  unit: milliseconds
  interpretation: Lower is better. Spikes indicate environment bottlenecks.

env_timing_per_epoch/frac/thread_idle:
  description: Fraction of time worker threads spend idle.
  interpretation: High values (>0.9) suggest CPU underutilization. Consider more environments.

# Agent actions
env_agent/action.move.success.rate:
  description: Success rate of agent movement actions.
  interpretation: Low rates may indicate crowded environments or poor navigation policy.

env_agent/action.attack.success.rate:
  description: Success rate of attack actions when attempted.
  interpretation: Balance between too aggressive (low success) and too passive (few attempts).

env_agent/action.failure_penalty:
  description: Penalty applied when agents attempt invalid actions.
  interpretation: High values indicate agents haven't learned action preconditions.

# System monitoring
monitor/monitor/gpu_utilization_avg:
  description: Average GPU utilization across all available GPUs.
  unit: percentage
  interpretation: Low values suggest compute bottleneck elsewhere. Aim for >80% during training.

monitor/monitor/memory_percent:
  description: System RAM usage percentage.
  unit: percentage
  interpretation: High values (>90%) risk OOM errors. Consider reducing batch size or environment count.

# Common patterns for auto-generated descriptions
patterns:
  "*.avg":
    suffix: " (average value)"
  "*.std_dev":
    suffix: " (standard deviation)"
  "*.min":
    suffix: " (minimum value)"
  "*.max":
    suffix: " (maximum value)"
  "*.rate":
    suffix: " (occurrences per step)"
  "*.first_step":
    suffix: " (first step where this occurred)"
  "*.last_step":
    suffix: " (last step where this occurred)"
  "*.activity_rate":
    suffix: " (fraction of steps where this was active)"
