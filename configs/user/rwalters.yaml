# @package __global__

defaults:
  - override /agent: fast_5x5
  - override /sim: communication
  - _self_

seed: null

# multicore training
device: cpu
vectorization: multiprocessing

trainer:
  # multicore training
  num_workers: 4
  update_epochs: 1
  batch_size: 4096
  minibatch_size: 1024
  forward_pass_minibatch_target_size: 512
  async_factor: 1
  checkpoint:
    checkpoint_interval: 100
    wandb_checkpoint_interval: ${.checkpoint_interval}
  bptt_horizon: 8

  curriculum: /env/mettagrid/curriculum/communication

  simulation:
    evaluate_interval: 500

env_overrides:
  game:
    max_steps: 50

policy_uri: null
npc_policy_uri: null
eval_db_uri: null

eval:
  policy_uri: ${..policy_uri}
  npc_policy_uri: ${..npc_policy_uri}
  eval_db_uri: ${..eval_db_uri}

analyzer:
  analysis:
    metrics:
      - metric: "action.use.altar.agent"

sweep:
  metric: "action.use.altar.agent"

run_id: 2
run: ${oc.env:USER}.local.${now:MMDD}.${run_id}
trained_policy_uri: ${run_dir}/checkpoints
sweep_name: "${oc.env:USER}.local.sweep.${run_id}"

replay_job:
  sim:
    env: /env/mettagrid/communication/training/up_ising_corridor
  open_browser_on_start: false
  policy_uri: "wandb://run/${..run}"
