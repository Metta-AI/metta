defaults:
  - /common
  - /agent/fast
  - /trainer/trainer
  - /sim/arena@evals
  - _self_

run: ${oc.env:USER,test}_checkpoint_npc_test
cmd: train

data_dir: ${oc.env:DATA_DIR,./train_dir}
run_dir: ${data_dir}/${run}
policy_uri: file://${run_dir}/checkpoints

trainer:
  curriculum: /env/mettagrid/arena/basic

  env_overrides:
    npc_policy_uri: wandb://run/daveey.lp.16x4.ue2
    policy_agents_pct: 0.5

  num_workers: 2

  checkpoint:
    checkpoint_dir: ${run_dir}/checkpoints
    checkpoint_interval: 10
    wandb_checkpoint_interval: 10

  simulation:
    evaluate_interval: 50
    evaluate_remote: false

  total_timesteps: 10000000
  batch_size: 65536
  minibatch_size: 1024
  bptt_horizon: 8

  initial_policy:
    uri: ${oc.env:CHECKPOINT_URI,null}
    type: top
    range: 1
    metric: epoch

  verbose: true

evals:
  simulations:
    arena/basic:
      env: /env/mettagrid/arena/basic
    arena/combat:
      env: /env/mettagrid/arena/combat

    arena/combat_npc:
      env: /env/mettagrid/arena/combat
      npc_policy_uri: wandb://run/daveey.lp.16x4.ue2
      policy_agents_pct: 0.5

    arena/advanced_npc:
      env: /env/mettagrid/arena/advanced
      npc_policy_uri: wandb://run/daveey.lp.16x4.ue2
      policy_agents_pct: 0.5

wandb:
  enabled: true

device: ${oc.env:DEVICE,cpu}
